reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994005875-172.17.0.3-1595593800692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-afd0837a-bb9a-4988-9bdd-fb3f966ad5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-e9aaa035-8737-4f04-b71c-26bcaf9f786d,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-bbb28e9a-66c9-4193-9a61-e7c0d4a37460,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-ea58e3d0-17b1-4c1a-bdb1-e22abb964e71,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-dc2f4644-4d6f-4848-b754-e6c1d3727763,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-8fb39b8d-fd28-4b2f-b0df-84200357e543,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-31f88514-ff9b-4ffb-92e3-58f39ca6d63a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-6795de16-0e05-460c-9791-49cb8a36a909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994005875-172.17.0.3-1595593800692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-afd0837a-bb9a-4988-9bdd-fb3f966ad5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-e9aaa035-8737-4f04-b71c-26bcaf9f786d,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-bbb28e9a-66c9-4193-9a61-e7c0d4a37460,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-ea58e3d0-17b1-4c1a-bdb1-e22abb964e71,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-dc2f4644-4d6f-4848-b754-e6c1d3727763,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-8fb39b8d-fd28-4b2f-b0df-84200357e543,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-31f88514-ff9b-4ffb-92e3-58f39ca6d63a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-6795de16-0e05-460c-9791-49cb8a36a909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714578787-172.17.0.3-1595594904938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-8d9ca496-8144-4db0-80f4-d1c6843e98cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-db266f0d-577e-4cf0-90b7-7b85427f5da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-16da5074-eb55-45b6-be3d-fcaafc8291d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-61830297-0e96-4113-adf5-81b89ee91ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-1b3f04e3-7796-4cd4-b1fe-95cbd79c5cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-a6bf9683-09c2-4cb5-9152-bf3126169342,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-b8046961-8fc3-4aaf-a38d-c3d15c5145f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-17e2de85-09fd-46bb-8cd2-6a2147af2869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714578787-172.17.0.3-1595594904938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-8d9ca496-8144-4db0-80f4-d1c6843e98cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-db266f0d-577e-4cf0-90b7-7b85427f5da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-16da5074-eb55-45b6-be3d-fcaafc8291d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-61830297-0e96-4113-adf5-81b89ee91ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-1b3f04e3-7796-4cd4-b1fe-95cbd79c5cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-a6bf9683-09c2-4cb5-9152-bf3126169342,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-b8046961-8fc3-4aaf-a38d-c3d15c5145f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-17e2de85-09fd-46bb-8cd2-6a2147af2869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384350945-172.17.0.3-1595595766018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39235,DS-63be7055-6a4a-446a-a07d-1c63b9571545,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-79d10372-1577-43a2-b8ef-fc1d0594cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-83ed4098-2993-4656-9fb8-d7ba68042469,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-87b70dd0-4d63-4ab7-97d5-e83e9b2c806b,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-da9d9ab5-acf4-4688-8e24-ead20522dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-684ddf88-7256-4474-9afa-49fd9abb1790,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-72cef761-b3ca-47ef-82f7-ee467dc8b405,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-da20e5b1-881e-43cc-a328-9d5d9ab74bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384350945-172.17.0.3-1595595766018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39235,DS-63be7055-6a4a-446a-a07d-1c63b9571545,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-79d10372-1577-43a2-b8ef-fc1d0594cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-83ed4098-2993-4656-9fb8-d7ba68042469,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-87b70dd0-4d63-4ab7-97d5-e83e9b2c806b,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-da9d9ab5-acf4-4688-8e24-ead20522dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-684ddf88-7256-4474-9afa-49fd9abb1790,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-72cef761-b3ca-47ef-82f7-ee467dc8b405,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-da20e5b1-881e-43cc-a328-9d5d9ab74bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223624765-172.17.0.3-1595595861819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33152,DS-8016814d-e455-44c8-bed5-ba681f61fafe,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-18b84caf-6023-4f83-ab51-0e84efd371a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-05f5047c-0ee3-4c78-a384-20343bfac339,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-77b48454-b833-49b3-a9bb-d51e1db691a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-3f9c7ffb-4744-432c-966b-ce9aa85f3322,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-445211c8-7b8b-4687-87aa-4c1476f898a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-fec2f124-55c4-4093-8038-3225d28e570e,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-5520ec81-b844-44ff-b7a7-5e43244c8526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223624765-172.17.0.3-1595595861819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33152,DS-8016814d-e455-44c8-bed5-ba681f61fafe,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-18b84caf-6023-4f83-ab51-0e84efd371a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-05f5047c-0ee3-4c78-a384-20343bfac339,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-77b48454-b833-49b3-a9bb-d51e1db691a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-3f9c7ffb-4744-432c-966b-ce9aa85f3322,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-445211c8-7b8b-4687-87aa-4c1476f898a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-fec2f124-55c4-4093-8038-3225d28e570e,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-5520ec81-b844-44ff-b7a7-5e43244c8526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000026752-172.17.0.3-1595596131064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-b76609b7-6903-4eb0-bdc5-5f580a6ac3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-11b3b8ec-8eb7-4d1e-a623-89ea3e26f862,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-76d8bf8c-7b2e-414f-bf35-aa5a3b6de97c,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-17071487-4074-47e9-baea-79f4552a6460,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-67952132-5e68-478e-8f65-8dc2baec00da,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d2435b62-1054-419d-b353-3ec188ffb558,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-07a2d67f-8d03-4ad2-9149-bbedecb2622b,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-20f1ba1d-c71d-4dbc-a14d-1e111f636e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000026752-172.17.0.3-1595596131064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-b76609b7-6903-4eb0-bdc5-5f580a6ac3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-11b3b8ec-8eb7-4d1e-a623-89ea3e26f862,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-76d8bf8c-7b2e-414f-bf35-aa5a3b6de97c,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-17071487-4074-47e9-baea-79f4552a6460,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-67952132-5e68-478e-8f65-8dc2baec00da,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d2435b62-1054-419d-b353-3ec188ffb558,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-07a2d67f-8d03-4ad2-9149-bbedecb2622b,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-20f1ba1d-c71d-4dbc-a14d-1e111f636e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872796016-172.17.0.3-1595596365320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-abf81240-7c4a-4c53-84ff-65178bde7334,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-0e00c00e-1724-421f-9bfe-bc78a06117c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-ee82c5b9-c183-4361-a6f1-d1447ec80c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-722598df-8e0c-44b7-af42-caeffd0e904d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-882f538c-85a6-4546-8ff3-e055e8648aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-719fd5f7-9567-4f4f-aca4-97fbf6fb158a,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-d961c16c-933c-494b-9835-221100b00f29,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-f5737d4f-e075-472f-a93a-81faf9d9f3cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872796016-172.17.0.3-1595596365320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-abf81240-7c4a-4c53-84ff-65178bde7334,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-0e00c00e-1724-421f-9bfe-bc78a06117c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-ee82c5b9-c183-4361-a6f1-d1447ec80c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-722598df-8e0c-44b7-af42-caeffd0e904d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-882f538c-85a6-4546-8ff3-e055e8648aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-719fd5f7-9567-4f4f-aca4-97fbf6fb158a,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-d961c16c-933c-494b-9835-221100b00f29,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-f5737d4f-e075-472f-a93a-81faf9d9f3cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80620549-172.17.0.3-1595596437866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-cbb36967-4cc1-4227-9b81-3ed7d215689a,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-43c51766-090b-430a-bcd1-842186227ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-96a08cb6-b88e-475e-b2f0-9b85a6633a03,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-9e3764df-da69-4dbe-bc4f-74debc8f8e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-e42aebc8-1241-43c2-a947-60469d7754ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-b2fed583-c2c5-4c74-bf7b-27fc30db0d95,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-3e481801-b913-4a12-a5c2-93b1798b3b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-496a41a5-97fa-4b80-99ea-298b9574599b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80620549-172.17.0.3-1595596437866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-cbb36967-4cc1-4227-9b81-3ed7d215689a,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-43c51766-090b-430a-bcd1-842186227ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-96a08cb6-b88e-475e-b2f0-9b85a6633a03,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-9e3764df-da69-4dbe-bc4f-74debc8f8e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-e42aebc8-1241-43c2-a947-60469d7754ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-b2fed583-c2c5-4c74-bf7b-27fc30db0d95,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-3e481801-b913-4a12-a5c2-93b1798b3b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-496a41a5-97fa-4b80-99ea-298b9574599b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475443962-172.17.0.3-1595596649521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-6b5dcc6c-bb34-4a30-8707-d5e38d161021,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-3e1df1d4-54ac-4663-bb8e-19e7d94e4b63,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-75b4b292-8984-4622-b051-dc3b0286183f,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-5221a94b-b013-4973-84ab-fd16ff9bb3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-fc329f9a-59e4-4bd3-8cfc-4a648b4a2275,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8f94cf43-fa62-4332-9602-2cbfd6c72db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-533757d7-9051-467f-9d95-36db8330a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-1c0efed4-de41-4311-918e-6b3d4778056d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475443962-172.17.0.3-1595596649521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-6b5dcc6c-bb34-4a30-8707-d5e38d161021,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-3e1df1d4-54ac-4663-bb8e-19e7d94e4b63,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-75b4b292-8984-4622-b051-dc3b0286183f,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-5221a94b-b013-4973-84ab-fd16ff9bb3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-fc329f9a-59e4-4bd3-8cfc-4a648b4a2275,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8f94cf43-fa62-4332-9602-2cbfd6c72db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-533757d7-9051-467f-9d95-36db8330a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-1c0efed4-de41-4311-918e-6b3d4778056d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283413619-172.17.0.3-1595597128567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-7365faf1-a078-4672-9026-94b3d1e67371,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-635b759e-3b6a-40f4-9129-72681573bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-e992a999-87fd-4482-b144-5a78587ba2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-b001b317-1251-41c3-ad46-3571f783493c,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-bed16189-bbe2-4f73-aa7d-980659fbd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-5a19343f-c783-4b0b-96e2-626176e2b644,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-9e894b2a-9a43-4cf0-9181-da797622ae26,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-f7a15610-762e-4d65-89be-d610fe76af69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283413619-172.17.0.3-1595597128567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-7365faf1-a078-4672-9026-94b3d1e67371,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-635b759e-3b6a-40f4-9129-72681573bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-e992a999-87fd-4482-b144-5a78587ba2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-b001b317-1251-41c3-ad46-3571f783493c,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-bed16189-bbe2-4f73-aa7d-980659fbd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-5a19343f-c783-4b0b-96e2-626176e2b644,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-9e894b2a-9a43-4cf0-9181-da797622ae26,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-f7a15610-762e-4d65-89be-d610fe76af69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370816350-172.17.0.3-1595598188247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-387f176e-4948-4135-91cc-aa8ce0fc5745,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b1a891f9-ef34-4378-88ed-011defc34b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-06e8033d-3898-4430-9a29-85df72bde9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-208f89ae-453f-4ab9-95be-e0403f674621,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-ea860761-8ac5-4733-8b1a-86183e56ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-309e9bb7-1c3d-43cc-b9b8-b1be388caa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f033fb24-e028-4991-9025-47bc8e9f999d,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-046c4719-300c-4008-8aea-5addcffd5faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370816350-172.17.0.3-1595598188247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-387f176e-4948-4135-91cc-aa8ce0fc5745,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b1a891f9-ef34-4378-88ed-011defc34b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-06e8033d-3898-4430-9a29-85df72bde9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-208f89ae-453f-4ab9-95be-e0403f674621,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-ea860761-8ac5-4733-8b1a-86183e56ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-309e9bb7-1c3d-43cc-b9b8-b1be388caa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f033fb24-e028-4991-9025-47bc8e9f999d,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-046c4719-300c-4008-8aea-5addcffd5faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687351236-172.17.0.3-1595598704157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-f6d544ca-ab28-467e-b943-6164e5295df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-c0318a8c-f91b-414a-b889-084c586f2434,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-e07b8866-641f-40f8-ae7a-5ee5ba6b5d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-6b5117fa-8b31-4d2d-93f2-1bbd4a00e7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-27bbf3fb-6690-4d1f-b519-b61a43196d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-64ba4f90-7cba-49b1-9f4f-e4f7a4558cff,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-850fafc7-10b7-4d99-aa8e-6e8f8eff196f,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a487690f-399f-4dfd-8ed3-943b7a77c406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687351236-172.17.0.3-1595598704157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-f6d544ca-ab28-467e-b943-6164e5295df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-c0318a8c-f91b-414a-b889-084c586f2434,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-e07b8866-641f-40f8-ae7a-5ee5ba6b5d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-6b5117fa-8b31-4d2d-93f2-1bbd4a00e7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-27bbf3fb-6690-4d1f-b519-b61a43196d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-64ba4f90-7cba-49b1-9f4f-e4f7a4558cff,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-850fafc7-10b7-4d99-aa8e-6e8f8eff196f,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a487690f-399f-4dfd-8ed3-943b7a77c406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72973183-172.17.0.3-1595599350770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45761,DS-e395758b-e8fd-4f9b-b145-f10f56a98974,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-541337a4-ad06-49ac-9b3e-e9ca7d5a07d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-58c072fd-63b4-45f5-b93e-fb1a949c3e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-ba0c0d24-77e4-40ac-a058-74093735d558,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-9da8b2e6-bd4f-4568-b4a5-be44f7cc433f,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-cc5790ad-af5b-422c-b017-1ac65c199aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-658f4175-bc6f-4110-95b1-498ee8fab14a,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-5a565c79-589a-4fea-9042-380f7511b358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72973183-172.17.0.3-1595599350770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45761,DS-e395758b-e8fd-4f9b-b145-f10f56a98974,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-541337a4-ad06-49ac-9b3e-e9ca7d5a07d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-58c072fd-63b4-45f5-b93e-fb1a949c3e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-ba0c0d24-77e4-40ac-a058-74093735d558,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-9da8b2e6-bd4f-4568-b4a5-be44f7cc433f,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-cc5790ad-af5b-422c-b017-1ac65c199aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-658f4175-bc6f-4110-95b1-498ee8fab14a,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-5a565c79-589a-4fea-9042-380f7511b358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84843111-172.17.0.3-1595599855300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35448,DS-3ec3635a-1f62-4836-ab03-b12db7e4b289,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-4417e38d-38af-4c38-b54c-8e8c75464ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-8a410007-dee5-4f50-9ea8-ed599d5c60ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-0c4c6e57-b0ba-45cd-9ab9-3053be933e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-9d5fa72f-8367-463a-8fbc-0dd855e1f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-46da91a4-96a1-439c-b2cd-ed9d8424e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-6737a2fc-0c93-45e4-949e-51433dd9979a,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-e266e22c-07ea-455c-9c33-8795d0a7b2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84843111-172.17.0.3-1595599855300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35448,DS-3ec3635a-1f62-4836-ab03-b12db7e4b289,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-4417e38d-38af-4c38-b54c-8e8c75464ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-8a410007-dee5-4f50-9ea8-ed599d5c60ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-0c4c6e57-b0ba-45cd-9ab9-3053be933e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-9d5fa72f-8367-463a-8fbc-0dd855e1f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-46da91a4-96a1-439c-b2cd-ed9d8424e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-6737a2fc-0c93-45e4-949e-51433dd9979a,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-e266e22c-07ea-455c-9c33-8795d0a7b2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681716848-172.17.0.3-1595600315140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-eb880020-086a-494d-96e7-61560372df50,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-b2aca32a-b10c-407a-a8a1-6e074904551e,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-9681bc85-0873-4992-b319-56db0846045d,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-4a561fe7-226b-4723-9a2f-2135f6b8807f,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-aefa3ddb-4421-403a-8310-2c0d68840208,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-40de3e1b-a4ce-4424-bd27-5c762576bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-b5e0775f-f927-4be2-8b37-c690169f98fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-b5214604-a53b-4928-9340-f5732a6b4d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681716848-172.17.0.3-1595600315140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-eb880020-086a-494d-96e7-61560372df50,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-b2aca32a-b10c-407a-a8a1-6e074904551e,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-9681bc85-0873-4992-b319-56db0846045d,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-4a561fe7-226b-4723-9a2f-2135f6b8807f,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-aefa3ddb-4421-403a-8310-2c0d68840208,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-40de3e1b-a4ce-4424-bd27-5c762576bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-b5e0775f-f927-4be2-8b37-c690169f98fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-b5214604-a53b-4928-9340-f5732a6b4d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014264830-172.17.0.3-1595601072683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-01a68140-70ca-4458-acd0-74069c3c1aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-5788249e-6175-4320-b0a4-34c789e9caa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-e69042db-4f1c-4584-9ef2-87c5ffb11632,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-99665242-7028-4a7b-93ee-294d7a4ae68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-08fd1d94-5f80-4951-819f-d916c7858a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-5883f967-5ec8-4d3c-962e-b4e0f2470cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-c01e0aba-a3d8-44d2-822e-71880aa1ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7e6c785a-c90c-45ce-830a-2a20b1bffaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014264830-172.17.0.3-1595601072683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-01a68140-70ca-4458-acd0-74069c3c1aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-5788249e-6175-4320-b0a4-34c789e9caa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-e69042db-4f1c-4584-9ef2-87c5ffb11632,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-99665242-7028-4a7b-93ee-294d7a4ae68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-08fd1d94-5f80-4951-819f-d916c7858a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-5883f967-5ec8-4d3c-962e-b4e0f2470cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-c01e0aba-a3d8-44d2-822e-71880aa1ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7e6c785a-c90c-45ce-830a-2a20b1bffaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85252949-172.17.0.3-1595601630790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40599,DS-12409e15-e3d4-40dc-8178-0c6ff8f730fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-14f9e607-36b8-4ef2-9163-89ac43e104ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-62e4158f-7e3b-46fd-8448-8e9bc153bd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-3eabfb40-50db-46ef-b4c8-5ab3dd200717,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-130d21c4-e4a9-45d4-ad66-a72ac43dbbac,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-fb1df6ff-e6a2-43b8-950a-6711c624a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-6a9728be-e1be-4b6f-8ff3-08c58d02fa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-d491f7e8-cc3c-4f7f-bd1c-ae8c57a2a3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85252949-172.17.0.3-1595601630790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40599,DS-12409e15-e3d4-40dc-8178-0c6ff8f730fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-14f9e607-36b8-4ef2-9163-89ac43e104ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-62e4158f-7e3b-46fd-8448-8e9bc153bd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-3eabfb40-50db-46ef-b4c8-5ab3dd200717,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-130d21c4-e4a9-45d4-ad66-a72ac43dbbac,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-fb1df6ff-e6a2-43b8-950a-6711c624a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-6a9728be-e1be-4b6f-8ff3-08c58d02fa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-d491f7e8-cc3c-4f7f-bd1c-ae8c57a2a3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 8497
