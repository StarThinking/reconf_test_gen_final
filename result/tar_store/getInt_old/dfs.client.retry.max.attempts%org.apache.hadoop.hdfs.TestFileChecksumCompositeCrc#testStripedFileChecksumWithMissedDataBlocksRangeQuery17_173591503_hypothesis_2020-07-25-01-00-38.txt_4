reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611323227-172.17.0.19-1595639152428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32926,DS-6d27d1e0-8fad-4ba3-8b14-7dc804ff6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-d98c0b56-4366-4779-92db-39f59733165a,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-c0354815-c53e-48c4-a52a-f7437a7752ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-89043f34-a99c-4f3d-8b63-8ef75f851b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-f1e7c473-68e6-4d09-995f-dc7b4964dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-1902afc5-72ff-4788-8adb-f742be51330c,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-f86ee1ab-7809-4ba8-9bab-72d8d2ca038e,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-e913f3d2-533a-47cc-86e2-87b209915d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611323227-172.17.0.19-1595639152428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32926,DS-6d27d1e0-8fad-4ba3-8b14-7dc804ff6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-d98c0b56-4366-4779-92db-39f59733165a,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-c0354815-c53e-48c4-a52a-f7437a7752ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-89043f34-a99c-4f3d-8b63-8ef75f851b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-f1e7c473-68e6-4d09-995f-dc7b4964dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-1902afc5-72ff-4788-8adb-f742be51330c,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-f86ee1ab-7809-4ba8-9bab-72d8d2ca038e,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-e913f3d2-533a-47cc-86e2-87b209915d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841201620-172.17.0.19-1595639336236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40460,DS-2d09553c-279f-41fa-90c0-c568ebf99617,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-981a62f7-e840-4d65-822f-627e337007a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-3302a549-c08d-44f9-8420-d90878e8d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-27361913-1a6b-4883-ac6e-8f439313e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-eed21937-3c7f-4d04-bc09-28d8703f9cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-cc9a14fa-3ffd-4401-9c96-ef0114e9f7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-aa05d71d-cee2-44d8-819c-3853f5938423,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-5eadeb24-c8f0-48df-94f9-b59f13ad3d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841201620-172.17.0.19-1595639336236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40460,DS-2d09553c-279f-41fa-90c0-c568ebf99617,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-981a62f7-e840-4d65-822f-627e337007a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-3302a549-c08d-44f9-8420-d90878e8d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-27361913-1a6b-4883-ac6e-8f439313e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-eed21937-3c7f-4d04-bc09-28d8703f9cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-cc9a14fa-3ffd-4401-9c96-ef0114e9f7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-aa05d71d-cee2-44d8-819c-3853f5938423,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-5eadeb24-c8f0-48df-94f9-b59f13ad3d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287212620-172.17.0.19-1595639449978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-ea0d7467-5839-4f94-a851-e7b4443f4094,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-3afef0a3-0d3c-4a31-a587-95d9e83a240b,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-e75bfb90-dc6a-4fd8-9cd7-765133acdc44,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6b014d55-fed0-4333-b5cb-858ebbfdaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-7faeab54-1502-4852-87ab-6102655e61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-7e02f3e8-ed68-411b-95b4-9bd387e2e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-ade083da-38d9-454b-a591-4f5db1ce1d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-f5862dc4-d90f-4efd-9f46-762f74bf7070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287212620-172.17.0.19-1595639449978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-ea0d7467-5839-4f94-a851-e7b4443f4094,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-3afef0a3-0d3c-4a31-a587-95d9e83a240b,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-e75bfb90-dc6a-4fd8-9cd7-765133acdc44,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6b014d55-fed0-4333-b5cb-858ebbfdaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-7faeab54-1502-4852-87ab-6102655e61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-7e02f3e8-ed68-411b-95b4-9bd387e2e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-ade083da-38d9-454b-a591-4f5db1ce1d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-f5862dc4-d90f-4efd-9f46-762f74bf7070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156093579-172.17.0.19-1595640224883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-62406603-d444-4840-9dee-484e1644595f,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-cb170c3a-4eb0-47d9-9503-6b93bdebd8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-52dada85-309c-4a79-8211-989470246abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-bf8714a4-bd5e-44b0-981a-336fd0a610af,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-4b355699-79b2-4dd7-8a47-31401609965c,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-9ea4c528-567f-43b3-aa26-9bc32d20f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-1022e13c-1314-4e0d-b61a-d691e9afba81,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-1349e391-63d8-4b68-b898-9eef7f082595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156093579-172.17.0.19-1595640224883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-62406603-d444-4840-9dee-484e1644595f,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-cb170c3a-4eb0-47d9-9503-6b93bdebd8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-52dada85-309c-4a79-8211-989470246abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-bf8714a4-bd5e-44b0-981a-336fd0a610af,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-4b355699-79b2-4dd7-8a47-31401609965c,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-9ea4c528-567f-43b3-aa26-9bc32d20f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-1022e13c-1314-4e0d-b61a-d691e9afba81,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-1349e391-63d8-4b68-b898-9eef7f082595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36889756-172.17.0.19-1595641224423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-c6edb6cc-b721-4424-afc6-88ff49e088c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-5b500768-f232-43f5-8577-9113c021f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-22a76e90-c784-4aff-9563-ac1c18cbd1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-170e77b6-3309-4e95-9249-787c7c9d26bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-e9348877-abf4-4adc-a29e-85d39556e244,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-3e2b69f5-7e49-495c-bb88-d0374e9bc564,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-2a24bf10-8637-4f5b-acd7-a5d125f6200a,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-45a75ab1-ef4f-4d7e-857c-946a7c683467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36889756-172.17.0.19-1595641224423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-c6edb6cc-b721-4424-afc6-88ff49e088c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-5b500768-f232-43f5-8577-9113c021f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-22a76e90-c784-4aff-9563-ac1c18cbd1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-170e77b6-3309-4e95-9249-787c7c9d26bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-e9348877-abf4-4adc-a29e-85d39556e244,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-3e2b69f5-7e49-495c-bb88-d0374e9bc564,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-2a24bf10-8637-4f5b-acd7-a5d125f6200a,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-45a75ab1-ef4f-4d7e-857c-946a7c683467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755883190-172.17.0.19-1595641656592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-52d140fa-9fa9-472a-a66c-4a1623d29178,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-4c2afbf8-8468-4ada-b0fe-3f652b26a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-3eeeadab-98d4-45c7-b5a6-d6f00140c62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c899d245-fbe1-49f5-abe6-7a44871e66a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-81debc19-e8b5-4af8-966a-e382aa4cabcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-25ca4166-eb93-4d5b-8a2a-91dc2b6f177f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-ce4cfb75-add7-4b39-a074-2a4c8197007d,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-cd9fdddd-83a4-4a46-81de-0baf68deac87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755883190-172.17.0.19-1595641656592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-52d140fa-9fa9-472a-a66c-4a1623d29178,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-4c2afbf8-8468-4ada-b0fe-3f652b26a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-3eeeadab-98d4-45c7-b5a6-d6f00140c62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c899d245-fbe1-49f5-abe6-7a44871e66a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-81debc19-e8b5-4af8-966a-e382aa4cabcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-25ca4166-eb93-4d5b-8a2a-91dc2b6f177f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-ce4cfb75-add7-4b39-a074-2a4c8197007d,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-cd9fdddd-83a4-4a46-81de-0baf68deac87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034196721-172.17.0.19-1595641691187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-3decba1a-3242-46d1-b045-7fb6b92b6201,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-631b6b88-b537-4c4a-b58f-fe7f9f209413,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-5ad38909-918c-46f0-9170-8cb5a8e0669d,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-5760688f-5e38-479b-9043-e92e2bb4f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-efab4201-1fe8-47f1-8e0d-74fc9dccaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-ebb3db66-7b70-4a7b-9f39-6ece0be30c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-0fed4a09-c259-4033-a420-adc2275473f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-ac5ae13c-688d-405f-85f1-949e8f8fc501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034196721-172.17.0.19-1595641691187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-3decba1a-3242-46d1-b045-7fb6b92b6201,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-631b6b88-b537-4c4a-b58f-fe7f9f209413,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-5ad38909-918c-46f0-9170-8cb5a8e0669d,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-5760688f-5e38-479b-9043-e92e2bb4f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-efab4201-1fe8-47f1-8e0d-74fc9dccaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-ebb3db66-7b70-4a7b-9f39-6ece0be30c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-0fed4a09-c259-4033-a420-adc2275473f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-ac5ae13c-688d-405f-85f1-949e8f8fc501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584946570-172.17.0.19-1595641800651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-62b29c9f-2940-4a89-92ac-6826a6236109,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-5d5cd56c-d4fb-4d89-b955-18059e3cd1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-4f6e1d50-0fa3-4b2f-b455-3eaa2fd49347,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-7d6da6c8-21e3-4f1f-8446-ef6fb931ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-dd03a366-6434-44e9-8be2-14bc478323ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-3fdc729f-101e-4fa0-ab10-8df44304e687,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-4e5e9aa7-ee39-42bf-a33f-9e446ab2f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-2e6b8ac4-281c-4262-912a-569b4517338a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584946570-172.17.0.19-1595641800651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-62b29c9f-2940-4a89-92ac-6826a6236109,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-5d5cd56c-d4fb-4d89-b955-18059e3cd1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-4f6e1d50-0fa3-4b2f-b455-3eaa2fd49347,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-7d6da6c8-21e3-4f1f-8446-ef6fb931ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-dd03a366-6434-44e9-8be2-14bc478323ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-3fdc729f-101e-4fa0-ab10-8df44304e687,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-4e5e9aa7-ee39-42bf-a33f-9e446ab2f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-2e6b8ac4-281c-4262-912a-569b4517338a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408383058-172.17.0.19-1595642781857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-54acb662-dc60-408e-952c-4be314d156cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-4c7d3594-3912-4ab4-a3ed-887e23a7123a,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-93fbc561-5026-4b0e-88c8-e59767519627,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-b6957e66-9ebc-4b95-b585-8ffc4f2dec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-8865faeb-d101-47d9-857a-c3479853b916,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-8ea71b01-1f66-47ee-ab22-7119c5feb8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-b61dd792-aa2a-49ad-a0b7-a73f162db57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-5a970c92-5c7a-444f-9075-e3d3e62eb135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408383058-172.17.0.19-1595642781857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-54acb662-dc60-408e-952c-4be314d156cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-4c7d3594-3912-4ab4-a3ed-887e23a7123a,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-93fbc561-5026-4b0e-88c8-e59767519627,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-b6957e66-9ebc-4b95-b585-8ffc4f2dec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-8865faeb-d101-47d9-857a-c3479853b916,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-8ea71b01-1f66-47ee-ab22-7119c5feb8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-b61dd792-aa2a-49ad-a0b7-a73f162db57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-5a970c92-5c7a-444f-9075-e3d3e62eb135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626582932-172.17.0.19-1595642817494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43885,DS-e1b96848-8556-41e0-b0a8-20b58663e22f,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-6d8e1d51-dd83-49d2-b4a8-4de4d382815e,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-8d25d468-aadb-43ea-a99f-0d6425b1274b,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-1845be45-b5e8-413b-b9f1-16b3f22203f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-eaa1bd59-ab98-41a6-aad8-db2e8ffee42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-7c1ba68a-b686-471e-8202-661c863787d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-16510a8c-078d-41f8-ba0b-0d7a9ca63bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-395f8a3b-b1ca-4e64-b5ea-38e5b17edae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626582932-172.17.0.19-1595642817494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43885,DS-e1b96848-8556-41e0-b0a8-20b58663e22f,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-6d8e1d51-dd83-49d2-b4a8-4de4d382815e,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-8d25d468-aadb-43ea-a99f-0d6425b1274b,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-1845be45-b5e8-413b-b9f1-16b3f22203f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-eaa1bd59-ab98-41a6-aad8-db2e8ffee42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-7c1ba68a-b686-471e-8202-661c863787d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-16510a8c-078d-41f8-ba0b-0d7a9ca63bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-395f8a3b-b1ca-4e64-b5ea-38e5b17edae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508657479-172.17.0.19-1595643921462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-61ea7221-c39e-4ff9-b48f-d7e061970a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-e3aee5a6-e682-4092-b7dd-b19e71500b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-b348f2fb-7c0a-4fff-9abf-0253cd1404eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-0ebd3a54-4431-413a-a299-bff0b38f281e,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-dd187829-a58c-400e-a308-9d428bd62e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-5a786f1a-9415-4537-8d2e-d45925390dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-21184a4c-1ce7-4368-82a9-81ac237df9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-e198207b-97fd-42dc-b97e-8c6f20a3e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508657479-172.17.0.19-1595643921462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-61ea7221-c39e-4ff9-b48f-d7e061970a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-e3aee5a6-e682-4092-b7dd-b19e71500b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-b348f2fb-7c0a-4fff-9abf-0253cd1404eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-0ebd3a54-4431-413a-a299-bff0b38f281e,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-dd187829-a58c-400e-a308-9d428bd62e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-5a786f1a-9415-4537-8d2e-d45925390dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-21184a4c-1ce7-4368-82a9-81ac237df9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-e198207b-97fd-42dc-b97e-8c6f20a3e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967737253-172.17.0.19-1595644184586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-dc0efd1a-95c2-4a49-a446-df56aef5217a,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-c1285c28-e0ba-4b34-a0cc-70b64e0f9475,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-d4ad4309-c45d-42b6-b4c2-8cd328ead6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-0896b85c-e858-4970-8069-85fb5088807a,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-2a2ab568-a705-442c-8229-e55fd413748c,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-f6c684fe-f9cd-4468-b11c-ee070d9be891,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-e3f7a1b3-5761-4663-835c-b7a6186f4465,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-78841dc2-a244-4048-8c18-f746599ecc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967737253-172.17.0.19-1595644184586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-dc0efd1a-95c2-4a49-a446-df56aef5217a,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-c1285c28-e0ba-4b34-a0cc-70b64e0f9475,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-d4ad4309-c45d-42b6-b4c2-8cd328ead6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-0896b85c-e858-4970-8069-85fb5088807a,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-2a2ab568-a705-442c-8229-e55fd413748c,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-f6c684fe-f9cd-4468-b11c-ee070d9be891,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-e3f7a1b3-5761-4663-835c-b7a6186f4465,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-78841dc2-a244-4048-8c18-f746599ecc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5472
