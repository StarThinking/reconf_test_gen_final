reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385459841-172.17.0.8-1595558023341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-20bdaa37-7090-4446-a88e-03bf97c31df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-2756c6fc-5eee-49a8-8b77-591789685ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-c6b5f61a-6f5a-4f21-baec-b82caffd49a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-c84d165a-2d17-4859-b4f3-e9ee266289fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-40fddad2-9889-4143-bdd3-7ab953e7df83,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-cbb9a6e8-abb7-4b06-bf2d-d3521ae4e962,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-5e74c490-2a77-41bd-a8b9-c73d2a5db860,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-1323c4e3-bf38-42f9-bdcc-f1af6ab470ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385459841-172.17.0.8-1595558023341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-20bdaa37-7090-4446-a88e-03bf97c31df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-2756c6fc-5eee-49a8-8b77-591789685ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-c6b5f61a-6f5a-4f21-baec-b82caffd49a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-c84d165a-2d17-4859-b4f3-e9ee266289fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-40fddad2-9889-4143-bdd3-7ab953e7df83,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-cbb9a6e8-abb7-4b06-bf2d-d3521ae4e962,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-5e74c490-2a77-41bd-a8b9-c73d2a5db860,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-1323c4e3-bf38-42f9-bdcc-f1af6ab470ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679071413-172.17.0.8-1595558196456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46455,DS-35b17279-e6bd-4beb-9ef2-49914b7b7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-9e7918a9-2408-4e2c-ab3b-bb32dee7607a,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-f7706b28-6982-4827-bf93-ee62699b120d,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-34e5c2a1-2800-40b2-94ba-7b75db00f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-75d2fe23-2cf9-4c4b-b239-ed48d5d273d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-27de6df1-76e5-4e96-b557-7bfa8f98ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-2f463483-eea1-41f2-9065-8f9a34f0da43,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-325c55bf-50dd-4dcf-bcd5-f0ca1992145b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679071413-172.17.0.8-1595558196456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46455,DS-35b17279-e6bd-4beb-9ef2-49914b7b7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-9e7918a9-2408-4e2c-ab3b-bb32dee7607a,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-f7706b28-6982-4827-bf93-ee62699b120d,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-34e5c2a1-2800-40b2-94ba-7b75db00f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-75d2fe23-2cf9-4c4b-b239-ed48d5d273d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-27de6df1-76e5-4e96-b557-7bfa8f98ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-2f463483-eea1-41f2-9065-8f9a34f0da43,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-325c55bf-50dd-4dcf-bcd5-f0ca1992145b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838382161-172.17.0.8-1595558279329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-ccf5202a-13f5-482a-894f-35eb5c31a2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-42f99de4-c231-45f8-8142-bd8c5cee7707,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-ee9efc72-ed1f-4d3f-894b-78a6717d38c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-3d08d21b-6c3d-450e-b9f6-07715a670ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-79468ad0-51dc-4c4c-8b7f-979f50cd3e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-25607a82-73d7-4c11-be7b-f8129bf159da,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-c952221a-9faa-4569-b616-a2733f6e6e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e5961de1-098c-4c74-b4c6-299931db7649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838382161-172.17.0.8-1595558279329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-ccf5202a-13f5-482a-894f-35eb5c31a2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-42f99de4-c231-45f8-8142-bd8c5cee7707,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-ee9efc72-ed1f-4d3f-894b-78a6717d38c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-3d08d21b-6c3d-450e-b9f6-07715a670ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-79468ad0-51dc-4c4c-8b7f-979f50cd3e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-25607a82-73d7-4c11-be7b-f8129bf159da,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-c952221a-9faa-4569-b616-a2733f6e6e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e5961de1-098c-4c74-b4c6-299931db7649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167865339-172.17.0.8-1595558645687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34542,DS-0ea1c570-ccc3-4ef9-907a-b8ecdb6f3810,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-ee84d548-1da2-47c6-9e37-29b5b63bb805,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-34cbf7a8-bc39-4382-88e4-46ca3dde05d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-1fbf53dc-0b6c-4ad4-bd57-7b85fce3c977,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-f2c3a84e-8d01-4692-846f-21323ddd891f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-b7ffa8ee-8f45-453f-a1fe-232110112138,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-3d8740f5-b04a-4d66-9c91-726201fbb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-9b7da1f4-642f-4abd-89f2-a632e7ce6273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167865339-172.17.0.8-1595558645687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34542,DS-0ea1c570-ccc3-4ef9-907a-b8ecdb6f3810,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-ee84d548-1da2-47c6-9e37-29b5b63bb805,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-34cbf7a8-bc39-4382-88e4-46ca3dde05d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-1fbf53dc-0b6c-4ad4-bd57-7b85fce3c977,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-f2c3a84e-8d01-4692-846f-21323ddd891f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-b7ffa8ee-8f45-453f-a1fe-232110112138,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-3d8740f5-b04a-4d66-9c91-726201fbb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-9b7da1f4-642f-4abd-89f2-a632e7ce6273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850272088-172.17.0.8-1595558853282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-938fb50b-a704-42d4-bf2e-94707e873316,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-8610f7b6-bd29-4351-a7a1-f9acdd8f5932,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-a2cb8015-58ab-424a-a7c3-cc8aa32a27c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-064efcb6-4b77-463b-ab9c-fdc69ad19123,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-8fad2965-1c00-4d51-ba39-bd1a8f15497a,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-90801c5b-26f4-423b-b23e-5f6d26ca43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-ad8794bd-c0c6-450f-b8b7-1a7c183586df,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-06e6c42f-9b6f-4b10-9307-ea32e8eb7367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850272088-172.17.0.8-1595558853282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-938fb50b-a704-42d4-bf2e-94707e873316,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-8610f7b6-bd29-4351-a7a1-f9acdd8f5932,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-a2cb8015-58ab-424a-a7c3-cc8aa32a27c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-064efcb6-4b77-463b-ab9c-fdc69ad19123,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-8fad2965-1c00-4d51-ba39-bd1a8f15497a,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-90801c5b-26f4-423b-b23e-5f6d26ca43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-ad8794bd-c0c6-450f-b8b7-1a7c183586df,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-06e6c42f-9b6f-4b10-9307-ea32e8eb7367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268760909-172.17.0.8-1595558925155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-55ccc546-f94b-46df-aaac-754f5a24a690,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-5b502cea-998c-43da-9d55-14461cb7a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-45544cee-be8e-4bb9-a8ac-db6027736615,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-6499c1b0-cabe-4163-8654-ea5163a50d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-6b98b575-17c0-4f24-8edc-098481ccb0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-a57b3ec0-a16b-4cde-9ed6-dc9ff9a07987,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-ee2bbf38-1353-4655-85cb-b8e38896fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-5b1af11c-7c9a-4390-a74f-b7ce96d887c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268760909-172.17.0.8-1595558925155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-55ccc546-f94b-46df-aaac-754f5a24a690,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-5b502cea-998c-43da-9d55-14461cb7a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-45544cee-be8e-4bb9-a8ac-db6027736615,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-6499c1b0-cabe-4163-8654-ea5163a50d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-6b98b575-17c0-4f24-8edc-098481ccb0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-a57b3ec0-a16b-4cde-9ed6-dc9ff9a07987,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-ee2bbf38-1353-4655-85cb-b8e38896fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-5b1af11c-7c9a-4390-a74f-b7ce96d887c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404121092-172.17.0.8-1595558959914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46799,DS-444a2579-6cf1-4dc5-830c-71730c8aae66,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-b9af1263-40e2-4621-beab-c204994ffe59,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-47a4afdd-489e-4803-a3ee-725ce9d3a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-e006e6d0-e322-47e3-915f-fb6c12674a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-7837de3f-cf20-4f7c-88eb-2a37c6349f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-598c3781-7b0c-4029-b611-0b0a03e3a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-4d83dada-b3ce-4afc-9f89-856c8c6113c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-96bc571c-6bb5-4e33-9fb2-79796e499ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404121092-172.17.0.8-1595558959914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46799,DS-444a2579-6cf1-4dc5-830c-71730c8aae66,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-b9af1263-40e2-4621-beab-c204994ffe59,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-47a4afdd-489e-4803-a3ee-725ce9d3a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-e006e6d0-e322-47e3-915f-fb6c12674a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-7837de3f-cf20-4f7c-88eb-2a37c6349f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-598c3781-7b0c-4029-b611-0b0a03e3a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-4d83dada-b3ce-4afc-9f89-856c8c6113c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-96bc571c-6bb5-4e33-9fb2-79796e499ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494482523-172.17.0.8-1595559389497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38726,DS-ba5df0e6-94fd-4f4c-a290-a26fc2fed589,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-43d36191-be62-4920-8832-b0536be54844,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-feb7ef90-cb24-4965-8b92-506a5e8d90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-f0c38a3a-166c-4ab9-b9fc-2803f7f085e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-988e6de5-7583-4a99-b6f0-c9e355dc27a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-111d0eba-b69d-4083-8859-ed83c5f23ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f488bca6-2e7f-4c69-8fa7-55a50e88796e,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-0d117b3e-3702-4f0f-a42a-c382e35ae150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494482523-172.17.0.8-1595559389497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38726,DS-ba5df0e6-94fd-4f4c-a290-a26fc2fed589,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-43d36191-be62-4920-8832-b0536be54844,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-feb7ef90-cb24-4965-8b92-506a5e8d90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-f0c38a3a-166c-4ab9-b9fc-2803f7f085e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-988e6de5-7583-4a99-b6f0-c9e355dc27a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-111d0eba-b69d-4083-8859-ed83c5f23ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f488bca6-2e7f-4c69-8fa7-55a50e88796e,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-0d117b3e-3702-4f0f-a42a-c382e35ae150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367039558-172.17.0.8-1595559529907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-1dc56585-1403-4187-be4f-df76f9a3173c,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-51df3e7e-489a-4b37-b052-949433bf3402,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-51ec9214-13df-428e-848d-2b21176b0a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-f95868e0-9649-45bc-80e0-c1837e8aa5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-4e56cc2a-6160-410a-8baf-481e26c48fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-51691995-30b2-4390-ad38-b7811ce8210c,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-2ee94b25-15de-4272-8437-d440f0c78c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-e528eb30-e93e-4516-aac8-0ffba7b6e772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367039558-172.17.0.8-1595559529907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-1dc56585-1403-4187-be4f-df76f9a3173c,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-51df3e7e-489a-4b37-b052-949433bf3402,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-51ec9214-13df-428e-848d-2b21176b0a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-f95868e0-9649-45bc-80e0-c1837e8aa5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-4e56cc2a-6160-410a-8baf-481e26c48fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-51691995-30b2-4390-ad38-b7811ce8210c,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-2ee94b25-15de-4272-8437-d440f0c78c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-e528eb30-e93e-4516-aac8-0ffba7b6e772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199136984-172.17.0.8-1595559810823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-2bce79d9-0bda-4326-8613-4928a5942ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-cf9420fa-00a8-4b12-98a6-1f0362c25067,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-cbac62e4-ffa0-4d43-8a29-b0d2165575c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-d5ff9d98-c011-4fbd-a8ad-843b85a7291c,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-cc05aaa0-3a62-4829-a3cf-356671b61d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-9e07b537-7904-4e41-ab0a-3bede0e7ba50,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-69b391fb-5b91-4430-a364-94cfbcfbabbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-e1eb0f6d-19b1-49dc-89ba-992cc1109e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199136984-172.17.0.8-1595559810823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-2bce79d9-0bda-4326-8613-4928a5942ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-cf9420fa-00a8-4b12-98a6-1f0362c25067,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-cbac62e4-ffa0-4d43-8a29-b0d2165575c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-d5ff9d98-c011-4fbd-a8ad-843b85a7291c,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-cc05aaa0-3a62-4829-a3cf-356671b61d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-9e07b537-7904-4e41-ab0a-3bede0e7ba50,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-69b391fb-5b91-4430-a364-94cfbcfbabbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-e1eb0f6d-19b1-49dc-89ba-992cc1109e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436447232-172.17.0.8-1595560025480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33054,DS-d38c7202-df8d-4c8a-9d1b-ec2a11b6d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-52171812-6f0b-4850-9645-aa03976bce67,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-d97af99c-a2d5-4938-846b-c8d583fa6dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-90d9af31-761d-495e-85b3-7335aff4e085,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-c52f474f-75ba-43b3-a00f-63313a444130,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-31c5a1b1-f795-4326-854f-e0d989ac4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-25b057ff-fb4d-4319-83a3-72623316839f,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-7a7b18dc-3247-4392-91b0-d979ba8d6ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436447232-172.17.0.8-1595560025480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33054,DS-d38c7202-df8d-4c8a-9d1b-ec2a11b6d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-52171812-6f0b-4850-9645-aa03976bce67,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-d97af99c-a2d5-4938-846b-c8d583fa6dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-90d9af31-761d-495e-85b3-7335aff4e085,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-c52f474f-75ba-43b3-a00f-63313a444130,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-31c5a1b1-f795-4326-854f-e0d989ac4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-25b057ff-fb4d-4319-83a3-72623316839f,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-7a7b18dc-3247-4392-91b0-d979ba8d6ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837455283-172.17.0.8-1595560168198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38999,DS-b1b96f38-2b31-48a3-973d-845405e2af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-bc9d2279-9c4e-4b0f-9ec7-76d1d21f2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-0f541332-1552-42e0-94f6-522ce43b8fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-eea6e3c1-7c33-455d-8958-446f82a0b33d,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-0f059519-94a6-43d2-ba04-b51ae7bcb3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-878e7b91-de65-4667-9477-ee916d789a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-a0388d8e-117f-45c2-904e-b8605335fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-83d4a43a-9d72-471e-a4e7-e3fc657fe1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837455283-172.17.0.8-1595560168198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38999,DS-b1b96f38-2b31-48a3-973d-845405e2af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-bc9d2279-9c4e-4b0f-9ec7-76d1d21f2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-0f541332-1552-42e0-94f6-522ce43b8fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-eea6e3c1-7c33-455d-8958-446f82a0b33d,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-0f059519-94a6-43d2-ba04-b51ae7bcb3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-878e7b91-de65-4667-9477-ee916d789a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-a0388d8e-117f-45c2-904e-b8605335fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-83d4a43a-9d72-471e-a4e7-e3fc657fe1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601818948-172.17.0.8-1595560414953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37992,DS-4b4290ab-9d4f-4f8b-9abb-0c8c384b0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-8af43a52-e5e9-4f80-852a-682c9558f841,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-8faee786-6b0e-49e8-a18d-6eb95ae9983d,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-9f6df82e-7c11-4d87-a06c-2cabf42c939e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-e5faffea-0ac2-4f79-b42a-e670a252c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-1dd67c36-54ce-4a84-8d34-c549c9f49e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-49b756a6-384a-4c62-8b8f-ca41448b3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-7094b6f0-b1e4-41b0-ae45-632e0dedb603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601818948-172.17.0.8-1595560414953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37992,DS-4b4290ab-9d4f-4f8b-9abb-0c8c384b0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-8af43a52-e5e9-4f80-852a-682c9558f841,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-8faee786-6b0e-49e8-a18d-6eb95ae9983d,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-9f6df82e-7c11-4d87-a06c-2cabf42c939e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-e5faffea-0ac2-4f79-b42a-e670a252c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-1dd67c36-54ce-4a84-8d34-c549c9f49e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-49b756a6-384a-4c62-8b8f-ca41448b3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-7094b6f0-b1e4-41b0-ae45-632e0dedb603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131169000-172.17.0.8-1595560728352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33808,DS-b35f430d-1af8-4cfd-ab7e-7da55ec80d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-a28b1f43-ce2a-4f34-a37b-221b5933cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-e9d7c10d-861d-49a6-b67c-ebc92924d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-8794146d-1c93-438d-9a0c-7686c4349bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-75953f0b-eb88-4c12-a7e5-13defa87981a,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-1292f057-539c-49cd-9aee-4fb47c83c5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-ce13fed4-9932-4981-9fdf-e3a8a8cead6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-32ff6636-a7b1-4b0c-bfff-541296d98592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131169000-172.17.0.8-1595560728352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33808,DS-b35f430d-1af8-4cfd-ab7e-7da55ec80d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-a28b1f43-ce2a-4f34-a37b-221b5933cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-e9d7c10d-861d-49a6-b67c-ebc92924d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-8794146d-1c93-438d-9a0c-7686c4349bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-75953f0b-eb88-4c12-a7e5-13defa87981a,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-1292f057-539c-49cd-9aee-4fb47c83c5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-ce13fed4-9932-4981-9fdf-e3a8a8cead6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-32ff6636-a7b1-4b0c-bfff-541296d98592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437084246-172.17.0.8-1595561144093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-c9771166-9c0b-4e72-abc9-1705980291a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-9b1e2c14-31d0-40a7-96a4-8e723dcc3c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-65a51576-d7d1-484f-9519-4866fa1d47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-6ff1b167-ced0-4fc6-be6a-ddeb48f64b55,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-49e7ab29-3638-487d-8992-5ccc777e6fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e0243cf4-2e1b-4aac-baff-31b5c0959ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-062bcb01-d8dc-4708-8d35-eb7b79f3a6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-8dbfb917-7c66-4191-b15c-4b5a336d9eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437084246-172.17.0.8-1595561144093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-c9771166-9c0b-4e72-abc9-1705980291a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-9b1e2c14-31d0-40a7-96a4-8e723dcc3c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-65a51576-d7d1-484f-9519-4866fa1d47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-6ff1b167-ced0-4fc6-be6a-ddeb48f64b55,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-49e7ab29-3638-487d-8992-5ccc777e6fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e0243cf4-2e1b-4aac-baff-31b5c0959ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-062bcb01-d8dc-4708-8d35-eb7b79f3a6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-8dbfb917-7c66-4191-b15c-4b5a336d9eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406620590-172.17.0.8-1595561436626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32926,DS-7fa731a6-b52a-4ca8-bc52-686e11db5142,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-d1aa28ca-efcb-41ec-91da-af8edf84a061,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-fd15ef00-91e6-473d-889f-d08ca00d641e,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-ff6c2db4-4b77-4158-88af-311502b7fbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-712283cb-0878-4113-84bb-bb1db70af06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-ffa70977-fcb9-4b88-989e-b72a7b261eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-aa39d4ea-3a87-4438-a0b3-d553feafccac,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-d1cb9f6f-d0c6-425b-8dc8-e5bba4209e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406620590-172.17.0.8-1595561436626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32926,DS-7fa731a6-b52a-4ca8-bc52-686e11db5142,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-d1aa28ca-efcb-41ec-91da-af8edf84a061,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-fd15ef00-91e6-473d-889f-d08ca00d641e,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-ff6c2db4-4b77-4158-88af-311502b7fbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-712283cb-0878-4113-84bb-bb1db70af06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-ffa70977-fcb9-4b88-989e-b72a7b261eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-aa39d4ea-3a87-4438-a0b3-d553feafccac,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-d1cb9f6f-d0c6-425b-8dc8-e5bba4209e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873502365-172.17.0.8-1595561761134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40556,DS-c4bc1f52-ecfe-4bbf-8b64-78ac211b01d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-42078f17-05f5-4637-8aa9-df13985d808b,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-012dbe47-159e-445e-a6a9-32af4362fc71,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-3d75f0d9-035b-42fd-ae05-a465f3be5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-2358eb96-30ac-4c46-bd10-ba1ffcc450ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-36f48cce-e750-449e-854f-9f6806a829c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-fcad5624-df58-444c-93e8-3475a5b57ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-e4457b45-f036-439b-a30d-9166bc6ee9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873502365-172.17.0.8-1595561761134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40556,DS-c4bc1f52-ecfe-4bbf-8b64-78ac211b01d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-42078f17-05f5-4637-8aa9-df13985d808b,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-012dbe47-159e-445e-a6a9-32af4362fc71,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-3d75f0d9-035b-42fd-ae05-a465f3be5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-2358eb96-30ac-4c46-bd10-ba1ffcc450ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-36f48cce-e750-449e-854f-9f6806a829c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-fcad5624-df58-444c-93e8-3475a5b57ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-e4457b45-f036-439b-a30d-9166bc6ee9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793352535-172.17.0.8-1595562124620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39505,DS-42090401-9252-46fb-893a-bb194340da24,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-7ecc270c-330a-4486-a54d-9cb9a64fd0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-99649dc8-59b0-47f2-becc-4bd7ddde8edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a6c2cfe5-9cb1-4cc6-acea-e2f6405b5fef,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-1467f41d-9556-4cde-84bc-495a84bb4008,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-eafd238d-8c91-4bba-b563-ec2a46407a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-284ee547-3843-41fd-9453-ee725a15b738,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-cdd05f2f-63b9-4f72-96d9-03e567f86abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793352535-172.17.0.8-1595562124620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39505,DS-42090401-9252-46fb-893a-bb194340da24,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-7ecc270c-330a-4486-a54d-9cb9a64fd0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-99649dc8-59b0-47f2-becc-4bd7ddde8edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a6c2cfe5-9cb1-4cc6-acea-e2f6405b5fef,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-1467f41d-9556-4cde-84bc-495a84bb4008,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-eafd238d-8c91-4bba-b563-ec2a46407a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-284ee547-3843-41fd-9453-ee725a15b738,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-cdd05f2f-63b9-4f72-96d9-03e567f86abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548077477-172.17.0.8-1595562195854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-b9d0de58-5810-4958-8541-f45e5d4ef7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-910b80f2-ca08-4dcd-b35d-d8734f28af92,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-f1e4ddd1-2d30-4e68-9d0d-663eda724c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-dc777701-1c26-4442-8156-da3e162d6216,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-7964f1c3-6f00-419b-9c7b-befd4cb7cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-f8314a26-2d9f-4233-8ce5-b8ba69840a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-422d0c72-b3fb-4073-8bbf-f5946d1cd8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-208811c6-a878-4d27-94b4-930bb3f018f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548077477-172.17.0.8-1595562195854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-b9d0de58-5810-4958-8541-f45e5d4ef7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-910b80f2-ca08-4dcd-b35d-d8734f28af92,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-f1e4ddd1-2d30-4e68-9d0d-663eda724c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-dc777701-1c26-4442-8156-da3e162d6216,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-7964f1c3-6f00-419b-9c7b-befd4cb7cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-f8314a26-2d9f-4233-8ce5-b8ba69840a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-422d0c72-b3fb-4073-8bbf-f5946d1cd8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-208811c6-a878-4d27-94b4-930bb3f018f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140381999-172.17.0.8-1595562237616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-6ac044d1-6433-4232-a964-8fa832308fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-7c8d4773-b032-4947-8e04-d4a8a137fe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-8200deff-757a-40d5-bc2f-eaecf7a2abdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-e779b962-6713-440c-9bd7-ad653022bf98,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-aedc307b-fea8-4f43-afad-36091365349a,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-2e56bb18-ff31-40f9-9618-7c86af49b781,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-d1374460-eb5d-45c6-8379-1d0ba62c9cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-843c2af5-1340-4681-93aa-a36a0e56946e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140381999-172.17.0.8-1595562237616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-6ac044d1-6433-4232-a964-8fa832308fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-7c8d4773-b032-4947-8e04-d4a8a137fe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-8200deff-757a-40d5-bc2f-eaecf7a2abdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-e779b962-6713-440c-9bd7-ad653022bf98,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-aedc307b-fea8-4f43-afad-36091365349a,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-2e56bb18-ff31-40f9-9618-7c86af49b781,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-d1374460-eb5d-45c6-8379-1d0ba62c9cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-843c2af5-1340-4681-93aa-a36a0e56946e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654730196-172.17.0.8-1595562347814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-c38f61d0-d57d-4015-8e15-ffb36c6b10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-93954488-55f9-4d2c-9e6e-e42f536b4d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-bd55c5e1-3152-4637-a81d-f8b6eac0f682,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-dcf7dedd-8782-4c28-9892-1a0615906ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-ccf0ace3-c39f-4e96-856d-599adbddac59,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-93dbd9ea-814a-4961-9e6c-765539b7abd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-cdc6bd2b-6a71-4987-926a-b035fe8d2852,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-d5d7b62a-2a5d-4428-98e8-4a6ab4c327bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654730196-172.17.0.8-1595562347814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-c38f61d0-d57d-4015-8e15-ffb36c6b10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-93954488-55f9-4d2c-9e6e-e42f536b4d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-bd55c5e1-3152-4637-a81d-f8b6eac0f682,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-dcf7dedd-8782-4c28-9892-1a0615906ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-ccf0ace3-c39f-4e96-856d-599adbddac59,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-93dbd9ea-814a-4961-9e6c-765539b7abd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-cdc6bd2b-6a71-4987-926a-b035fe8d2852,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-d5d7b62a-2a5d-4428-98e8-4a6ab4c327bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5319
