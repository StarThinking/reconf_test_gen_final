reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322612314-172.17.0.18-1595695741980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-a4805e1f-9a43-446a-bfe2-dd90d97c9770,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-4435806e-5b2b-47e1-bdd3-5d3b43d45aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-09a2fdfa-b98a-475f-802c-abd82dd6d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-c3b22b11-fd15-4f44-8efa-d15e51e173ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-803b37a3-72d9-4d75-931a-64fef1eff607,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-4aaf6bd4-0659-4f85-a172-5b4f951fd348,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-75283d4e-a27f-48ad-ad59-549f6a7399c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-f0f8daa7-184d-4c23-bca8-00d49a1512d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322612314-172.17.0.18-1595695741980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-a4805e1f-9a43-446a-bfe2-dd90d97c9770,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-4435806e-5b2b-47e1-bdd3-5d3b43d45aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-09a2fdfa-b98a-475f-802c-abd82dd6d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-c3b22b11-fd15-4f44-8efa-d15e51e173ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-803b37a3-72d9-4d75-931a-64fef1eff607,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-4aaf6bd4-0659-4f85-a172-5b4f951fd348,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-75283d4e-a27f-48ad-ad59-549f6a7399c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-f0f8daa7-184d-4c23-bca8-00d49a1512d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457147975-172.17.0.18-1595695848880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-8e55a6bf-7c65-4bf8-938d-db8e57c7981e,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-2158b81a-9aed-4642-882e-be449705dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-6fa70902-f339-4152-8ed7-1dacead67d24,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-6e951430-29f6-43d7-95b1-299a5ab8b63b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-362430a0-ac79-47e3-afe6-a8928878b321,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-1c26add2-e9fc-446f-923b-e826d087e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-c4a22206-40ba-4108-b8ed-dafefedcf290,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-4dc580e0-8dde-4347-b09d-becd6f24f165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457147975-172.17.0.18-1595695848880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-8e55a6bf-7c65-4bf8-938d-db8e57c7981e,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-2158b81a-9aed-4642-882e-be449705dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-6fa70902-f339-4152-8ed7-1dacead67d24,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-6e951430-29f6-43d7-95b1-299a5ab8b63b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-362430a0-ac79-47e3-afe6-a8928878b321,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-1c26add2-e9fc-446f-923b-e826d087e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-c4a22206-40ba-4108-b8ed-dafefedcf290,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-4dc580e0-8dde-4347-b09d-becd6f24f165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874915134-172.17.0.18-1595696145250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-86dd0d76-6974-43c2-89b7-dc8750e56876,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-72447158-39b4-4cd4-af54-a70b7fe57b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-2be544e8-ba89-48aa-b635-7581d0412f25,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-46792ad4-387e-429e-9e31-ca300a91afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-b2df108c-bc63-4a36-bf81-540f21c59a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-a8befecc-25d5-445d-8b43-8eef1004d449,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-07c3b24e-9921-4ee5-95a9-cc71b6b1d503,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-ad3b0ed0-884c-41af-b6e0-de0e11c0f340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874915134-172.17.0.18-1595696145250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-86dd0d76-6974-43c2-89b7-dc8750e56876,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-72447158-39b4-4cd4-af54-a70b7fe57b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-2be544e8-ba89-48aa-b635-7581d0412f25,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-46792ad4-387e-429e-9e31-ca300a91afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-b2df108c-bc63-4a36-bf81-540f21c59a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-a8befecc-25d5-445d-8b43-8eef1004d449,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-07c3b24e-9921-4ee5-95a9-cc71b6b1d503,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-ad3b0ed0-884c-41af-b6e0-de0e11c0f340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171576225-172.17.0.18-1595696182632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-1bc61d02-55a2-49b3-8e55-3dc4728dab89,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-10e55eb3-c9e9-4940-bc6e-c56f8bf6e300,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-06f08435-96a9-4209-bad1-4959e2a993be,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-4f1e1bad-f189-4ac0-9a84-39329c7896f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-2754c786-6743-42d7-9ce7-2e6f719db759,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-2dc5812b-2c80-4383-9fa6-3f28ebc18cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-0744a754-3d6f-422d-89c7-c19b6da6adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-017405dd-1a0f-4330-9dbd-feffa2acdf9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171576225-172.17.0.18-1595696182632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-1bc61d02-55a2-49b3-8e55-3dc4728dab89,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-10e55eb3-c9e9-4940-bc6e-c56f8bf6e300,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-06f08435-96a9-4209-bad1-4959e2a993be,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-4f1e1bad-f189-4ac0-9a84-39329c7896f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-2754c786-6743-42d7-9ce7-2e6f719db759,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-2dc5812b-2c80-4383-9fa6-3f28ebc18cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-0744a754-3d6f-422d-89c7-c19b6da6adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-017405dd-1a0f-4330-9dbd-feffa2acdf9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063902594-172.17.0.18-1595696319376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-d6a1af57-f25e-48c5-959a-f6b431fc4fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-e39c14ac-6572-4940-83c3-7aa8051efc54,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-adbd0166-8914-49a1-a21a-116d1b3968f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-f302e10e-e8bd-4fe3-b9fa-9462cb1fb0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-70658901-b894-4efe-91cc-1d06afd079c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-7d4ac3a6-c59a-4e53-8e53-08feca4c2eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-d081106b-7198-441e-834c-a58b1f14c070,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-a29aa69b-ca6b-437b-9974-11a03523789b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063902594-172.17.0.18-1595696319376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-d6a1af57-f25e-48c5-959a-f6b431fc4fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-e39c14ac-6572-4940-83c3-7aa8051efc54,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-adbd0166-8914-49a1-a21a-116d1b3968f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-f302e10e-e8bd-4fe3-b9fa-9462cb1fb0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-70658901-b894-4efe-91cc-1d06afd079c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-7d4ac3a6-c59a-4e53-8e53-08feca4c2eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-d081106b-7198-441e-834c-a58b1f14c070,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-a29aa69b-ca6b-437b-9974-11a03523789b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895758967-172.17.0.18-1595696355850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34383,DS-856c1ea1-9aff-4f91-bd1b-49824c72db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-27c61e12-e6f3-4a09-a2ac-4b481aac1782,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-dd150ccb-d128-4f74-8545-93a5ea1bab74,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e0939d1e-5660-4bbb-ab54-0a1bc33edd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-3fb3f42c-6ea6-41ce-b2d7-a2095e873fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-ec972d38-7bd8-46a4-aa1c-809765b95390,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-0d18d26d-379c-45cf-ba21-6ab4976ba4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-37b29aeb-16a3-42f9-b767-9b4fc0030d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895758967-172.17.0.18-1595696355850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34383,DS-856c1ea1-9aff-4f91-bd1b-49824c72db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-27c61e12-e6f3-4a09-a2ac-4b481aac1782,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-dd150ccb-d128-4f74-8545-93a5ea1bab74,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e0939d1e-5660-4bbb-ab54-0a1bc33edd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-3fb3f42c-6ea6-41ce-b2d7-a2095e873fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-ec972d38-7bd8-46a4-aa1c-809765b95390,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-0d18d26d-379c-45cf-ba21-6ab4976ba4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-37b29aeb-16a3-42f9-b767-9b4fc0030d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470281382-172.17.0.18-1595696718351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38455,DS-5d023112-605e-4af9-a332-6d7c42adc8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-629e0dc7-b59c-4078-9d43-601380c23d76,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-36859c3f-5a5f-4e6b-ab97-ff5cc5439e73,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-1b635f6d-1559-44d4-82b6-7be173d3cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-9ca49acc-9099-4289-b84b-b2ad5b6771ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-35d314d4-ec0c-401b-ab00-18dedf8906be,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-b871f85f-28ee-4d8a-a692-e3e7c996e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-387321ff-9484-45da-a076-c4b85b920e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470281382-172.17.0.18-1595696718351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38455,DS-5d023112-605e-4af9-a332-6d7c42adc8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-629e0dc7-b59c-4078-9d43-601380c23d76,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-36859c3f-5a5f-4e6b-ab97-ff5cc5439e73,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-1b635f6d-1559-44d4-82b6-7be173d3cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-9ca49acc-9099-4289-b84b-b2ad5b6771ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-35d314d4-ec0c-401b-ab00-18dedf8906be,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-b871f85f-28ee-4d8a-a692-e3e7c996e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-387321ff-9484-45da-a076-c4b85b920e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284298915-172.17.0.18-1595697286196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-8f6e39b2-ae5c-4f40-a10e-e071c7ebf2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-e690a8cd-7388-4b9f-b189-e5b6fe8bdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-eb7e3f62-5f89-4396-b9e3-7da1499ffb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-e84330fb-a0d4-4c21-a567-8c120d79b723,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-3591aa8f-697e-44fa-a6a9-92d618b2faff,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-1103c9e9-326e-4ded-9e8d-d50cdfca076c,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-de6eaf18-cb6a-45bc-8583-9cf67bd05ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-19f06695-8d83-402a-826f-434c8870a7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284298915-172.17.0.18-1595697286196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-8f6e39b2-ae5c-4f40-a10e-e071c7ebf2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-e690a8cd-7388-4b9f-b189-e5b6fe8bdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-eb7e3f62-5f89-4396-b9e3-7da1499ffb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-e84330fb-a0d4-4c21-a567-8c120d79b723,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-3591aa8f-697e-44fa-a6a9-92d618b2faff,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-1103c9e9-326e-4ded-9e8d-d50cdfca076c,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-de6eaf18-cb6a-45bc-8583-9cf67bd05ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-19f06695-8d83-402a-826f-434c8870a7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454360453-172.17.0.18-1595697518906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-54d332a7-54dd-4963-a917-3a8163b138f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-62207a2b-78cb-4b80-851a-92a5846e2782,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-be8d8062-747d-4fe7-85fc-d1e159775cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-6205343c-0518-4d74-a659-ece03abb2110,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-3188c0dd-30f5-4e67-b0e6-d1f92a302cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-2a6214c3-2216-4234-bf51-5409e66f0501,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-ddb542f5-9ebd-4f5d-a7ae-4baaaff59514,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-bfb95b4c-0986-4fbd-9579-890bd60cd1fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454360453-172.17.0.18-1595697518906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-54d332a7-54dd-4963-a917-3a8163b138f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-62207a2b-78cb-4b80-851a-92a5846e2782,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-be8d8062-747d-4fe7-85fc-d1e159775cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-6205343c-0518-4d74-a659-ece03abb2110,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-3188c0dd-30f5-4e67-b0e6-d1f92a302cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-2a6214c3-2216-4234-bf51-5409e66f0501,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-ddb542f5-9ebd-4f5d-a7ae-4baaaff59514,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-bfb95b4c-0986-4fbd-9579-890bd60cd1fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51447378-172.17.0.18-1595698022609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45128,DS-45741113-4df1-49d5-95bd-f44e0d8e430d,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-1f08bd46-e679-4f6b-a161-5a5f459a0599,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-5740c38f-73bc-4705-8b7b-10a5993e723b,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-b919a963-f002-4fab-a6db-b8c2b690edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-cf7541ff-d817-42a6-9fee-553dff49adbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-a9534132-6b53-4fbc-8a61-213a26eab8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-ee1d98d8-b605-4dab-ad4a-e2798a4f85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ef1b6a06-8b81-4480-acae-f06a0b8540a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51447378-172.17.0.18-1595698022609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45128,DS-45741113-4df1-49d5-95bd-f44e0d8e430d,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-1f08bd46-e679-4f6b-a161-5a5f459a0599,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-5740c38f-73bc-4705-8b7b-10a5993e723b,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-b919a963-f002-4fab-a6db-b8c2b690edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-cf7541ff-d817-42a6-9fee-553dff49adbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-a9534132-6b53-4fbc-8a61-213a26eab8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-ee1d98d8-b605-4dab-ad4a-e2798a4f85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ef1b6a06-8b81-4480-acae-f06a0b8540a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132354373-172.17.0.18-1595698056331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41506,DS-92c415cf-f369-4f13-a194-d47e009b975f,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-a6545b8f-2d86-49f8-a57a-9b2c10f5cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-9b215ce5-e69e-4ff6-ad08-c8dbfa9f7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-17d97b65-cc55-4ddc-8f5f-c46be2525a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-58748e05-7943-425e-a752-268b3e8d1ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-f5b739d1-7cb1-4661-b2e3-3d8bd6902e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-e86067b1-02d8-415a-89e1-3b3687ef3d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-44832d13-20dc-4f8a-9f3c-ff6acd40897a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132354373-172.17.0.18-1595698056331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41506,DS-92c415cf-f369-4f13-a194-d47e009b975f,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-a6545b8f-2d86-49f8-a57a-9b2c10f5cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-9b215ce5-e69e-4ff6-ad08-c8dbfa9f7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-17d97b65-cc55-4ddc-8f5f-c46be2525a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-58748e05-7943-425e-a752-268b3e8d1ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-f5b739d1-7cb1-4661-b2e3-3d8bd6902e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-e86067b1-02d8-415a-89e1-3b3687ef3d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-44832d13-20dc-4f8a-9f3c-ff6acd40897a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867969583-172.17.0.18-1595698423162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-d3067baf-7cef-4366-89b3-ce449c6e32e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-27e607cd-23de-4fda-8f8e-075f64552492,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-911b2128-160b-4e17-a843-619d111be6be,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-887ea478-7a56-4b26-942a-2186d6a1cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-86c116f2-1188-4965-aeb3-bdf37425f273,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-c0a65ba0-678f-41e5-a688-32f829de838c,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-6953db43-0f66-4f55-be28-be8300d232df,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-efd7dfd6-0bdb-4e09-a29c-7d00890b078f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867969583-172.17.0.18-1595698423162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-d3067baf-7cef-4366-89b3-ce449c6e32e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-27e607cd-23de-4fda-8f8e-075f64552492,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-911b2128-160b-4e17-a843-619d111be6be,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-887ea478-7a56-4b26-942a-2186d6a1cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-86c116f2-1188-4965-aeb3-bdf37425f273,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-c0a65ba0-678f-41e5-a688-32f829de838c,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-6953db43-0f66-4f55-be28-be8300d232df,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-efd7dfd6-0bdb-4e09-a29c-7d00890b078f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249620328-172.17.0.18-1595698505361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-488adc17-625e-400c-a89d-9cfcef9c547b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-27c31f6f-d52d-4852-92cd-9b60afe6d4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-144e67aa-075a-4b1b-b1f6-83f0f297c928,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-7e24a213-fbd3-428d-8959-c1e57e650a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-184bd87b-7293-408f-bb30-445e33aa0897,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-1e854ce2-47ef-4b07-820f-7f2a3d4de5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-3be48b1c-86ae-4b63-9903-d1581388203d,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-ba7e23f7-d818-4161-9bf6-610c156966b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249620328-172.17.0.18-1595698505361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-488adc17-625e-400c-a89d-9cfcef9c547b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-27c31f6f-d52d-4852-92cd-9b60afe6d4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-144e67aa-075a-4b1b-b1f6-83f0f297c928,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-7e24a213-fbd3-428d-8959-c1e57e650a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-184bd87b-7293-408f-bb30-445e33aa0897,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-1e854ce2-47ef-4b07-820f-7f2a3d4de5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-3be48b1c-86ae-4b63-9903-d1581388203d,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-ba7e23f7-d818-4161-9bf6-610c156966b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132055105-172.17.0.18-1595698541999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-a582a3ab-f2fe-425b-babf-d25d1af0fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-cc3b1292-ddc0-4dc3-a71c-5c5a71396f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-ddd5803f-d271-44e2-854a-ea29a18b56b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-127998a6-d86c-40b9-b3ff-586a8cbd9240,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-ae1fe578-2970-4c41-9171-c5a864d892ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-56e7f694-9907-4500-b673-3f7468d52801,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-6fe80dfb-ce39-4c03-ae1e-23ee2e59d49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-eac89c8d-e15c-4dd9-8870-2b988e9e7cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132055105-172.17.0.18-1595698541999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-a582a3ab-f2fe-425b-babf-d25d1af0fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-cc3b1292-ddc0-4dc3-a71c-5c5a71396f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-ddd5803f-d271-44e2-854a-ea29a18b56b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-127998a6-d86c-40b9-b3ff-586a8cbd9240,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-ae1fe578-2970-4c41-9171-c5a864d892ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-56e7f694-9907-4500-b673-3f7468d52801,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-6fe80dfb-ce39-4c03-ae1e-23ee2e59d49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-eac89c8d-e15c-4dd9-8870-2b988e9e7cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652066154-172.17.0.18-1595699104742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35981,DS-cd35590f-9ebe-4291-b0cd-6e4d539a9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-79e0731a-10bb-4cc5-85da-541699ad736a,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-3466d19c-7df8-41c8-93a1-c787e7ec104a,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-df755acc-9c15-4b34-a44c-5678bfc92bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ec05f8c2-436e-4300-a212-6a5a8109a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-4153b985-3e94-4dcc-8689-86546ab47bab,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-4d8890ae-9008-47a3-8608-48f5914d7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-33a3c69c-85c9-47f8-a706-07e280540a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652066154-172.17.0.18-1595699104742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35981,DS-cd35590f-9ebe-4291-b0cd-6e4d539a9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-79e0731a-10bb-4cc5-85da-541699ad736a,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-3466d19c-7df8-41c8-93a1-c787e7ec104a,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-df755acc-9c15-4b34-a44c-5678bfc92bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ec05f8c2-436e-4300-a212-6a5a8109a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-4153b985-3e94-4dcc-8689-86546ab47bab,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-4d8890ae-9008-47a3-8608-48f5914d7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-33a3c69c-85c9-47f8-a706-07e280540a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77324032-172.17.0.18-1595699210417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38802,DS-e3c82c37-d0f6-435a-90b4-cba9f0c1a1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-4fb8f5b1-0014-4403-8634-a86ac182b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-c16ee470-2a8f-4170-9472-d79d8aafa4af,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-a6175945-4fbe-4108-bff6-7f4d6e625887,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-d04d761b-b439-42be-afca-7f6ab2ccbfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-9babd4a9-cda9-43a9-b18f-06a434f5ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-8ab9a811-5c44-4a92-9e61-fcfeee61f300,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-ba3c0f11-42ad-4232-9041-936f914677a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77324032-172.17.0.18-1595699210417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38802,DS-e3c82c37-d0f6-435a-90b4-cba9f0c1a1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-4fb8f5b1-0014-4403-8634-a86ac182b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-c16ee470-2a8f-4170-9472-d79d8aafa4af,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-a6175945-4fbe-4108-bff6-7f4d6e625887,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-d04d761b-b439-42be-afca-7f6ab2ccbfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-9babd4a9-cda9-43a9-b18f-06a434f5ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-8ab9a811-5c44-4a92-9e61-fcfeee61f300,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-ba3c0f11-42ad-4232-9041-936f914677a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239380947-172.17.0.18-1595699391330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-7ef76d26-ec07-42f8-8fd6-33c9c73e4222,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-85c41af8-0927-4567-90d1-031ce8fa088c,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-a35761c3-4287-401d-9968-d27745e3f73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-7b386e5d-f26a-40cb-866a-a59e5055fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-8c1ee3e9-fbbc-4f9d-9d5a-3b292a7ce29e,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c777f396-3aab-4424-a64c-b831e41b5eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-9b1dd9a1-352c-4631-81a2-6fa358eec2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-42dd6215-e0a7-4664-aaa9-1debdc5d8db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239380947-172.17.0.18-1595699391330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-7ef76d26-ec07-42f8-8fd6-33c9c73e4222,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-85c41af8-0927-4567-90d1-031ce8fa088c,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-a35761c3-4287-401d-9968-d27745e3f73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-7b386e5d-f26a-40cb-866a-a59e5055fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-8c1ee3e9-fbbc-4f9d-9d5a-3b292a7ce29e,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c777f396-3aab-4424-a64c-b831e41b5eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-9b1dd9a1-352c-4631-81a2-6fa358eec2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-42dd6215-e0a7-4664-aaa9-1debdc5d8db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736060963-172.17.0.18-1595699638716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43866,DS-20ca9d97-a5ec-447e-892e-7bf99d73bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-bd938f4c-267a-4cb7-9408-d242d1261a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-70a1257e-5777-4fe7-8bd3-fb979a4376f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-ed08ebe4-5318-4be4-a186-6d0ade0a8f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-10cfa0d4-bff1-4220-9592-d43c9af826a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-89bcf905-dad3-4268-9ac2-49c7ed708c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-42401ec1-dabb-434f-8695-16faa188244b,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-42c8e158-b22d-44db-b98b-4a60c0413525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736060963-172.17.0.18-1595699638716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43866,DS-20ca9d97-a5ec-447e-892e-7bf99d73bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-bd938f4c-267a-4cb7-9408-d242d1261a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-70a1257e-5777-4fe7-8bd3-fb979a4376f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-ed08ebe4-5318-4be4-a186-6d0ade0a8f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-10cfa0d4-bff1-4220-9592-d43c9af826a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-89bcf905-dad3-4268-9ac2-49c7ed708c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-42401ec1-dabb-434f-8695-16faa188244b,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-42c8e158-b22d-44db-b98b-4a60c0413525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615038622-172.17.0.18-1595699788494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-0ab8d87b-ff42-430d-acff-0ccd68dced80,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-7211f760-bb98-48d9-a90c-0a18038d42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ae7bb819-88b0-4f50-adaa-30c95f2f99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-e6e77df4-f55a-4bbc-a79c-206ffbfa7b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-e1dbd510-5d2e-4eab-8177-2ad37af2215d,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-ed4743fb-78d3-4150-9c96-bc318f5c6889,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-3e9b7d2d-f5ce-4f29-9883-a16058eba14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-4d7e350b-6455-4b85-93e6-08cd1124405d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615038622-172.17.0.18-1595699788494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-0ab8d87b-ff42-430d-acff-0ccd68dced80,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-7211f760-bb98-48d9-a90c-0a18038d42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ae7bb819-88b0-4f50-adaa-30c95f2f99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-e6e77df4-f55a-4bbc-a79c-206ffbfa7b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-e1dbd510-5d2e-4eab-8177-2ad37af2215d,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-ed4743fb-78d3-4150-9c96-bc318f5c6889,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-3e9b7d2d-f5ce-4f29-9883-a16058eba14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-4d7e350b-6455-4b85-93e6-08cd1124405d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858280530-172.17.0.18-1595699886898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-31686a2d-8d89-4103-9236-3921f27ec546,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-60f9abec-10d3-4734-9e69-421907c0881c,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-772a201a-9c7f-45e0-a884-04a99a95a080,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cfde8f27-5350-4f89-b2f2-dd7fe6093d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-c35a967e-6006-4d29-a20b-0b2cd4ba609b,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-7cc78a89-58d3-40ac-ac0d-896931d5bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-c04a0127-8305-4763-93af-83c7c46622b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-199d9a77-2698-4486-89b1-d1e1e8b9b8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858280530-172.17.0.18-1595699886898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-31686a2d-8d89-4103-9236-3921f27ec546,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-60f9abec-10d3-4734-9e69-421907c0881c,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-772a201a-9c7f-45e0-a884-04a99a95a080,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cfde8f27-5350-4f89-b2f2-dd7fe6093d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-c35a967e-6006-4d29-a20b-0b2cd4ba609b,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-7cc78a89-58d3-40ac-ac0d-896931d5bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-c04a0127-8305-4763-93af-83c7c46622b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-199d9a77-2698-4486-89b1-d1e1e8b9b8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46727004-172.17.0.18-1595699924751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33693,DS-2d80229c-89be-4e43-8b39-dee21499600c,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-1e0eccb8-b507-439f-8582-9322c43a082d,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-6fc3c669-22be-48f5-8905-963144ed15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-34f27228-9da2-407f-995b-dae50bc2ed82,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-389fe616-3590-4789-a18b-52f46a46caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-7e627f4a-d630-4a7b-8c5d-335e2a265208,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-47175ca7-137f-46b2-bdcb-68e432c8511f,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-e4bbb7be-2221-496c-9c9e-31f4597bf847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46727004-172.17.0.18-1595699924751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33693,DS-2d80229c-89be-4e43-8b39-dee21499600c,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-1e0eccb8-b507-439f-8582-9322c43a082d,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-6fc3c669-22be-48f5-8905-963144ed15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-34f27228-9da2-407f-995b-dae50bc2ed82,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-389fe616-3590-4789-a18b-52f46a46caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-7e627f4a-d630-4a7b-8c5d-335e2a265208,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-47175ca7-137f-46b2-bdcb-68e432c8511f,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-e4bbb7be-2221-496c-9c9e-31f4597bf847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974447413-172.17.0.18-1595700685819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-7cdf34d3-6346-4c56-a899-8f01f00d57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-581637df-a24f-481b-bf50-775436f4e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-99d8a602-1d20-4ff5-9352-98d3a4fbf988,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-1bd9050d-591d-42dd-9e2c-077be7972d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-c6c66ab3-e40d-467a-ab81-5c6cf29cbad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7ba7dad8-76c6-4b16-b6e8-099e7d24134d,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-c4866304-8011-4e2b-a304-12dedc077ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-12d8c6b0-da9d-4133-953e-92c32ab3827a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974447413-172.17.0.18-1595700685819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-7cdf34d3-6346-4c56-a899-8f01f00d57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-581637df-a24f-481b-bf50-775436f4e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-99d8a602-1d20-4ff5-9352-98d3a4fbf988,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-1bd9050d-591d-42dd-9e2c-077be7972d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-c6c66ab3-e40d-467a-ab81-5c6cf29cbad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7ba7dad8-76c6-4b16-b6e8-099e7d24134d,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-c4866304-8011-4e2b-a304-12dedc077ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-12d8c6b0-da9d-4133-953e-92c32ab3827a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706044008-172.17.0.18-1595700973934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-fee4bd92-6caa-49c8-9ccc-cf4092b6455d,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-b050e7d5-4f4e-40eb-b5bf-cf78d6aaa0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-d0c5c017-6459-4aad-a3e9-b2c6684eb79b,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-76744fd4-1aa9-46b7-9f9c-3a10bab241e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-31a77477-648b-4ede-945a-adb21788db7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-cab87bd7-33bf-42ac-82f1-1678d84715df,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-bed1952e-337a-4033-bf62-c2c06c490462,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-75557950-3ad9-420c-88d5-fb7ab763cbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706044008-172.17.0.18-1595700973934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-fee4bd92-6caa-49c8-9ccc-cf4092b6455d,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-b050e7d5-4f4e-40eb-b5bf-cf78d6aaa0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-d0c5c017-6459-4aad-a3e9-b2c6684eb79b,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-76744fd4-1aa9-46b7-9f9c-3a10bab241e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-31a77477-648b-4ede-945a-adb21788db7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-cab87bd7-33bf-42ac-82f1-1678d84715df,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-bed1952e-337a-4033-bf62-c2c06c490462,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-75557950-3ad9-420c-88d5-fb7ab763cbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072630372-172.17.0.18-1595701014713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-1ef48fee-ad98-467c-9484-a8246e6c7720,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-50cc87b2-582c-4127-a7b4-7896a65b182e,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-9c812663-d874-404d-9441-3e100f28b3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-2442a9b6-6236-4f73-aec6-c0a508aac72a,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-29448874-5966-48ea-98f9-d28203e5a541,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-109e1879-5eed-422d-a3a1-6e80d617fe02,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-fd805f5c-a6b1-4715-b72c-e1c7043f2d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-26eb5a0e-1fd7-4985-9cb8-f58ad86b799a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072630372-172.17.0.18-1595701014713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-1ef48fee-ad98-467c-9484-a8246e6c7720,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-50cc87b2-582c-4127-a7b4-7896a65b182e,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-9c812663-d874-404d-9441-3e100f28b3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-2442a9b6-6236-4f73-aec6-c0a508aac72a,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-29448874-5966-48ea-98f9-d28203e5a541,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-109e1879-5eed-422d-a3a1-6e80d617fe02,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-fd805f5c-a6b1-4715-b72c-e1c7043f2d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-26eb5a0e-1fd7-4985-9cb8-f58ad86b799a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5528
