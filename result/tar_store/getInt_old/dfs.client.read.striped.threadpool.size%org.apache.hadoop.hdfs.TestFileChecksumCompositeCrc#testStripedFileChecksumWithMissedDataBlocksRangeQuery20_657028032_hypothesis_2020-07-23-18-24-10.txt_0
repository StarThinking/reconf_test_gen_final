reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397998036-172.17.0.21-1595529244419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-d24c964d-a867-4109-af21-e487534a4924,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-d7466ff1-cf3c-4339-bfbb-d3e2225ace9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-3289e38a-b997-4c69-b01b-b39a719f6149,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-da23e246-2e56-4fb6-8745-d03c98e2f778,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-edff2301-ec3b-469c-9f08-01db74460efe,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-bfc1830e-01a3-442a-aa7f-275ae1729e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-9204b025-3bba-4859-966c-97b2be7e6f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-c146dbf8-17a9-4436-b7ff-641fd01f418d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397998036-172.17.0.21-1595529244419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-d24c964d-a867-4109-af21-e487534a4924,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-d7466ff1-cf3c-4339-bfbb-d3e2225ace9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-3289e38a-b997-4c69-b01b-b39a719f6149,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-da23e246-2e56-4fb6-8745-d03c98e2f778,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-edff2301-ec3b-469c-9f08-01db74460efe,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-bfc1830e-01a3-442a-aa7f-275ae1729e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-9204b025-3bba-4859-966c-97b2be7e6f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-c146dbf8-17a9-4436-b7ff-641fd01f418d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152618277-172.17.0.21-1595529408575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-d7ef7879-cae4-45bd-a965-88e0b1b13c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-01143d3b-e71b-4e14-9a58-3f8c70ab8f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-7958a4fc-b230-429b-b41f-9b06e869885e,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-3789de48-826f-49bf-bf3a-f3a43ceec115,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-91288a6f-295e-4f27-8fa8-7e19f2f3346c,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-7df51587-620e-4078-9769-bf0127040e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-db385e2c-b96f-4c16-8330-29d79b562e23,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-4e73dc3d-4d9f-4b38-973f-38d77f0732c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152618277-172.17.0.21-1595529408575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-d7ef7879-cae4-45bd-a965-88e0b1b13c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-01143d3b-e71b-4e14-9a58-3f8c70ab8f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-7958a4fc-b230-429b-b41f-9b06e869885e,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-3789de48-826f-49bf-bf3a-f3a43ceec115,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-91288a6f-295e-4f27-8fa8-7e19f2f3346c,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-7df51587-620e-4078-9769-bf0127040e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-db385e2c-b96f-4c16-8330-29d79b562e23,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-4e73dc3d-4d9f-4b38-973f-38d77f0732c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725473814-172.17.0.21-1595529526994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-81e108ee-280e-43c2-b241-5e0f288c5c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-8ff4f91e-c8d5-41f7-9be0-b3474165e9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-6944cae9-ce75-4ae1-addc-7b99ef10f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-eee78a46-a92f-4c96-a891-b2dc8260cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-7acb0ff9-e3b4-416a-a9d9-5e312566aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-3641a983-07fe-4221-947c-72163a0eadea,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-337c7954-a9eb-4f88-8c0c-4ce6f8cf4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-86e7ede2-fe9c-4ec1-92c0-61900bd64ae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725473814-172.17.0.21-1595529526994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-81e108ee-280e-43c2-b241-5e0f288c5c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-8ff4f91e-c8d5-41f7-9be0-b3474165e9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-6944cae9-ce75-4ae1-addc-7b99ef10f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-eee78a46-a92f-4c96-a891-b2dc8260cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-7acb0ff9-e3b4-416a-a9d9-5e312566aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-3641a983-07fe-4221-947c-72163a0eadea,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-337c7954-a9eb-4f88-8c0c-4ce6f8cf4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-86e7ede2-fe9c-4ec1-92c0-61900bd64ae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309076617-172.17.0.21-1595529656592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-1e98fa0c-158d-4e19-bc6c-077420c8e532,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-2678147b-c2e2-4efc-87fc-cf148e7c12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-545218bf-9a23-4f8f-b18d-8c7b667553b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-5d513255-e268-48b2-a642-c3afb61cc35e,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-9f00e054-cb42-4afc-8305-1d66211a3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-48b49586-0e35-4328-9add-16e82be6394a,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-c9a72573-a449-44e0-b1a4-54a0738c726c,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-8cc40dbd-52de-4a3a-9b3a-75b09cb67fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309076617-172.17.0.21-1595529656592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-1e98fa0c-158d-4e19-bc6c-077420c8e532,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-2678147b-c2e2-4efc-87fc-cf148e7c12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-545218bf-9a23-4f8f-b18d-8c7b667553b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-5d513255-e268-48b2-a642-c3afb61cc35e,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-9f00e054-cb42-4afc-8305-1d66211a3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-48b49586-0e35-4328-9add-16e82be6394a,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-c9a72573-a449-44e0-b1a4-54a0738c726c,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-8cc40dbd-52de-4a3a-9b3a-75b09cb67fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740717710-172.17.0.21-1595529809652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-a3a9c1b8-730d-4abd-960a-70a603d39347,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-e0aa2b5d-5c70-42bb-80fc-d8ab5297799e,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-b8b2bced-7e6a-439d-ac9b-7959fc8cb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-c3f4a5bd-e8b9-449e-a431-fc4087f404f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e0adbebf-2ef8-4e80-bb5b-9c4b1a0ed518,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-6524172b-7291-46d4-beb1-e3f790999b25,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-9f2b3f68-cd5b-4905-8793-ff09021b10f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-870f9cc5-767b-48b1-9547-6393fe54faf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740717710-172.17.0.21-1595529809652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-a3a9c1b8-730d-4abd-960a-70a603d39347,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-e0aa2b5d-5c70-42bb-80fc-d8ab5297799e,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-b8b2bced-7e6a-439d-ac9b-7959fc8cb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-c3f4a5bd-e8b9-449e-a431-fc4087f404f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e0adbebf-2ef8-4e80-bb5b-9c4b1a0ed518,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-6524172b-7291-46d4-beb1-e3f790999b25,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-9f2b3f68-cd5b-4905-8793-ff09021b10f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-870f9cc5-767b-48b1-9547-6393fe54faf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172109630-172.17.0.21-1595529901880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38378,DS-41a96072-2b62-41b9-b0c4-3d05973610dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-53c783dd-7823-4538-89cb-0c01f8697863,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-62413165-7f59-498a-a5a9-64c5c0154440,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-37e1f42c-2276-462f-9f54-bebc6587e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-5bb7cca4-bb57-4376-a2ad-362bd722a1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-ab791a47-534f-4b8b-a4e8-70670131f0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-6e6e0035-84aa-4186-bb8f-d67014815c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-0b232aa8-64b0-4866-a850-977956706f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172109630-172.17.0.21-1595529901880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38378,DS-41a96072-2b62-41b9-b0c4-3d05973610dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-53c783dd-7823-4538-89cb-0c01f8697863,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-62413165-7f59-498a-a5a9-64c5c0154440,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-37e1f42c-2276-462f-9f54-bebc6587e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-5bb7cca4-bb57-4376-a2ad-362bd722a1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-ab791a47-534f-4b8b-a4e8-70670131f0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-6e6e0035-84aa-4186-bb8f-d67014815c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-0b232aa8-64b0-4866-a850-977956706f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193907503-172.17.0.21-1595529929348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37461,DS-96562043-1f92-40c5-9307-402606409cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-51a69357-70de-4da3-90e4-13e0b3569975,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-42966075-b1aa-4002-8d0d-eb118c865226,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-16bb2112-77b1-4836-ab15-9a399fe521f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-1ba80002-5723-4b45-83bf-36401597344a,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-316cda89-9111-4706-b22f-335e2769f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-65ab899f-9cfd-44ea-934a-dba934d38d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-8db6a649-11f2-4be3-aedd-23a48300103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193907503-172.17.0.21-1595529929348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37461,DS-96562043-1f92-40c5-9307-402606409cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-51a69357-70de-4da3-90e4-13e0b3569975,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-42966075-b1aa-4002-8d0d-eb118c865226,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-16bb2112-77b1-4836-ab15-9a399fe521f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-1ba80002-5723-4b45-83bf-36401597344a,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-316cda89-9111-4706-b22f-335e2769f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-65ab899f-9cfd-44ea-934a-dba934d38d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-8db6a649-11f2-4be3-aedd-23a48300103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619711614-172.17.0.21-1595530879725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-ba49d74e-ab7c-4581-ab6a-06e315bb657a,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-e72f12b2-641a-446c-aa2c-c29c076e8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-97156d3f-fae1-4f21-861c-26d2dacdd648,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-153d1c7d-1ae2-4906-9034-090162f21798,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-b11d27ad-8de1-4519-b6b0-5150612b2ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-e78db8f4-0374-49cc-b515-58fadb0a4118,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2a150342-74a1-4f9e-8f72-2a6bb73eb645,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-4a8fb82e-b37f-4f78-9aea-43359da3da34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619711614-172.17.0.21-1595530879725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-ba49d74e-ab7c-4581-ab6a-06e315bb657a,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-e72f12b2-641a-446c-aa2c-c29c076e8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-97156d3f-fae1-4f21-861c-26d2dacdd648,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-153d1c7d-1ae2-4906-9034-090162f21798,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-b11d27ad-8de1-4519-b6b0-5150612b2ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-e78db8f4-0374-49cc-b515-58fadb0a4118,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2a150342-74a1-4f9e-8f72-2a6bb73eb645,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-4a8fb82e-b37f-4f78-9aea-43359da3da34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111137826-172.17.0.21-1595531065800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-28f74c3a-b155-4b08-ab34-8068635c07fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-7ad7de78-2219-4cf4-9ccb-adc1fb641c40,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-0e932f7e-b8da-44b2-b7fe-14175c57a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-108ecfa8-9bd7-4080-a98c-5b3705a5c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-96946f0f-a681-4cc8-9594-b46fe8e9e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-af56eddc-47b6-4f33-98a4-526e1f940011,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-19add260-a3be-483f-8f98-22b8bacbf6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-35c1799f-2519-42e7-a10b-ff211e83dc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111137826-172.17.0.21-1595531065800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-28f74c3a-b155-4b08-ab34-8068635c07fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-7ad7de78-2219-4cf4-9ccb-adc1fb641c40,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-0e932f7e-b8da-44b2-b7fe-14175c57a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-108ecfa8-9bd7-4080-a98c-5b3705a5c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-96946f0f-a681-4cc8-9594-b46fe8e9e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-af56eddc-47b6-4f33-98a4-526e1f940011,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-19add260-a3be-483f-8f98-22b8bacbf6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-35c1799f-2519-42e7-a10b-ff211e83dc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795610914-172.17.0.21-1595531972541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-fe3b9406-74a4-4531-bccf-f5f099c781a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-3a4017d5-8b3a-4331-b313-6daf028a8d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-123ac83f-ea14-4c6f-9670-a9e10a2a6ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-da122f8b-68f5-46cc-a959-ddd706c71bac,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-4eb3fd5a-1738-4a04-9400-47200172704e,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-f078a37a-b0d7-4cfb-ba76-c5cad4ad6433,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f32dafa0-7c02-4059-b040-553b298e5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-a4aa5bd2-00ee-4fd6-99e8-ceb1cc475d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795610914-172.17.0.21-1595531972541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-fe3b9406-74a4-4531-bccf-f5f099c781a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-3a4017d5-8b3a-4331-b313-6daf028a8d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-123ac83f-ea14-4c6f-9670-a9e10a2a6ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-da122f8b-68f5-46cc-a959-ddd706c71bac,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-4eb3fd5a-1738-4a04-9400-47200172704e,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-f078a37a-b0d7-4cfb-ba76-c5cad4ad6433,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f32dafa0-7c02-4059-b040-553b298e5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-a4aa5bd2-00ee-4fd6-99e8-ceb1cc475d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356130889-172.17.0.21-1595532313935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-df1b539e-99d9-42fd-a002-5300a39057ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-dc85e980-cb7c-4066-b9ba-0fe68d112b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-59e2013b-7319-4a5d-8ec8-e21408daa5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-dd62b502-9485-4f3e-a2e3-2c0e5263a8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-6631ac68-9fbf-49fc-93fa-86b9d53e11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-22138b51-a5e0-4f97-9de1-7d8a6f4b0640,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-d2916788-686e-4d9f-a066-0b17280331f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-233dde50-05bf-4044-bd86-d31e96d8925d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356130889-172.17.0.21-1595532313935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-df1b539e-99d9-42fd-a002-5300a39057ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-dc85e980-cb7c-4066-b9ba-0fe68d112b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-59e2013b-7319-4a5d-8ec8-e21408daa5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-dd62b502-9485-4f3e-a2e3-2c0e5263a8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-6631ac68-9fbf-49fc-93fa-86b9d53e11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-22138b51-a5e0-4f97-9de1-7d8a6f4b0640,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-d2916788-686e-4d9f-a066-0b17280331f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-233dde50-05bf-4044-bd86-d31e96d8925d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826031171-172.17.0.21-1595532635844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-e343ec10-debf-44ae-a77d-0f90761f2139,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-c70b6d21-33a1-4966-8317-30f0c88b8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-708d2039-7551-4fca-9934-d7b174eddd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-d32a244c-42a9-4d55-bee2-e5b18d41e272,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-eda9addc-033f-40da-967d-400ab3f78431,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-5ed61621-e83c-49b0-bb10-99fff813f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ceafca41-7b14-4e79-baeb-b31525520170,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-d6082ab7-60ae-4fde-9612-8a0ba13b5a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826031171-172.17.0.21-1595532635844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-e343ec10-debf-44ae-a77d-0f90761f2139,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-c70b6d21-33a1-4966-8317-30f0c88b8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-708d2039-7551-4fca-9934-d7b174eddd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-d32a244c-42a9-4d55-bee2-e5b18d41e272,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-eda9addc-033f-40da-967d-400ab3f78431,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-5ed61621-e83c-49b0-bb10-99fff813f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ceafca41-7b14-4e79-baeb-b31525520170,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-d6082ab7-60ae-4fde-9612-8a0ba13b5a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704816171-172.17.0.21-1595532671709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-4c7ea80e-ada1-45ba-beb9-1b71f5a49cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-b4dbc979-bd6a-43ba-aaa1-aea1fadb7ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-fe841211-5d1b-45b2-a0fa-0c76f7577157,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-3980e666-b0b4-4b6c-bd9e-bd6a7310a951,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-26d06f47-7997-4a35-8a42-cdc774dd778a,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-7f627dea-2c85-4991-93e3-c093c5e9bade,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-2df359e8-dfcb-4d91-8d5e-3da9491447da,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-982b847d-9b0f-4dcc-99fd-a00a3ab97c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704816171-172.17.0.21-1595532671709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-4c7ea80e-ada1-45ba-beb9-1b71f5a49cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-b4dbc979-bd6a-43ba-aaa1-aea1fadb7ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-fe841211-5d1b-45b2-a0fa-0c76f7577157,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-3980e666-b0b4-4b6c-bd9e-bd6a7310a951,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-26d06f47-7997-4a35-8a42-cdc774dd778a,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-7f627dea-2c85-4991-93e3-c093c5e9bade,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-2df359e8-dfcb-4d91-8d5e-3da9491447da,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-982b847d-9b0f-4dcc-99fd-a00a3ab97c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090527519-172.17.0.21-1595532922202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40737,DS-c5c5d62b-4c80-4d04-842f-bb6c1c134ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-8e00aa6c-2f48-49e0-be97-f328ddc22977,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-f871b648-7a61-487c-9515-eddd0d6689be,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-aacf3632-7829-47a2-acfe-3e9037c06f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-9302930f-3f94-4d6f-8ea8-b51b0cc06da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-fa03a6c6-4cb2-4637-b0c1-8717682952e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a8a01c45-31c2-41cb-88f9-fed6a9b2b7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-6c347986-b4d1-479d-8ed3-f0f364a6f6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090527519-172.17.0.21-1595532922202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40737,DS-c5c5d62b-4c80-4d04-842f-bb6c1c134ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-8e00aa6c-2f48-49e0-be97-f328ddc22977,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-f871b648-7a61-487c-9515-eddd0d6689be,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-aacf3632-7829-47a2-acfe-3e9037c06f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-9302930f-3f94-4d6f-8ea8-b51b0cc06da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-fa03a6c6-4cb2-4637-b0c1-8717682952e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a8a01c45-31c2-41cb-88f9-fed6a9b2b7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-6c347986-b4d1-479d-8ed3-f0f364a6f6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619314569-172.17.0.21-1595532965760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44042,DS-882b46e5-ef34-4d37-a91b-05a89e54806d,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-e68b5e34-d098-4692-9daa-fbec1d748f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-39b2d282-283e-4ec3-a8bb-4c5c0f1f5dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-6d117715-08ac-429b-bd34-2ec500649321,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-b51b2cb4-ed44-42a8-af21-16872034e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-9a6f5885-9663-4461-9c19-386ab0652de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-b03a5bb1-dcff-4ca2-a498-267c5f458c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-53e4f9e9-b258-47a9-96d1-38a477159513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619314569-172.17.0.21-1595532965760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44042,DS-882b46e5-ef34-4d37-a91b-05a89e54806d,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-e68b5e34-d098-4692-9daa-fbec1d748f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-39b2d282-283e-4ec3-a8bb-4c5c0f1f5dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-6d117715-08ac-429b-bd34-2ec500649321,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-b51b2cb4-ed44-42a8-af21-16872034e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-9a6f5885-9663-4461-9c19-386ab0652de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-b03a5bb1-dcff-4ca2-a498-267c5f458c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-53e4f9e9-b258-47a9-96d1-38a477159513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724618452-172.17.0.21-1595533327875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41064,DS-eb87dac0-e289-420e-be74-c88b8120180b,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-b3e3d8d2-9e6c-4e8c-8d01-940a22c46647,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-3f8efab9-5738-4ace-8bb6-796297c96869,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-2d17c7c3-fe82-4c8c-80b4-2c77444309e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-505dc7e1-f9c6-4504-94fb-de52e917c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-4a8cd5c8-f0d1-427b-b23d-06d11737c203,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-78633992-13f4-4976-a1f5-ab4f6ac98058,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-9763c8c2-fb4b-482f-9b3e-a078de3dc425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724618452-172.17.0.21-1595533327875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41064,DS-eb87dac0-e289-420e-be74-c88b8120180b,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-b3e3d8d2-9e6c-4e8c-8d01-940a22c46647,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-3f8efab9-5738-4ace-8bb6-796297c96869,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-2d17c7c3-fe82-4c8c-80b4-2c77444309e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-505dc7e1-f9c6-4504-94fb-de52e917c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-4a8cd5c8-f0d1-427b-b23d-06d11737c203,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-78633992-13f4-4976-a1f5-ab4f6ac98058,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-9763c8c2-fb4b-482f-9b3e-a078de3dc425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131245113-172.17.0.21-1595533504503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34242,DS-afeb3d11-51ff-4d51-a90f-56716aee43c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-8e7810cd-5992-438a-b81d-950cc766a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-d5c4e753-45bd-464f-aa20-5b006accec26,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-55a8e30b-2063-4441-8df7-1f14796e26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-72c11ff2-c3b1-42e9-a51a-6a09154cb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-56d47009-613e-43ed-917e-909ffe8371d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-0a67770f-99c8-4607-8ef8-5b11d3020c90,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-f8da3892-29d6-4fec-b99d-f3cf34a18f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131245113-172.17.0.21-1595533504503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34242,DS-afeb3d11-51ff-4d51-a90f-56716aee43c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-8e7810cd-5992-438a-b81d-950cc766a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-d5c4e753-45bd-464f-aa20-5b006accec26,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-55a8e30b-2063-4441-8df7-1f14796e26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-72c11ff2-c3b1-42e9-a51a-6a09154cb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-56d47009-613e-43ed-917e-909ffe8371d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-0a67770f-99c8-4607-8ef8-5b11d3020c90,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-f8da3892-29d6-4fec-b99d-f3cf34a18f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5185
