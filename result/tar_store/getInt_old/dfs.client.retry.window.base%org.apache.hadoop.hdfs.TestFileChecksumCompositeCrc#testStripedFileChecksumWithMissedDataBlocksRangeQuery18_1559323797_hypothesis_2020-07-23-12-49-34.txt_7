reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747588745-172.17.0.5-1595508628130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-187663b7-c39c-44d8-879e-c1ce2145f169,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-375e00d6-233b-450e-bb5c-bea8185c9b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-6d365b97-c498-4ba5-b4ab-4bdfd7a93143,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-674e18af-cc3f-4662-aa61-bfd09577c639,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-f3866a13-09b3-424e-9bbe-b8ceed9244ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-fbc0aeca-2476-421d-a2ec-e512642c1a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-fe7a4e05-693f-43b4-b55b-6e479b2c71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-c7263933-76da-4a78-81f0-fc5bb8650f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747588745-172.17.0.5-1595508628130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-187663b7-c39c-44d8-879e-c1ce2145f169,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-375e00d6-233b-450e-bb5c-bea8185c9b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-6d365b97-c498-4ba5-b4ab-4bdfd7a93143,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-674e18af-cc3f-4662-aa61-bfd09577c639,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-f3866a13-09b3-424e-9bbe-b8ceed9244ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-fbc0aeca-2476-421d-a2ec-e512642c1a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-fe7a4e05-693f-43b4-b55b-6e479b2c71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-c7263933-76da-4a78-81f0-fc5bb8650f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250498226-172.17.0.5-1595508739746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45055,DS-f1e2d7ed-5dd5-46fa-b1c6-4b1026fe098c,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-cd660674-f1f4-4623-9169-b8da856e242d,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-c9b534fc-17be-4142-8ef1-7192e2741fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-ec507f00-0277-4ceb-98b5-c797f71dde47,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-d39bb617-af23-473c-9a56-8564135e0461,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-cfa1ee1b-ba17-445f-8264-be7e528430fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-ae413453-d5a0-483f-a06f-b71680f6df03,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-babe6355-6c7c-4b73-ace9-05272305dc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250498226-172.17.0.5-1595508739746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45055,DS-f1e2d7ed-5dd5-46fa-b1c6-4b1026fe098c,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-cd660674-f1f4-4623-9169-b8da856e242d,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-c9b534fc-17be-4142-8ef1-7192e2741fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-ec507f00-0277-4ceb-98b5-c797f71dde47,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-d39bb617-af23-473c-9a56-8564135e0461,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-cfa1ee1b-ba17-445f-8264-be7e528430fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-ae413453-d5a0-483f-a06f-b71680f6df03,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-babe6355-6c7c-4b73-ace9-05272305dc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804788297-172.17.0.5-1595508848173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-4a13509d-bfb6-415b-91b7-b07576bc1c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-1f63bbf7-31d7-476c-ad03-1e06b3bd93ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-8c7e5bed-aecc-465e-8b16-68eb754b5579,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-8508f5fe-0794-4456-8309-bac29deeb798,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-99504d6e-9030-4e13-a36f-540cf2d802a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-b748bb6a-9a77-4b6f-ba3f-8f30b00e7448,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-69569218-ffcd-4e4d-bc74-afbb0eb9980b,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-df2d4620-e203-4e23-b0fb-83eaa0606c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804788297-172.17.0.5-1595508848173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-4a13509d-bfb6-415b-91b7-b07576bc1c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-1f63bbf7-31d7-476c-ad03-1e06b3bd93ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-8c7e5bed-aecc-465e-8b16-68eb754b5579,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-8508f5fe-0794-4456-8309-bac29deeb798,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-99504d6e-9030-4e13-a36f-540cf2d802a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-b748bb6a-9a77-4b6f-ba3f-8f30b00e7448,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-69569218-ffcd-4e4d-bc74-afbb0eb9980b,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-df2d4620-e203-4e23-b0fb-83eaa0606c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137615207-172.17.0.5-1595509291967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-5a4a64a1-2c4a-48ec-9daa-5c1e7c8f0a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-9dc01301-a989-42b8-ad19-e30fd8e4b503,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-2b684023-1b11-4e10-9cec-a59e484f240e,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-7376b932-8752-4484-a5a8-d1736a3af4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-ca081e91-572c-4bb6-9746-2994e42b8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-e2884d70-ed84-41ef-9eb9-81786275cfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-6ffb705a-34a9-4831-88fa-4fcc7b5b4a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-238e9bbb-9c4d-476d-9550-04dbab3351cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137615207-172.17.0.5-1595509291967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-5a4a64a1-2c4a-48ec-9daa-5c1e7c8f0a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-9dc01301-a989-42b8-ad19-e30fd8e4b503,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-2b684023-1b11-4e10-9cec-a59e484f240e,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-7376b932-8752-4484-a5a8-d1736a3af4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-ca081e91-572c-4bb6-9746-2994e42b8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-e2884d70-ed84-41ef-9eb9-81786275cfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-6ffb705a-34a9-4831-88fa-4fcc7b5b4a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-238e9bbb-9c4d-476d-9550-04dbab3351cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263014031-172.17.0.5-1595509396810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-a2b2e6b2-9a12-4e20-8278-d7340bccc77c,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-5617958e-e305-435c-8d19-1ba688e3499a,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-8ec80541-ae63-4140-8b00-77424858746d,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-32783ffa-8fb3-403d-baf7-028155c49f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-58ecaba7-27d5-400e-bcb3-57068d642717,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-25df36b8-908c-407e-89de-29bff44a3ced,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-3694428b-2bd6-4a86-8874-63a9b02ab84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-070f6470-082b-4228-9c5f-956969959272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263014031-172.17.0.5-1595509396810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-a2b2e6b2-9a12-4e20-8278-d7340bccc77c,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-5617958e-e305-435c-8d19-1ba688e3499a,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-8ec80541-ae63-4140-8b00-77424858746d,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-32783ffa-8fb3-403d-baf7-028155c49f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-58ecaba7-27d5-400e-bcb3-57068d642717,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-25df36b8-908c-407e-89de-29bff44a3ced,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-3694428b-2bd6-4a86-8874-63a9b02ab84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-070f6470-082b-4228-9c5f-956969959272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206506041-172.17.0.5-1595509916098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34577,DS-214c1773-4b48-4341-8a8b-8f96ba98b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-a54e6042-4db4-4f3f-8b11-b5f20d0d340c,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-90dfa20b-6e1e-48c3-97b0-76c7c2387802,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-2f9f4007-ef57-4baa-9c72-1961fa3b4060,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-458e142d-e76e-426c-9076-e84f9966d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-6befbd0a-4cf6-461e-838a-a4c090bd2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-1ca444c3-b4eb-43f5-a74d-61bb61aa54b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-585661f6-6923-4f3c-be49-fb903b3193f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206506041-172.17.0.5-1595509916098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34577,DS-214c1773-4b48-4341-8a8b-8f96ba98b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-a54e6042-4db4-4f3f-8b11-b5f20d0d340c,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-90dfa20b-6e1e-48c3-97b0-76c7c2387802,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-2f9f4007-ef57-4baa-9c72-1961fa3b4060,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-458e142d-e76e-426c-9076-e84f9966d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-6befbd0a-4cf6-461e-838a-a4c090bd2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-1ca444c3-b4eb-43f5-a74d-61bb61aa54b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-585661f6-6923-4f3c-be49-fb903b3193f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807897824-172.17.0.5-1595510053521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-9f6a780b-eacc-44a5-8832-fa63d8f759d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-0a8331e8-d6c8-4c03-bc39-fdbc65ef0bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-bb1b1757-bdfb-44cc-b526-5da638bec9db,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-56c00656-b534-4984-8195-312d15f4d267,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-40dea684-571f-4b7f-9b10-e0ce2e01263c,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-178b1d5e-862b-40d5-aeb0-f2df49135002,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-7cd2dabc-1f42-4a33-9728-74a94a9d62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-02fa32f4-9a3f-48bf-8377-c17bb7ef73b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807897824-172.17.0.5-1595510053521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-9f6a780b-eacc-44a5-8832-fa63d8f759d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-0a8331e8-d6c8-4c03-bc39-fdbc65ef0bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-bb1b1757-bdfb-44cc-b526-5da638bec9db,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-56c00656-b534-4984-8195-312d15f4d267,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-40dea684-571f-4b7f-9b10-e0ce2e01263c,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-178b1d5e-862b-40d5-aeb0-f2df49135002,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-7cd2dabc-1f42-4a33-9728-74a94a9d62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-02fa32f4-9a3f-48bf-8377-c17bb7ef73b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686495006-172.17.0.5-1595510896021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37043,DS-753c4812-1d90-47ed-a8b7-3da35bc773e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-58759b23-1cc6-42ad-97fb-f6084d36818b,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-6c9e51d5-efb9-4ce7-8464-1bf8a745db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-4151dee9-76c4-4947-ae70-81dba1def899,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-24bd20fe-d361-4a58-b96b-8b14cee9f366,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-3a7cc0a8-62c6-4219-bcc5-6966654bc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-681b0416-d162-477f-bdf4-6b36105a5899,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-631c95f3-57f0-41e3-bc4d-759b73ea5fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686495006-172.17.0.5-1595510896021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37043,DS-753c4812-1d90-47ed-a8b7-3da35bc773e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-58759b23-1cc6-42ad-97fb-f6084d36818b,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-6c9e51d5-efb9-4ce7-8464-1bf8a745db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-4151dee9-76c4-4947-ae70-81dba1def899,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-24bd20fe-d361-4a58-b96b-8b14cee9f366,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-3a7cc0a8-62c6-4219-bcc5-6966654bc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-681b0416-d162-477f-bdf4-6b36105a5899,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-631c95f3-57f0-41e3-bc4d-759b73ea5fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694770296-172.17.0.5-1595511139998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-236ace0d-987f-435c-9bac-15c6a5631628,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-573087f0-8c65-464c-8144-965e4f964421,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-1d876982-e6d9-4888-8f3f-9f1b9d381d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-b3232afc-b3be-4c0a-b055-52e6c95222cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-4e10bf9c-6724-4f58-bb70-a36dc2fe7868,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-6dfbc217-a2fd-4060-b080-c4aa9e5838c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-8aa46880-f4d6-40fd-bbe7-032355bd0393,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-ba33d7ae-0ca1-49f2-a429-05ba827e02fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694770296-172.17.0.5-1595511139998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-236ace0d-987f-435c-9bac-15c6a5631628,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-573087f0-8c65-464c-8144-965e4f964421,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-1d876982-e6d9-4888-8f3f-9f1b9d381d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-b3232afc-b3be-4c0a-b055-52e6c95222cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-4e10bf9c-6724-4f58-bb70-a36dc2fe7868,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-6dfbc217-a2fd-4060-b080-c4aa9e5838c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-8aa46880-f4d6-40fd-bbe7-032355bd0393,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-ba33d7ae-0ca1-49f2-a429-05ba827e02fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776919678-172.17.0.5-1595511396747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-73bf059a-ae4b-4092-9059-f86b6c11d918,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-6313062f-893f-47e7-accc-66fa1e710c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-ad8f3b44-d421-43cf-a302-b40795fb1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-f3f72eb8-30d0-4148-88a1-afe7d87b0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-ab11877f-0d41-46cd-85d3-c31f3f703dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-70e84bd5-77f4-4e12-91d4-7d5f1e375c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-50ac2bd9-5214-4cf5-8ad4-0a8ee5c15892,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-4028ff51-a69b-4cf1-9ecb-85276bf31222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776919678-172.17.0.5-1595511396747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-73bf059a-ae4b-4092-9059-f86b6c11d918,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-6313062f-893f-47e7-accc-66fa1e710c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-ad8f3b44-d421-43cf-a302-b40795fb1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-f3f72eb8-30d0-4148-88a1-afe7d87b0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-ab11877f-0d41-46cd-85d3-c31f3f703dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-70e84bd5-77f4-4e12-91d4-7d5f1e375c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-50ac2bd9-5214-4cf5-8ad4-0a8ee5c15892,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-4028ff51-a69b-4cf1-9ecb-85276bf31222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200324778-172.17.0.5-1595511433090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-271f4a08-fe42-42b5-a580-0fb8a5cacb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-aab11ee3-8943-41b0-9c89-fa74a4166b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-582e1a21-52f2-45a9-96c1-71ae52a2a740,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-eb987492-bfda-4553-b2ab-8b773b2f6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-98e94d7b-762c-4a51-b09d-b1c89f12c453,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-cf0cee32-5e08-4794-b929-bc05299451e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-82b3bb55-4c0b-4dda-8fda-dfd511b84a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-631a314e-9b99-448e-b8d8-60da68ca4994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200324778-172.17.0.5-1595511433090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-271f4a08-fe42-42b5-a580-0fb8a5cacb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-aab11ee3-8943-41b0-9c89-fa74a4166b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-582e1a21-52f2-45a9-96c1-71ae52a2a740,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-eb987492-bfda-4553-b2ab-8b773b2f6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-98e94d7b-762c-4a51-b09d-b1c89f12c453,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-cf0cee32-5e08-4794-b929-bc05299451e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-82b3bb55-4c0b-4dda-8fda-dfd511b84a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-631a314e-9b99-448e-b8d8-60da68ca4994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866730967-172.17.0.5-1595511470083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-9c8ff5dc-227d-4f90-86b5-5df54444f0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-5fc7634f-9448-44aa-add1-881013e8d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-6781f43c-9f80-4804-a5f0-e7d2fbbbe802,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-3249f779-46f4-4352-ae3f-e4254f95bf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-938cf697-9500-4232-ba4c-3c7737e309b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-b6a77ce3-e063-44b5-b945-221dee8669dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-cf39ad97-2d6d-4c54-9fe7-4328320b2781,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-75b75e22-7b4d-4473-ba4e-662a369333e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866730967-172.17.0.5-1595511470083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-9c8ff5dc-227d-4f90-86b5-5df54444f0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-5fc7634f-9448-44aa-add1-881013e8d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-6781f43c-9f80-4804-a5f0-e7d2fbbbe802,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-3249f779-46f4-4352-ae3f-e4254f95bf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-938cf697-9500-4232-ba4c-3c7737e309b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-b6a77ce3-e063-44b5-b945-221dee8669dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-cf39ad97-2d6d-4c54-9fe7-4328320b2781,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-75b75e22-7b4d-4473-ba4e-662a369333e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139664534-172.17.0.5-1595511644980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-d60a378d-7b69-4860-b6b2-b31d7f6cda84,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-2521edf4-9e67-43a4-9ad2-2722368a5576,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-4ec24932-5f86-4f88-b0fb-1850239bcb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-fa0e942e-600c-4cfb-9084-bc67d6af89c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-5494a318-446b-4e90-8977-32818551ea34,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-1d4fff1e-bdc1-4b85-8571-d87c2d5e1eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-3575bfdf-f533-4954-85b1-6e4fe0eedefd,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-9d62cc5f-3bf9-46d5-a798-1257d1c72eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139664534-172.17.0.5-1595511644980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-d60a378d-7b69-4860-b6b2-b31d7f6cda84,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-2521edf4-9e67-43a4-9ad2-2722368a5576,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-4ec24932-5f86-4f88-b0fb-1850239bcb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-fa0e942e-600c-4cfb-9084-bc67d6af89c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-5494a318-446b-4e90-8977-32818551ea34,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-1d4fff1e-bdc1-4b85-8571-d87c2d5e1eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-3575bfdf-f533-4954-85b1-6e4fe0eedefd,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-9d62cc5f-3bf9-46d5-a798-1257d1c72eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750892740-172.17.0.5-1595511838232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-f8f0d09d-8e94-4ab1-aac3-4701bbeedbef,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-60dc3079-9d7d-40bf-829d-7b6e6b913808,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-56b2c753-1967-4fb3-8431-1849b1026500,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-4aa6a633-c655-4f75-945b-18a6f5aa062a,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-26629d66-ff17-45ee-8ff9-9a7913d49671,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-caf79368-cfa7-4b60-b62a-deb12ab74240,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-143480ae-18a9-4a40-b3d4-2c1a54745835,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-c3f8ba72-b6c2-4570-9796-85eb3616c81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750892740-172.17.0.5-1595511838232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-f8f0d09d-8e94-4ab1-aac3-4701bbeedbef,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-60dc3079-9d7d-40bf-829d-7b6e6b913808,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-56b2c753-1967-4fb3-8431-1849b1026500,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-4aa6a633-c655-4f75-945b-18a6f5aa062a,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-26629d66-ff17-45ee-8ff9-9a7913d49671,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-caf79368-cfa7-4b60-b62a-deb12ab74240,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-143480ae-18a9-4a40-b3d4-2c1a54745835,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-c3f8ba72-b6c2-4570-9796-85eb3616c81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194042571-172.17.0.5-1595512275337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-79fcae9a-5243-4f6f-bf50-00d32318071f,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-998ccc71-7813-4930-b086-40a9aae64529,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-1a7af807-1f8c-46d7-a66d-cde14f2e5836,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-bd3da373-f528-47c8-9e49-002782c6005a,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c7d6866f-5f89-4725-8819-1ecfe2100825,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-8c0aab21-2b63-4323-9089-3e36b79d42cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-f9e97686-35de-4640-9c9a-1157e9f6afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-5164de1b-da1e-4014-87ed-74ac7611887e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194042571-172.17.0.5-1595512275337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-79fcae9a-5243-4f6f-bf50-00d32318071f,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-998ccc71-7813-4930-b086-40a9aae64529,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-1a7af807-1f8c-46d7-a66d-cde14f2e5836,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-bd3da373-f528-47c8-9e49-002782c6005a,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c7d6866f-5f89-4725-8819-1ecfe2100825,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-8c0aab21-2b63-4323-9089-3e36b79d42cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-f9e97686-35de-4640-9c9a-1157e9f6afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-5164de1b-da1e-4014-87ed-74ac7611887e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443438041-172.17.0.5-1595512314925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-7fa28c1c-2f08-4bad-8ab9-96e03191d270,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-6feca46a-6b94-4149-87be-7ea4159e20ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-9fbd0000-948a-44aa-a357-0dc1e424af95,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-fc2a8d65-c149-4adc-8a6e-a7281b103d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4d5280d9-eeea-430d-957d-72e5fd0b6f70,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-b6f49af8-ee90-4179-be25-38fa7892679b,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-e6068fe3-632d-4352-8587-ce590bd37493,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-430a36a4-9ec6-48fe-bc4d-3c999188b155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443438041-172.17.0.5-1595512314925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-7fa28c1c-2f08-4bad-8ab9-96e03191d270,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-6feca46a-6b94-4149-87be-7ea4159e20ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-9fbd0000-948a-44aa-a357-0dc1e424af95,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-fc2a8d65-c149-4adc-8a6e-a7281b103d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4d5280d9-eeea-430d-957d-72e5fd0b6f70,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-b6f49af8-ee90-4179-be25-38fa7892679b,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-e6068fe3-632d-4352-8587-ce590bd37493,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-430a36a4-9ec6-48fe-bc4d-3c999188b155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265896224-172.17.0.5-1595512771877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-c29edfd3-9ca2-4ac7-a14c-c2aaed6ff552,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-e71b8dbc-fc7c-4693-be9a-2f911b987f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-9e0ca1ed-6b97-46ec-8163-c2d8c5b9a846,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-fdcac0c3-065c-4c9f-a686-13b0971b446d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-1d6fa514-d189-4c93-aeb5-e670dd775b26,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-617ddf7f-8690-4070-98f0-edc2b0a38675,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-ca34797e-48de-4e5f-b954-4b369463b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-915507ee-dbeb-4a82-b658-3b76f0aa6605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265896224-172.17.0.5-1595512771877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-c29edfd3-9ca2-4ac7-a14c-c2aaed6ff552,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-e71b8dbc-fc7c-4693-be9a-2f911b987f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-9e0ca1ed-6b97-46ec-8163-c2d8c5b9a846,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-fdcac0c3-065c-4c9f-a686-13b0971b446d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-1d6fa514-d189-4c93-aeb5-e670dd775b26,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-617ddf7f-8690-4070-98f0-edc2b0a38675,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-ca34797e-48de-4e5f-b954-4b369463b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-915507ee-dbeb-4a82-b658-3b76f0aa6605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015321036-172.17.0.5-1595513569631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-69184e44-f22e-4aa8-8c4d-d661f3a4e2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-ce0cbd00-6fbb-4a39-9291-e550c74e7524,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-c90874c0-1bab-4f05-b55a-5ba82349e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-a9515191-bb02-4bbe-a48f-238b01b310fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-126be4d0-46a7-426d-9c28-6fe58002e631,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-812be164-d0ae-4603-b866-3589f9b2ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-b40d8b7d-a74b-4b95-a97e-e5da0fa28fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-e3537af0-b1a4-4c6d-9b03-c0702ed9ab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015321036-172.17.0.5-1595513569631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-69184e44-f22e-4aa8-8c4d-d661f3a4e2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-ce0cbd00-6fbb-4a39-9291-e550c74e7524,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-c90874c0-1bab-4f05-b55a-5ba82349e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-a9515191-bb02-4bbe-a48f-238b01b310fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-126be4d0-46a7-426d-9c28-6fe58002e631,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-812be164-d0ae-4603-b866-3589f9b2ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-b40d8b7d-a74b-4b95-a97e-e5da0fa28fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-e3537af0-b1a4-4c6d-9b03-c0702ed9ab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5413
