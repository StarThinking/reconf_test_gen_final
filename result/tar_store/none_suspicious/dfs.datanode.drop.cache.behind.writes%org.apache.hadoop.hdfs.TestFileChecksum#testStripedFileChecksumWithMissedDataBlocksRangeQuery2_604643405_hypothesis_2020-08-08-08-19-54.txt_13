reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212792818-172.17.0.10-1596874889026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-28c7532c-630d-4bd1-a616-4fe48374ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-baf88d97-89f4-402b-be4e-8ce97fceda49,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9bb3854a-29ea-48fc-a165-90eb7e247592,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-ae543e73-b8ae-4b54-8b4b-5e5635c9c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-e9529e5b-67fe-47fd-8fa3-1918ff29fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-5a3ce896-930f-4c68-b2ab-a2d4a870412c,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-2fc2c2a0-9d2a-4c2f-82c2-5bea577266e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-101f5f87-a9c1-4f34-9e3c-df5ea1507b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212792818-172.17.0.10-1596874889026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-28c7532c-630d-4bd1-a616-4fe48374ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-baf88d97-89f4-402b-be4e-8ce97fceda49,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9bb3854a-29ea-48fc-a165-90eb7e247592,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-ae543e73-b8ae-4b54-8b4b-5e5635c9c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-e9529e5b-67fe-47fd-8fa3-1918ff29fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-5a3ce896-930f-4c68-b2ab-a2d4a870412c,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-2fc2c2a0-9d2a-4c2f-82c2-5bea577266e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-101f5f87-a9c1-4f34-9e3c-df5ea1507b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544563736-172.17.0.10-1596875643951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-e450c48e-2089-43b7-8a20-ae105f945c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0af200b4-28c5-46b3-89b1-95291346f228,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-f80223ae-8fd5-4178-b7f3-bf265e0c04f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-415c31b4-741c-4b8b-876b-0ada276b787e,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-e5a8c352-e9da-4635-b4b6-e24297cb746a,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-71c44d48-a41a-4928-b5c0-2586ddd86e46,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-f82300eb-5d28-4f7d-bedf-b5f138b06416,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-eaa1e780-c0d3-4dc7-941b-6a53790cae90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544563736-172.17.0.10-1596875643951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-e450c48e-2089-43b7-8a20-ae105f945c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0af200b4-28c5-46b3-89b1-95291346f228,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-f80223ae-8fd5-4178-b7f3-bf265e0c04f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-415c31b4-741c-4b8b-876b-0ada276b787e,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-e5a8c352-e9da-4635-b4b6-e24297cb746a,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-71c44d48-a41a-4928-b5c0-2586ddd86e46,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-f82300eb-5d28-4f7d-bedf-b5f138b06416,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-eaa1e780-c0d3-4dc7-941b-6a53790cae90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409837038-172.17.0.10-1596875998604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37628,DS-5a7d6e4e-5bd9-4c44-926a-3806e94e00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-a94c0918-65d5-4b2e-9697-15b5dd97b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-dbb31426-3a12-4d94-bdb1-34bec79ac1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-005ea5fa-fa44-4da8-8626-c1b71127071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-437fe315-ef0f-4cfa-bc54-93e846a0d175,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-41f8de1e-5f0b-4589-9cb8-cdf2bef12077,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-90940bad-35a7-4b68-a9f9-0702f1332c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-237491d9-6969-431c-923d-af1c686932df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409837038-172.17.0.10-1596875998604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37628,DS-5a7d6e4e-5bd9-4c44-926a-3806e94e00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-a94c0918-65d5-4b2e-9697-15b5dd97b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-dbb31426-3a12-4d94-bdb1-34bec79ac1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-005ea5fa-fa44-4da8-8626-c1b71127071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-437fe315-ef0f-4cfa-bc54-93e846a0d175,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-41f8de1e-5f0b-4589-9cb8-cdf2bef12077,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-90940bad-35a7-4b68-a9f9-0702f1332c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-237491d9-6969-431c-923d-af1c686932df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003725601-172.17.0.10-1596876158425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35978,DS-7beedb17-8a11-42a4-b712-e0ab82b5ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-ff29cb0d-2267-48b6-a573-bea51120ebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-3d1765c2-5664-4210-9b70-abd9427ceeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-427462ad-1479-4bf2-9d37-60f6d0d206d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-8df61da3-63d1-48fc-92d0-e6097d521378,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-ab23998d-9962-45da-bd5f-b9dc1488ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-9deba7e6-dc28-42a4-aa47-618bd5a7cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-46415cb7-75c8-4c82-ad9b-fb1ff42955a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003725601-172.17.0.10-1596876158425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35978,DS-7beedb17-8a11-42a4-b712-e0ab82b5ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-ff29cb0d-2267-48b6-a573-bea51120ebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-3d1765c2-5664-4210-9b70-abd9427ceeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-427462ad-1479-4bf2-9d37-60f6d0d206d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-8df61da3-63d1-48fc-92d0-e6097d521378,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-ab23998d-9962-45da-bd5f-b9dc1488ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-9deba7e6-dc28-42a4-aa47-618bd5a7cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-46415cb7-75c8-4c82-ad9b-fb1ff42955a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322672803-172.17.0.10-1596876687454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40719,DS-837bb83f-f8ff-4be5-a708-6f7ceabb59f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-365762ae-3537-44f1-93c5-f79fb9a51b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-e31f30b2-ae44-4a7c-9344-a12a4000d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-1a6db5eb-8181-4608-9f5b-4dd46d7a2c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-d9432d7a-6701-43f7-9012-a77e1ee4ed31,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-aaea1139-f49a-4ca4-affa-0ccee9022951,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-615e2c65-a080-403e-ad51-acd1ae0fb544,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-397d4c80-d127-45d0-9fb8-b63b2bc3215d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322672803-172.17.0.10-1596876687454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40719,DS-837bb83f-f8ff-4be5-a708-6f7ceabb59f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-365762ae-3537-44f1-93c5-f79fb9a51b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-e31f30b2-ae44-4a7c-9344-a12a4000d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-1a6db5eb-8181-4608-9f5b-4dd46d7a2c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-d9432d7a-6701-43f7-9012-a77e1ee4ed31,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-aaea1139-f49a-4ca4-affa-0ccee9022951,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-615e2c65-a080-403e-ad51-acd1ae0fb544,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-397d4c80-d127-45d0-9fb8-b63b2bc3215d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310899631-172.17.0.10-1596877194178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-bdec24aa-00b8-45ca-bf97-fa9577b563bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-d8b909c3-6a6f-4cea-b0fd-9fad48c9c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-8591e111-ae65-45be-a456-1442b9446647,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-6144d25a-e159-4125-8d7e-544f2fea19c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-98dbfdcf-95ed-49da-bbff-3b632d4e9c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-14f92c95-6ab6-4d2a-8226-d357c27b8e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-97d9ebd7-8446-4f84-acc1-4feded1a1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-88d0f016-aa9f-452a-a46d-160625f55575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310899631-172.17.0.10-1596877194178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-bdec24aa-00b8-45ca-bf97-fa9577b563bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-d8b909c3-6a6f-4cea-b0fd-9fad48c9c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-8591e111-ae65-45be-a456-1442b9446647,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-6144d25a-e159-4125-8d7e-544f2fea19c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-98dbfdcf-95ed-49da-bbff-3b632d4e9c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-14f92c95-6ab6-4d2a-8226-d357c27b8e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-97d9ebd7-8446-4f84-acc1-4feded1a1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-88d0f016-aa9f-452a-a46d-160625f55575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765908820-172.17.0.10-1596877331090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45632,DS-4e19c105-352b-4530-a1ce-636efa6b0730,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8f6c2219-e0fc-4f76-a52e-21f748cb29d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-6d714da8-44d9-413e-9a65-ebc067ce4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-732e2c92-f4f1-417b-a613-1d546b2e1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-7ef8a10b-a2c9-4ce6-86ee-b20ae8c02991,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-e91bfd95-b657-4a28-98f3-9edb6b2ab14e,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-9f79a05c-7a70-4a09-8ff3-04080ffe4442,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-b34d6fda-7dc5-4352-ade9-3724ca3c2403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765908820-172.17.0.10-1596877331090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45632,DS-4e19c105-352b-4530-a1ce-636efa6b0730,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8f6c2219-e0fc-4f76-a52e-21f748cb29d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-6d714da8-44d9-413e-9a65-ebc067ce4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-732e2c92-f4f1-417b-a613-1d546b2e1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-7ef8a10b-a2c9-4ce6-86ee-b20ae8c02991,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-e91bfd95-b657-4a28-98f3-9edb6b2ab14e,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-9f79a05c-7a70-4a09-8ff3-04080ffe4442,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-b34d6fda-7dc5-4352-ade9-3724ca3c2403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183872354-172.17.0.10-1596878569414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-c30582eb-f9da-4bbc-9105-cbd9f022716d,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-69070710-5db0-4d0e-8d2c-ae8b6c87ea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-cf5d0f01-dd1a-4405-9d83-2b7965ce392f,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-4bbfe7c5-15c7-4531-be40-f752294d0457,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-fec689b7-8577-445a-8422-418478c93d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-ee19bf83-9794-4731-ad4c-f6d3325d951e,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-4018b515-b17a-4319-b70a-36c754c46c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-d659c289-b6db-4a55-b0d9-866706655fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183872354-172.17.0.10-1596878569414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-c30582eb-f9da-4bbc-9105-cbd9f022716d,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-69070710-5db0-4d0e-8d2c-ae8b6c87ea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-cf5d0f01-dd1a-4405-9d83-2b7965ce392f,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-4bbfe7c5-15c7-4531-be40-f752294d0457,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-fec689b7-8577-445a-8422-418478c93d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-ee19bf83-9794-4731-ad4c-f6d3325d951e,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-4018b515-b17a-4319-b70a-36c754c46c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-d659c289-b6db-4a55-b0d9-866706655fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668930307-172.17.0.10-1596878605433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-9706d110-a7b4-4136-9e94-caa1343ef44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-74f2d681-f5af-40a1-bd39-7aa747ed6fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-f75402f4-81c7-4120-8f6c-f1e977cda408,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-a8a291ad-2bec-4795-94a4-eea5e4aa75cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-bc8934fb-1249-4087-9c0c-791f93752bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-c7d52da8-c845-4ec4-b02f-19459a93d9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-e8bc6743-9277-472e-b623-8458928edcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-479c562f-839b-45c4-85c1-0a06a1be82f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668930307-172.17.0.10-1596878605433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-9706d110-a7b4-4136-9e94-caa1343ef44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-74f2d681-f5af-40a1-bd39-7aa747ed6fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-f75402f4-81c7-4120-8f6c-f1e977cda408,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-a8a291ad-2bec-4795-94a4-eea5e4aa75cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-bc8934fb-1249-4087-9c0c-791f93752bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-c7d52da8-c845-4ec4-b02f-19459a93d9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-e8bc6743-9277-472e-b623-8458928edcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-479c562f-839b-45c4-85c1-0a06a1be82f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542832619-172.17.0.10-1596878811668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44936,DS-544707c4-a264-487c-b480-13e8bb1cb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-f5ea6483-a720-41d2-b19f-f4a0517a4687,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-b4a18063-26a4-4dd3-b978-a913deddd1db,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-af708ef3-eaf6-4a2a-96bf-3668959e4f96,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-7872c2cf-af68-4d1d-aac0-c8fcd8e065c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-e92f315b-dfeb-4dc2-8e97-b57d83d6f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-e2065b33-dcc2-448e-97b4-783a55f8e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-dc5869b9-e485-4c2c-8f7c-2823b0586601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542832619-172.17.0.10-1596878811668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44936,DS-544707c4-a264-487c-b480-13e8bb1cb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-f5ea6483-a720-41d2-b19f-f4a0517a4687,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-b4a18063-26a4-4dd3-b978-a913deddd1db,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-af708ef3-eaf6-4a2a-96bf-3668959e4f96,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-7872c2cf-af68-4d1d-aac0-c8fcd8e065c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-e92f315b-dfeb-4dc2-8e97-b57d83d6f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-e2065b33-dcc2-448e-97b4-783a55f8e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-dc5869b9-e485-4c2c-8f7c-2823b0586601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372833962-172.17.0.10-1596879189082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-4913b3ee-87f4-43b0-b63f-e294592188ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-b8ed3a5a-38e0-4e88-9368-e8530aae6154,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-dfc8e576-ee36-4f56-8cdc-fd8f38787746,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-f5e42d83-a16c-49cf-bcbc-87b2a477a219,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-50049b8c-d48d-452d-94a9-a98a01dd4569,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-763095d0-f737-4e81-92e7-1e149168606f,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-ee4ed5b9-4788-45d9-9a5b-6099afb0054e,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-7caa0bde-6a70-47d7-bbf9-9f439864eac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372833962-172.17.0.10-1596879189082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-4913b3ee-87f4-43b0-b63f-e294592188ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-b8ed3a5a-38e0-4e88-9368-e8530aae6154,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-dfc8e576-ee36-4f56-8cdc-fd8f38787746,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-f5e42d83-a16c-49cf-bcbc-87b2a477a219,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-50049b8c-d48d-452d-94a9-a98a01dd4569,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-763095d0-f737-4e81-92e7-1e149168606f,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-ee4ed5b9-4788-45d9-9a5b-6099afb0054e,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-7caa0bde-6a70-47d7-bbf9-9f439864eac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277210445-172.17.0.10-1596879974407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-215bb43d-d13c-4765-82b8-81cb1a1a7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-40935568-e7a0-4a02-99aa-4e59050efa46,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-de53f22c-bd73-4452-9ef8-5547697ced68,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-ef9dd4a0-c182-4ec8-b39a-fe08056521f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-d5a5f9fe-5f80-4599-81a7-e50833c76883,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-4eb0447f-28ed-47d4-aabe-b1117bcb51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-4ab48631-0369-490e-8151-e626f850e700,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-b1abef4d-e6ef-4cb4-9c04-887e9226bef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277210445-172.17.0.10-1596879974407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-215bb43d-d13c-4765-82b8-81cb1a1a7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-40935568-e7a0-4a02-99aa-4e59050efa46,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-de53f22c-bd73-4452-9ef8-5547697ced68,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-ef9dd4a0-c182-4ec8-b39a-fe08056521f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-d5a5f9fe-5f80-4599-81a7-e50833c76883,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-4eb0447f-28ed-47d4-aabe-b1117bcb51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-4ab48631-0369-490e-8151-e626f850e700,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-b1abef4d-e6ef-4cb4-9c04-887e9226bef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196982221-172.17.0.10-1596880100774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39727,DS-2e479140-e21b-4d03-b6a6-fc0f7bcf41f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b364d122-0f63-4b03-88fb-f7edc572aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-64f7f9e1-4127-4445-a612-90065e32e255,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-b5838b4a-b79d-4d0c-a127-4da6cf099def,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-f46886a7-cf06-4dc0-b966-3d4c0e51a09a,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-c821eaa0-7062-4c56-a28d-5f560935f844,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-84923895-dabd-420b-a9bf-fb8815d8755d,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-52903c67-5011-4740-8c51-a98b0dee2088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196982221-172.17.0.10-1596880100774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39727,DS-2e479140-e21b-4d03-b6a6-fc0f7bcf41f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b364d122-0f63-4b03-88fb-f7edc572aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-64f7f9e1-4127-4445-a612-90065e32e255,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-b5838b4a-b79d-4d0c-a127-4da6cf099def,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-f46886a7-cf06-4dc0-b966-3d4c0e51a09a,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-c821eaa0-7062-4c56-a28d-5f560935f844,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-84923895-dabd-420b-a9bf-fb8815d8755d,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-52903c67-5011-4740-8c51-a98b0dee2088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5354
