reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864858127-172.17.0.18-1596949192860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-5d9256c0-b88a-4a1c-9eb0-6d606596402a,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-e83ae4ef-3139-4d40-a75a-a608ef5ab4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-50520f80-f7c2-4207-983b-c6e0e9146275,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d86b1232-b152-4121-9daf-7cbc5cdbfa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-0c630fd3-b9bb-4018-a9b3-0f1654f9b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-3d8b4e57-38f8-43e9-97dc-ba15f6c39936,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-d0a3ee9a-8507-40c4-8626-ea715d68b195,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-ff03433d-71f6-470a-94ec-e260e63e9e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864858127-172.17.0.18-1596949192860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-5d9256c0-b88a-4a1c-9eb0-6d606596402a,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-e83ae4ef-3139-4d40-a75a-a608ef5ab4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-50520f80-f7c2-4207-983b-c6e0e9146275,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d86b1232-b152-4121-9daf-7cbc5cdbfa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-0c630fd3-b9bb-4018-a9b3-0f1654f9b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-3d8b4e57-38f8-43e9-97dc-ba15f6c39936,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-d0a3ee9a-8507-40c4-8626-ea715d68b195,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-ff03433d-71f6-470a-94ec-e260e63e9e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723912404-172.17.0.18-1596949298911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38485,DS-44cc8d60-6ff2-48a1-9fc8-7d816ef94d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-1728d99f-9363-453e-af4a-cd04648a6059,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-1588a5c6-5982-4952-b8a7-70ea0b9915ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-145e9bc0-0116-4901-9e38-21a8dd4683a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-13d8627a-1700-4dbe-9a10-ee43d33239e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-74cf8719-75d0-43a6-b897-b6c5aa4525f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-4940d5d0-7ee8-4e11-8cf2-ee5b8fa7a32b,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-0b100edd-efed-4df1-aba1-817cd219dc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723912404-172.17.0.18-1596949298911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38485,DS-44cc8d60-6ff2-48a1-9fc8-7d816ef94d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-1728d99f-9363-453e-af4a-cd04648a6059,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-1588a5c6-5982-4952-b8a7-70ea0b9915ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-145e9bc0-0116-4901-9e38-21a8dd4683a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-13d8627a-1700-4dbe-9a10-ee43d33239e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-74cf8719-75d0-43a6-b897-b6c5aa4525f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-4940d5d0-7ee8-4e11-8cf2-ee5b8fa7a32b,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-0b100edd-efed-4df1-aba1-817cd219dc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628919041-172.17.0.18-1596950785632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44374,DS-e06b0341-b9d2-412c-b119-a54003b87069,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-a36f6f2e-cec9-4595-9185-72201c308a78,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-54e5ecc9-1aed-4a68-b16a-26f8bdb936c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f1db76ce-6626-40a2-a203-695ae2983397,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-67cf65b1-6bb4-4326-bc46-ae71007a6046,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-3902313d-e34d-4a79-b1d9-d9ef0ebe2197,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-5e3b2f68-d74e-4f5a-824a-f77d259311f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-1e23f76c-b3ee-4834-bb05-190b4e5e1bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628919041-172.17.0.18-1596950785632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44374,DS-e06b0341-b9d2-412c-b119-a54003b87069,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-a36f6f2e-cec9-4595-9185-72201c308a78,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-54e5ecc9-1aed-4a68-b16a-26f8bdb936c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f1db76ce-6626-40a2-a203-695ae2983397,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-67cf65b1-6bb4-4326-bc46-ae71007a6046,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-3902313d-e34d-4a79-b1d9-d9ef0ebe2197,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-5e3b2f68-d74e-4f5a-824a-f77d259311f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-1e23f76c-b3ee-4834-bb05-190b4e5e1bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022390928-172.17.0.18-1596951891733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44425,DS-860b9d0c-aae3-4bde-86df-4637d6acf4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-3e45a7d0-e4ea-423d-b88c-7da153cbf9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-6d806c0e-e597-474d-ae1a-263e980c7a06,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-603a86ec-36ff-48ff-b4ca-bd64a3225d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-6b0b4ae3-ddfe-4daf-981d-54fb51ed9701,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-80a26e7a-c012-4a32-ad9d-ffaea2e405d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-79f32091-92f6-4a0e-8101-45368277d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-8905c146-331b-40dc-a5ea-23b154a9a158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022390928-172.17.0.18-1596951891733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44425,DS-860b9d0c-aae3-4bde-86df-4637d6acf4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-3e45a7d0-e4ea-423d-b88c-7da153cbf9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-6d806c0e-e597-474d-ae1a-263e980c7a06,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-603a86ec-36ff-48ff-b4ca-bd64a3225d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-6b0b4ae3-ddfe-4daf-981d-54fb51ed9701,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-80a26e7a-c012-4a32-ad9d-ffaea2e405d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-79f32091-92f6-4a0e-8101-45368277d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-8905c146-331b-40dc-a5ea-23b154a9a158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103235135-172.17.0.18-1596951959588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-110d7478-89bd-4545-bf0e-a5f56da01d94,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-df75b0d6-e8c2-4d17-89a9-231d2d274f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-1a4991f5-a4f1-49e1-9d13-b66bd14726f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-d379c57e-83ba-4de0-aaf8-c70a14ae2682,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-58d20720-3047-408a-90b6-fc6a628121ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-99155d68-6ad9-45f9-a9c4-d95fca8cfe00,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-2744c430-5248-48da-bd2a-0269b40f2f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-924c3783-5350-4f12-82d2-da74d25e85d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103235135-172.17.0.18-1596951959588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-110d7478-89bd-4545-bf0e-a5f56da01d94,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-df75b0d6-e8c2-4d17-89a9-231d2d274f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-1a4991f5-a4f1-49e1-9d13-b66bd14726f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-d379c57e-83ba-4de0-aaf8-c70a14ae2682,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-58d20720-3047-408a-90b6-fc6a628121ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-99155d68-6ad9-45f9-a9c4-d95fca8cfe00,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-2744c430-5248-48da-bd2a-0269b40f2f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-924c3783-5350-4f12-82d2-da74d25e85d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483462623-172.17.0.18-1596952000158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-9018a447-9097-4f4b-b22a-a943d142e057,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-d806db6a-5813-4b2f-a141-04e73950157d,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-6d0caf88-32e3-49af-9dc4-b9335312ed19,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-8e7eb1b1-e39c-4f48-a820-2eae05212f25,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-95e5d798-42c2-406a-8251-06fb2f527c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f1b2add3-d0be-444d-8a33-a48e5e1c11e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e116ecc2-8901-44be-8211-e5ce245fe365,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-4fdedcc7-58d1-473d-9328-e0551bae2847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483462623-172.17.0.18-1596952000158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-9018a447-9097-4f4b-b22a-a943d142e057,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-d806db6a-5813-4b2f-a141-04e73950157d,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-6d0caf88-32e3-49af-9dc4-b9335312ed19,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-8e7eb1b1-e39c-4f48-a820-2eae05212f25,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-95e5d798-42c2-406a-8251-06fb2f527c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f1b2add3-d0be-444d-8a33-a48e5e1c11e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e116ecc2-8901-44be-8211-e5ce245fe365,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-4fdedcc7-58d1-473d-9328-e0551bae2847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994278932-172.17.0.18-1596952493676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42107,DS-1c96956c-8ec0-48d3-8cee-6c6c4ec0c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-d3703a72-29ee-4bf8-87c2-08ff5ea5cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-163901a3-5510-4ef5-b6a5-252a563bee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-56a16f3f-7181-4211-9a4d-025a6019d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-1a42b394-0a8d-4b50-b9cc-b73bfba4a614,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-b12b1e8d-6e90-4218-bfe5-fb7bbe99bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-bcfec5cd-fbfc-4cf8-9f5c-1708384f4fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-82dc2869-b06d-4606-a760-e4a9be171658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994278932-172.17.0.18-1596952493676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42107,DS-1c96956c-8ec0-48d3-8cee-6c6c4ec0c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-d3703a72-29ee-4bf8-87c2-08ff5ea5cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-163901a3-5510-4ef5-b6a5-252a563bee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-56a16f3f-7181-4211-9a4d-025a6019d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-1a42b394-0a8d-4b50-b9cc-b73bfba4a614,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-b12b1e8d-6e90-4218-bfe5-fb7bbe99bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-bcfec5cd-fbfc-4cf8-9f5c-1708384f4fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-82dc2869-b06d-4606-a760-e4a9be171658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022041923-172.17.0.18-1596952550322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-e235f613-c887-49cf-a615-c6d8a1816e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-bb73ab85-8826-4d14-9e98-404e89857565,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-8ae88955-ab02-409a-a178-3debbf4c054d,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-7edcacb3-c7f4-49f5-b929-efc3023c1a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-74137171-0437-448b-811e-22c7f4c65a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-c8a9c1f9-fe58-47cd-a42a-c0e3d2af3eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-54004a30-ccc8-4bce-9eb3-a41020cdce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-05f781fd-7657-463e-93c6-4fb92ea359f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022041923-172.17.0.18-1596952550322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-e235f613-c887-49cf-a615-c6d8a1816e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-bb73ab85-8826-4d14-9e98-404e89857565,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-8ae88955-ab02-409a-a178-3debbf4c054d,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-7edcacb3-c7f4-49f5-b929-efc3023c1a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-74137171-0437-448b-811e-22c7f4c65a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-c8a9c1f9-fe58-47cd-a42a-c0e3d2af3eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-54004a30-ccc8-4bce-9eb3-a41020cdce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-05f781fd-7657-463e-93c6-4fb92ea359f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524509204-172.17.0.18-1596952717861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-f8c4e679-b208-4008-ba14-6387195df8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-23734e8f-18fe-4439-be5a-f813223dd811,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-5cec4e8b-709d-4266-b736-268f11d1e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-6fbc5e3d-24bd-4ac0-b864-670e2044fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-02b37f31-3435-4722-a563-c619269fd41c,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-2983f3fa-3fb9-42cc-8bcb-f59abfd007eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-78600722-b8a6-4319-92b8-ada3cc5f9560,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-a3a751d2-80de-4e6a-9c87-5baaaee7f5eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524509204-172.17.0.18-1596952717861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-f8c4e679-b208-4008-ba14-6387195df8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-23734e8f-18fe-4439-be5a-f813223dd811,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-5cec4e8b-709d-4266-b736-268f11d1e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-6fbc5e3d-24bd-4ac0-b864-670e2044fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-02b37f31-3435-4722-a563-c619269fd41c,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-2983f3fa-3fb9-42cc-8bcb-f59abfd007eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-78600722-b8a6-4319-92b8-ada3cc5f9560,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-a3a751d2-80de-4e6a-9c87-5baaaee7f5eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382844580-172.17.0.18-1596952842651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-e2c29e47-b302-4a6f-b543-194b7c96aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-3a53c9cf-beda-4a58-ad5d-58251173e958,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-ccc41625-f4bc-4bfa-a2e8-8973bc4d4e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-c66dabab-9359-44e2-b4cf-e9c73a4a7723,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-5e1c53b2-423e-475a-8e21-4e3c43c99025,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-9b51c921-119f-40f0-b4cc-7f315447d96f,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-c2e12416-cc20-475d-9e14-0941193ef5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-199309d9-86c3-43e5-a4c1-21ef3186262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382844580-172.17.0.18-1596952842651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-e2c29e47-b302-4a6f-b543-194b7c96aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-3a53c9cf-beda-4a58-ad5d-58251173e958,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-ccc41625-f4bc-4bfa-a2e8-8973bc4d4e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-c66dabab-9359-44e2-b4cf-e9c73a4a7723,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-5e1c53b2-423e-475a-8e21-4e3c43c99025,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-9b51c921-119f-40f0-b4cc-7f315447d96f,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-c2e12416-cc20-475d-9e14-0941193ef5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-199309d9-86c3-43e5-a4c1-21ef3186262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859315874-172.17.0.18-1596952875649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35652,DS-99b51862-fd09-489a-b769-b84ad20fa52c,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-2ecb6afd-158e-4816-9005-db4cdca06edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-25950ed5-8fa1-4b46-8cc4-2b4550aa8973,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-2ae4b218-a684-4619-8359-c8fea9bae7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-b71a912d-5b5c-436a-a154-53cccb26fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-48cbd994-3482-4070-9c82-16d21190dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-3fe32e77-b106-4617-8b84-3b6259cabd11,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-889019f9-8083-4983-9d78-40dab0d81739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859315874-172.17.0.18-1596952875649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35652,DS-99b51862-fd09-489a-b769-b84ad20fa52c,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-2ecb6afd-158e-4816-9005-db4cdca06edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-25950ed5-8fa1-4b46-8cc4-2b4550aa8973,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-2ae4b218-a684-4619-8359-c8fea9bae7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-b71a912d-5b5c-436a-a154-53cccb26fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-48cbd994-3482-4070-9c82-16d21190dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-3fe32e77-b106-4617-8b84-3b6259cabd11,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-889019f9-8083-4983-9d78-40dab0d81739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120029212-172.17.0.18-1596953197100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-f6e3c02b-b915-487c-8720-bec3a0612c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-5fdc9f55-f575-419f-aad9-0df268368fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-3155da60-109a-47cb-9546-70ae73ca8b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-4ba3c0ed-68ce-45e4-ba1e-e9aba7a61d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-f6b393bc-b6ce-46d2-af20-8dac4509bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-6f3339ce-b469-48dc-a57f-6575b1fe17ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-42ede72d-cbec-41a7-bd1b-fbefe9adb89f,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-37c7ff8f-0b9c-49e3-b566-820bd9300935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120029212-172.17.0.18-1596953197100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-f6e3c02b-b915-487c-8720-bec3a0612c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-5fdc9f55-f575-419f-aad9-0df268368fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-3155da60-109a-47cb-9546-70ae73ca8b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-4ba3c0ed-68ce-45e4-ba1e-e9aba7a61d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-f6b393bc-b6ce-46d2-af20-8dac4509bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-6f3339ce-b469-48dc-a57f-6575b1fe17ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-42ede72d-cbec-41a7-bd1b-fbefe9adb89f,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-37c7ff8f-0b9c-49e3-b566-820bd9300935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146520304-172.17.0.18-1596953595493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40194,DS-d90f2134-27b0-4d4a-9516-dafd66da7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-32892e6d-a929-4426-9c70-3efabaeed0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-d3fe28aa-71d9-42dc-8d01-d3d39ef7dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-77ad4618-5a6e-4741-a2a0-1b1e8450d290,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-0be01042-ac1d-427c-9e9d-46f7b6841c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-a14a9fb3-b1a1-408b-893a-63c641e69240,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-10a9c95b-9a3e-41a6-9561-a522db44a875,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-af9fedf3-5d11-4715-a000-eb0c0486890c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146520304-172.17.0.18-1596953595493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40194,DS-d90f2134-27b0-4d4a-9516-dafd66da7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-32892e6d-a929-4426-9c70-3efabaeed0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-d3fe28aa-71d9-42dc-8d01-d3d39ef7dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-77ad4618-5a6e-4741-a2a0-1b1e8450d290,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-0be01042-ac1d-427c-9e9d-46f7b6841c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-a14a9fb3-b1a1-408b-893a-63c641e69240,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-10a9c95b-9a3e-41a6-9561-a522db44a875,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-af9fedf3-5d11-4715-a000-eb0c0486890c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522005660-172.17.0.18-1596953731601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-aa6b31ba-b08c-4263-bf8d-83d8efb414f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-eb2988df-746a-4872-8f2e-a2b856a52149,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-1db6b480-6c74-4a0f-853b-6efd87d8471c,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-f2d0f7bb-6944-4c2d-96ab-fe21ff98a1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-21b0b9b0-d868-49e4-ad40-35b7177f5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-d9524c9b-4a6d-4f86-9254-96930ac44e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-01753d23-bf2f-4a2a-b411-7c51811e165c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-2731adf8-d4f1-43f3-862b-39289d45d83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522005660-172.17.0.18-1596953731601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-aa6b31ba-b08c-4263-bf8d-83d8efb414f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-eb2988df-746a-4872-8f2e-a2b856a52149,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-1db6b480-6c74-4a0f-853b-6efd87d8471c,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-f2d0f7bb-6944-4c2d-96ab-fe21ff98a1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-21b0b9b0-d868-49e4-ad40-35b7177f5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-d9524c9b-4a6d-4f86-9254-96930ac44e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-01753d23-bf2f-4a2a-b411-7c51811e165c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-2731adf8-d4f1-43f3-862b-39289d45d83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5259
