reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248372360-172.17.0.14-1596891445271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-0cbb9289-ceec-4b14-aacd-7702ac345764,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-66012da3-f161-4eb2-b47b-6ba0a496c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-9714c33f-7d68-4bc2-9ae6-aba359bd4d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-8eb5ef6a-1e80-4580-a9d5-555a56127297,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-56b2c0df-0d63-408f-8c17-385796def210,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-a6aedf3a-476f-4914-a03f-0e51b5b1bbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-d122f073-1e9b-4d88-bded-980ddbea6fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-eb644956-8c05-437c-b3ea-d761ad652e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248372360-172.17.0.14-1596891445271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-0cbb9289-ceec-4b14-aacd-7702ac345764,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-66012da3-f161-4eb2-b47b-6ba0a496c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-9714c33f-7d68-4bc2-9ae6-aba359bd4d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-8eb5ef6a-1e80-4580-a9d5-555a56127297,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-56b2c0df-0d63-408f-8c17-385796def210,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-a6aedf3a-476f-4914-a03f-0e51b5b1bbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-d122f073-1e9b-4d88-bded-980ddbea6fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-eb644956-8c05-437c-b3ea-d761ad652e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410674707-172.17.0.14-1596891575642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-8d100271-f123-4a78-a877-721944b7dade,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-84206ad1-4081-45d5-b444-ce0c52c821c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-ee9a667b-2ac7-447d-aff3-b9236cafa390,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-7c05f659-4d5e-4a3a-85db-fbd7380e0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-47c71a00-c7eb-49a7-9a38-2e3f0e306871,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-ff285ccb-e8cb-4c73-a408-5f236cd5fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-1722dd38-f0a3-41c9-8bfb-1866edd4fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-7b927154-5468-4481-ba61-274b77c0b9d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410674707-172.17.0.14-1596891575642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-8d100271-f123-4a78-a877-721944b7dade,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-84206ad1-4081-45d5-b444-ce0c52c821c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-ee9a667b-2ac7-447d-aff3-b9236cafa390,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-7c05f659-4d5e-4a3a-85db-fbd7380e0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-47c71a00-c7eb-49a7-9a38-2e3f0e306871,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-ff285ccb-e8cb-4c73-a408-5f236cd5fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-1722dd38-f0a3-41c9-8bfb-1866edd4fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-7b927154-5468-4481-ba61-274b77c0b9d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731146218-172.17.0.14-1596891618257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-bba2bc4d-1ee0-4e65-be95-9b61eddea3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-22ff79d1-61f7-4374-80f9-0efa91a4bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-fc914146-24fd-40ae-a361-e9e10b14ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-0222f50c-b313-4ffb-83d1-c72f36e25f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-dbdb0b33-1cf5-4688-8a75-84a537e7e7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-26516bd5-d3c2-4d34-8587-dc1a689a3050,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-07d3594c-3a9e-4836-ab7d-07e448da5ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-be12c550-7cd5-41f5-8a5e-1014b1f1fdf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731146218-172.17.0.14-1596891618257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-bba2bc4d-1ee0-4e65-be95-9b61eddea3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-22ff79d1-61f7-4374-80f9-0efa91a4bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-fc914146-24fd-40ae-a361-e9e10b14ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-0222f50c-b313-4ffb-83d1-c72f36e25f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-dbdb0b33-1cf5-4688-8a75-84a537e7e7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-26516bd5-d3c2-4d34-8587-dc1a689a3050,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-07d3594c-3a9e-4836-ab7d-07e448da5ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-be12c550-7cd5-41f5-8a5e-1014b1f1fdf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197068238-172.17.0.14-1596892240733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-2af01152-6964-493b-93cd-25c4b7f73de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-00e5b135-b2d0-46b6-9875-c0b8c14ea0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-bee3e983-cf78-4300-81d5-aad1b2cd12d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-7502b8f7-d58a-4732-a7ba-b9996f041eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-80c86318-9f74-464e-812b-60222d3bfb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-9d05c1b1-6a82-4c36-bf34-83523f127cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-b5f22552-b445-4b5e-a914-8cb627e3081c,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-fb0c3124-1b83-4dda-9b8e-429bfe52be80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197068238-172.17.0.14-1596892240733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-2af01152-6964-493b-93cd-25c4b7f73de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-00e5b135-b2d0-46b6-9875-c0b8c14ea0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-bee3e983-cf78-4300-81d5-aad1b2cd12d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-7502b8f7-d58a-4732-a7ba-b9996f041eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-80c86318-9f74-464e-812b-60222d3bfb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-9d05c1b1-6a82-4c36-bf34-83523f127cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-b5f22552-b445-4b5e-a914-8cb627e3081c,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-fb0c3124-1b83-4dda-9b8e-429bfe52be80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128393504-172.17.0.14-1596892287234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-c39f2eb7-38fa-4445-814e-1203c3250ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-922c5c85-c116-44c2-979f-3b0f3687f9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-2714a834-bd03-47e1-8853-9af173166f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-ea8875a1-7d0e-47d1-b373-44970dfc878f,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-099003a5-d199-44d6-9e84-22475ede12f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-ffa88c72-aaf1-4310-a8dc-2405f6b63e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a76ba274-d1d5-41d1-aaf4-a14c17f8212d,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-5c30f73b-ef22-490c-bab5-39455ee4550b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128393504-172.17.0.14-1596892287234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-c39f2eb7-38fa-4445-814e-1203c3250ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-922c5c85-c116-44c2-979f-3b0f3687f9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-2714a834-bd03-47e1-8853-9af173166f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-ea8875a1-7d0e-47d1-b373-44970dfc878f,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-099003a5-d199-44d6-9e84-22475ede12f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-ffa88c72-aaf1-4310-a8dc-2405f6b63e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a76ba274-d1d5-41d1-aaf4-a14c17f8212d,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-5c30f73b-ef22-490c-bab5-39455ee4550b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465645081-172.17.0.14-1596892428324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38483,DS-1c9888e7-6d2d-44ae-acc7-0bf78168ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-18d18935-c0b2-4d51-a615-cb77027bca07,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-a853ecb1-adf2-41b1-be7b-05a494364690,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-bbc741af-5fcb-4a4c-8966-9e254ade2431,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-a8d5f52f-f26b-4b46-9231-b2c9face62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-7bf8c150-f7ae-4cb3-943f-12322cb8f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-7e631bfa-98fd-4cc9-b4d6-ea0cec1a1e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-f3f54a90-9283-4fef-bc86-33ef90c7d0a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465645081-172.17.0.14-1596892428324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38483,DS-1c9888e7-6d2d-44ae-acc7-0bf78168ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-18d18935-c0b2-4d51-a615-cb77027bca07,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-a853ecb1-adf2-41b1-be7b-05a494364690,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-bbc741af-5fcb-4a4c-8966-9e254ade2431,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-a8d5f52f-f26b-4b46-9231-b2c9face62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-7bf8c150-f7ae-4cb3-943f-12322cb8f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-7e631bfa-98fd-4cc9-b4d6-ea0cec1a1e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-f3f54a90-9283-4fef-bc86-33ef90c7d0a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825188716-172.17.0.14-1596892838244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-14a15d1b-ad87-492d-879a-9d5b697b7807,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-b0775b94-04e0-43a5-9cad-20c79f5a0234,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-3d190687-43f4-4bd7-93fe-a962a95ac352,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-1ce0ca26-8c88-43da-8778-2e2210615f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-1071887d-55a2-41ea-93a5-00be6456f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-11e1b764-f116-4e5e-b270-aaa30abeb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-b2787e90-181e-4851-a838-1ca40fd5317f,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-23fc94c3-46d6-4dab-9049-207926ea5d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825188716-172.17.0.14-1596892838244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-14a15d1b-ad87-492d-879a-9d5b697b7807,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-b0775b94-04e0-43a5-9cad-20c79f5a0234,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-3d190687-43f4-4bd7-93fe-a962a95ac352,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-1ce0ca26-8c88-43da-8778-2e2210615f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-1071887d-55a2-41ea-93a5-00be6456f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-11e1b764-f116-4e5e-b270-aaa30abeb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-b2787e90-181e-4851-a838-1ca40fd5317f,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-23fc94c3-46d6-4dab-9049-207926ea5d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885375493-172.17.0.14-1596892920659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-24a71e93-84ce-4ba5-9127-a0b030cbca65,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-324170aa-4baa-4dd1-bee3-c674a05f14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-aa3450f5-7af6-421d-9c66-28f939c7d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-d5fb86f6-298a-4068-9640-8bed7af5243b,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-0620a411-27b3-4f69-bf1c-74e476df8da1,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-089d0dc0-3d3b-4167-abc5-bcf130fd98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-d4b2ae88-574f-473f-b685-f56255f66149,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-a4086816-4b70-4c53-bb8e-bdfb22147b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885375493-172.17.0.14-1596892920659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-24a71e93-84ce-4ba5-9127-a0b030cbca65,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-324170aa-4baa-4dd1-bee3-c674a05f14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-aa3450f5-7af6-421d-9c66-28f939c7d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-d5fb86f6-298a-4068-9640-8bed7af5243b,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-0620a411-27b3-4f69-bf1c-74e476df8da1,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-089d0dc0-3d3b-4167-abc5-bcf130fd98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-d4b2ae88-574f-473f-b685-f56255f66149,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-a4086816-4b70-4c53-bb8e-bdfb22147b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651715862-172.17.0.14-1596893285640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-688eb9fd-b47d-4347-95ac-177450a0989c,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-d17439c5-ff55-479b-ae00-d4d8330f0760,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-76f599d1-af36-4eeb-8f4d-050b6d99c8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-b01fe0f4-e2a0-4ee3-a210-4b6167cc822d,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-be2d6f84-a1a2-45fb-96fc-6cec69a968a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-34d7cc68-cebc-4fbe-a914-970d2bb24715,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-9ffd6bb9-b5a6-45a9-b2db-e548664485b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-5aa8dd3c-98e8-41d4-b7e9-0488d71c6349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651715862-172.17.0.14-1596893285640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-688eb9fd-b47d-4347-95ac-177450a0989c,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-d17439c5-ff55-479b-ae00-d4d8330f0760,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-76f599d1-af36-4eeb-8f4d-050b6d99c8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-b01fe0f4-e2a0-4ee3-a210-4b6167cc822d,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-be2d6f84-a1a2-45fb-96fc-6cec69a968a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-34d7cc68-cebc-4fbe-a914-970d2bb24715,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-9ffd6bb9-b5a6-45a9-b2db-e548664485b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-5aa8dd3c-98e8-41d4-b7e9-0488d71c6349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9888421-172.17.0.14-1596893342142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33572,DS-65e48753-e99e-4e22-96fe-8ab1df32dd33,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-629774e4-ea6c-456a-a19a-4cbf64d107ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-f12d6252-56b7-4600-8226-9191977baccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-bbb5d939-854d-42c0-b3dd-85009863892d,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-cfd239dc-d5e3-462e-a055-16434d22052d,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-1d959550-bdbc-4fb3-b9e9-3158fdf50ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-74533d53-2f6e-4407-9a06-cde6ad32f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-c3d41929-7258-4b15-8d85-cfd42025aa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9888421-172.17.0.14-1596893342142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33572,DS-65e48753-e99e-4e22-96fe-8ab1df32dd33,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-629774e4-ea6c-456a-a19a-4cbf64d107ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-f12d6252-56b7-4600-8226-9191977baccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-bbb5d939-854d-42c0-b3dd-85009863892d,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-cfd239dc-d5e3-462e-a055-16434d22052d,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-1d959550-bdbc-4fb3-b9e9-3158fdf50ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-74533d53-2f6e-4407-9a06-cde6ad32f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-c3d41929-7258-4b15-8d85-cfd42025aa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503966337-172.17.0.14-1596894235109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34683,DS-7cae5622-35ca-4eac-b60d-ec234156609e,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-187159ae-8c60-4daf-bbad-8e6e4275112f,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-174ea1c9-498e-455e-818d-c3fe489e4ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-61da1279-80da-4584-95e9-0debbe59159c,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-3ed0d774-ac1b-4a9e-8cd2-da5ae3dc134b,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-78d73c9b-73a1-4c17-a5e3-7d6565510e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-60a7b0e9-6a0b-4a62-80e4-6febaeffa7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-c24182bd-1bd9-4b12-964a-32f06e18f6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503966337-172.17.0.14-1596894235109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34683,DS-7cae5622-35ca-4eac-b60d-ec234156609e,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-187159ae-8c60-4daf-bbad-8e6e4275112f,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-174ea1c9-498e-455e-818d-c3fe489e4ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-61da1279-80da-4584-95e9-0debbe59159c,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-3ed0d774-ac1b-4a9e-8cd2-da5ae3dc134b,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-78d73c9b-73a1-4c17-a5e3-7d6565510e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-60a7b0e9-6a0b-4a62-80e4-6febaeffa7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-c24182bd-1bd9-4b12-964a-32f06e18f6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94516240-172.17.0.14-1596894330875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-21b14d80-67d7-4a1c-8531-7b20b1e97e67,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-fdff7625-94ef-47a6-ba56-3ed719bb392d,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-64cd61a8-7a36-4fcd-81dc-0dfa426c59be,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ecc3f029-382d-47bb-b5e5-caf673cf15bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-68f660aa-353d-4a67-92e6-a22735d3f8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-65993d8b-9d46-42a5-b5a1-34069cbd4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-582a1144-177c-4a8c-b16e-fd58f7f0fd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-b2023cc5-3c37-4b01-a375-54021c8986d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94516240-172.17.0.14-1596894330875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-21b14d80-67d7-4a1c-8531-7b20b1e97e67,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-fdff7625-94ef-47a6-ba56-3ed719bb392d,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-64cd61a8-7a36-4fcd-81dc-0dfa426c59be,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ecc3f029-382d-47bb-b5e5-caf673cf15bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-68f660aa-353d-4a67-92e6-a22735d3f8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-65993d8b-9d46-42a5-b5a1-34069cbd4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-582a1144-177c-4a8c-b16e-fd58f7f0fd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-b2023cc5-3c37-4b01-a375-54021c8986d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561315086-172.17.0.14-1596894828092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-55decda1-8277-4f98-a651-3c8edffd1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-8001a40b-5316-41c2-b736-12fbf1b44d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-3e6ca9b7-441b-4c7d-8838-4fe26475897d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-8f70cfd1-ca1a-4383-9a28-16ba51eaf003,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-0d1c4b7a-7781-4fb1-ae3d-585b6fbfb73f,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-23a0dec4-13da-4530-ba50-73c9dfce0f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-527e383b-fdd0-431b-9ceb-5468eff4f224,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1291400a-9c49-4270-bfb2-92596a055230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561315086-172.17.0.14-1596894828092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-55decda1-8277-4f98-a651-3c8edffd1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-8001a40b-5316-41c2-b736-12fbf1b44d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-3e6ca9b7-441b-4c7d-8838-4fe26475897d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-8f70cfd1-ca1a-4383-9a28-16ba51eaf003,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-0d1c4b7a-7781-4fb1-ae3d-585b6fbfb73f,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-23a0dec4-13da-4530-ba50-73c9dfce0f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-527e383b-fdd0-431b-9ceb-5468eff4f224,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1291400a-9c49-4270-bfb2-92596a055230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043437469-172.17.0.14-1596895064232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39655,DS-5cb8e2f2-7ee3-4a5a-a393-f161d207db84,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-44268dee-79aa-45e2-b6aa-d845c3684293,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c22d76e6-c908-4988-aaa7-77523f9196ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-c0ee82b2-3a0d-4dbe-a87a-c4ee74721b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-ac990cd8-4b41-481a-8587-2cee2ef3ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-e9d61d9c-10d3-4776-b685-a3aaf5ffa4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-06ad5274-3bd2-4f1c-9cc0-5c7dc051677b,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-74eb427e-e581-4f75-a73d-fc97a53f2211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043437469-172.17.0.14-1596895064232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39655,DS-5cb8e2f2-7ee3-4a5a-a393-f161d207db84,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-44268dee-79aa-45e2-b6aa-d845c3684293,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c22d76e6-c908-4988-aaa7-77523f9196ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-c0ee82b2-3a0d-4dbe-a87a-c4ee74721b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-ac990cd8-4b41-481a-8587-2cee2ef3ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-e9d61d9c-10d3-4776-b685-a3aaf5ffa4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-06ad5274-3bd2-4f1c-9cc0-5c7dc051677b,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-74eb427e-e581-4f75-a73d-fc97a53f2211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171593443-172.17.0.14-1596895198437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-8d4bb220-e1ae-4afc-8aaf-10f6ecdc1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-5e5ba479-9dec-4851-85a7-02d376fc9668,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-2fb2d4c5-1c1a-4f36-a0be-09e570ebd1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-7529622c-2422-47c1-9e92-4ab0719b6818,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-21c0abeb-a321-4009-b660-dae541cbc10a,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-c12be968-fb63-4287-aab8-93fec13c2ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-58dbb550-ba89-4b84-8f59-abf76a3fa924,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-90399e27-5105-49ae-af9d-026a40ec89fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171593443-172.17.0.14-1596895198437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-8d4bb220-e1ae-4afc-8aaf-10f6ecdc1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-5e5ba479-9dec-4851-85a7-02d376fc9668,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-2fb2d4c5-1c1a-4f36-a0be-09e570ebd1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-7529622c-2422-47c1-9e92-4ab0719b6818,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-21c0abeb-a321-4009-b660-dae541cbc10a,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-c12be968-fb63-4287-aab8-93fec13c2ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-58dbb550-ba89-4b84-8f59-abf76a3fa924,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-90399e27-5105-49ae-af9d-026a40ec89fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274491531-172.17.0.14-1596895469738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-23caf458-9324-4007-8cc5-38b2e0a2c570,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-e154b976-0b2d-4aee-b6a8-f666f527c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-80468f49-2091-4d82-b90d-1e62a1cb1b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-7bc7916b-8ccd-4917-a8cf-ce4ae9536a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-af05dc03-497a-479c-8bab-073829831cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-90f96bd8-27f4-4133-a91e-ab051f45e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-861a1d73-e2d4-4e3f-bec6-ea05132d4628,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-b352f474-c2ea-45aa-bea5-ae29a4fbfeec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274491531-172.17.0.14-1596895469738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-23caf458-9324-4007-8cc5-38b2e0a2c570,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-e154b976-0b2d-4aee-b6a8-f666f527c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-80468f49-2091-4d82-b90d-1e62a1cb1b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-7bc7916b-8ccd-4917-a8cf-ce4ae9536a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-af05dc03-497a-479c-8bab-073829831cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-90f96bd8-27f4-4133-a91e-ab051f45e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-861a1d73-e2d4-4e3f-bec6-ea05132d4628,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-b352f474-c2ea-45aa-bea5-ae29a4fbfeec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417940378-172.17.0.14-1596895926435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-94fdac27-37c3-4d21-99e3-d1eb5c974119,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-b003ee59-a03e-43f7-97a7-5ba907259901,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-b9f97330-5c07-4573-88b8-3e8e459c9bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-09d2e3dc-91ee-4431-9dc9-7c338ec97fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-d25967ef-5911-4e06-9008-18a9614a4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-dd73ced1-2622-4097-b523-262ae2841c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-3283f19d-8de2-46be-9b9b-0ea8829cf4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-78ab1ee8-e31f-48df-8b28-dcaa01abe8f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417940378-172.17.0.14-1596895926435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-94fdac27-37c3-4d21-99e3-d1eb5c974119,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-b003ee59-a03e-43f7-97a7-5ba907259901,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-b9f97330-5c07-4573-88b8-3e8e459c9bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-09d2e3dc-91ee-4431-9dc9-7c338ec97fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-d25967ef-5911-4e06-9008-18a9614a4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-dd73ced1-2622-4097-b523-262ae2841c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-3283f19d-8de2-46be-9b9b-0ea8829cf4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-78ab1ee8-e31f-48df-8b28-dcaa01abe8f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884239337-172.17.0.14-1596896007923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37294,DS-a03b331c-6bf2-4b27-a104-72c13e4e87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-f4064632-41fc-4089-b338-f96fb24d3fde,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-24b21be2-0260-4595-9b94-d31d9e2fcba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-11eec32d-1ef2-437a-9aae-fccbea59712f,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-5d9a1324-5d67-4339-9b4a-ead2e17b37a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-c6ae0f35-fc2d-49db-a4d3-f41dd5eb7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-201440f2-7574-4f58-9db5-64bbe3e43881,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-5bea9238-6292-4669-bad3-a9f02b3419aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884239337-172.17.0.14-1596896007923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37294,DS-a03b331c-6bf2-4b27-a104-72c13e4e87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-f4064632-41fc-4089-b338-f96fb24d3fde,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-24b21be2-0260-4595-9b94-d31d9e2fcba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-11eec32d-1ef2-437a-9aae-fccbea59712f,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-5d9a1324-5d67-4339-9b4a-ead2e17b37a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-c6ae0f35-fc2d-49db-a4d3-f41dd5eb7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-201440f2-7574-4f58-9db5-64bbe3e43881,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-5bea9238-6292-4669-bad3-a9f02b3419aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981316462-172.17.0.14-1596896048212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-9cfdeed4-8b75-46dc-bec5-1214b1a55fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-ccf26e54-f4aa-48b9-bfd1-bc72f835e328,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-c9df0733-5d12-405a-936d-e88a72325586,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-bc0f43ec-20ec-46c9-9705-4b47a6acbce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-7827c3e3-9eb3-44ba-b763-acbcad2febc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-cd3c7f1d-b5be-400d-a816-2cd1234bb99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-cac28d7d-8c4c-466b-b77a-9a78531f8570,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-f733af5f-c2c2-495a-8a8c-36e44ad67b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981316462-172.17.0.14-1596896048212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-9cfdeed4-8b75-46dc-bec5-1214b1a55fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-ccf26e54-f4aa-48b9-bfd1-bc72f835e328,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-c9df0733-5d12-405a-936d-e88a72325586,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-bc0f43ec-20ec-46c9-9705-4b47a6acbce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-7827c3e3-9eb3-44ba-b763-acbcad2febc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-cd3c7f1d-b5be-400d-a816-2cd1234bb99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-cac28d7d-8c4c-466b-b77a-9a78531f8570,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-f733af5f-c2c2-495a-8a8c-36e44ad67b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211827539-172.17.0.14-1596896219284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43028,DS-9b23e299-a257-4dc1-a876-64997022d32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-73b1e3f4-dd78-4bf7-bfee-817dd3e033cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-740777b5-682a-48d0-a055-d71c816f161a,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-1a5c0f56-d7cb-4117-88d4-5b43792f32d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-3e5299a4-2276-4afb-b46e-45b604d54d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-6c6be095-7d7b-432e-abec-8b3029d445b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-b0e6a71c-28cf-4601-aa6a-92892f8b4a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-6ddeb087-f10d-4f71-872e-6802a660fac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211827539-172.17.0.14-1596896219284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43028,DS-9b23e299-a257-4dc1-a876-64997022d32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-73b1e3f4-dd78-4bf7-bfee-817dd3e033cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-740777b5-682a-48d0-a055-d71c816f161a,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-1a5c0f56-d7cb-4117-88d4-5b43792f32d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-3e5299a4-2276-4afb-b46e-45b604d54d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-6c6be095-7d7b-432e-abec-8b3029d445b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-b0e6a71c-28cf-4601-aa6a-92892f8b4a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-6ddeb087-f10d-4f71-872e-6802a660fac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19759432-172.17.0.14-1596896396440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42477,DS-17c126cb-b242-4891-8cf4-65fa6b969998,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-b8fed31f-ee4e-4f34-a4a8-835b8f667d80,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-f72114ea-a6b1-40ea-beed-45c82f9d7ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-132ad72a-867c-4a4f-a7dd-63161af75dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-b3a377b5-b8c3-4868-8748-0bfc7c39cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-01217926-eac7-4e4f-b89f-c3915758f700,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-df9576d4-f586-4514-bba6-01a30863da17,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-74d15f4b-b096-4f8c-b708-1924ab08d134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19759432-172.17.0.14-1596896396440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42477,DS-17c126cb-b242-4891-8cf4-65fa6b969998,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-b8fed31f-ee4e-4f34-a4a8-835b8f667d80,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-f72114ea-a6b1-40ea-beed-45c82f9d7ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-132ad72a-867c-4a4f-a7dd-63161af75dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-b3a377b5-b8c3-4868-8748-0bfc7c39cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-01217926-eac7-4e4f-b89f-c3915758f700,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-df9576d4-f586-4514-bba6-01a30863da17,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-74d15f4b-b096-4f8c-b708-1924ab08d134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667424062-172.17.0.14-1596896607689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38256,DS-d7953b77-5f30-4b4d-9dd1-2f9bae166bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-9675710d-b93d-4641-9bd8-67e6e6ee64c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-55ad77be-cc53-4279-a578-45c6bb6d4a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-4346d266-eec6-4b5d-a670-42b353432c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-97882ff9-2725-4c81-84c1-af62385ae032,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-ebb0b982-3bee-4bd8-8aa1-59f5ad1a73f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-282f6408-6c8d-4b03-8275-1df6c9247dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-ffaa5b78-ced8-451c-9cda-fc49119d4119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667424062-172.17.0.14-1596896607689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38256,DS-d7953b77-5f30-4b4d-9dd1-2f9bae166bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-9675710d-b93d-4641-9bd8-67e6e6ee64c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-55ad77be-cc53-4279-a578-45c6bb6d4a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-4346d266-eec6-4b5d-a670-42b353432c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-97882ff9-2725-4c81-84c1-af62385ae032,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-ebb0b982-3bee-4bd8-8aa1-59f5ad1a73f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-282f6408-6c8d-4b03-8275-1df6c9247dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-ffaa5b78-ced8-451c-9cda-fc49119d4119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6764
