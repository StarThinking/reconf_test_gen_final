reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952917849-172.17.0.3-1596951815355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-4688ddee-3442-4e49-8c95-36af23e53796,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-c8adb825-98d7-4fcc-b137-0313132959e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-871e0318-5ab0-46e5-b0e7-affbce00c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-4d50dd5a-427f-41e9-a3bc-f3293a02c468,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-761de357-d6b9-4263-8082-120be3adef82,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-cfa639a4-8e68-4bd5-a461-76e30d3a9862,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-60e1d035-ea8f-4424-b655-c89868503899,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-9b287c71-dc58-42a7-9577-93e3b73c8e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952917849-172.17.0.3-1596951815355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-4688ddee-3442-4e49-8c95-36af23e53796,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-c8adb825-98d7-4fcc-b137-0313132959e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-871e0318-5ab0-46e5-b0e7-affbce00c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-4d50dd5a-427f-41e9-a3bc-f3293a02c468,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-761de357-d6b9-4263-8082-120be3adef82,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-cfa639a4-8e68-4bd5-a461-76e30d3a9862,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-60e1d035-ea8f-4424-b655-c89868503899,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-9b287c71-dc58-42a7-9577-93e3b73c8e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248591076-172.17.0.3-1596951912178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-ca7980ca-63a1-4049-b33e-b10a77185ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-ce6e346c-916b-4817-b3a7-a6db9eb49998,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-8a6fa775-ca42-4b8c-871a-46202f4939f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-20f5f00f-1f2d-4f7e-a1f0-76195dba670e,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-31e774d7-9089-4d67-b19c-89a30972589d,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-574777f4-31d4-4483-b88d-c8b7d8c2df3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-365874fc-9e2b-4967-a0dc-5044c6f8e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-47780d02-a3e3-4903-98cb-5f0b24906f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248591076-172.17.0.3-1596951912178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-ca7980ca-63a1-4049-b33e-b10a77185ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-ce6e346c-916b-4817-b3a7-a6db9eb49998,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-8a6fa775-ca42-4b8c-871a-46202f4939f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-20f5f00f-1f2d-4f7e-a1f0-76195dba670e,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-31e774d7-9089-4d67-b19c-89a30972589d,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-574777f4-31d4-4483-b88d-c8b7d8c2df3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-365874fc-9e2b-4967-a0dc-5044c6f8e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-47780d02-a3e3-4903-98cb-5f0b24906f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234342397-172.17.0.3-1596951943803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-e4166035-b273-49db-ae92-5b23b2d54edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-88ba0bac-e08a-4f1e-9d68-39c291075ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-2d438b48-c6f6-4320-ac30-498bd4fb0774,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-260a1380-e032-45a1-87d4-64b509ad6a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-96d121dd-8383-472b-91c9-4276cd2921dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-ec476770-9314-4a74-9ae5-472370115600,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-f9b52a7d-1a23-4683-b051-62872d25c973,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-acf360cd-9606-4950-a762-b9715bef3413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234342397-172.17.0.3-1596951943803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-e4166035-b273-49db-ae92-5b23b2d54edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-88ba0bac-e08a-4f1e-9d68-39c291075ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-2d438b48-c6f6-4320-ac30-498bd4fb0774,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-260a1380-e032-45a1-87d4-64b509ad6a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-96d121dd-8383-472b-91c9-4276cd2921dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-ec476770-9314-4a74-9ae5-472370115600,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-f9b52a7d-1a23-4683-b051-62872d25c973,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-acf360cd-9606-4950-a762-b9715bef3413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364264004-172.17.0.3-1596952175645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-48642344-39cb-43a4-a177-67335bb0bfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-55b2cc15-5122-4aa8-819f-72f69a84c035,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-25faf9c8-6ff5-4cd1-8f99-d9b2351dba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-e0878e72-8242-4eda-8640-ef5161eff5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-d4be956d-4e83-488c-a6fa-1341b3b3e510,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-c9abb8a0-5d73-46f3-b361-8cb5052fc4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-b8476ffe-2e33-4ef0-a125-2d53c947a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-4cfdc4ab-59b9-4ee0-932e-69fea46caa32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364264004-172.17.0.3-1596952175645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-48642344-39cb-43a4-a177-67335bb0bfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-55b2cc15-5122-4aa8-819f-72f69a84c035,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-25faf9c8-6ff5-4cd1-8f99-d9b2351dba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-e0878e72-8242-4eda-8640-ef5161eff5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-d4be956d-4e83-488c-a6fa-1341b3b3e510,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-c9abb8a0-5d73-46f3-b361-8cb5052fc4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-b8476ffe-2e33-4ef0-a125-2d53c947a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-4cfdc4ab-59b9-4ee0-932e-69fea46caa32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126574036-172.17.0.3-1596952263932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-79d848c3-e2dc-4510-a20e-16778abb3ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-6b84af45-7629-4f6a-acc3-b947a14565a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-cc5b9ea8-2557-4eec-b5d4-c280407c6827,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-866db16f-1c84-4e1a-a5a8-35e14017f340,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-dde5869d-69e8-413b-a385-8cca18459738,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-1deb912c-8e19-4210-9a2a-07b620fe3253,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-a462889e-41cb-4dda-a108-3c970fe3291d,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-903b2cd8-685a-4559-bb3a-bf0f64f52878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126574036-172.17.0.3-1596952263932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-79d848c3-e2dc-4510-a20e-16778abb3ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-6b84af45-7629-4f6a-acc3-b947a14565a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-cc5b9ea8-2557-4eec-b5d4-c280407c6827,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-866db16f-1c84-4e1a-a5a8-35e14017f340,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-dde5869d-69e8-413b-a385-8cca18459738,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-1deb912c-8e19-4210-9a2a-07b620fe3253,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-a462889e-41cb-4dda-a108-3c970fe3291d,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-903b2cd8-685a-4559-bb3a-bf0f64f52878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60999577-172.17.0.3-1596952760529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45306,DS-bab5383d-587c-4f88-948f-b47220c6eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-58a2baa8-6355-492e-82b1-8b8be30c3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-0af57f96-a5ee-4e7e-8a6a-735bff08056f,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-3bbcb87d-f6d7-4d5c-b948-b53619d22ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-9e739cfe-4eb4-4d74-b0f2-e36509f27cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-acdf27d4-b1c2-4a56-a320-f38a6a2de8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-4cf5ec37-0daa-4bde-a514-8df040cd3d67,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-07ef8777-e347-4a4f-abc2-b32a43b01ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60999577-172.17.0.3-1596952760529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45306,DS-bab5383d-587c-4f88-948f-b47220c6eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-58a2baa8-6355-492e-82b1-8b8be30c3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-0af57f96-a5ee-4e7e-8a6a-735bff08056f,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-3bbcb87d-f6d7-4d5c-b948-b53619d22ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-9e739cfe-4eb4-4d74-b0f2-e36509f27cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-acdf27d4-b1c2-4a56-a320-f38a6a2de8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-4cf5ec37-0daa-4bde-a514-8df040cd3d67,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-07ef8777-e347-4a4f-abc2-b32a43b01ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355701386-172.17.0.3-1596953280610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-6064e860-6355-4302-95e3-8a0aaa9b4ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-c23d42cc-e8a9-4acd-8c1d-360daf5e1b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-8241005b-7795-4e3b-8b3a-199033dff3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-c7625e5a-24ee-4d81-af34-592fbf33d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-ae620f40-49f4-4612-9225-a6c2eb580dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-acbaec02-afa4-419d-9d74-8806f18f5de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-6766af0a-5471-4d89-a02c-2efdab3ed683,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-bf85ff67-128e-4c39-ab39-277fbc7d4702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355701386-172.17.0.3-1596953280610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-6064e860-6355-4302-95e3-8a0aaa9b4ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-c23d42cc-e8a9-4acd-8c1d-360daf5e1b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-8241005b-7795-4e3b-8b3a-199033dff3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-c7625e5a-24ee-4d81-af34-592fbf33d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-ae620f40-49f4-4612-9225-a6c2eb580dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-acbaec02-afa4-419d-9d74-8806f18f5de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-6766af0a-5471-4d89-a02c-2efdab3ed683,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-bf85ff67-128e-4c39-ab39-277fbc7d4702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489075656-172.17.0.3-1596954085911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-5fb97ef8-21f7-4d93-8db1-e100f5b6bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-be90546e-cd3f-452f-979b-b6388f3f395c,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-7e3a076a-effb-41f1-999d-7682c3260538,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-58ada545-2780-486a-a9f2-a6a54fd40ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-0894f458-f78f-4a27-a712-b0c7c22d9715,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-7faba42d-cc90-43c3-8dac-c53ab6ad4ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-f46893ff-6f0e-416f-9e35-2dba3d830d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2f60df60-2491-49b0-b920-ac62ac77bba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489075656-172.17.0.3-1596954085911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-5fb97ef8-21f7-4d93-8db1-e100f5b6bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-be90546e-cd3f-452f-979b-b6388f3f395c,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-7e3a076a-effb-41f1-999d-7682c3260538,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-58ada545-2780-486a-a9f2-a6a54fd40ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-0894f458-f78f-4a27-a712-b0c7c22d9715,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-7faba42d-cc90-43c3-8dac-c53ab6ad4ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-f46893ff-6f0e-416f-9e35-2dba3d830d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2f60df60-2491-49b0-b920-ac62ac77bba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241076622-172.17.0.3-1596954531381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-08383337-78ac-41a6-a5b2-b23753623346,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-e293d3c6-ce03-464d-9cc0-dccc51fa38c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-27bdd0e6-7460-456c-891c-18c46b74c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-5af09e3c-5101-412a-a6f1-85fb61a8aee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-99ab5daf-da1c-4908-8cd0-ec8c204c3976,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-13c5812a-6e1e-4296-b2a1-91efce84c567,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-937424b5-ca3d-4339-a592-1af9102c866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-3b440ccc-43f6-4ae3-a233-9d140823b02f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241076622-172.17.0.3-1596954531381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-08383337-78ac-41a6-a5b2-b23753623346,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-e293d3c6-ce03-464d-9cc0-dccc51fa38c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-27bdd0e6-7460-456c-891c-18c46b74c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-5af09e3c-5101-412a-a6f1-85fb61a8aee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-99ab5daf-da1c-4908-8cd0-ec8c204c3976,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-13c5812a-6e1e-4296-b2a1-91efce84c567,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-937424b5-ca3d-4339-a592-1af9102c866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-3b440ccc-43f6-4ae3-a233-9d140823b02f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924558162-172.17.0.3-1596955142677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35432,DS-2b231535-39d6-4aba-9b07-a275aab62642,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ebe6e75d-f58f-4f41-9965-96abed59abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-eca79c9a-b9da-42ca-a74b-d0cee933cdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-0740e184-4d73-4852-87b2-2bbd308b2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e06d1443-1a84-4f61-9a05-89c59e23670b,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-58304734-7233-41f4-9880-bac0f2c99804,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-40d8c6ae-3ae6-4971-8f7f-13446cbef506,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-3d4cdb4c-48a8-47b2-b1e9-69a3418f0667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924558162-172.17.0.3-1596955142677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35432,DS-2b231535-39d6-4aba-9b07-a275aab62642,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ebe6e75d-f58f-4f41-9965-96abed59abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-eca79c9a-b9da-42ca-a74b-d0cee933cdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-0740e184-4d73-4852-87b2-2bbd308b2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e06d1443-1a84-4f61-9a05-89c59e23670b,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-58304734-7233-41f4-9880-bac0f2c99804,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-40d8c6ae-3ae6-4971-8f7f-13446cbef506,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-3d4cdb4c-48a8-47b2-b1e9-69a3418f0667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828771822-172.17.0.3-1596955671556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-0ef5d70b-3343-409b-a14c-d01fa8f4eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-71be7412-c3e9-4bc8-8bd4-b634684dafb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-c6f08f63-98e5-4b5e-b41a-880049ff5059,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-fd206b73-58c8-44c2-8bf5-3152a2b84bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-5e7f124c-69ed-4d0d-b20a-1b487a4a35a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-ac568798-0c50-4fc5-b568-af8e7fa62245,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-a24cc233-99fa-4079-84ec-f78fdbaa4e81,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-efc0e792-239c-438b-a28c-c31ce45d8880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828771822-172.17.0.3-1596955671556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-0ef5d70b-3343-409b-a14c-d01fa8f4eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-71be7412-c3e9-4bc8-8bd4-b634684dafb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-c6f08f63-98e5-4b5e-b41a-880049ff5059,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-fd206b73-58c8-44c2-8bf5-3152a2b84bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-5e7f124c-69ed-4d0d-b20a-1b487a4a35a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-ac568798-0c50-4fc5-b568-af8e7fa62245,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-a24cc233-99fa-4079-84ec-f78fdbaa4e81,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-efc0e792-239c-438b-a28c-c31ce45d8880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507310404-172.17.0.3-1596956156527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-e1f65d97-f9f9-431e-88e3-48f64de50027,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-a6023986-99ef-47e0-a163-6234db9ae694,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-750aca8b-497a-4f37-968c-694e26b3aee6,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-78f2098c-ab79-4e19-b373-cd9ac1794a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-1a371186-9bbd-4a1d-8553-884dbbb1d156,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-588b117e-763e-4e24-91e8-5c848d644921,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-1c6c0a55-5e06-47e6-aab3-c6b4a488c614,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-36c69e62-2f45-42a1-8a13-1e71ba4a3a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507310404-172.17.0.3-1596956156527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-e1f65d97-f9f9-431e-88e3-48f64de50027,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-a6023986-99ef-47e0-a163-6234db9ae694,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-750aca8b-497a-4f37-968c-694e26b3aee6,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-78f2098c-ab79-4e19-b373-cd9ac1794a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-1a371186-9bbd-4a1d-8553-884dbbb1d156,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-588b117e-763e-4e24-91e8-5c848d644921,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-1c6c0a55-5e06-47e6-aab3-c6b4a488c614,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-36c69e62-2f45-42a1-8a13-1e71ba4a3a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085672814-172.17.0.3-1596956226433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-84278d42-cd7d-49ed-a83a-345d5ed6d643,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-4ce0a2fe-2f57-4abc-aff7-46bdcc299a48,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-80f9387b-cb51-4606-b913-a0f7fddfccab,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-14b5b20b-5ce2-453f-bc00-87b921481f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-c279c011-38e9-4682-aac2-1131fadb9ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-cd2e0cdb-745c-469f-852b-f8d31ab84467,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-ebb1d33d-5fc5-483c-b0ca-355f4b0e683b,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-be601a91-4574-448e-bbf2-a7c3ca72a4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085672814-172.17.0.3-1596956226433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36965,DS-84278d42-cd7d-49ed-a83a-345d5ed6d643,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-4ce0a2fe-2f57-4abc-aff7-46bdcc299a48,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-80f9387b-cb51-4606-b913-a0f7fddfccab,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-14b5b20b-5ce2-453f-bc00-87b921481f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-c279c011-38e9-4682-aac2-1131fadb9ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-cd2e0cdb-745c-469f-852b-f8d31ab84467,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-ebb1d33d-5fc5-483c-b0ca-355f4b0e683b,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-be601a91-4574-448e-bbf2-a7c3ca72a4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638220712-172.17.0.3-1596956342275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-107666da-f710-4156-a061-3c57e63be5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-21487814-673f-4da7-b72d-8a7325a185a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-ea28288b-839e-434a-881c-c6ab14bace0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-26052391-732a-4545-aa02-135b17120d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-286d7bae-34b6-432f-9869-4aa6fd43eca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-294f67fb-667a-43ed-8659-780a26fe3290,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-60fdf425-4fe6-40bb-8238-f5ea18b0f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-6311e6d6-6952-4a14-98d2-4eae0297fb5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638220712-172.17.0.3-1596956342275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-107666da-f710-4156-a061-3c57e63be5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-21487814-673f-4da7-b72d-8a7325a185a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-ea28288b-839e-434a-881c-c6ab14bace0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-26052391-732a-4545-aa02-135b17120d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-286d7bae-34b6-432f-9869-4aa6fd43eca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-294f67fb-667a-43ed-8659-780a26fe3290,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-60fdf425-4fe6-40bb-8238-f5ea18b0f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-6311e6d6-6952-4a14-98d2-4eae0297fb5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4890
