reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923743246-172.17.0.14-1596891565836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39323,DS-06f6e5e3-3644-4991-998a-879bc16b9a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-18e00ede-87e6-45c4-b4bf-c993d351a2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-d6d09abb-49e0-43c2-a256-aa292758fa40,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-c2eb42b5-f9b9-4097-8422-12eaf49424ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-bcfb7804-93be-462b-a013-4014214b3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-c98c05c5-2615-4809-9523-2eca4f0bf630,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-ed0b97d2-65e6-4b88-aecd-16bc83c1eac7,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-8938ff7e-8607-4b11-aad5-cd4c2ce57bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923743246-172.17.0.14-1596891565836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39323,DS-06f6e5e3-3644-4991-998a-879bc16b9a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-18e00ede-87e6-45c4-b4bf-c993d351a2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-d6d09abb-49e0-43c2-a256-aa292758fa40,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-c2eb42b5-f9b9-4097-8422-12eaf49424ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-bcfb7804-93be-462b-a013-4014214b3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-c98c05c5-2615-4809-9523-2eca4f0bf630,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-ed0b97d2-65e6-4b88-aecd-16bc83c1eac7,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-8938ff7e-8607-4b11-aad5-cd4c2ce57bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913546790-172.17.0.14-1596892070410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40441,DS-b00ea183-d7a4-4499-aaec-542433a4434f,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-6c59dee5-00ce-4011-91f2-5d4862b84a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-fb969fb7-febf-48b9-a87a-00e87484fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-33b00a81-992b-4d68-bd27-00cc2db476b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-fc5092c5-385c-479f-86d2-e7cc605fca57,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-07c4baa0-9fca-4e3a-9e2e-90046e7eb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-e97f6a54-f090-4ef1-a8a1-7c24e0440323,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-875911d3-499b-4b42-be90-87844c34bf83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913546790-172.17.0.14-1596892070410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40441,DS-b00ea183-d7a4-4499-aaec-542433a4434f,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-6c59dee5-00ce-4011-91f2-5d4862b84a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-fb969fb7-febf-48b9-a87a-00e87484fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-33b00a81-992b-4d68-bd27-00cc2db476b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-fc5092c5-385c-479f-86d2-e7cc605fca57,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-07c4baa0-9fca-4e3a-9e2e-90046e7eb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-e97f6a54-f090-4ef1-a8a1-7c24e0440323,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-875911d3-499b-4b42-be90-87844c34bf83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92011421-172.17.0.14-1596892110997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-91911c8c-0c39-49d2-b9a7-80b40a159bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-3ce0833e-c707-404b-8b6c-203cb504eec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-07c95518-4509-43ab-bed2-20c28087d1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-5719edf7-fdfe-4c27-ba74-4b9eb892cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-f1f546fe-1c6f-4bda-9bc3-9e3c204deb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-7fe2774a-04af-400c-a96e-0ae8c1523396,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-d79a5c98-9267-428b-bf6c-6fed6b44ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-521565ca-7afe-46ae-81c4-973a74b1c276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92011421-172.17.0.14-1596892110997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-91911c8c-0c39-49d2-b9a7-80b40a159bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-3ce0833e-c707-404b-8b6c-203cb504eec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-07c95518-4509-43ab-bed2-20c28087d1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-5719edf7-fdfe-4c27-ba74-4b9eb892cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-f1f546fe-1c6f-4bda-9bc3-9e3c204deb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-7fe2774a-04af-400c-a96e-0ae8c1523396,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-d79a5c98-9267-428b-bf6c-6fed6b44ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-521565ca-7afe-46ae-81c4-973a74b1c276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840673113-172.17.0.14-1596892975312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32845,DS-422d18cb-29b4-43cc-a7db-76c89740e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-4a8ade41-026d-4489-91fb-a3e6f7a01c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-d6a55ced-b085-4b43-a9f6-c6dfeec64e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-d4548a16-83df-46dc-9651-7a6a32bf9931,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4a67530b-eda9-4995-96cf-c278121627db,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-e08d1859-57ed-4a27-810c-1d14f65554c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-7025a93a-05cb-438b-9e00-7acc8152e900,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-1161280a-193c-400c-83a8-81f12ada7cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840673113-172.17.0.14-1596892975312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32845,DS-422d18cb-29b4-43cc-a7db-76c89740e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-4a8ade41-026d-4489-91fb-a3e6f7a01c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-d6a55ced-b085-4b43-a9f6-c6dfeec64e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-d4548a16-83df-46dc-9651-7a6a32bf9931,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4a67530b-eda9-4995-96cf-c278121627db,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-e08d1859-57ed-4a27-810c-1d14f65554c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-7025a93a-05cb-438b-9e00-7acc8152e900,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-1161280a-193c-400c-83a8-81f12ada7cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414357533-172.17.0.14-1596893115659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41425,DS-fda29694-c329-4ded-b27c-bbebdcf44262,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-c8a3e1b2-4079-4209-80b2-a1fcf5f1cce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-2efd895c-9ad5-4480-ad8c-707d80252aee,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-3be19f0b-e306-421f-9c52-ee3b630c1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-819c6af8-a94c-4352-88d9-f46f86d9ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-d37f7738-a38e-4dbc-8b46-b209b0bdc8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-ebcf159d-5ae5-4b0a-9aa8-e77b87cab9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-a3d5a5da-7bbe-40ab-b8f4-53f6b9f0999b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414357533-172.17.0.14-1596893115659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41425,DS-fda29694-c329-4ded-b27c-bbebdcf44262,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-c8a3e1b2-4079-4209-80b2-a1fcf5f1cce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-2efd895c-9ad5-4480-ad8c-707d80252aee,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-3be19f0b-e306-421f-9c52-ee3b630c1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-819c6af8-a94c-4352-88d9-f46f86d9ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-d37f7738-a38e-4dbc-8b46-b209b0bdc8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-ebcf159d-5ae5-4b0a-9aa8-e77b87cab9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-a3d5a5da-7bbe-40ab-b8f4-53f6b9f0999b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946335638-172.17.0.14-1596893400373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-55c09f5a-7e87-4153-ae10-c8e8e6cdebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-bc99385d-89cf-4c65-92fc-2dd4b1efc1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-3f582b91-542f-45f6-aa86-452b4734ded7,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-fa346809-570a-413f-874e-a929561fdfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-b29fde50-28bd-4b47-8c85-61dd56b8f5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-08a29072-08c3-4abb-b298-05d032c7c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-4af192b3-c1b0-4a87-9082-83dc1d5fc0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-9b35566f-765f-439e-b5d8-af4edeaaf606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946335638-172.17.0.14-1596893400373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-55c09f5a-7e87-4153-ae10-c8e8e6cdebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-bc99385d-89cf-4c65-92fc-2dd4b1efc1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-3f582b91-542f-45f6-aa86-452b4734ded7,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-fa346809-570a-413f-874e-a929561fdfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-b29fde50-28bd-4b47-8c85-61dd56b8f5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-08a29072-08c3-4abb-b298-05d032c7c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-4af192b3-c1b0-4a87-9082-83dc1d5fc0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-9b35566f-765f-439e-b5d8-af4edeaaf606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950915072-172.17.0.14-1596893779117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34922,DS-e42694c7-36b9-46f6-81d5-7a5f09a06516,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-7778834c-5639-4376-acbf-a14ff801a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-2cd35221-10cd-4867-a91a-bf6cd3e463c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-00c6fe83-3293-4098-a068-4f8ceeb493e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-190658f9-96a1-401d-a2bd-9feb9d2f0d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-752d99dc-f62f-4eac-8734-86c5f5c0fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-32592c7a-6bf5-4a67-ab0c-e39c4047dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-0c29f941-64f1-4849-832c-7856334f380f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950915072-172.17.0.14-1596893779117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34922,DS-e42694c7-36b9-46f6-81d5-7a5f09a06516,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-7778834c-5639-4376-acbf-a14ff801a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-2cd35221-10cd-4867-a91a-bf6cd3e463c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-00c6fe83-3293-4098-a068-4f8ceeb493e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-190658f9-96a1-401d-a2bd-9feb9d2f0d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-752d99dc-f62f-4eac-8734-86c5f5c0fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-32592c7a-6bf5-4a67-ab0c-e39c4047dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-0c29f941-64f1-4849-832c-7856334f380f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028546109-172.17.0.14-1596893921289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38765,DS-32d2c7c6-d343-4380-bce4-4434f7374a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-af9fad12-f9b8-4434-8029-1c1f342fa3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-888a7a9a-f6b6-4578-be7c-6b6f031bfef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-12ed9079-d1aa-4571-92d1-315bbefcd4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-732af871-1352-4003-bd98-6ba21adee43f,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-72c46f24-8df4-4718-8ea0-15e8853c0503,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-ea486a66-639a-4129-ac3b-7173baeb4822,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-3e614e06-291e-401c-b05e-2e7868619e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028546109-172.17.0.14-1596893921289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38765,DS-32d2c7c6-d343-4380-bce4-4434f7374a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-af9fad12-f9b8-4434-8029-1c1f342fa3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-888a7a9a-f6b6-4578-be7c-6b6f031bfef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-12ed9079-d1aa-4571-92d1-315bbefcd4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-732af871-1352-4003-bd98-6ba21adee43f,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-72c46f24-8df4-4718-8ea0-15e8853c0503,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-ea486a66-639a-4129-ac3b-7173baeb4822,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-3e614e06-291e-401c-b05e-2e7868619e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195009420-172.17.0.14-1596894537117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-dd7d5b12-32b5-4472-af4a-476d81efe7db,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-74728d16-f153-47b0-b58d-05d48e661557,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-7ed405f1-beb8-4e90-a649-74ac2400a555,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-7cd5bbd1-348d-4271-8236-bf9efa0ffef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-86c94c65-afca-470c-a3d8-25de53e583af,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-057f96bf-b658-4a8e-ad4f-d57329c82908,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-84915182-9caa-4e52-87b5-1cf255130bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-a6dac09f-4e81-4dea-b502-42173f4c1d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195009420-172.17.0.14-1596894537117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-dd7d5b12-32b5-4472-af4a-476d81efe7db,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-74728d16-f153-47b0-b58d-05d48e661557,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-7ed405f1-beb8-4e90-a649-74ac2400a555,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-7cd5bbd1-348d-4271-8236-bf9efa0ffef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-86c94c65-afca-470c-a3d8-25de53e583af,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-057f96bf-b658-4a8e-ad4f-d57329c82908,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-84915182-9caa-4e52-87b5-1cf255130bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-a6dac09f-4e81-4dea-b502-42173f4c1d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497699458-172.17.0.14-1596894667440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-efa18338-671c-4a4f-bf43-9d49874e41be,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-8b64d84b-657c-4207-b3a1-80cd2a4cc49f,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-489bd8e4-57ba-43f0-8883-a7ece1c6d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-c3a9473e-43e7-4a45-a4a8-da4ed69a0112,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-e8cb5005-c767-44ea-ad3e-db2335f70e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-817d8b99-401f-45ed-893a-568cdf179572,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-1d8ad7b4-73a4-428b-8829-248e0e54d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ab60af74-8913-4a8b-ae52-52fd93db1e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497699458-172.17.0.14-1596894667440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-efa18338-671c-4a4f-bf43-9d49874e41be,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-8b64d84b-657c-4207-b3a1-80cd2a4cc49f,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-489bd8e4-57ba-43f0-8883-a7ece1c6d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-c3a9473e-43e7-4a45-a4a8-da4ed69a0112,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-e8cb5005-c767-44ea-ad3e-db2335f70e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-817d8b99-401f-45ed-893a-568cdf179572,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-1d8ad7b4-73a4-428b-8829-248e0e54d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ab60af74-8913-4a8b-ae52-52fd93db1e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472171405-172.17.0.14-1596895004225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-0f326bc6-66c2-46c3-8ccd-9ef4c135ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-5ef61c5f-e589-43b0-bab8-62863c66281a,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-af54a56f-ec09-49a2-be70-f0ba903ac29b,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-46166a04-69d5-4529-ac44-1589ffc8c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-e9f9e95d-4675-4531-aa0f-bd6acd162074,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-22774a2f-b007-4649-b846-91e2d79ea4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-8aa199fe-fb59-4f18-8a76-749c60e12b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-1a2cbc1c-1daf-4acc-82f0-06e85c795281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472171405-172.17.0.14-1596895004225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-0f326bc6-66c2-46c3-8ccd-9ef4c135ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-5ef61c5f-e589-43b0-bab8-62863c66281a,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-af54a56f-ec09-49a2-be70-f0ba903ac29b,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-46166a04-69d5-4529-ac44-1589ffc8c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-e9f9e95d-4675-4531-aa0f-bd6acd162074,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-22774a2f-b007-4649-b846-91e2d79ea4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-8aa199fe-fb59-4f18-8a76-749c60e12b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-1a2cbc1c-1daf-4acc-82f0-06e85c795281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106340103-172.17.0.14-1596895078215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-79230f92-4e2b-4925-a832-6a78a7de9e42,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-8a3909ab-65e3-4abd-a41a-b8d865561ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-1abf71b0-d955-40f8-8e58-3e6cf774aeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-d31d1bac-75ef-409e-9792-13d63eff428b,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-da024564-beea-431b-989b-f09585e9c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-f67e0cfb-a859-4d14-8fdd-e9a7859e12e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-dd9a5882-7e87-4673-9e00-a61bd56b6b06,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-114ceb09-ca85-4fe5-a995-143938125abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106340103-172.17.0.14-1596895078215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-79230f92-4e2b-4925-a832-6a78a7de9e42,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-8a3909ab-65e3-4abd-a41a-b8d865561ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-1abf71b0-d955-40f8-8e58-3e6cf774aeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-d31d1bac-75ef-409e-9792-13d63eff428b,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-da024564-beea-431b-989b-f09585e9c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-f67e0cfb-a859-4d14-8fdd-e9a7859e12e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-dd9a5882-7e87-4673-9e00-a61bd56b6b06,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-114ceb09-ca85-4fe5-a995-143938125abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566034591-172.17.0.14-1596895208606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-a299c59a-c6b7-4a1a-9964-c8a4adb57d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-551e3b4a-2b4d-4d07-a5b5-7458eeefb885,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-d68123c3-98ba-4dd5-9c7f-086134f00bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-eb64619d-ac85-4758-b1fc-0a129473b390,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-9b1a6a19-679f-48df-8399-d851152fb5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-b129ca3b-cb25-4ecf-8f4c-6ce0f0dc7055,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-b08a7c03-31bc-42bb-b14f-7f72aec5f068,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-37b260f9-00a5-4270-b517-41797e37344e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566034591-172.17.0.14-1596895208606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-a299c59a-c6b7-4a1a-9964-c8a4adb57d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-551e3b4a-2b4d-4d07-a5b5-7458eeefb885,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-d68123c3-98ba-4dd5-9c7f-086134f00bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-eb64619d-ac85-4758-b1fc-0a129473b390,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-9b1a6a19-679f-48df-8399-d851152fb5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-b129ca3b-cb25-4ecf-8f4c-6ce0f0dc7055,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-b08a7c03-31bc-42bb-b14f-7f72aec5f068,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-37b260f9-00a5-4270-b517-41797e37344e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576075274-172.17.0.14-1596895307109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39526,DS-e613cec4-5015-4f36-af10-ec774e6d920a,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-74f84279-6a2b-4436-9b36-bdc6227f9faf,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-5930c449-fcaa-4458-a66c-c5f06fb30f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-1a241057-f3fc-4000-8138-3b27083e7975,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-4596cd39-7201-4072-b330-cccf9ddcb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-2d8276de-32ef-402a-84c5-daac42b544ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-1eca472d-f227-441d-ae50-08da6c211b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-9604e414-01d1-4d8b-a19e-4d3743b16c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576075274-172.17.0.14-1596895307109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39526,DS-e613cec4-5015-4f36-af10-ec774e6d920a,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-74f84279-6a2b-4436-9b36-bdc6227f9faf,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-5930c449-fcaa-4458-a66c-c5f06fb30f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-1a241057-f3fc-4000-8138-3b27083e7975,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-4596cd39-7201-4072-b330-cccf9ddcb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-2d8276de-32ef-402a-84c5-daac42b544ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-1eca472d-f227-441d-ae50-08da6c211b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-9604e414-01d1-4d8b-a19e-4d3743b16c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609682623-172.17.0.14-1596895409479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42267,DS-f638028e-f34d-4650-83ed-60faa51db730,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-e75ccfd9-bc9d-499f-bf11-e407d6ab0014,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-b764aa57-de53-4034-9f3e-5e892b1e02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-bc5c4455-c7c5-4c39-bee0-96c31cf6b69b,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-fe614afa-57eb-440c-ab01-b54cb91d781b,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-4f2b6e15-6d76-413b-b42d-8d29cc8b589e,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-db811f09-0984-4a2c-8ec2-c7e8e46b332d,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-51d285cb-2832-4419-9fb7-b7a8badca583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609682623-172.17.0.14-1596895409479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42267,DS-f638028e-f34d-4650-83ed-60faa51db730,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-e75ccfd9-bc9d-499f-bf11-e407d6ab0014,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-b764aa57-de53-4034-9f3e-5e892b1e02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-bc5c4455-c7c5-4c39-bee0-96c31cf6b69b,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-fe614afa-57eb-440c-ab01-b54cb91d781b,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-4f2b6e15-6d76-413b-b42d-8d29cc8b589e,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-db811f09-0984-4a2c-8ec2-c7e8e46b332d,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-51d285cb-2832-4419-9fb7-b7a8badca583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766968640-172.17.0.14-1596896161284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-1b21792f-573d-4a12-8d74-1e46b21fb3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-74a34d7f-553a-44ad-99cd-fe32c211f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-ba84296c-9a40-4949-98ec-537220f8abfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-a35eb2ab-700a-40ca-aafe-33fbb182c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-cf144389-b775-4303-b7b8-40858cd55b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-187d2a09-a9b7-4819-be42-3c3413f6ad55,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-1ade2a0d-6a7d-4b09-af13-96c3e6e87f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-d6ab030e-7abb-49aa-9367-2cafcd974dc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766968640-172.17.0.14-1596896161284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-1b21792f-573d-4a12-8d74-1e46b21fb3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-74a34d7f-553a-44ad-99cd-fe32c211f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-ba84296c-9a40-4949-98ec-537220f8abfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-a35eb2ab-700a-40ca-aafe-33fbb182c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-cf144389-b775-4303-b7b8-40858cd55b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-187d2a09-a9b7-4819-be42-3c3413f6ad55,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-1ade2a0d-6a7d-4b09-af13-96c3e6e87f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-d6ab030e-7abb-49aa-9367-2cafcd974dc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382966285-172.17.0.14-1596896317878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-30549137-e0c2-4a0b-b2c6-66ba87454a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-64c2f3cc-36fc-4b4b-8f4b-b6db7822ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-9164693e-375e-47ea-abbf-dcdc4b678ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-6d68d5de-204b-4bc0-ae20-48b41ee2a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-be19542c-5537-4c11-8145-269ce2e0e229,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-566262c2-57ab-4b0b-9009-59483187a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-c1d4aa31-1d58-4fcf-9f20-fbc5950a8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-c0f51afd-2644-4197-af57-7b81a4d0cd31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382966285-172.17.0.14-1596896317878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-30549137-e0c2-4a0b-b2c6-66ba87454a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-64c2f3cc-36fc-4b4b-8f4b-b6db7822ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-9164693e-375e-47ea-abbf-dcdc4b678ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-6d68d5de-204b-4bc0-ae20-48b41ee2a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-be19542c-5537-4c11-8145-269ce2e0e229,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-566262c2-57ab-4b0b-9009-59483187a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-c1d4aa31-1d58-4fcf-9f20-fbc5950a8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-c0f51afd-2644-4197-af57-7b81a4d0cd31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5146
