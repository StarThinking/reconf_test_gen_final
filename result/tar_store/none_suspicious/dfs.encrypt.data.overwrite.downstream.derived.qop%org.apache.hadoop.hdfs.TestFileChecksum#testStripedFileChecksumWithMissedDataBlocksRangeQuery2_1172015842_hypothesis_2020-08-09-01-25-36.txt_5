reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779262887-172.17.0.17-1596936649427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41043,DS-e6adfbbb-7e52-4cd8-a6e8-ab8253e002a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-c26f8740-74d5-4c5d-b528-dcde2e35b015,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-032c983a-99df-43ca-85c4-46f0682fdcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-db1c85b4-328f-4c89-95a8-befa030469f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-bfdc033b-5f44-49f0-8402-d0c156f31e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-2d5e13e8-32a1-4206-ad44-4ec4188f3330,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8d65ea30-cbf3-4705-b21d-8b90c50a22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c7fb7ff6-7d11-47d7-8f61-083ec3ede7f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779262887-172.17.0.17-1596936649427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41043,DS-e6adfbbb-7e52-4cd8-a6e8-ab8253e002a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-c26f8740-74d5-4c5d-b528-dcde2e35b015,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-032c983a-99df-43ca-85c4-46f0682fdcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-db1c85b4-328f-4c89-95a8-befa030469f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-bfdc033b-5f44-49f0-8402-d0c156f31e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-2d5e13e8-32a1-4206-ad44-4ec4188f3330,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8d65ea30-cbf3-4705-b21d-8b90c50a22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c7fb7ff6-7d11-47d7-8f61-083ec3ede7f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940810340-172.17.0.17-1596937211536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41578,DS-cccf2764-8aab-4eb5-9988-7623e217aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-0b6fecd4-6cee-4b6e-8e24-c1136fdf28da,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-539ac8dd-8c5f-4bca-8b0f-0f7ea8d67afa,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-c0bbb10e-c8df-49f1-a63f-8a5549e052ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-029934a6-11ad-46a3-9d50-a815c0dbefff,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-36071918-e6c6-433f-8444-451c422b87be,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-228fdd1b-5b27-4fa2-9263-c7cbc6463d08,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-1a637e10-fdde-4fa0-ac7b-e70e9c571269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940810340-172.17.0.17-1596937211536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41578,DS-cccf2764-8aab-4eb5-9988-7623e217aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-0b6fecd4-6cee-4b6e-8e24-c1136fdf28da,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-539ac8dd-8c5f-4bca-8b0f-0f7ea8d67afa,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-c0bbb10e-c8df-49f1-a63f-8a5549e052ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-029934a6-11ad-46a3-9d50-a815c0dbefff,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-36071918-e6c6-433f-8444-451c422b87be,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-228fdd1b-5b27-4fa2-9263-c7cbc6463d08,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-1a637e10-fdde-4fa0-ac7b-e70e9c571269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587996883-172.17.0.17-1596937301156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-1d5fbe13-4b1f-42e5-9867-d42f2eb56615,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-e5bfaa6f-35b6-4a5d-bb81-04303eb20aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-fc085ee5-1e6e-4a33-86d6-79179183783e,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-7490142b-100c-40b3-8dd4-ecf6cd1c5a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-39cc710b-b1cd-48eb-a4dc-c5d28ce35a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-edd76fb7-0469-4023-813f-c76dafaef410,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-9b6f68f8-6443-42c4-b487-5a358caf64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-e71123d6-cc90-4f23-aa58-31aa4fb5fa1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587996883-172.17.0.17-1596937301156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-1d5fbe13-4b1f-42e5-9867-d42f2eb56615,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-e5bfaa6f-35b6-4a5d-bb81-04303eb20aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-fc085ee5-1e6e-4a33-86d6-79179183783e,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-7490142b-100c-40b3-8dd4-ecf6cd1c5a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-39cc710b-b1cd-48eb-a4dc-c5d28ce35a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-edd76fb7-0469-4023-813f-c76dafaef410,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-9b6f68f8-6443-42c4-b487-5a358caf64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-e71123d6-cc90-4f23-aa58-31aa4fb5fa1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321097091-172.17.0.17-1596937684897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-0585f115-2c68-4764-9e29-eb1a79096c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-20e7b477-8d6d-461b-a131-5d27002c274e,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-bb931491-674c-4577-b8ba-f6783032a880,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-5dd7e40d-8ad2-4606-a681-bc3cb3a19fba,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-30dab0b2-98f0-4ac2-bd4d-8bd73a50d465,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-aff1e85c-3230-4ded-a088-d156438e7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-08912407-d258-4a7c-9fe6-3b7144c56699,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-b1ab8978-22a1-4c67-be56-6975e84465fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321097091-172.17.0.17-1596937684897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-0585f115-2c68-4764-9e29-eb1a79096c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-20e7b477-8d6d-461b-a131-5d27002c274e,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-bb931491-674c-4577-b8ba-f6783032a880,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-5dd7e40d-8ad2-4606-a681-bc3cb3a19fba,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-30dab0b2-98f0-4ac2-bd4d-8bd73a50d465,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-aff1e85c-3230-4ded-a088-d156438e7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-08912407-d258-4a7c-9fe6-3b7144c56699,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-b1ab8978-22a1-4c67-be56-6975e84465fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581380579-172.17.0.17-1596937820144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-9acdf632-3663-455e-8506-fb9cfcd0f896,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-d6ffedba-0eb5-4829-9a2c-c6bd4a73a916,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-f6e19687-4773-4c15-9591-bacde7e2eff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-8d31fa7a-7c79-4187-8c1b-39ca1ae4877e,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-1763674b-a0b7-4165-98b1-8252bc876229,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-99be8946-766e-48f7-9a70-2d7162f6c8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-937f6b99-211a-4ca3-a136-32520b4b524b,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-cdcae70c-e7f3-42e3-9a2b-0419b0ada748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581380579-172.17.0.17-1596937820144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-9acdf632-3663-455e-8506-fb9cfcd0f896,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-d6ffedba-0eb5-4829-9a2c-c6bd4a73a916,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-f6e19687-4773-4c15-9591-bacde7e2eff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-8d31fa7a-7c79-4187-8c1b-39ca1ae4877e,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-1763674b-a0b7-4165-98b1-8252bc876229,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-99be8946-766e-48f7-9a70-2d7162f6c8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-937f6b99-211a-4ca3-a136-32520b4b524b,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-cdcae70c-e7f3-42e3-9a2b-0419b0ada748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583145001-172.17.0.17-1596938198050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-d714cd1a-a2a2-4ca0-b27a-15e2d4785ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-55e22e7c-9944-4e85-bc5b-2b2d0f97c1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-e21af066-b3ef-4e61-a7fd-e97401aac523,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-c5e6313b-b71b-4707-bc0d-9670c8d92580,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-f1f3fe1a-3410-449b-a203-19a290637737,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-51f5ddc3-50fb-4ba5-887c-2bc324ae0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-7ff00fb6-fdb3-4c37-a51e-c834ed311bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-96253208-8e3a-4aa2-86bc-a34263513be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583145001-172.17.0.17-1596938198050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-d714cd1a-a2a2-4ca0-b27a-15e2d4785ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-55e22e7c-9944-4e85-bc5b-2b2d0f97c1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-e21af066-b3ef-4e61-a7fd-e97401aac523,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-c5e6313b-b71b-4707-bc0d-9670c8d92580,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-f1f3fe1a-3410-449b-a203-19a290637737,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-51f5ddc3-50fb-4ba5-887c-2bc324ae0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-7ff00fb6-fdb3-4c37-a51e-c834ed311bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-96253208-8e3a-4aa2-86bc-a34263513be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019236938-172.17.0.17-1596938313858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-6866c013-f320-48f5-b921-70f3c51e5e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-734a6b16-f011-4cd4-b667-2684185a1e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-2e719dfc-10a1-4e09-aaa2-b1f7ad667d65,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-c7e9b268-1e65-46f8-9a54-0bd6fc85c040,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-cd15192e-af15-4cb3-8684-7e93a0306128,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-8ecfedfc-d6c4-4fc3-afcf-d00c6e18cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-cfeadc97-5d92-4c73-9e3d-d35eac13629b,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-33884d15-45b4-49f9-8f93-4c2bf2f68427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019236938-172.17.0.17-1596938313858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-6866c013-f320-48f5-b921-70f3c51e5e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-734a6b16-f011-4cd4-b667-2684185a1e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-2e719dfc-10a1-4e09-aaa2-b1f7ad667d65,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-c7e9b268-1e65-46f8-9a54-0bd6fc85c040,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-cd15192e-af15-4cb3-8684-7e93a0306128,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-8ecfedfc-d6c4-4fc3-afcf-d00c6e18cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-cfeadc97-5d92-4c73-9e3d-d35eac13629b,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-33884d15-45b4-49f9-8f93-4c2bf2f68427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412794919-172.17.0.17-1596938824201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41560,DS-8b921057-d450-4691-babb-99b039170903,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-6cefd3b1-1727-4ef6-b327-f1384621d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-b9480368-3595-46b7-8f11-2c99afaa99c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-2e86d990-6b73-4bf1-8804-91db0ca52dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-decf7541-ad68-4724-9a53-d10e27edc0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-e01b639a-7e38-40ee-be50-10499f6789a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-013ebfe2-44ed-49a6-99ec-324511e8b2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-99cc40a7-8c1d-46f6-84e0-5c8755e78848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412794919-172.17.0.17-1596938824201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41560,DS-8b921057-d450-4691-babb-99b039170903,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-6cefd3b1-1727-4ef6-b327-f1384621d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-b9480368-3595-46b7-8f11-2c99afaa99c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-2e86d990-6b73-4bf1-8804-91db0ca52dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-decf7541-ad68-4724-9a53-d10e27edc0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-e01b639a-7e38-40ee-be50-10499f6789a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-013ebfe2-44ed-49a6-99ec-324511e8b2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-99cc40a7-8c1d-46f6-84e0-5c8755e78848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610083188-172.17.0.17-1596939114167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37423,DS-787cac72-cd34-4441-bafe-8170dd755090,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-9a39fe3c-fbf8-4061-be88-02d115303989,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-7b8eeda0-bbf2-4032-a006-e07f779190dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-4390d2af-2a33-4471-ab3f-e1f584f64674,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-8bc1295a-0a23-4237-b187-0098024cfeca,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-645f9ee2-59a6-4483-8594-2c4b13a7efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-c4caf398-7d8b-476a-99d8-3657ae9241b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a221d311-c3f4-4671-9a50-f05b7deca48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610083188-172.17.0.17-1596939114167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37423,DS-787cac72-cd34-4441-bafe-8170dd755090,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-9a39fe3c-fbf8-4061-be88-02d115303989,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-7b8eeda0-bbf2-4032-a006-e07f779190dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-4390d2af-2a33-4471-ab3f-e1f584f64674,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-8bc1295a-0a23-4237-b187-0098024cfeca,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-645f9ee2-59a6-4483-8594-2c4b13a7efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-c4caf398-7d8b-476a-99d8-3657ae9241b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a221d311-c3f4-4671-9a50-f05b7deca48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784115372-172.17.0.17-1596939242848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-055131f1-33df-4bac-9a6a-42c88e9a0937,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-3a17c725-d7fe-46c0-b504-a13a6aaaed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-de06750e-6f2b-4735-a541-368bed178fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-ccf532c9-5f14-4808-a4a7-a2733a6c2e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-d2892359-13f6-49de-b2c2-11b1cb538d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-7676b271-f092-4271-93df-ff6f3fa096b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-e9966da5-34fa-46bf-b107-776db545898a,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-f14b1644-d0eb-4830-8b02-782cc3f2a613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784115372-172.17.0.17-1596939242848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-055131f1-33df-4bac-9a6a-42c88e9a0937,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-3a17c725-d7fe-46c0-b504-a13a6aaaed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-de06750e-6f2b-4735-a541-368bed178fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-ccf532c9-5f14-4808-a4a7-a2733a6c2e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-d2892359-13f6-49de-b2c2-11b1cb538d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-7676b271-f092-4271-93df-ff6f3fa096b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-e9966da5-34fa-46bf-b107-776db545898a,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-f14b1644-d0eb-4830-8b02-782cc3f2a613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721147022-172.17.0.17-1596939328954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44342,DS-e2372269-d02b-423d-9f3c-c56998dc9153,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-8ee3cbdb-e443-4799-a752-23101a0750d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-a29f35d8-4ccf-4a19-acf4-7df34ff4ac20,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-9f19901e-99a5-4771-a702-cc3c24711e26,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-4dacb589-3edf-48fb-8fae-eb61c9de99bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-2dfd67eb-630d-4ad8-9105-1c778a682e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-986a4465-eb13-434b-b08f-23caf27f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-a475923e-d641-49e3-b3a3-47abd29915b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721147022-172.17.0.17-1596939328954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44342,DS-e2372269-d02b-423d-9f3c-c56998dc9153,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-8ee3cbdb-e443-4799-a752-23101a0750d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-a29f35d8-4ccf-4a19-acf4-7df34ff4ac20,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-9f19901e-99a5-4771-a702-cc3c24711e26,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-4dacb589-3edf-48fb-8fae-eb61c9de99bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-2dfd67eb-630d-4ad8-9105-1c778a682e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-986a4465-eb13-434b-b08f-23caf27f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-a475923e-d641-49e3-b3a3-47abd29915b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374669791-172.17.0.17-1596939718263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-fbd7c8af-fcd3-4f5e-9938-9feea00bee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-d1d00c10-6e94-41fa-b895-061036462ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-856d85cf-35ae-4fc8-adff-ed88feee5532,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-0fffba3a-7974-4aea-9a58-1946229c02e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-820493ae-e325-4be3-a7d9-e8a322cd495d,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-92402105-049e-40d4-8496-1bb3f3c3d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-2d19aa96-9f1f-49ca-b228-173cd7aa96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-9c0480db-f36a-4ab0-bb10-df7c1dd10383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374669791-172.17.0.17-1596939718263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-fbd7c8af-fcd3-4f5e-9938-9feea00bee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-d1d00c10-6e94-41fa-b895-061036462ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-856d85cf-35ae-4fc8-adff-ed88feee5532,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-0fffba3a-7974-4aea-9a58-1946229c02e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-820493ae-e325-4be3-a7d9-e8a322cd495d,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-92402105-049e-40d4-8496-1bb3f3c3d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-2d19aa96-9f1f-49ca-b228-173cd7aa96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-9c0480db-f36a-4ab0-bb10-df7c1dd10383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22708054-172.17.0.17-1596940137814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45136,DS-16a0144a-675d-4b62-8129-521cfdc6fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-dd56eaea-ddc7-4448-8adb-64c32b48e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-6a0ecee4-e984-453f-8c58-b5effa981b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-b348db3d-760d-41ac-ac30-55c9a4a8f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-f6caf9b3-9250-4743-afa6-ea6515225de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-57a665b1-fbf5-42b3-9f5e-997e03d2cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-1ef9dcce-76b2-40d5-8008-0d4132413722,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-8d1dd920-fecb-46e5-896d-917711c567ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22708054-172.17.0.17-1596940137814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45136,DS-16a0144a-675d-4b62-8129-521cfdc6fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-dd56eaea-ddc7-4448-8adb-64c32b48e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-6a0ecee4-e984-453f-8c58-b5effa981b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-b348db3d-760d-41ac-ac30-55c9a4a8f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-f6caf9b3-9250-4743-afa6-ea6515225de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-57a665b1-fbf5-42b3-9f5e-997e03d2cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-1ef9dcce-76b2-40d5-8008-0d4132413722,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-8d1dd920-fecb-46e5-896d-917711c567ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405456645-172.17.0.17-1596940540258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-633f67a0-7580-4226-943c-3a506fa5ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-27b9f1ac-47a5-4fa6-a8b0-1f7a8434f359,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-a7ecd95f-fada-425f-9dbb-de365f357010,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-4846f3d7-5235-4f77-90bb-258727e10738,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-d3d1c01e-23c7-4185-a79e-ed47129f4e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-98257252-156f-4a35-a54e-f7112e61e265,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-8fe13f00-1384-40c0-af14-071c0fa9d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-1032e320-dcbc-47f2-91c4-df15b6ef3986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405456645-172.17.0.17-1596940540258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-633f67a0-7580-4226-943c-3a506fa5ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-27b9f1ac-47a5-4fa6-a8b0-1f7a8434f359,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-a7ecd95f-fada-425f-9dbb-de365f357010,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-4846f3d7-5235-4f77-90bb-258727e10738,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-d3d1c01e-23c7-4185-a79e-ed47129f4e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-98257252-156f-4a35-a54e-f7112e61e265,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-8fe13f00-1384-40c0-af14-071c0fa9d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-1032e320-dcbc-47f2-91c4-df15b6ef3986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450126212-172.17.0.17-1596940661065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-0a4f883b-bb54-4202-b7de-67130a96c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-4dccf6d6-3680-469e-991e-5ff4de14ae37,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-758d888a-7dee-4cd6-a537-2964a0a2eb91,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-2b3ae7d5-35fe-47fc-97b7-05b5f5e72ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-ed9f9f4a-6daa-4f8d-abed-5802d9093eee,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-0f7cf98d-6f96-4300-b3a7-7b1e4a06f476,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-7ee701fc-ed82-46a5-bde4-e36e9c21c505,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-8a440161-bd90-4572-835c-df14084949ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450126212-172.17.0.17-1596940661065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-0a4f883b-bb54-4202-b7de-67130a96c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-4dccf6d6-3680-469e-991e-5ff4de14ae37,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-758d888a-7dee-4cd6-a537-2964a0a2eb91,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-2b3ae7d5-35fe-47fc-97b7-05b5f5e72ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-ed9f9f4a-6daa-4f8d-abed-5802d9093eee,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-0f7cf98d-6f96-4300-b3a7-7b1e4a06f476,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-7ee701fc-ed82-46a5-bde4-e36e9c21c505,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-8a440161-bd90-4572-835c-df14084949ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819951981-172.17.0.17-1596940744397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41814,DS-fe755410-548f-4fff-83b3-0b8ce492348e,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-4fec7964-3c24-43f2-b0a6-79ec72b8cc60,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-a1a066e3-3933-4182-91d5-c58f4a86fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-f3fe7331-632d-4f38-89f3-789f210e6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-933bcd06-6a65-45b8-b427-4ca0707c610b,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-9727297c-1552-4070-b3ed-cda1dc00bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-b42af1bc-ca56-446d-ab4c-0d7d8c833828,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-11b5e72f-0dad-48cf-83ad-c05df2060293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819951981-172.17.0.17-1596940744397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41814,DS-fe755410-548f-4fff-83b3-0b8ce492348e,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-4fec7964-3c24-43f2-b0a6-79ec72b8cc60,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-a1a066e3-3933-4182-91d5-c58f4a86fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-f3fe7331-632d-4f38-89f3-789f210e6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-933bcd06-6a65-45b8-b427-4ca0707c610b,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-9727297c-1552-4070-b3ed-cda1dc00bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-b42af1bc-ca56-446d-ab4c-0d7d8c833828,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-11b5e72f-0dad-48cf-83ad-c05df2060293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069712137-172.17.0.17-1596941159403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36467,DS-cea7e421-4a47-4365-818f-356ade68487d,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-c6cf9c95-bf62-4dcb-9b2a-2d1ad31d5a26,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-d8ea7bef-237e-474f-824f-1c4976c1884d,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f87aa380-d170-4c46-af5b-e4728960bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-75260baf-6a5b-4153-8c09-0d7f758a5778,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-86ae5630-06ed-4d35-82f4-fe55879d0f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-7ee533a3-92be-44f2-a87c-53843aada22c,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-d25f390e-541a-4e99-981b-4b37981ed668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069712137-172.17.0.17-1596941159403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36467,DS-cea7e421-4a47-4365-818f-356ade68487d,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-c6cf9c95-bf62-4dcb-9b2a-2d1ad31d5a26,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-d8ea7bef-237e-474f-824f-1c4976c1884d,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f87aa380-d170-4c46-af5b-e4728960bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-75260baf-6a5b-4153-8c09-0d7f758a5778,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-86ae5630-06ed-4d35-82f4-fe55879d0f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-7ee533a3-92be-44f2-a87c-53843aada22c,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-d25f390e-541a-4e99-981b-4b37981ed668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623136672-172.17.0.17-1596941195401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-362fd6a6-3bfd-467b-8377-99685249d140,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-17ea79d3-6637-43b5-bc0a-d50df92df75c,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-bb1588bf-b0f8-4be8-9329-846d27ec2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-1372e121-a9c8-4a9c-b2ed-89666a78d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-488a6369-f8e1-45c1-86c3-150ed1e4a294,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b43a96a5-ff18-4f07-95ae-c65af3186f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-3db5d0a5-ba67-487f-a33b-280cb110ceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-c37b5597-1043-492d-a1d6-b382219f04e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623136672-172.17.0.17-1596941195401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-362fd6a6-3bfd-467b-8377-99685249d140,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-17ea79d3-6637-43b5-bc0a-d50df92df75c,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-bb1588bf-b0f8-4be8-9329-846d27ec2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-1372e121-a9c8-4a9c-b2ed-89666a78d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-488a6369-f8e1-45c1-86c3-150ed1e4a294,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b43a96a5-ff18-4f07-95ae-c65af3186f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-3db5d0a5-ba67-487f-a33b-280cb110ceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-c37b5597-1043-492d-a1d6-b382219f04e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398764518-172.17.0.17-1596941399864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-f4dcd17a-ade0-4ba9-841c-ecbacfbb5592,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-62cfdf21-373b-49af-8fd8-fc2beba9988a,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-9f0ee5e0-d3cb-4131-8067-05c346ac4651,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-c24efbbb-47fa-49bf-b0e1-55026c740bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-ba4d8ef3-77b3-469c-a68d-5b8f449993aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-2425e32c-6a9f-44d7-8705-3ef7c96a6517,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-a76cdf33-fe8a-4478-8ec4-3d01e357784f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-352b46de-ce52-4ace-bd41-288183c0902b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398764518-172.17.0.17-1596941399864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-f4dcd17a-ade0-4ba9-841c-ecbacfbb5592,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-62cfdf21-373b-49af-8fd8-fc2beba9988a,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-9f0ee5e0-d3cb-4131-8067-05c346ac4651,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-c24efbbb-47fa-49bf-b0e1-55026c740bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-ba4d8ef3-77b3-469c-a68d-5b8f449993aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-2425e32c-6a9f-44d7-8705-3ef7c96a6517,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-a76cdf33-fe8a-4478-8ec4-3d01e357784f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-352b46de-ce52-4ace-bd41-288183c0902b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915626501-172.17.0.17-1596941607027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45482,DS-49b40f18-6fc9-44e1-8dbc-48e109bea54b,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-cf8bfc7b-695c-415c-ada1-d217e7d5ddd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-316bbfcb-00e1-467a-bb49-1c29f0389271,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-cf747971-d93f-478f-8c65-193bf76dc24b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-4ee7ea35-951f-43f5-bec0-8179b55a5a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-6b2fb3b3-9cfa-4464-8ff2-36870850ce49,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-e5d851bc-824f-4f92-b8fb-748d76e2eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-6eda76eb-1297-41cb-a084-f6915a28a19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915626501-172.17.0.17-1596941607027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45482,DS-49b40f18-6fc9-44e1-8dbc-48e109bea54b,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-cf8bfc7b-695c-415c-ada1-d217e7d5ddd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-316bbfcb-00e1-467a-bb49-1c29f0389271,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-cf747971-d93f-478f-8c65-193bf76dc24b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-4ee7ea35-951f-43f5-bec0-8179b55a5a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-6b2fb3b3-9cfa-4464-8ff2-36870850ce49,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-e5d851bc-824f-4f92-b8fb-748d76e2eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-6eda76eb-1297-41cb-a084-f6915a28a19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695825942-172.17.0.17-1596942057257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37706,DS-d088dc27-44a6-4787-a303-402a76cfca43,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-72a89f09-ef33-45e8-8161-be03380f35c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-a448ed31-2f60-4f96-b8d6-e69bd0508a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-7e9b856b-9578-4762-9c70-9d2bb761cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-a98212fb-38ac-4475-81fe-0dd183a2102b,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-f593ccf8-a70f-403e-b9f4-e70fdff5dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-2b2a5baa-4303-42ba-9973-c45e774b98aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-805a5897-7b83-4a32-a4b4-3a3137cc7f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695825942-172.17.0.17-1596942057257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37706,DS-d088dc27-44a6-4787-a303-402a76cfca43,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-72a89f09-ef33-45e8-8161-be03380f35c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-a448ed31-2f60-4f96-b8d6-e69bd0508a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-7e9b856b-9578-4762-9c70-9d2bb761cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-a98212fb-38ac-4475-81fe-0dd183a2102b,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-f593ccf8-a70f-403e-b9f4-e70fdff5dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-2b2a5baa-4303-42ba-9973-c45e774b98aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-805a5897-7b83-4a32-a4b4-3a3137cc7f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580540542-172.17.0.17-1596942514854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38514,DS-be0861c1-985a-40bf-989f-0bf413b0aeed,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-a782c7ab-6661-41fa-affa-4346c3435235,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-fa6a8b8f-4807-41f8-857d-0c5ea41a06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-55b68e51-a974-47a7-8935-b758758f50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-8b9f1421-844a-415b-a503-22305df651c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-95b479a1-54c5-47bd-8857-dc0d375099f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-6121f202-aa5e-4468-a259-8ba577747331,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-39e19226-ea94-4037-8cb1-8ca818fedfec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580540542-172.17.0.17-1596942514854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38514,DS-be0861c1-985a-40bf-989f-0bf413b0aeed,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-a782c7ab-6661-41fa-affa-4346c3435235,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-fa6a8b8f-4807-41f8-857d-0c5ea41a06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-55b68e51-a974-47a7-8935-b758758f50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-8b9f1421-844a-415b-a503-22305df651c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-95b479a1-54c5-47bd-8857-dc0d375099f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-6121f202-aa5e-4468-a259-8ba577747331,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-39e19226-ea94-4037-8cb1-8ca818fedfec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 6324
