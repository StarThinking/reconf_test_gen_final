reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041525451-172.17.0.16-1596868384284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43624,DS-afe63568-ed70-486d-b75d-4dee177fef49,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-e32d042c-0829-44c1-8a47-8c7a0c249a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-5eedacb0-eaf8-40e9-99e1-607c503c5545,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-3559bca3-47fe-4c08-8047-7431240b3a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-98da90d5-d2ef-4339-a201-c8fcd9bba340,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-569aedbe-3256-4bc1-a323-8c3384f8f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-a98e6237-9c95-4296-9435-035b1cb2d2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-6f93665d-c7b0-43e9-b10b-8dec321e43e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041525451-172.17.0.16-1596868384284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43624,DS-afe63568-ed70-486d-b75d-4dee177fef49,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-e32d042c-0829-44c1-8a47-8c7a0c249a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-5eedacb0-eaf8-40e9-99e1-607c503c5545,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-3559bca3-47fe-4c08-8047-7431240b3a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-98da90d5-d2ef-4339-a201-c8fcd9bba340,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-569aedbe-3256-4bc1-a323-8c3384f8f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-a98e6237-9c95-4296-9435-035b1cb2d2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-6f93665d-c7b0-43e9-b10b-8dec321e43e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163853732-172.17.0.16-1596868864865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-32d7eec1-efa0-43a6-abcf-56e441367989,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-dba97b83-37a5-498f-bde6-d723ffc56ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-626272dd-c5c2-4cc1-979b-21a622c5ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-5eb0af4b-f0a2-4b24-ae3c-63628bdbfa05,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-f4e6dbc7-5781-4c7a-a44f-5fc1983c3503,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-c05d3da2-6bfb-40f5-9c1a-d9b7d5617195,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-7a6760ed-333d-4a00-8f6f-3d6ee85ba870,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-86f09984-68c2-4724-af3d-9fe932405218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163853732-172.17.0.16-1596868864865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-32d7eec1-efa0-43a6-abcf-56e441367989,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-dba97b83-37a5-498f-bde6-d723ffc56ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-626272dd-c5c2-4cc1-979b-21a622c5ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-5eb0af4b-f0a2-4b24-ae3c-63628bdbfa05,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-f4e6dbc7-5781-4c7a-a44f-5fc1983c3503,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-c05d3da2-6bfb-40f5-9c1a-d9b7d5617195,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-7a6760ed-333d-4a00-8f6f-3d6ee85ba870,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-86f09984-68c2-4724-af3d-9fe932405218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182869232-172.17.0.16-1596869136541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-bf662a05-2382-4143-946a-0a0920efed81,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-bcdf307b-fcd6-42b1-82c8-0b7d505737e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-e047965a-36ba-4e2e-a7f7-126d160629eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-b0570bb6-60a7-4b96-8f12-b2d810b8848b,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c4687e31-ff8a-417c-9d93-48959c17fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-74d5c00b-9669-4a6a-b9ba-9cc3350bd877,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-e21aa011-5aa6-4404-bc68-f9aeff75dc69,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-03a4cfae-edfe-4404-b4c2-86f17af4ca4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182869232-172.17.0.16-1596869136541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-bf662a05-2382-4143-946a-0a0920efed81,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-bcdf307b-fcd6-42b1-82c8-0b7d505737e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-e047965a-36ba-4e2e-a7f7-126d160629eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-b0570bb6-60a7-4b96-8f12-b2d810b8848b,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c4687e31-ff8a-417c-9d93-48959c17fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-74d5c00b-9669-4a6a-b9ba-9cc3350bd877,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-e21aa011-5aa6-4404-bc68-f9aeff75dc69,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-03a4cfae-edfe-4404-b4c2-86f17af4ca4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236244780-172.17.0.16-1596870632996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-10420b72-a19e-40ab-a93e-944e8c30d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-648deeba-76a7-4bf5-b96a-9746f38a8721,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-50bd848a-229e-46e3-8d29-791d0f1d52b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-686443d6-da51-4dc5-9ab6-8bbaf04227e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-4f67854a-c50e-40dd-81c9-cdc84f206db5,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-cae5f8e5-177c-40d7-b0c2-0d5517d15b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-9ef816b7-22ed-4ebd-9e6a-be9040871ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-156e3c5c-b969-46bd-8418-d8a4a311f999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236244780-172.17.0.16-1596870632996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-10420b72-a19e-40ab-a93e-944e8c30d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-648deeba-76a7-4bf5-b96a-9746f38a8721,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-50bd848a-229e-46e3-8d29-791d0f1d52b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-686443d6-da51-4dc5-9ab6-8bbaf04227e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-4f67854a-c50e-40dd-81c9-cdc84f206db5,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-cae5f8e5-177c-40d7-b0c2-0d5517d15b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-9ef816b7-22ed-4ebd-9e6a-be9040871ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-156e3c5c-b969-46bd-8418-d8a4a311f999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219884827-172.17.0.16-1596871479634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34374,DS-444a177b-b65d-43b8-959c-6c18f439ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-ae84f391-f51b-4ffa-ba30-38d126137496,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-4a4e389e-8ede-448e-89ed-3d0ddc6b954a,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-eb73afa0-ff1d-435c-bd5e-664bc83846d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-dcbfeec7-ce6f-4e95-9499-8dee3dccc680,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-b45ec20c-ad27-4d1d-ac5f-b0e046392e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-f9c514be-01f1-439a-a5f4-ef4f9149ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-7115bc91-598b-43c6-a9b3-4f0cead237af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219884827-172.17.0.16-1596871479634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34374,DS-444a177b-b65d-43b8-959c-6c18f439ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-ae84f391-f51b-4ffa-ba30-38d126137496,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-4a4e389e-8ede-448e-89ed-3d0ddc6b954a,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-eb73afa0-ff1d-435c-bd5e-664bc83846d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-dcbfeec7-ce6f-4e95-9499-8dee3dccc680,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-b45ec20c-ad27-4d1d-ac5f-b0e046392e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-f9c514be-01f1-439a-a5f4-ef4f9149ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-7115bc91-598b-43c6-a9b3-4f0cead237af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169304394-172.17.0.16-1596871554530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-6fb47818-58c2-43e1-8800-cf95025d3bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-717464f4-5f81-4bba-8745-a53f9ccebbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-e52cad7f-ec70-4f46-baf2-a05cc1a6f826,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-29995c0b-08ed-45f3-b768-a577e3f67b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-04a4acc9-df13-4422-809a-773cadc6bddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-2ba88967-b156-4695-a1f7-acd4081c0a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-e28608bb-ffd9-4ce2-ba54-241e9489f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-5a068bfc-6669-4d7c-bc73-25c2de702ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169304394-172.17.0.16-1596871554530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-6fb47818-58c2-43e1-8800-cf95025d3bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-717464f4-5f81-4bba-8745-a53f9ccebbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-e52cad7f-ec70-4f46-baf2-a05cc1a6f826,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-29995c0b-08ed-45f3-b768-a577e3f67b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-04a4acc9-df13-4422-809a-773cadc6bddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-2ba88967-b156-4695-a1f7-acd4081c0a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-e28608bb-ffd9-4ce2-ba54-241e9489f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-5a068bfc-6669-4d7c-bc73-25c2de702ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625760151-172.17.0.16-1596871795301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-3de6e636-e280-41f8-b2c3-645e605255a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-49adc5de-a502-49f0-ad61-7ced0f9b7f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-32ff0f20-048d-44fc-8633-83d0034c7f39,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-f531af7d-09f5-474b-9582-e14d45b60b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-c812b65b-0f63-4582-82cc-86b8e9450069,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-52fed02f-30b5-41d0-9753-8c6eae0af6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-54aa5855-6559-4615-9085-679bbf35bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-420d7fc3-beb2-488b-b4b5-2448e00e45f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625760151-172.17.0.16-1596871795301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-3de6e636-e280-41f8-b2c3-645e605255a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-49adc5de-a502-49f0-ad61-7ced0f9b7f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-32ff0f20-048d-44fc-8633-83d0034c7f39,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-f531af7d-09f5-474b-9582-e14d45b60b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-c812b65b-0f63-4582-82cc-86b8e9450069,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-52fed02f-30b5-41d0-9753-8c6eae0af6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-54aa5855-6559-4615-9085-679bbf35bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-420d7fc3-beb2-488b-b4b5-2448e00e45f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231883470-172.17.0.16-1596871980025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36113,DS-037686ee-50b4-4785-bab3-0c46c6f5deee,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-87fb78cb-0658-456a-b680-c5c4c750f779,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-2de83c0f-0588-420b-81cf-dc635464a259,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-33a4a1d8-b20a-44ff-9e80-c19f2b95f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-76d82620-da5a-400b-bc69-e3bb1879b5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-a4497397-9e32-400c-b931-932bc429bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-e6b0e50b-bef7-4ee7-8b71-e424eb78cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-f94e5388-ad4a-4ebb-b363-683aa5bffd0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231883470-172.17.0.16-1596871980025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36113,DS-037686ee-50b4-4785-bab3-0c46c6f5deee,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-87fb78cb-0658-456a-b680-c5c4c750f779,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-2de83c0f-0588-420b-81cf-dc635464a259,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-33a4a1d8-b20a-44ff-9e80-c19f2b95f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-76d82620-da5a-400b-bc69-e3bb1879b5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-a4497397-9e32-400c-b931-932bc429bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-e6b0e50b-bef7-4ee7-8b71-e424eb78cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-f94e5388-ad4a-4ebb-b363-683aa5bffd0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482483800-172.17.0.16-1596872798245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-a3089a1a-27b7-4920-bad5-bb96db3667e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-25e3ed80-b051-49fe-8fa7-9020ce706e18,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-8f97e0b8-516b-4307-a204-cbbbb03094c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-ad416832-fc26-4d95-9542-78171eac1db2,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-5971c34c-af51-4950-b8f5-d62f723a16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-035a5fd8-7e7d-4a29-9625-1c3872932d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-b441bd5d-9db2-4d98-802f-b294c2fa9377,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-4875edbc-deec-4d74-8876-e5a6c16888a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482483800-172.17.0.16-1596872798245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-a3089a1a-27b7-4920-bad5-bb96db3667e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-25e3ed80-b051-49fe-8fa7-9020ce706e18,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-8f97e0b8-516b-4307-a204-cbbbb03094c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-ad416832-fc26-4d95-9542-78171eac1db2,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-5971c34c-af51-4950-b8f5-d62f723a16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-035a5fd8-7e7d-4a29-9625-1c3872932d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-b441bd5d-9db2-4d98-802f-b294c2fa9377,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-4875edbc-deec-4d74-8876-e5a6c16888a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969667608-172.17.0.16-1596873021112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-a185a593-43d9-4e34-865c-345adb7d283f,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-f1fdaed3-d51c-4b47-88d6-39212b35a580,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-7a273c82-6755-46b5-9234-0a4b7c8d5456,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-327b2e43-1a22-472b-9e86-57b5e1a9629c,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-2216a238-bad3-4430-b4cc-36a53d5d1c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-cd8e3f8d-0e3d-4635-91ac-dcb216163a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-46b41122-c65b-40e3-b714-213e068a2b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7830aba3-3c50-457d-8c9b-a7b7b7a92e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969667608-172.17.0.16-1596873021112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-a185a593-43d9-4e34-865c-345adb7d283f,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-f1fdaed3-d51c-4b47-88d6-39212b35a580,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-7a273c82-6755-46b5-9234-0a4b7c8d5456,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-327b2e43-1a22-472b-9e86-57b5e1a9629c,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-2216a238-bad3-4430-b4cc-36a53d5d1c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-cd8e3f8d-0e3d-4635-91ac-dcb216163a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-46b41122-c65b-40e3-b714-213e068a2b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7830aba3-3c50-457d-8c9b-a7b7b7a92e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5156
