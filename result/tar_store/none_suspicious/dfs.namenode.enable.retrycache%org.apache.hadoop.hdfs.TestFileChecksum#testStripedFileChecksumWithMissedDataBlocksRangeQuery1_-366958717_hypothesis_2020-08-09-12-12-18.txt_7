reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913094981-172.17.0.6-1596975215632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38052,DS-1c66b55e-fee2-4b6e-be25-78d6d6138bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-5d35e020-2cf0-4d31-9480-8f5fc0454740,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-4ec768fa-c3ec-4475-bde6-0844e834f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-5973f53b-d8bc-49d7-b894-a1e698f505d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-7cf9e5b1-ae8f-44f2-9bc4-030ec520ee14,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-fc487c87-3dec-4609-8819-c522cb5e39bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-37b26719-c62b-4c5d-ae83-976c210e60b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-9b18460f-9f26-4b58-a24c-f6c9d539a22f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913094981-172.17.0.6-1596975215632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38052,DS-1c66b55e-fee2-4b6e-be25-78d6d6138bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-5d35e020-2cf0-4d31-9480-8f5fc0454740,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-4ec768fa-c3ec-4475-bde6-0844e834f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-5973f53b-d8bc-49d7-b894-a1e698f505d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-7cf9e5b1-ae8f-44f2-9bc4-030ec520ee14,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-fc487c87-3dec-4609-8819-c522cb5e39bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-37b26719-c62b-4c5d-ae83-976c210e60b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-9b18460f-9f26-4b58-a24c-f6c9d539a22f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501733634-172.17.0.6-1596975464631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-399e3672-4785-4f7d-83e0-f9909ca11ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-8c4111a5-5227-4d3a-aa0a-93e280e45f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-019ba43a-4df4-4065-8ef2-5bda342c362f,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-28ef3d15-9065-403d-b971-f57522ef1036,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-176f6242-c5ce-4d6f-b399-aaddb84be26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-f827cce0-a035-4c58-8dcf-bf64ecb98970,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-bece81fd-8d02-4ef3-9077-9f885fc6b254,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-a4ce8af2-82af-4a0b-a375-dbff258a3ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501733634-172.17.0.6-1596975464631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-399e3672-4785-4f7d-83e0-f9909ca11ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-8c4111a5-5227-4d3a-aa0a-93e280e45f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-019ba43a-4df4-4065-8ef2-5bda342c362f,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-28ef3d15-9065-403d-b971-f57522ef1036,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-176f6242-c5ce-4d6f-b399-aaddb84be26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-f827cce0-a035-4c58-8dcf-bf64ecb98970,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-bece81fd-8d02-4ef3-9077-9f885fc6b254,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-a4ce8af2-82af-4a0b-a375-dbff258a3ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862121424-172.17.0.6-1596975679662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37066,DS-d71a623d-d215-4d2c-b11e-d62bc3d93133,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-2d423d32-cc69-4535-889a-b0cf522283b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-abe7e030-9a25-4f1d-ad80-a8f76786de1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-98140eb1-3f8b-4ffa-b0af-4fee12100b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ce1e8233-7af4-4bd1-877c-5a9f1e742b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-c5f90abd-cd93-4be1-b294-42612aa302a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-8861eeec-0c56-4e06-aab1-c53069f7f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-b496453d-9bd0-47c9-8b53-5481fa9c1d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862121424-172.17.0.6-1596975679662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37066,DS-d71a623d-d215-4d2c-b11e-d62bc3d93133,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-2d423d32-cc69-4535-889a-b0cf522283b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-abe7e030-9a25-4f1d-ad80-a8f76786de1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-98140eb1-3f8b-4ffa-b0af-4fee12100b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ce1e8233-7af4-4bd1-877c-5a9f1e742b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-c5f90abd-cd93-4be1-b294-42612aa302a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-8861eeec-0c56-4e06-aab1-c53069f7f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-b496453d-9bd0-47c9-8b53-5481fa9c1d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454394094-172.17.0.6-1596975794125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-fc28a827-8992-4803-8865-541a391d4887,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-50266ea9-ed37-45a1-a7a0-f094ed3c9b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-383e8808-8667-4517-b280-77ba9716c789,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-60fa6d89-1427-45cc-ab73-c03ecbc0092a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-fdfdcc7f-d224-4086-a31e-40569deeff50,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-225b8e3b-4b82-47bd-95d6-da188958dc31,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-9a1566b5-180e-4c2b-b80a-9f85a1e5b642,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-1ca9c10f-d5db-491b-b234-f63bfdb3ca30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454394094-172.17.0.6-1596975794125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-fc28a827-8992-4803-8865-541a391d4887,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-50266ea9-ed37-45a1-a7a0-f094ed3c9b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-383e8808-8667-4517-b280-77ba9716c789,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-60fa6d89-1427-45cc-ab73-c03ecbc0092a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-fdfdcc7f-d224-4086-a31e-40569deeff50,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-225b8e3b-4b82-47bd-95d6-da188958dc31,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-9a1566b5-180e-4c2b-b80a-9f85a1e5b642,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-1ca9c10f-d5db-491b-b234-f63bfdb3ca30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012959599-172.17.0.6-1596976054251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44208,DS-09cb5a48-f985-4482-b791-21e0d611a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-35b09ddd-8855-436a-a669-60032d201f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-4adca4aa-8dbc-48e1-8244-7441a476d6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-1abe86ff-4f31-44c4-8520-848d3a866045,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-123d8490-93d6-4d31-be80-c9f0db2e1ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4cd37687-596f-49f0-bfa2-e97800d709b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-7d24a4d9-f642-4cd7-9571-cb7f7e921368,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-ec54b2ad-e760-4b6f-a03d-0b309f57e3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012959599-172.17.0.6-1596976054251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44208,DS-09cb5a48-f985-4482-b791-21e0d611a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-35b09ddd-8855-436a-a669-60032d201f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-4adca4aa-8dbc-48e1-8244-7441a476d6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-1abe86ff-4f31-44c4-8520-848d3a866045,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-123d8490-93d6-4d31-be80-c9f0db2e1ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4cd37687-596f-49f0-bfa2-e97800d709b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-7d24a4d9-f642-4cd7-9571-cb7f7e921368,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-ec54b2ad-e760-4b6f-a03d-0b309f57e3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616281244-172.17.0.6-1596976629710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-091ef1c5-b7bf-4e10-95b0-bedb0497f806,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-ccff5897-f17c-4554-a7d5-e89d59da09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-bab3cc94-680e-4484-854d-836ea58bc316,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-27995500-02d0-40ec-b15f-0bd14da2b582,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-afdcf48e-a10c-4c22-b6ed-28fac08d7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-5430e7fc-aa85-4973-87b8-753b47ac9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-85546b48-23c6-4667-84bc-6b60e086000d,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-4695a93c-ff75-497b-88d1-5d7a241b3146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616281244-172.17.0.6-1596976629710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-091ef1c5-b7bf-4e10-95b0-bedb0497f806,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-ccff5897-f17c-4554-a7d5-e89d59da09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-bab3cc94-680e-4484-854d-836ea58bc316,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-27995500-02d0-40ec-b15f-0bd14da2b582,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-afdcf48e-a10c-4c22-b6ed-28fac08d7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-5430e7fc-aa85-4973-87b8-753b47ac9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-85546b48-23c6-4667-84bc-6b60e086000d,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-4695a93c-ff75-497b-88d1-5d7a241b3146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089528775-172.17.0.6-1596976800092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-5361781a-c63e-40df-a86b-baa1419b4e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-c68fdec9-0cf6-49b8-a37f-60eb4e7f74c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-2b281188-604d-470d-8a6d-f9076f5fe72f,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-e12f6ee3-a34c-49ff-8819-d4968f979ace,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-d19cc1ea-6aea-4a55-9f79-6df4fc3cbd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-048baaeb-c36a-471c-85fb-dd5fba5d0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-e255b805-682d-4b07-b96c-907154fb46ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-c3977542-f97c-4f06-a473-bab010e7f2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089528775-172.17.0.6-1596976800092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-5361781a-c63e-40df-a86b-baa1419b4e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-c68fdec9-0cf6-49b8-a37f-60eb4e7f74c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-2b281188-604d-470d-8a6d-f9076f5fe72f,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-e12f6ee3-a34c-49ff-8819-d4968f979ace,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-d19cc1ea-6aea-4a55-9f79-6df4fc3cbd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-048baaeb-c36a-471c-85fb-dd5fba5d0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-e255b805-682d-4b07-b96c-907154fb46ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-c3977542-f97c-4f06-a473-bab010e7f2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051161663-172.17.0.6-1596977229206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33721,DS-1a3a9e50-3a20-4a37-94b4-6eaa292d5da3,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-2a69bde2-2fdf-4758-9549-35a5a29705a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-bafd9183-d3dc-4673-818b-29f2ca6b5e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-0e1d564d-133e-4b65-8bb3-135b170e5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-c4045497-ea4c-4a9f-a5f0-40fb5ab47068,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-46800881-09b7-498a-88ba-da1d60373da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-d41b6872-fa7e-4f37-a349-47315b2d3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-aa4b8141-42b0-4b76-91b0-2d2210deed0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051161663-172.17.0.6-1596977229206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33721,DS-1a3a9e50-3a20-4a37-94b4-6eaa292d5da3,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-2a69bde2-2fdf-4758-9549-35a5a29705a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-bafd9183-d3dc-4673-818b-29f2ca6b5e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-0e1d564d-133e-4b65-8bb3-135b170e5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-c4045497-ea4c-4a9f-a5f0-40fb5ab47068,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-46800881-09b7-498a-88ba-da1d60373da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-d41b6872-fa7e-4f37-a349-47315b2d3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-aa4b8141-42b0-4b76-91b0-2d2210deed0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269609800-172.17.0.6-1596977444416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-df0e7a00-479d-4ec2-9a0b-68904ea4cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-87c3b1b9-f263-4849-8247-f7d4378ed48e,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-b3586143-fbf9-42f6-bc48-88c28868a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-fa6d87a4-35c4-4f9c-8f32-0245d3ae4a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-fbb1a5b4-1a45-46f5-b418-a785f1f5d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-d2b4b0d2-3d9d-4adc-9305-5fc2fbf30a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-1532d002-3e62-4ad4-9d5c-062f56e409a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-04ff425b-9b3c-4577-b8c5-5299f15aab4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269609800-172.17.0.6-1596977444416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-df0e7a00-479d-4ec2-9a0b-68904ea4cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-87c3b1b9-f263-4849-8247-f7d4378ed48e,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-b3586143-fbf9-42f6-bc48-88c28868a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-fa6d87a4-35c4-4f9c-8f32-0245d3ae4a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-fbb1a5b4-1a45-46f5-b418-a785f1f5d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-d2b4b0d2-3d9d-4adc-9305-5fc2fbf30a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-1532d002-3e62-4ad4-9d5c-062f56e409a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-04ff425b-9b3c-4577-b8c5-5299f15aab4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73771520-172.17.0.6-1596978434448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-ca5742b2-2115-49ef-a2d4-b369da2070ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-7d321e42-0bac-49af-9fe6-2f387711f81d,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-eddbfa02-d452-424c-b712-ade50f3b05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-e360fc69-2bb9-40b7-ad48-b2800dd4f444,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-58f11ca2-0496-4332-afee-89c0482a9bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-2f1763cb-ae73-4b21-b0b4-fcbeaabcdb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-f32029ce-ad74-4fb4-93bf-fd6268efc4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-966a164a-f6f9-4bda-94b1-afb15f5362b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73771520-172.17.0.6-1596978434448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-ca5742b2-2115-49ef-a2d4-b369da2070ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-7d321e42-0bac-49af-9fe6-2f387711f81d,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-eddbfa02-d452-424c-b712-ade50f3b05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-e360fc69-2bb9-40b7-ad48-b2800dd4f444,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-58f11ca2-0496-4332-afee-89c0482a9bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-2f1763cb-ae73-4b21-b0b4-fcbeaabcdb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-f32029ce-ad74-4fb4-93bf-fd6268efc4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-966a164a-f6f9-4bda-94b1-afb15f5362b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206052539-172.17.0.6-1596979129026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-0d1d8499-f7c8-4ae1-b42b-cc7235069dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-535bc80d-e021-48a1-a0eb-70f017dfb678,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-d12cf9d6-8563-4afe-886f-b064ed6224ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-71500d71-1221-4e1b-a7e4-8a052ab099ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-6981e541-0db5-4ea0-8533-79519be52de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-0b28c25a-ece6-4b31-84e0-75ba9eefaad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-a642e85d-54d2-45c5-886d-d3f1ae9aab56,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-52fe2e88-dcd7-4e29-bccf-efe6fba9c157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206052539-172.17.0.6-1596979129026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-0d1d8499-f7c8-4ae1-b42b-cc7235069dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-535bc80d-e021-48a1-a0eb-70f017dfb678,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-d12cf9d6-8563-4afe-886f-b064ed6224ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-71500d71-1221-4e1b-a7e4-8a052ab099ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-6981e541-0db5-4ea0-8533-79519be52de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-0b28c25a-ece6-4b31-84e0-75ba9eefaad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-a642e85d-54d2-45c5-886d-d3f1ae9aab56,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-52fe2e88-dcd7-4e29-bccf-efe6fba9c157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859560916-172.17.0.6-1596979228001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-ef31403a-e0c8-424e-bdae-cbc1853257ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-d8eaa7b7-9913-4118-84fb-6552aef7db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-c9601a5e-58e7-4445-a1d8-febc62548ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-28b4a1ca-e225-41b7-8a97-364a41a0beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-688e0e59-fef1-4bec-8f3f-328b5a220e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-9d451154-afe1-4866-a0db-6ab2ac4b0128,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-7e72c97b-e755-4fda-b261-b517273d9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-71dfef5c-ff86-4d76-b98b-793e690dd7df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859560916-172.17.0.6-1596979228001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-ef31403a-e0c8-424e-bdae-cbc1853257ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-d8eaa7b7-9913-4118-84fb-6552aef7db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-c9601a5e-58e7-4445-a1d8-febc62548ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-28b4a1ca-e225-41b7-8a97-364a41a0beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-688e0e59-fef1-4bec-8f3f-328b5a220e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-9d451154-afe1-4866-a0db-6ab2ac4b0128,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-7e72c97b-e755-4fda-b261-b517273d9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-71dfef5c-ff86-4d76-b98b-793e690dd7df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117423201-172.17.0.6-1596979618698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-0290197e-dd1e-4895-826e-81c1ac3f229c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-99d34e28-dde6-4ab7-9248-9fae1d69006a,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-17e85b51-2347-4eb7-9469-2eb5369c34f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-240ee6ed-c3a4-419d-a48e-b00d25bd5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-ebe7b792-6ec4-43d7-8d9c-3550782d71a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-a19bde2e-3bfc-46f1-aa86-733fff48eab0,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-cbd07d27-943c-4e4c-9a83-ab61c363f33b,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-9a92d268-ef7d-4363-93e9-4a9245ea0a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117423201-172.17.0.6-1596979618698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-0290197e-dd1e-4895-826e-81c1ac3f229c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-99d34e28-dde6-4ab7-9248-9fae1d69006a,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-17e85b51-2347-4eb7-9469-2eb5369c34f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-240ee6ed-c3a4-419d-a48e-b00d25bd5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-ebe7b792-6ec4-43d7-8d9c-3550782d71a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-a19bde2e-3bfc-46f1-aa86-733fff48eab0,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-cbd07d27-943c-4e4c-9a83-ab61c363f33b,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-9a92d268-ef7d-4363-93e9-4a9245ea0a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381635769-172.17.0.6-1596979649628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-fcd33465-9709-4875-b9e6-751b4ea3a947,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-3a7afe01-cfa3-4dcc-b51d-18ca1500afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-56e3ba40-2647-4f90-b4da-390264ec1907,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-e39da2f4-f745-4776-8a3d-e1ab578c17cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-43f48a85-465f-4887-9cbc-0b7a44cb4d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-19b8d6b5-e0ce-45a2-b8e9-6a71540843d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-93e5bc75-fef7-4bac-b11e-86b74e041fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-79859937-7f12-4a69-b31a-1027b105227e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381635769-172.17.0.6-1596979649628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-fcd33465-9709-4875-b9e6-751b4ea3a947,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-3a7afe01-cfa3-4dcc-b51d-18ca1500afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-56e3ba40-2647-4f90-b4da-390264ec1907,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-e39da2f4-f745-4776-8a3d-e1ab578c17cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-43f48a85-465f-4887-9cbc-0b7a44cb4d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-19b8d6b5-e0ce-45a2-b8e9-6a71540843d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-93e5bc75-fef7-4bac-b11e-86b74e041fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-79859937-7f12-4a69-b31a-1027b105227e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392300028-172.17.0.6-1596979815677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45449,DS-5f46562c-5751-4786-8ccd-53f28c955ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-41541a6e-0d56-4d01-a777-053b33e04119,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-9a4b21b3-0b72-4057-9089-f07cb37413ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-68ca27f4-d4df-410e-8d5b-1c048c362909,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-7aa5be93-ac40-46f9-82b8-76b215c0dd67,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-41c8e977-f902-4b23-9705-9dc49a91e964,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-c7985de4-750a-457a-839b-30ef96599fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-50c0e78a-9d1f-40c5-be78-14f7c5fad314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392300028-172.17.0.6-1596979815677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45449,DS-5f46562c-5751-4786-8ccd-53f28c955ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-41541a6e-0d56-4d01-a777-053b33e04119,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-9a4b21b3-0b72-4057-9089-f07cb37413ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-68ca27f4-d4df-410e-8d5b-1c048c362909,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-7aa5be93-ac40-46f9-82b8-76b215c0dd67,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-41c8e977-f902-4b23-9705-9dc49a91e964,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-c7985de4-750a-457a-839b-30ef96599fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-50c0e78a-9d1f-40c5-be78-14f7c5fad314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161461821-172.17.0.6-1596980009252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42416,DS-4b082edc-5c40-487b-8fe7-4baa1a28258e,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-81a2822d-3960-46a9-928a-54dfe64beb51,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-3218e0a1-7b72-4f18-83cf-507de5196106,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-dcff5629-bd2a-4c9c-acc5-9c95aad69c45,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-b1e91f4e-7471-4c00-a00b-d09ee2c07206,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-f0034191-bf35-4f27-b6cd-e61106a3756d,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-00c185a7-6ad7-4f71-b245-c21ec806e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-ecf2f907-67dc-461d-b4d3-a5a1aa98f016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161461821-172.17.0.6-1596980009252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42416,DS-4b082edc-5c40-487b-8fe7-4baa1a28258e,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-81a2822d-3960-46a9-928a-54dfe64beb51,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-3218e0a1-7b72-4f18-83cf-507de5196106,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-dcff5629-bd2a-4c9c-acc5-9c95aad69c45,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-b1e91f4e-7471-4c00-a00b-d09ee2c07206,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-f0034191-bf35-4f27-b6cd-e61106a3756d,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-00c185a7-6ad7-4f71-b245-c21ec806e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-ecf2f907-67dc-461d-b4d3-a5a1aa98f016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376443712-172.17.0.6-1596980242381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-197246e0-3ac1-4dc4-a38d-825f9efa8419,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-5363ab51-243d-4699-9df9-159b10eb708c,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-ee054e8c-6aa6-464e-97a6-592c6f9260cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-d1339630-88c2-4ce4-b116-0fcdc6206637,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-d10d1f7c-f046-4fd6-a1da-5e5f12fc5f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-5535870c-280f-448e-8f96-a6114a74115b,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-1f5073cc-0917-401a-9760-d83893662612,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-b8c2ef49-6038-4412-8dda-1152ab9a6a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376443712-172.17.0.6-1596980242381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-197246e0-3ac1-4dc4-a38d-825f9efa8419,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-5363ab51-243d-4699-9df9-159b10eb708c,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-ee054e8c-6aa6-464e-97a6-592c6f9260cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-d1339630-88c2-4ce4-b116-0fcdc6206637,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-d10d1f7c-f046-4fd6-a1da-5e5f12fc5f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-5535870c-280f-448e-8f96-a6114a74115b,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-1f5073cc-0917-401a-9760-d83893662612,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-b8c2ef49-6038-4412-8dda-1152ab9a6a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5186
