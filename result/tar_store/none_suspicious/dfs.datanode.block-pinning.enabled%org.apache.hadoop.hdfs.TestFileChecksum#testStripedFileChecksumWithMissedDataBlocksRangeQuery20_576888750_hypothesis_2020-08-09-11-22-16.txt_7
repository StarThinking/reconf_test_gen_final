reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444471722-172.17.0.10-1596972570376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-ec3a7924-9785-43e2-a393-77a04815aad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-f7c8bc7b-3500-4529-96a3-614e4986ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-1cbc2274-2714-4a95-a688-c00f189f4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-764e465a-a1b3-4ef0-a8c5-582fe0fd7d94,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-b66dd58d-d3db-4473-988a-126dd71f6525,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-21403b53-55b5-465e-8825-bc6b302b7024,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-b727c56e-60ed-4e7d-9aab-117462212d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-3384a202-77c1-4dcf-a9c5-ad49c2d3f00d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444471722-172.17.0.10-1596972570376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-ec3a7924-9785-43e2-a393-77a04815aad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-f7c8bc7b-3500-4529-96a3-614e4986ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-1cbc2274-2714-4a95-a688-c00f189f4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-764e465a-a1b3-4ef0-a8c5-582fe0fd7d94,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-b66dd58d-d3db-4473-988a-126dd71f6525,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-21403b53-55b5-465e-8825-bc6b302b7024,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-b727c56e-60ed-4e7d-9aab-117462212d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-3384a202-77c1-4dcf-a9c5-ad49c2d3f00d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061431043-172.17.0.10-1596972681817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-3240ea3f-cc56-4034-ac40-bd07dd257a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-a695d2e1-0619-47cd-8d34-d99d49970362,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-dc9ef44a-0005-44ab-974f-f8fe94c218ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-f17716bf-69f2-4ce7-822a-b94a5ea10c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-e5c2a0a1-e537-45a8-816d-77969c833755,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-07c772e2-bb76-48e9-a99c-323bd13eef16,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-f52025e2-c884-449e-ab0a-842332929349,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-0279511e-c2b4-477e-bab2-d5c4c4bbf731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061431043-172.17.0.10-1596972681817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-3240ea3f-cc56-4034-ac40-bd07dd257a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-a695d2e1-0619-47cd-8d34-d99d49970362,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-dc9ef44a-0005-44ab-974f-f8fe94c218ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-f17716bf-69f2-4ce7-822a-b94a5ea10c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-e5c2a0a1-e537-45a8-816d-77969c833755,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-07c772e2-bb76-48e9-a99c-323bd13eef16,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-f52025e2-c884-449e-ab0a-842332929349,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-0279511e-c2b4-477e-bab2-d5c4c4bbf731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71082541-172.17.0.10-1596973037767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-14c35067-b89a-40a3-b19c-889ebce3a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-f50b1f53-2e66-4b90-a962-afb062c82ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-716666ca-92f1-4980-ab64-1d3368fe3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-b56da594-eb27-47bf-8204-a957670623e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-89c8ac43-02a3-4cac-ab40-c7addafba3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-7794b560-ba58-46b6-a63b-4cc7ab7cdec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-5501a9ae-21fb-499c-8782-aeae9dd36ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-64d8ac61-4432-4387-a69f-d92d036a8625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71082541-172.17.0.10-1596973037767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-14c35067-b89a-40a3-b19c-889ebce3a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-f50b1f53-2e66-4b90-a962-afb062c82ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-716666ca-92f1-4980-ab64-1d3368fe3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-b56da594-eb27-47bf-8204-a957670623e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-89c8ac43-02a3-4cac-ab40-c7addafba3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-7794b560-ba58-46b6-a63b-4cc7ab7cdec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-5501a9ae-21fb-499c-8782-aeae9dd36ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-64d8ac61-4432-4387-a69f-d92d036a8625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912732264-172.17.0.10-1596973113480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-3cb9eee8-91d6-4aa6-9aa2-4a36b64b8efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-13eaf4b6-c989-46b7-8e56-1fdcc198af17,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-21e43581-1d51-4091-97a9-0c4af740d550,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-f9db268e-2c43-4979-9e85-c7ec3a50ed5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-82cb6e12-8273-48ed-a588-6c15cd85b810,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-ab98ea91-fefb-4a17-b008-ffd4aed5e447,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0f5af0c8-45c1-4689-a27e-ff196321414e,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-08a87fd2-4fa9-4ba4-be24-173ca736620a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912732264-172.17.0.10-1596973113480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-3cb9eee8-91d6-4aa6-9aa2-4a36b64b8efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-13eaf4b6-c989-46b7-8e56-1fdcc198af17,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-21e43581-1d51-4091-97a9-0c4af740d550,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-f9db268e-2c43-4979-9e85-c7ec3a50ed5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-82cb6e12-8273-48ed-a588-6c15cd85b810,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-ab98ea91-fefb-4a17-b008-ffd4aed5e447,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0f5af0c8-45c1-4689-a27e-ff196321414e,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-08a87fd2-4fa9-4ba4-be24-173ca736620a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142412750-172.17.0.10-1596973248019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-8e24ca2f-d679-4aa4-91af-45fd73fe4176,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-5178a4be-257d-4b1f-8f5a-35df1b52e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-d1c33b19-48f6-4a76-8798-06f6b12511ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-7338b218-f3d9-403e-afac-765d725bb319,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-303e0652-9a10-4e61-befd-0927a9fa001c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b2194360-7ea7-4344-86d6-b9083fde5022,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-c0955bc1-d53e-4811-91f5-7e8b6eb068b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-21434090-8dd0-4377-965b-9835e8c1f977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142412750-172.17.0.10-1596973248019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-8e24ca2f-d679-4aa4-91af-45fd73fe4176,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-5178a4be-257d-4b1f-8f5a-35df1b52e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-d1c33b19-48f6-4a76-8798-06f6b12511ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-7338b218-f3d9-403e-afac-765d725bb319,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-303e0652-9a10-4e61-befd-0927a9fa001c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b2194360-7ea7-4344-86d6-b9083fde5022,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-c0955bc1-d53e-4811-91f5-7e8b6eb068b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-21434090-8dd0-4377-965b-9835e8c1f977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997058644-172.17.0.10-1596973521199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-6dc4b3a4-0d28-49fe-b042-b449d7a531ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-cfd9f7c3-7fad-4a20-b6c7-15fb62bbe3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-5a32f8c3-0c48-4612-8905-1f3a0cc087dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-4d211fb7-4576-436e-adf8-a775ac36c5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-56b8ab6e-daa9-4ecf-bb86-bca552c72c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-799b4bb0-a0ef-41a2-9482-8e5b14a06633,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-b6696836-63c7-45ed-b987-ed071c56e730,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-8bf9dbb3-4b95-4989-b071-7691db0a21ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997058644-172.17.0.10-1596973521199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-6dc4b3a4-0d28-49fe-b042-b449d7a531ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-cfd9f7c3-7fad-4a20-b6c7-15fb62bbe3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-5a32f8c3-0c48-4612-8905-1f3a0cc087dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-4d211fb7-4576-436e-adf8-a775ac36c5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-56b8ab6e-daa9-4ecf-bb86-bca552c72c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-799b4bb0-a0ef-41a2-9482-8e5b14a06633,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-b6696836-63c7-45ed-b987-ed071c56e730,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-8bf9dbb3-4b95-4989-b071-7691db0a21ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353873036-172.17.0.10-1596974470666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38578,DS-3fdadf19-86a9-4020-81e4-0574c7fddf41,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-b54375ba-3787-4289-ae49-34f4d3f08c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-ad1b93dd-2338-4176-95d7-98620a71ac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a249fe86-59a0-4668-a467-628a7e694ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-8dcc021c-502f-49a4-b606-77a9035af021,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-d8665e6f-824a-4fe2-91c3-edcaa9ec788e,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-c1b1e261-21bd-4826-a2ae-13449a2c0f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-00b3f923-1951-405d-a088-2ab010f17515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353873036-172.17.0.10-1596974470666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38578,DS-3fdadf19-86a9-4020-81e4-0574c7fddf41,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-b54375ba-3787-4289-ae49-34f4d3f08c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-ad1b93dd-2338-4176-95d7-98620a71ac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a249fe86-59a0-4668-a467-628a7e694ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-8dcc021c-502f-49a4-b606-77a9035af021,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-d8665e6f-824a-4fe2-91c3-edcaa9ec788e,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-c1b1e261-21bd-4826-a2ae-13449a2c0f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-00b3f923-1951-405d-a088-2ab010f17515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059962497-172.17.0.10-1596974739110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46121,DS-4fcce913-2697-476d-a7a6-a8f5c7abd4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-811fdbf9-b178-49e3-ab44-b9e6c91cd4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-521ef51c-1098-4f36-a76c-7440ec6be713,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-98ee6696-7f79-418e-90f2-d4daf1c35e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-b9312e6b-d593-4def-820b-7cdd9834d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-1118e473-7b10-4cc5-854d-aceb2e8e8e89,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-e694ffeb-7b36-46b2-b78c-ebdd53285ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-bd771827-1f5e-4729-98d8-d17e24407ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059962497-172.17.0.10-1596974739110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46121,DS-4fcce913-2697-476d-a7a6-a8f5c7abd4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-811fdbf9-b178-49e3-ab44-b9e6c91cd4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-521ef51c-1098-4f36-a76c-7440ec6be713,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-98ee6696-7f79-418e-90f2-d4daf1c35e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-b9312e6b-d593-4def-820b-7cdd9834d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-1118e473-7b10-4cc5-854d-aceb2e8e8e89,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-e694ffeb-7b36-46b2-b78c-ebdd53285ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-bd771827-1f5e-4729-98d8-d17e24407ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492152098-172.17.0.10-1596974845182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46548,DS-236e196b-99c3-4408-b3d9-6e7ba8a69247,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-986d4be5-5f87-44bf-a130-2edf5d40cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-9afa0089-6218-4d9a-9db8-ff334c035195,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-c97b9b2f-d5d5-4515-acc7-fed593b5c471,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-af27038e-0577-41f0-bfdb-74ef9cafb7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-79841111-3ed9-40d9-afd9-3210e2f9feda,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-b284b00d-e8f3-49c5-bc70-3413dfc70472,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-031e23ab-7ec3-4baa-9d45-0f5e1e57f749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492152098-172.17.0.10-1596974845182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46548,DS-236e196b-99c3-4408-b3d9-6e7ba8a69247,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-986d4be5-5f87-44bf-a130-2edf5d40cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-9afa0089-6218-4d9a-9db8-ff334c035195,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-c97b9b2f-d5d5-4515-acc7-fed593b5c471,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-af27038e-0577-41f0-bfdb-74ef9cafb7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-79841111-3ed9-40d9-afd9-3210e2f9feda,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-b284b00d-e8f3-49c5-bc70-3413dfc70472,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-031e23ab-7ec3-4baa-9d45-0f5e1e57f749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869290019-172.17.0.10-1596975217952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-fdc68791-8d03-4287-93c4-ac1adc8b4cee,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e7a777a7-81ab-4120-b2d5-f76c5730b8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-19ef1a29-701b-438a-9f40-b877c0acc7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-6eda974c-8125-46b2-a94a-93571b9134b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-a4ec3a3a-9172-4c17-9ffa-5e575863b059,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-ab858044-1afd-4995-ab2a-7534a8a9ac17,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-e2c527a7-dbe8-466b-8b0c-9270e0ba81b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-e687c74c-cb1e-4c7e-a766-044745f2e803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869290019-172.17.0.10-1596975217952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-fdc68791-8d03-4287-93c4-ac1adc8b4cee,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e7a777a7-81ab-4120-b2d5-f76c5730b8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-19ef1a29-701b-438a-9f40-b877c0acc7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-6eda974c-8125-46b2-a94a-93571b9134b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-a4ec3a3a-9172-4c17-9ffa-5e575863b059,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-ab858044-1afd-4995-ab2a-7534a8a9ac17,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-e2c527a7-dbe8-466b-8b0c-9270e0ba81b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-e687c74c-cb1e-4c7e-a766-044745f2e803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5269
