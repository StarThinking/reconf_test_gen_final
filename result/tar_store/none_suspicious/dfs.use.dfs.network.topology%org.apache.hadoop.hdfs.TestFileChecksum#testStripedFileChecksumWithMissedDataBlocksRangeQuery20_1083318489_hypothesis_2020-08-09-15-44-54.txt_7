reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344803027-172.17.0.3-1596988041083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-92e2edba-f338-4317-a66e-527543f8b8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-35d3138d-5d98-4cf3-a547-42e7058e7014,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-d75a492e-e4a7-42c4-bd3f-e6c9aeefb52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-cde4d695-40ab-44b0-8ce6-11a54715d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-a5a02058-a39b-4515-a391-6c9d2d954515,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-c72c9040-ea61-4b71-82ad-5469f9806442,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-7f7f7947-ac05-47cf-9ea6-566350962523,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-5ce75e1e-4d6a-4053-9b6c-fa360cecd603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344803027-172.17.0.3-1596988041083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-92e2edba-f338-4317-a66e-527543f8b8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-35d3138d-5d98-4cf3-a547-42e7058e7014,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-d75a492e-e4a7-42c4-bd3f-e6c9aeefb52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-cde4d695-40ab-44b0-8ce6-11a54715d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-a5a02058-a39b-4515-a391-6c9d2d954515,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-c72c9040-ea61-4b71-82ad-5469f9806442,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-7f7f7947-ac05-47cf-9ea6-566350962523,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-5ce75e1e-4d6a-4053-9b6c-fa360cecd603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790472186-172.17.0.3-1596989214396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-3400bf94-afcc-4c14-8044-c3101df68d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-d5bee570-d550-4315-989e-5295db0409d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-87317ec2-e01f-4d85-ba9a-65d93a5d93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-fa6e8ea2-3547-4bb8-a342-38e52cd18de5,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-a4ef7452-4101-4978-989e-fc7ef7aac101,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-a6ec83b6-7395-4702-a4c2-f4ea1993f248,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-63813b68-9f2d-40a1-b2e4-c393f7caa83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-931f2fbd-cd63-4f10-968b-b49070d5ec4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790472186-172.17.0.3-1596989214396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-3400bf94-afcc-4c14-8044-c3101df68d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-d5bee570-d550-4315-989e-5295db0409d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-87317ec2-e01f-4d85-ba9a-65d93a5d93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-fa6e8ea2-3547-4bb8-a342-38e52cd18de5,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-a4ef7452-4101-4978-989e-fc7ef7aac101,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-a6ec83b6-7395-4702-a4c2-f4ea1993f248,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-63813b68-9f2d-40a1-b2e4-c393f7caa83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-931f2fbd-cd63-4f10-968b-b49070d5ec4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279466107-172.17.0.3-1596989301543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-0e9ea39f-3f94-4c17-b8c6-fbd63334235d,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-4a599a4d-b5ff-44e8-a82f-25c86bf236ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-0f2aa87f-0446-4106-9ab2-80b716969f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-1446dbf5-318e-4c82-a67c-b0e66570edb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1356fe30-d1db-4479-813b-7e2097fc4531,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-6b2afebf-90e3-4e07-9270-34dc0eed9bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-575d3522-f556-4a2b-8fd9-357d9f9608bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-b72fc151-c8ef-452b-87cd-2e8be17f25ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279466107-172.17.0.3-1596989301543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-0e9ea39f-3f94-4c17-b8c6-fbd63334235d,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-4a599a4d-b5ff-44e8-a82f-25c86bf236ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-0f2aa87f-0446-4106-9ab2-80b716969f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-1446dbf5-318e-4c82-a67c-b0e66570edb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1356fe30-d1db-4479-813b-7e2097fc4531,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-6b2afebf-90e3-4e07-9270-34dc0eed9bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-575d3522-f556-4a2b-8fd9-357d9f9608bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-b72fc151-c8ef-452b-87cd-2e8be17f25ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622484911-172.17.0.3-1596989615530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42565,DS-7679f76d-eda7-4895-b91e-8403c1dce6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-8924eacf-dbe3-4bf6-9907-c5b2614099f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-997266f8-d4e8-4c59-bdb1-d3a1f36a00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-763d8219-c365-4566-a1a3-e95ba0b9f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-e01e1afe-3817-4b39-b07c-9302052d4980,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-1ea80bcc-d292-4eb7-bd2c-85ae80403d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-51161193-0580-4acf-a19d-315ca278d16c,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-1b5c5f90-34fe-46c2-b31b-19f7429b249b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622484911-172.17.0.3-1596989615530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42565,DS-7679f76d-eda7-4895-b91e-8403c1dce6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-8924eacf-dbe3-4bf6-9907-c5b2614099f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-997266f8-d4e8-4c59-bdb1-d3a1f36a00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-763d8219-c365-4566-a1a3-e95ba0b9f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-e01e1afe-3817-4b39-b07c-9302052d4980,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-1ea80bcc-d292-4eb7-bd2c-85ae80403d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-51161193-0580-4acf-a19d-315ca278d16c,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-1b5c5f90-34fe-46c2-b31b-19f7429b249b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464567754-172.17.0.3-1596990071904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-a876a31e-a5a3-4c99-9b5f-92a283f7244f,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-ec591cf0-bcc2-4188-ad95-69ebf1d59bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-f45cb30b-595b-4a50-b20e-2ed27351929c,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-dedf03f6-f91d-4d26-9c81-6aa9f0faf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-bec4a2ff-693e-45fe-af77-c143ff696cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-bf56a2c5-49b5-4c4f-88a7-21d5e8682ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-a296348e-ad30-4414-9c28-8bb31382ef6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-b8c7500a-4c6e-4dee-839f-fcbaec2cd08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464567754-172.17.0.3-1596990071904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-a876a31e-a5a3-4c99-9b5f-92a283f7244f,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-ec591cf0-bcc2-4188-ad95-69ebf1d59bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-f45cb30b-595b-4a50-b20e-2ed27351929c,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-dedf03f6-f91d-4d26-9c81-6aa9f0faf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-bec4a2ff-693e-45fe-af77-c143ff696cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-bf56a2c5-49b5-4c4f-88a7-21d5e8682ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-a296348e-ad30-4414-9c28-8bb31382ef6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-b8c7500a-4c6e-4dee-839f-fcbaec2cd08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799256376-172.17.0.3-1596990336880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35354,DS-e78ce61e-a433-466f-a598-88220b8dcb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4488e819-776c-4e52-889a-326401e7bc00,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-9622b317-98be-4e8f-af6e-232107c3c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-513e7258-fafa-4d4f-a9f9-8cad23b98f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-30bcd32a-bfa8-41e5-b01b-9dd0862f3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-90587581-35be-47a8-a097-16cd45267bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-84a0677e-6e47-4f09-9c65-4580bf119b64,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-0f72b5d1-cc9e-464b-8400-b9984d45becb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799256376-172.17.0.3-1596990336880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35354,DS-e78ce61e-a433-466f-a598-88220b8dcb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4488e819-776c-4e52-889a-326401e7bc00,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-9622b317-98be-4e8f-af6e-232107c3c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-513e7258-fafa-4d4f-a9f9-8cad23b98f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-30bcd32a-bfa8-41e5-b01b-9dd0862f3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-90587581-35be-47a8-a097-16cd45267bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-84a0677e-6e47-4f09-9c65-4580bf119b64,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-0f72b5d1-cc9e-464b-8400-b9984d45becb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602347991-172.17.0.3-1596990419052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33824,DS-59812c54-4098-498d-9781-c17868ec030d,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-3232a585-2eea-4558-8d02-ecff6a6a62de,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-9fc4edce-4f0e-4850-91ad-9938062c727a,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-731e1bdb-5b01-42bb-a09a-53bc1079a528,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-ef867494-5a25-41fa-95c5-b26c5fd35a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-ec0f8196-d07f-4569-9d65-bbff3ad6ca71,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-62364ca2-3de1-41e2-8611-1ee2d1be43db,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-53a78aa9-8f3a-4864-b676-7f63044b25f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602347991-172.17.0.3-1596990419052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33824,DS-59812c54-4098-498d-9781-c17868ec030d,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-3232a585-2eea-4558-8d02-ecff6a6a62de,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-9fc4edce-4f0e-4850-91ad-9938062c727a,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-731e1bdb-5b01-42bb-a09a-53bc1079a528,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-ef867494-5a25-41fa-95c5-b26c5fd35a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-ec0f8196-d07f-4569-9d65-bbff3ad6ca71,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-62364ca2-3de1-41e2-8611-1ee2d1be43db,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-53a78aa9-8f3a-4864-b676-7f63044b25f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866059499-172.17.0.3-1596991072993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-6a86a1c8-9df0-46d4-bd93-08fdaf8ffca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-5f7499c5-1366-4866-a27b-172b39555d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-b88191ce-4d36-474c-a183-73c344df455d,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-15ec4b67-f0f9-41c6-b152-236e8c9b41d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-538c1bbe-3144-4d0e-9277-cd4a63028d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4994e620-6799-428d-aced-d4123cc14b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-685f7265-da47-45bf-86ae-be2ecc5512d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-6f3cbc30-59fe-467a-a971-a9420673115a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866059499-172.17.0.3-1596991072993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-6a86a1c8-9df0-46d4-bd93-08fdaf8ffca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-5f7499c5-1366-4866-a27b-172b39555d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-b88191ce-4d36-474c-a183-73c344df455d,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-15ec4b67-f0f9-41c6-b152-236e8c9b41d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-538c1bbe-3144-4d0e-9277-cd4a63028d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4994e620-6799-428d-aced-d4123cc14b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-685f7265-da47-45bf-86ae-be2ecc5512d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-6f3cbc30-59fe-467a-a971-a9420673115a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980557633-172.17.0.3-1596991122867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-80859c65-ecdd-4aab-bf98-801d4948c856,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-8d1e25cf-d781-4171-afdf-a2d82750f085,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0f2b1439-501e-4f9d-b022-7aab7e58ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-e48562b6-f7a1-4c67-aeb2-1f5a5a80320c,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-10edd7f0-4da4-4fc6-9afd-e37a34a2ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-5b4ae626-3492-4038-b000-a0bedcfad031,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-ec10b242-85b1-4408-98c3-5d0610410e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-4d252d45-2b0f-4290-9d3d-9233c88718b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980557633-172.17.0.3-1596991122867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-80859c65-ecdd-4aab-bf98-801d4948c856,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-8d1e25cf-d781-4171-afdf-a2d82750f085,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0f2b1439-501e-4f9d-b022-7aab7e58ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-e48562b6-f7a1-4c67-aeb2-1f5a5a80320c,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-10edd7f0-4da4-4fc6-9afd-e37a34a2ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-5b4ae626-3492-4038-b000-a0bedcfad031,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-ec10b242-85b1-4408-98c3-5d0610410e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-4d252d45-2b0f-4290-9d3d-9233c88718b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071625964-172.17.0.3-1596991264736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-aa535194-06fd-4a5e-ad38-ed992a43addb,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-90a38b2e-9004-411e-9b54-a34b3ef725a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-868c2249-b919-41d0-8f1a-a6d827d7b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-924dc4b4-0fa7-46f2-ae81-7c694a304a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-eb91b697-4fba-48fc-ae13-b8366ced08ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-5f5cf16d-41e1-4fd3-b4d9-b5bbcd38ef18,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-464f0113-a5ea-4462-952c-0629a69be51e,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-c0ecc5d5-6b93-405c-9c3c-1b6ea0a949e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071625964-172.17.0.3-1596991264736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-aa535194-06fd-4a5e-ad38-ed992a43addb,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-90a38b2e-9004-411e-9b54-a34b3ef725a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-868c2249-b919-41d0-8f1a-a6d827d7b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-924dc4b4-0fa7-46f2-ae81-7c694a304a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-eb91b697-4fba-48fc-ae13-b8366ced08ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-5f5cf16d-41e1-4fd3-b4d9-b5bbcd38ef18,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-464f0113-a5ea-4462-952c-0629a69be51e,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-c0ecc5d5-6b93-405c-9c3c-1b6ea0a949e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622876625-172.17.0.3-1596991348887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36010,DS-a3f9d08d-3f40-4974-a1ea-23964c8e3dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-f8e37db2-af31-4380-86a4-cb9f00f485e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-c8aa4e2f-405d-4484-acac-415a7468dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-f403fd6f-c912-49f8-8cae-b5f2c9e5ece4,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-1608ea1a-8133-49d5-8c15-2ce9b76195ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-2694c10f-a6b0-421a-bd7f-91b3aea36e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-829fa06a-f3f1-424c-aeee-d40fcba71c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-6e1e3e71-b946-4701-9cd0-29c141c644f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622876625-172.17.0.3-1596991348887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36010,DS-a3f9d08d-3f40-4974-a1ea-23964c8e3dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-f8e37db2-af31-4380-86a4-cb9f00f485e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-c8aa4e2f-405d-4484-acac-415a7468dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-f403fd6f-c912-49f8-8cae-b5f2c9e5ece4,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-1608ea1a-8133-49d5-8c15-2ce9b76195ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-2694c10f-a6b0-421a-bd7f-91b3aea36e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-829fa06a-f3f1-424c-aeee-d40fcba71c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-6e1e3e71-b946-4701-9cd0-29c141c644f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530275498-172.17.0.3-1596991475588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36312,DS-e2fce404-51f7-47da-b592-f444a5e72b55,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-7324fb41-66ba-46ef-9950-f10f4c79f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-e153782b-bdbd-482d-8f08-6e3fa703262b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-8fe49a58-bcc3-4f7c-85be-e0aba5d62a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-ed5ecd8b-f869-4254-88ee-4e1521476300,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-6161077b-0a99-46ec-b480-147fad98480f,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-78e150fa-2aba-4aa3-b01a-9b44fbac7808,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-b6674c5d-fdc7-491b-a39b-9867f59b0b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530275498-172.17.0.3-1596991475588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36312,DS-e2fce404-51f7-47da-b592-f444a5e72b55,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-7324fb41-66ba-46ef-9950-f10f4c79f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-e153782b-bdbd-482d-8f08-6e3fa703262b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-8fe49a58-bcc3-4f7c-85be-e0aba5d62a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-ed5ecd8b-f869-4254-88ee-4e1521476300,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-6161077b-0a99-46ec-b480-147fad98480f,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-78e150fa-2aba-4aa3-b01a-9b44fbac7808,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-b6674c5d-fdc7-491b-a39b-9867f59b0b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274993720-172.17.0.3-1596991555928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-0dd34724-807e-434f-a9fb-5c49bb435fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-f0dbbf87-e944-49b3-8c92-3c78d7a2076d,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-4a54f39f-1fae-4e98-b899-0a32d2f40d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-90cebf3c-d5f4-480e-8723-6080a5c7f2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-d7731220-135f-4047-a93a-cb14d51401f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-842d4908-5e7b-4e27-9c06-1091f243d24e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-82aed948-4701-4d45-babb-bccd1ff5ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-1f1bcc60-560a-4dfc-8a7f-27a8b38c7b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274993720-172.17.0.3-1596991555928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-0dd34724-807e-434f-a9fb-5c49bb435fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-f0dbbf87-e944-49b3-8c92-3c78d7a2076d,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-4a54f39f-1fae-4e98-b899-0a32d2f40d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-90cebf3c-d5f4-480e-8723-6080a5c7f2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-d7731220-135f-4047-a93a-cb14d51401f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-842d4908-5e7b-4e27-9c06-1091f243d24e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-82aed948-4701-4d45-babb-bccd1ff5ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-1f1bcc60-560a-4dfc-8a7f-27a8b38c7b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878767725-172.17.0.3-1596991742163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-50825922-87ca-4878-8521-197c62d12eed,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-f8cd97a3-159b-4284-ac58-42fda03775ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-edcf52cd-723c-4c13-933a-aca65e56080d,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-c3097fdf-42ad-416f-ab16-5136e672f139,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-39a3734b-e66f-48a9-925d-c2a4aacf3085,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-d4315f2f-3e02-47a2-aa7c-f699d37ee83c,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-9e7fbe23-cc01-4e76-b25d-2022dfa6f836,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-59545195-030c-4997-927b-bb777b058e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878767725-172.17.0.3-1596991742163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-50825922-87ca-4878-8521-197c62d12eed,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-f8cd97a3-159b-4284-ac58-42fda03775ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-edcf52cd-723c-4c13-933a-aca65e56080d,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-c3097fdf-42ad-416f-ab16-5136e672f139,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-39a3734b-e66f-48a9-925d-c2a4aacf3085,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-d4315f2f-3e02-47a2-aa7c-f699d37ee83c,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-9e7fbe23-cc01-4e76-b25d-2022dfa6f836,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-59545195-030c-4997-927b-bb777b058e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435200382-172.17.0.3-1596992049448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42378,DS-fdcd6a1f-3d39-4a99-b84e-507416e01125,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-fbd02baa-d234-499e-b8fb-e8439e68e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-eff052c3-1937-49a7-8f70-4611dd44b313,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-6a78a876-5ead-4a4b-a722-46ac35a9983d,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-ea88396a-34ea-48e7-9322-aafa9f8ddd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-8ab1484d-2071-4710-8d85-9394e29f5bde,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-efd7f62c-764f-4ebf-bc2e-0fb18a165917,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-58b5c160-e509-449b-9a21-5bb6ed8aa60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435200382-172.17.0.3-1596992049448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42378,DS-fdcd6a1f-3d39-4a99-b84e-507416e01125,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-fbd02baa-d234-499e-b8fb-e8439e68e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-eff052c3-1937-49a7-8f70-4611dd44b313,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-6a78a876-5ead-4a4b-a722-46ac35a9983d,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-ea88396a-34ea-48e7-9322-aafa9f8ddd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-8ab1484d-2071-4710-8d85-9394e29f5bde,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-efd7f62c-764f-4ebf-bc2e-0fb18a165917,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-58b5c160-e509-449b-9a21-5bb6ed8aa60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686582179-172.17.0.3-1596992151247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40091,DS-237cd4cc-0cab-465f-82d9-dba10c91182c,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-fc9c34c6-fe27-4ca3-973a-7bc396140259,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-e1baf508-34e4-4546-b2be-e7fb641b1de3,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-691e27b2-4327-4f34-b792-f866d83ee6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-ef6d49db-059f-4ed3-973c-a3b02369afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-507420db-7de6-4b9b-bfac-a288f452baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-95d9ab83-3a42-4faf-85bc-c821e8593803,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-4045f2f0-895f-4ef7-ac3d-6ce4e8063b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686582179-172.17.0.3-1596992151247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40091,DS-237cd4cc-0cab-465f-82d9-dba10c91182c,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-fc9c34c6-fe27-4ca3-973a-7bc396140259,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-e1baf508-34e4-4546-b2be-e7fb641b1de3,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-691e27b2-4327-4f34-b792-f866d83ee6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-ef6d49db-059f-4ed3-973c-a3b02369afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-507420db-7de6-4b9b-bfac-a288f452baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-95d9ab83-3a42-4faf-85bc-c821e8593803,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-4045f2f0-895f-4ef7-ac3d-6ce4e8063b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294583998-172.17.0.3-1596992190029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-64fd159b-9b7e-4762-b276-901b34c5fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-0c34c797-6696-4425-9c10-3938dcf956e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-c31022b7-2f65-4d60-95e2-64e352566356,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-0391b9ae-6a63-43ff-9803-4b43057c4226,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-08064a87-cdde-4ed9-8dfe-419942d2e127,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-54d16de4-274c-4351-90cc-81f036d9db03,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-ecf162e8-7c6f-4bd7-80bc-618cd77b77ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-4b896948-47d7-4148-aa71-474bf1803a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294583998-172.17.0.3-1596992190029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-64fd159b-9b7e-4762-b276-901b34c5fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-0c34c797-6696-4425-9c10-3938dcf956e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-c31022b7-2f65-4d60-95e2-64e352566356,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-0391b9ae-6a63-43ff-9803-4b43057c4226,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-08064a87-cdde-4ed9-8dfe-419942d2e127,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-54d16de4-274c-4351-90cc-81f036d9db03,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-ecf162e8-7c6f-4bd7-80bc-618cd77b77ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-4b896948-47d7-4148-aa71-474bf1803a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33022649-172.17.0.3-1596992449337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-ba2b365e-6e15-49dd-8e36-c8fc3c0a260c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-2a28ff8e-2e73-4d06-a5c6-a917d7937a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-f45e8e25-07eb-4354-8dec-0d66eff4e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-97e07a74-8aeb-4b1e-855b-27b690383174,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-ea192cd9-ee9d-4bef-842f-2e912b24b909,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-71eca9a1-e6bd-4bcc-92bc-f2eced95aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-d6d25e08-f5af-41f1-81cb-e44d686f30ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-9a5db234-7301-44da-bca2-947e932af520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33022649-172.17.0.3-1596992449337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-ba2b365e-6e15-49dd-8e36-c8fc3c0a260c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-2a28ff8e-2e73-4d06-a5c6-a917d7937a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-f45e8e25-07eb-4354-8dec-0d66eff4e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-97e07a74-8aeb-4b1e-855b-27b690383174,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-ea192cd9-ee9d-4bef-842f-2e912b24b909,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-71eca9a1-e6bd-4bcc-92bc-f2eced95aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-d6d25e08-f5af-41f1-81cb-e44d686f30ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-9a5db234-7301-44da-bca2-947e932af520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885574602-172.17.0.3-1596992944685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-90e8a4c5-c18e-430d-a6aa-022c4083d9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-2237f208-c9f2-4739-92c2-03ff02721cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-f5022b0b-178a-46a3-b10a-6b9aba6766e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-a5a133e5-cf9d-486c-8cd8-d8ab60b4bdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-7cd1a125-0bff-4a77-8c85-2cf32294f895,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-ee7ca7f9-a310-446c-a76d-1e8eb4857076,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-4f3ea4bd-10e7-4840-bc05-9c23253a052b,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-f32c1cd8-9426-4126-87b1-b2e50c573e96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885574602-172.17.0.3-1596992944685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-90e8a4c5-c18e-430d-a6aa-022c4083d9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-2237f208-c9f2-4739-92c2-03ff02721cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-f5022b0b-178a-46a3-b10a-6b9aba6766e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-a5a133e5-cf9d-486c-8cd8-d8ab60b4bdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-7cd1a125-0bff-4a77-8c85-2cf32294f895,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-ee7ca7f9-a310-446c-a76d-1e8eb4857076,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-4f3ea4bd-10e7-4840-bc05-9c23253a052b,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-f32c1cd8-9426-4126-87b1-b2e50c573e96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041017917-172.17.0.3-1596993080346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-68d02467-6be1-430d-a37a-f5b068f9d534,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-fdec9d32-4a20-4a5f-92b6-c954273eda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-3323f6e7-780f-4d24-a811-a9b580241068,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-14df38e2-0626-4e45-8f3c-aa1b09f018db,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-77d865bf-2088-4e82-999f-4e851e541fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-a5db9ff5-6e5c-436b-8f2b-a049f88201a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-0920ba0f-3e74-43a0-9646-3d0b5e9ed8be,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-164564dc-bbfe-4ecd-9b68-9b620f696d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041017917-172.17.0.3-1596993080346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-68d02467-6be1-430d-a37a-f5b068f9d534,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-fdec9d32-4a20-4a5f-92b6-c954273eda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-3323f6e7-780f-4d24-a811-a9b580241068,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-14df38e2-0626-4e45-8f3c-aa1b09f018db,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-77d865bf-2088-4e82-999f-4e851e541fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-a5db9ff5-6e5c-436b-8f2b-a049f88201a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-0920ba0f-3e74-43a0-9646-3d0b5e9ed8be,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-164564dc-bbfe-4ecd-9b68-9b620f696d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330046392-172.17.0.3-1596993167663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-58393019-5a02-4002-a823-0a64a251e026,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-3a88df8c-1c2c-4181-839c-2c4a56795f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-db112b34-6c69-4fca-ba7e-9a2b98076ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-9ef453c1-353c-4086-b7f0-e4e1bf97c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-d2444564-805c-4447-9da9-52020f102a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-719f6123-a48e-4a27-89d7-2152ece085e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-ce7f86a1-32c0-4733-9dde-6d8d8894c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-72c253b2-5ac9-49f8-b6ac-a95689bcf8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330046392-172.17.0.3-1596993167663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-58393019-5a02-4002-a823-0a64a251e026,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-3a88df8c-1c2c-4181-839c-2c4a56795f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-db112b34-6c69-4fca-ba7e-9a2b98076ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-9ef453c1-353c-4086-b7f0-e4e1bf97c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-d2444564-805c-4447-9da9-52020f102a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-719f6123-a48e-4a27-89d7-2152ece085e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-ce7f86a1-32c0-4733-9dde-6d8d8894c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-72c253b2-5ac9-49f8-b6ac-a95689bcf8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897716529-172.17.0.3-1596993477715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42831,DS-48abca87-e731-42c3-b2c2-239bed4d7a73,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-64f7f741-d59e-445e-9ee2-5b04ce9d340b,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-b0c6e928-899b-4aef-8886-75d997753c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-c2a4b306-c081-496f-81ba-a1f5223e42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-0ea710af-422e-4f1a-b14a-34a7d3b73ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-89ef0213-af58-4706-abe2-5ab1c8d4a42e,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-21d9ed78-b466-4586-9125-bb8a3a3e3e38,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-5ed907f7-b0f7-44e6-a857-90a96b0f3757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897716529-172.17.0.3-1596993477715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42831,DS-48abca87-e731-42c3-b2c2-239bed4d7a73,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-64f7f741-d59e-445e-9ee2-5b04ce9d340b,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-b0c6e928-899b-4aef-8886-75d997753c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-c2a4b306-c081-496f-81ba-a1f5223e42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-0ea710af-422e-4f1a-b14a-34a7d3b73ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-89ef0213-af58-4706-abe2-5ab1c8d4a42e,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-21d9ed78-b466-4586-9125-bb8a3a3e3e38,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-5ed907f7-b0f7-44e6-a857-90a96b0f3757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714815497-172.17.0.3-1596993597349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-90f60537-60cb-4d6a-87f3-bb4859a772c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-031d77b3-ae0f-4042-8aa6-751b196503f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-c3180237-3c3b-425f-968c-a78cfc10b46a,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-2fc997f6-7b9c-4a7d-b7c0-c1aa5ae1598c,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c2df0a87-e08e-40b5-82d5-9bd9c02304b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-8a6e7263-0aa9-4d44-84ae-c54154f5de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-f662c768-6fc4-4866-823e-fe26d1eab649,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-4fb3320d-a2fc-42c0-9447-4fb68ca210d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714815497-172.17.0.3-1596993597349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-90f60537-60cb-4d6a-87f3-bb4859a772c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-031d77b3-ae0f-4042-8aa6-751b196503f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-c3180237-3c3b-425f-968c-a78cfc10b46a,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-2fc997f6-7b9c-4a7d-b7c0-c1aa5ae1598c,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c2df0a87-e08e-40b5-82d5-9bd9c02304b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-8a6e7263-0aa9-4d44-84ae-c54154f5de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-f662c768-6fc4-4866-823e-fe26d1eab649,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-4fb3320d-a2fc-42c0-9447-4fb68ca210d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219177638-172.17.0.3-1596994085392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-82cd7b4b-eca7-4e1b-b751-208b548b4769,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-d4c5e57e-9f8c-419b-bf46-fa61722b9c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-9698d32a-8e89-45ef-9776-a29c6ba0c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-3e4dddae-571e-4073-96ff-763ee4c7ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-e291f0c8-793b-436d-b4ad-9d9c9b551396,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-0d4b5d0c-40e3-4da3-8e0f-e41ea4301058,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-9db62b9c-68e4-4448-aaf2-8a49b1095cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-de851a4e-1bcc-451a-a4ca-967d68b749b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219177638-172.17.0.3-1596994085392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-82cd7b4b-eca7-4e1b-b751-208b548b4769,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-d4c5e57e-9f8c-419b-bf46-fa61722b9c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-9698d32a-8e89-45ef-9776-a29c6ba0c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-3e4dddae-571e-4073-96ff-763ee4c7ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-e291f0c8-793b-436d-b4ad-9d9c9b551396,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-0d4b5d0c-40e3-4da3-8e0f-e41ea4301058,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-9db62b9c-68e4-4448-aaf2-8a49b1095cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-de851a4e-1bcc-451a-a4ca-967d68b749b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95336684-172.17.0.3-1596994410758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-924ba764-76df-4852-a8e5-f885e027169b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-d85e7b7c-c5a6-4f32-b5a5-0a163da4dd16,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-f81dc133-2fb4-457c-b1a4-c7991dd5098c,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-1170035f-9a1b-4ca9-83c2-4223324d37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-31c43be5-890b-4dad-9007-42d215c0c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-620ade51-9527-4160-9a26-74a85995e8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-2f13c8bd-8299-40b3-9102-dda6775750fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-87953530-850b-44b7-8ae2-8c350ecf4ffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95336684-172.17.0.3-1596994410758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-924ba764-76df-4852-a8e5-f885e027169b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-d85e7b7c-c5a6-4f32-b5a5-0a163da4dd16,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-f81dc133-2fb4-457c-b1a4-c7991dd5098c,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-1170035f-9a1b-4ca9-83c2-4223324d37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-31c43be5-890b-4dad-9007-42d215c0c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-620ade51-9527-4160-9a26-74a85995e8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-2f13c8bd-8299-40b3-9102-dda6775750fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-87953530-850b-44b7-8ae2-8c350ecf4ffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6669
