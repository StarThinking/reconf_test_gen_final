reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869065346-172.17.0.11-1596894543654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-3b50e4ad-a9a4-4ed2-9635-194bd3e95e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1a19880a-f6fe-4f29-958b-3e8188a41e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-e5452490-de20-4537-a92a-b64250df5145,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-2fcf5c5f-3a40-4feb-990d-6f85fdd6fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-59761b2f-5c46-4eec-9b44-febca0737342,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-968b2d93-d6d2-427a-9a90-af2175e87b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-297c7746-42f6-442b-be49-9a98c0500078,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-4c330148-c3aa-4beb-b1b8-05eb6ff606c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869065346-172.17.0.11-1596894543654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-3b50e4ad-a9a4-4ed2-9635-194bd3e95e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1a19880a-f6fe-4f29-958b-3e8188a41e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-e5452490-de20-4537-a92a-b64250df5145,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-2fcf5c5f-3a40-4feb-990d-6f85fdd6fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-59761b2f-5c46-4eec-9b44-febca0737342,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-968b2d93-d6d2-427a-9a90-af2175e87b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-297c7746-42f6-442b-be49-9a98c0500078,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-4c330148-c3aa-4beb-b1b8-05eb6ff606c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318813042-172.17.0.11-1596894620645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-280b1da0-abb3-484e-b2b9-c0ff3bfb43f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-ec3f4fd9-71b8-4290-8906-391be27f9095,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-fce267c8-9415-40f8-9b26-4a342df9eb21,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-88e51d2d-7215-4ee4-93e4-100b59e151cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-41424212-1a0e-403b-bea9-c9a2746ca12e,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-9fe4e132-b720-4ef4-8a22-d78840a2281d,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-8fd98f7e-235c-444c-89da-8b5ac6b05d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-db9205f5-e425-4e78-8ebb-aaefc79a65ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318813042-172.17.0.11-1596894620645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-280b1da0-abb3-484e-b2b9-c0ff3bfb43f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-ec3f4fd9-71b8-4290-8906-391be27f9095,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-fce267c8-9415-40f8-9b26-4a342df9eb21,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-88e51d2d-7215-4ee4-93e4-100b59e151cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-41424212-1a0e-403b-bea9-c9a2746ca12e,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-9fe4e132-b720-4ef4-8a22-d78840a2281d,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-8fd98f7e-235c-444c-89da-8b5ac6b05d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-db9205f5-e425-4e78-8ebb-aaefc79a65ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577093086-172.17.0.11-1596895602128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-421d9c04-a587-4371-b7f8-dc79e5c601bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-7b5bf850-1305-4c58-ba17-caa84b7c2be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-069f8d89-dd72-40dc-8f4d-40d4c671a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-b8df2324-c3d1-4a42-8c14-4effa07096b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-a1784fbc-da77-4b3d-89d7-761bf082d7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-d90cf4e2-6f54-4081-8fd1-352a7d41caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-026c5837-d3b5-43e8-98ac-324197569fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b64bf3d6-6824-4a99-88a5-bfbd5e10a7d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577093086-172.17.0.11-1596895602128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-421d9c04-a587-4371-b7f8-dc79e5c601bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-7b5bf850-1305-4c58-ba17-caa84b7c2be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-069f8d89-dd72-40dc-8f4d-40d4c671a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-b8df2324-c3d1-4a42-8c14-4effa07096b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-a1784fbc-da77-4b3d-89d7-761bf082d7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-d90cf4e2-6f54-4081-8fd1-352a7d41caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-026c5837-d3b5-43e8-98ac-324197569fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b64bf3d6-6824-4a99-88a5-bfbd5e10a7d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892340820-172.17.0.11-1596895745073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39287,DS-213fd948-9137-44f3-baf0-e52c3eda557f,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-f8583364-7479-4938-b437-96ebd0fab67c,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-e541d871-5fac-4448-b48c-677356e7d431,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-c6c26b9a-4998-4d3c-af2b-39ff31afcb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-9f862a3b-c076-4615-8b65-4ffb0dba618c,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-d452f2e7-ae86-499d-861e-e3400e01767d,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-36396d34-ec4f-483b-be09-666b9793fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-2e04cd90-d285-43aa-8afe-e5b3b3593a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892340820-172.17.0.11-1596895745073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39287,DS-213fd948-9137-44f3-baf0-e52c3eda557f,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-f8583364-7479-4938-b437-96ebd0fab67c,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-e541d871-5fac-4448-b48c-677356e7d431,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-c6c26b9a-4998-4d3c-af2b-39ff31afcb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-9f862a3b-c076-4615-8b65-4ffb0dba618c,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-d452f2e7-ae86-499d-861e-e3400e01767d,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-36396d34-ec4f-483b-be09-666b9793fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-2e04cd90-d285-43aa-8afe-e5b3b3593a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408489891-172.17.0.11-1596896351270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-3e89b686-8c14-448b-9f42-0da171c13b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-4927d43b-4dc7-4b89-8075-9bfb61cb2f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-bbedb343-5b7a-448e-af8c-efaae3849eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-81b715ec-db4a-4a26-9bc7-d0c2a1de5178,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-239981ed-4993-40fd-8ded-5303d97ad157,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-36127fdf-5ac5-42ad-bca1-2aaf99ab1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-4c73a46e-7bad-4b24-895f-232f471efc68,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-9ae440ac-db21-4f92-bb62-0607524a6bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408489891-172.17.0.11-1596896351270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-3e89b686-8c14-448b-9f42-0da171c13b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-4927d43b-4dc7-4b89-8075-9bfb61cb2f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-bbedb343-5b7a-448e-af8c-efaae3849eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-81b715ec-db4a-4a26-9bc7-d0c2a1de5178,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-239981ed-4993-40fd-8ded-5303d97ad157,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-36127fdf-5ac5-42ad-bca1-2aaf99ab1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-4c73a46e-7bad-4b24-895f-232f471efc68,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-9ae440ac-db21-4f92-bb62-0607524a6bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308928133-172.17.0.11-1596896381991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-185ff28c-5d97-49eb-b41f-10d8a7571a90,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-d3ef2da5-1c9f-46d8-a70a-7ff991781089,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-3f8d1acd-2ccb-4bd4-82a9-5d8c6ba77add,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ac9424d7-af46-448d-8787-38bf73ff1640,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-9ee2ac0d-08a0-4a86-8bf6-0024e1ed8e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-ea595867-c468-4660-961a-8b67658bb390,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-56071e2e-ad08-4c4f-907c-275cecdcc89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-e6e3af91-26e3-4af1-b7f9-8f5879ec7200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308928133-172.17.0.11-1596896381991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-185ff28c-5d97-49eb-b41f-10d8a7571a90,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-d3ef2da5-1c9f-46d8-a70a-7ff991781089,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-3f8d1acd-2ccb-4bd4-82a9-5d8c6ba77add,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ac9424d7-af46-448d-8787-38bf73ff1640,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-9ee2ac0d-08a0-4a86-8bf6-0024e1ed8e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-ea595867-c468-4660-961a-8b67658bb390,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-56071e2e-ad08-4c4f-907c-275cecdcc89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-e6e3af91-26e3-4af1-b7f9-8f5879ec7200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037272242-172.17.0.11-1596896871341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40704,DS-15acb82e-08fc-4f99-9e7d-d8f3ae258e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-b204d548-5baf-44ce-b213-d0d0610d0b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-12cf565b-5733-44f7-a69b-032978c634e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-b29c9f0c-62c7-485a-857d-bf023a7ffec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-cb67b8b2-863c-4513-9b71-81f351867f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-9debacd2-9b78-4d67-bc6b-c6f06f547957,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-e7efd04e-0260-4961-82a5-812b2ed4d336,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-27d81f4f-f678-48a6-9ca8-0e573806ac46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037272242-172.17.0.11-1596896871341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40704,DS-15acb82e-08fc-4f99-9e7d-d8f3ae258e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-b204d548-5baf-44ce-b213-d0d0610d0b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-12cf565b-5733-44f7-a69b-032978c634e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-b29c9f0c-62c7-485a-857d-bf023a7ffec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-cb67b8b2-863c-4513-9b71-81f351867f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-9debacd2-9b78-4d67-bc6b-c6f06f547957,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-e7efd04e-0260-4961-82a5-812b2ed4d336,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-27d81f4f-f678-48a6-9ca8-0e573806ac46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825374278-172.17.0.11-1596897149095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44487,DS-7bdef6dd-e498-4720-941b-b97c072665be,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-33bec905-f9c7-479e-9714-9791caa0f28d,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0bffbeb0-f2a4-4297-80f6-911ea3cbcf80,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-b13397b8-ab61-497e-a931-ca051a315e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-1a93b8f6-7c07-414c-8654-0f443ae14724,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-a73e9561-6967-4bc3-9ee8-84d8b722b12d,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-f79f7e72-c4aa-40b7-8c7b-7799934d9352,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-85b25945-c7fc-42dc-a074-54628d7486b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825374278-172.17.0.11-1596897149095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44487,DS-7bdef6dd-e498-4720-941b-b97c072665be,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-33bec905-f9c7-479e-9714-9791caa0f28d,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0bffbeb0-f2a4-4297-80f6-911ea3cbcf80,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-b13397b8-ab61-497e-a931-ca051a315e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-1a93b8f6-7c07-414c-8654-0f443ae14724,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-a73e9561-6967-4bc3-9ee8-84d8b722b12d,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-f79f7e72-c4aa-40b7-8c7b-7799934d9352,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-85b25945-c7fc-42dc-a074-54628d7486b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434344838-172.17.0.11-1596897486214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-bc3313cc-e542-47b8-a628-4c45703c1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-785a4f5d-d59e-45e1-953f-f2b0ad8f3508,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-5eea2f0c-4f6f-44b3-9991-5fe414c48895,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-f76bbfd1-235c-412b-ba21-c3156008ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-a044167a-92a5-47ef-8170-54439f1646c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-217f0873-bf37-468f-b8b0-6327073babe5,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-b917c551-608b-4716-ad25-97c720f663bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-12b6c93e-3cdf-43c4-8f96-e425871699b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434344838-172.17.0.11-1596897486214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-bc3313cc-e542-47b8-a628-4c45703c1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-785a4f5d-d59e-45e1-953f-f2b0ad8f3508,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-5eea2f0c-4f6f-44b3-9991-5fe414c48895,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-f76bbfd1-235c-412b-ba21-c3156008ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-a044167a-92a5-47ef-8170-54439f1646c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-217f0873-bf37-468f-b8b0-6327073babe5,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-b917c551-608b-4716-ad25-97c720f663bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-12b6c93e-3cdf-43c4-8f96-e425871699b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677539010-172.17.0.11-1596898219133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-1649e9c8-48b5-41c7-94aa-57bdfcacafc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-48860c80-72c9-423d-b772-635ee51899aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-0be2542d-c562-4e59-a501-745e76428cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-e677fbfb-1156-4c87-a8d1-4d5999a4425f,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-fb07bd0a-319b-43f9-8eea-07ea2c818279,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-e791b2fe-2cce-4617-8b79-1468eb0620b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-cb310be0-dbda-4302-ac26-df9ecd966763,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-51cb6993-a4cf-4d8f-b196-44a9840c469f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677539010-172.17.0.11-1596898219133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-1649e9c8-48b5-41c7-94aa-57bdfcacafc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-48860c80-72c9-423d-b772-635ee51899aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-0be2542d-c562-4e59-a501-745e76428cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-e677fbfb-1156-4c87-a8d1-4d5999a4425f,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-fb07bd0a-319b-43f9-8eea-07ea2c818279,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-e791b2fe-2cce-4617-8b79-1468eb0620b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-cb310be0-dbda-4302-ac26-df9ecd966763,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-51cb6993-a4cf-4d8f-b196-44a9840c469f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832980697-172.17.0.11-1596898290286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-ff674258-eaee-49ca-a587-90cc4783b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-370ace23-2dea-498f-83e5-c79915e3550b,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-61716403-176f-43a0-b6c3-95a751dc8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-9e70b2c1-2a03-4ae7-b9f7-eefd3c484f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-5daaf9bb-f99a-4cc0-ad80-031cb8632bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-d7a942e0-6601-4934-a37a-7890bccf95f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-c2f46369-f6cb-4043-9687-64063cced865,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-66e8e67e-d5f8-4d00-962e-4f128fa51ba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832980697-172.17.0.11-1596898290286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-ff674258-eaee-49ca-a587-90cc4783b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-370ace23-2dea-498f-83e5-c79915e3550b,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-61716403-176f-43a0-b6c3-95a751dc8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-9e70b2c1-2a03-4ae7-b9f7-eefd3c484f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-5daaf9bb-f99a-4cc0-ad80-031cb8632bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-d7a942e0-6601-4934-a37a-7890bccf95f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-c2f46369-f6cb-4043-9687-64063cced865,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-66e8e67e-d5f8-4d00-962e-4f128fa51ba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391546660-172.17.0.11-1596898327155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-eb7cdaf7-3824-45ee-9cf3-b444d15e89a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-6ccf05f6-f01f-49fa-bb83-f6105cd0ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-316f4612-0a4f-4ac2-945e-2084418bf66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-2450660c-45f3-4353-ad78-51a1b2ea70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-6196ae45-a7d5-4a68-877c-c366c1e02221,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-04f2eb3f-815a-415e-904b-ac2d3b55864f,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-6f305177-9bec-4485-b5a7-1101d4043698,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-ca7aa327-3ad5-475f-bc47-acb2c408de7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391546660-172.17.0.11-1596898327155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-eb7cdaf7-3824-45ee-9cf3-b444d15e89a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-6ccf05f6-f01f-49fa-bb83-f6105cd0ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-316f4612-0a4f-4ac2-945e-2084418bf66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-2450660c-45f3-4353-ad78-51a1b2ea70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-6196ae45-a7d5-4a68-877c-c366c1e02221,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-04f2eb3f-815a-415e-904b-ac2d3b55864f,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-6f305177-9bec-4485-b5a7-1101d4043698,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-ca7aa327-3ad5-475f-bc47-acb2c408de7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255851493-172.17.0.11-1596899433380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-5624a5c9-7213-4feb-821d-9ad6efdffb70,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-d6e6fcf6-cc0a-4f35-9224-7412aa989fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-29420b81-3266-4e9f-8ca2-7ff23eedd0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-71d7dbb7-ad5e-401c-97a1-ee67c5e3498a,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-be85203f-8801-42fa-beef-07a18a286aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-219168e8-052b-4252-9c0c-feea03d87794,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-5119f774-134f-4f33-a476-2f6df55b123b,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-24614f31-332f-4759-8deb-802890cb98b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255851493-172.17.0.11-1596899433380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-5624a5c9-7213-4feb-821d-9ad6efdffb70,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-d6e6fcf6-cc0a-4f35-9224-7412aa989fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-29420b81-3266-4e9f-8ca2-7ff23eedd0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-71d7dbb7-ad5e-401c-97a1-ee67c5e3498a,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-be85203f-8801-42fa-beef-07a18a286aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-219168e8-052b-4252-9c0c-feea03d87794,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-5119f774-134f-4f33-a476-2f6df55b123b,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-24614f31-332f-4759-8deb-802890cb98b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886204480-172.17.0.11-1596899466250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43347,DS-cecf1092-e5da-416d-bc64-f6e9160a4f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-b83fb9be-c9fd-4971-b543-46de4a755901,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-5c1bc670-cc93-4251-8908-0a4c9e0b28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-24cb7c4a-bb01-4817-a441-060257888957,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-2956f5e4-9366-490e-b77a-8cf960e442a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-519ae6dd-d8ad-446b-916c-435578a99036,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-d41f195a-0dd7-4842-b0a4-8cef13ff7827,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-2fdd05df-f2dd-4600-91c3-fcd762b14351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886204480-172.17.0.11-1596899466250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43347,DS-cecf1092-e5da-416d-bc64-f6e9160a4f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-b83fb9be-c9fd-4971-b543-46de4a755901,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-5c1bc670-cc93-4251-8908-0a4c9e0b28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-24cb7c4a-bb01-4817-a441-060257888957,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-2956f5e4-9366-490e-b77a-8cf960e442a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-519ae6dd-d8ad-446b-916c-435578a99036,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-d41f195a-0dd7-4842-b0a4-8cef13ff7827,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-2fdd05df-f2dd-4600-91c3-fcd762b14351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5072
