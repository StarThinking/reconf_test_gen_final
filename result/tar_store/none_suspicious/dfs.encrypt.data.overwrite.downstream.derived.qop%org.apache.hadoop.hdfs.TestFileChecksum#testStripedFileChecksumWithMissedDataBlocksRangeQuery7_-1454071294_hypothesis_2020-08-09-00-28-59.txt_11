reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779341062-172.17.0.11-1596933030102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33295,DS-c976bc02-34e0-43c6-b78a-adc797149e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-713b883d-fca9-4b18-aad8-10f813a88431,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-8dc76918-9cdc-43e7-af8c-72965db326ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-377a28a0-e50a-40d3-aa78-7a93b1d25425,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-2fb9f67a-ba7f-4816-b589-b65f7ae2d373,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-ccca2355-62b3-4b6c-a3a0-b3004cac0361,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-446d13cf-0889-4ab2-bd69-396adf4bdb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-86b9bc56-cc4a-4619-b25c-84d4d9a581d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779341062-172.17.0.11-1596933030102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33295,DS-c976bc02-34e0-43c6-b78a-adc797149e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-713b883d-fca9-4b18-aad8-10f813a88431,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-8dc76918-9cdc-43e7-af8c-72965db326ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-377a28a0-e50a-40d3-aa78-7a93b1d25425,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-2fb9f67a-ba7f-4816-b589-b65f7ae2d373,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-ccca2355-62b3-4b6c-a3a0-b3004cac0361,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-446d13cf-0889-4ab2-bd69-396adf4bdb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-86b9bc56-cc4a-4619-b25c-84d4d9a581d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352018568-172.17.0.11-1596933105167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-b5e4d56d-396e-445a-8bc2-94ab34d3dcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-e209a65a-c4bb-4061-9875-0af70c3f08f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-31ad3bad-0860-456d-ab54-d83b3ff8f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-b7d4d486-66a6-4509-9ecb-7f209bf83f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-2af224e7-0ac7-4447-ba91-1558c6d84407,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-e79a2266-b463-48f9-a049-c49d8b23a7af,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-bbdab534-cbd0-4922-9891-fe33c5dad6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-44d748f5-89b0-4ca8-bd8f-582412e2bb14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352018568-172.17.0.11-1596933105167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-b5e4d56d-396e-445a-8bc2-94ab34d3dcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-e209a65a-c4bb-4061-9875-0af70c3f08f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-31ad3bad-0860-456d-ab54-d83b3ff8f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-b7d4d486-66a6-4509-9ecb-7f209bf83f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-2af224e7-0ac7-4447-ba91-1558c6d84407,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-e79a2266-b463-48f9-a049-c49d8b23a7af,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-bbdab534-cbd0-4922-9891-fe33c5dad6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-44d748f5-89b0-4ca8-bd8f-582412e2bb14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435394313-172.17.0.11-1596933139588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37457,DS-99c870f7-74ce-43fd-9f80-f14caf483a20,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-37cf109c-3f7e-464b-a531-3a04679f82b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-d0f8a756-e99e-485e-89cd-a62e1dabebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-1a6dba18-9db2-475d-9dda-2fd4cd31fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-17f7d94c-0e4a-41da-b695-47e30b7e33f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-26978f47-e9e6-4730-8039-9923d50c69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-7c51ee0a-68b2-4351-91b2-77b38fae6ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-ad89ed6a-b444-4ee7-bb6d-d64bd7b41cb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435394313-172.17.0.11-1596933139588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37457,DS-99c870f7-74ce-43fd-9f80-f14caf483a20,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-37cf109c-3f7e-464b-a531-3a04679f82b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-d0f8a756-e99e-485e-89cd-a62e1dabebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-1a6dba18-9db2-475d-9dda-2fd4cd31fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-17f7d94c-0e4a-41da-b695-47e30b7e33f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-26978f47-e9e6-4730-8039-9923d50c69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-7c51ee0a-68b2-4351-91b2-77b38fae6ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-ad89ed6a-b444-4ee7-bb6d-d64bd7b41cb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034149105-172.17.0.11-1596933323318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-0f161f6d-97c7-4c4a-9377-0ea8b297ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-83cdf535-3f5a-4e70-bc3b-555b1b3ff70e,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-36f92951-6d1c-4445-bb6d-ce915f4388bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-04d64f73-883f-45bb-b7c8-9f826154a370,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-438be96e-dfec-4de5-bd6d-cf28dd6baee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-cc5effbd-12a2-4787-bc62-230da381b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-1cfd5a93-46b3-4fd3-966b-312395542a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-c54fa627-d07f-4a39-b88e-7020f6c4fa13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034149105-172.17.0.11-1596933323318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-0f161f6d-97c7-4c4a-9377-0ea8b297ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-83cdf535-3f5a-4e70-bc3b-555b1b3ff70e,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-36f92951-6d1c-4445-bb6d-ce915f4388bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-04d64f73-883f-45bb-b7c8-9f826154a370,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-438be96e-dfec-4de5-bd6d-cf28dd6baee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-cc5effbd-12a2-4787-bc62-230da381b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-1cfd5a93-46b3-4fd3-966b-312395542a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-c54fa627-d07f-4a39-b88e-7020f6c4fa13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863235493-172.17.0.11-1596933357694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-64886ba3-1ef5-4f7d-8224-13148750944c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-c185be8d-124f-4e0e-a948-d78c3d1dc005,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-97774c39-5cce-4212-8526-6d4684203950,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-2c0dc02c-7bcd-4fdb-bfc9-00cd29175e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-206b8602-261f-4bbc-a0c8-81c73fcc3d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-610c44eb-eb6f-4582-b627-296d548ab041,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-35f436a6-83a4-447c-ade6-077ae0a2e235,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-7ebdf097-dd5e-4afd-a9e6-c9813311c93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863235493-172.17.0.11-1596933357694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-64886ba3-1ef5-4f7d-8224-13148750944c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-c185be8d-124f-4e0e-a948-d78c3d1dc005,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-97774c39-5cce-4212-8526-6d4684203950,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-2c0dc02c-7bcd-4fdb-bfc9-00cd29175e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-206b8602-261f-4bbc-a0c8-81c73fcc3d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-610c44eb-eb6f-4582-b627-296d548ab041,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-35f436a6-83a4-447c-ade6-077ae0a2e235,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-7ebdf097-dd5e-4afd-a9e6-c9813311c93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965141083-172.17.0.11-1596933797030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38294,DS-053efae6-a55f-43c2-ad3b-eea20539b116,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0313a62d-4ffe-448a-b8c9-5dac74e92f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-2a39da8b-e155-48bc-b87e-12357ea8c926,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-ece55c57-c8df-4c5a-a76d-1b8de9393549,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-92a026a2-199a-474f-a184-68391fb28d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-78b9e2ed-2b3e-4c5c-8582-6201213a2660,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-461c719c-f8f3-4ce8-adc6-d981d4270141,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-20a568ca-9939-40b5-8c48-1e889bf68b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965141083-172.17.0.11-1596933797030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38294,DS-053efae6-a55f-43c2-ad3b-eea20539b116,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0313a62d-4ffe-448a-b8c9-5dac74e92f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-2a39da8b-e155-48bc-b87e-12357ea8c926,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-ece55c57-c8df-4c5a-a76d-1b8de9393549,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-92a026a2-199a-474f-a184-68391fb28d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-78b9e2ed-2b3e-4c5c-8582-6201213a2660,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-461c719c-f8f3-4ce8-adc6-d981d4270141,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-20a568ca-9939-40b5-8c48-1e889bf68b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840786401-172.17.0.11-1596933830223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-6317987d-e5d0-4130-99ff-471846b6a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-085b8b04-ff63-4c21-a151-73d2c1e08262,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-3d64e480-b377-4a4a-a4a9-8b9be79586bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-b958b0ab-e19e-4d6c-937d-59a77506fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-482bc1c1-5c45-40ca-be13-c725e00f92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-2e0364f7-6b0e-4150-90ab-ed15beefdb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-d4293761-f87d-4ed8-adbb-50c9ef510d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-a4e7ff78-addc-40af-b9fa-48b73ace511c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840786401-172.17.0.11-1596933830223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-6317987d-e5d0-4130-99ff-471846b6a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-085b8b04-ff63-4c21-a151-73d2c1e08262,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-3d64e480-b377-4a4a-a4a9-8b9be79586bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-b958b0ab-e19e-4d6c-937d-59a77506fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-482bc1c1-5c45-40ca-be13-c725e00f92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-2e0364f7-6b0e-4150-90ab-ed15beefdb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-d4293761-f87d-4ed8-adbb-50c9ef510d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-a4e7ff78-addc-40af-b9fa-48b73ace511c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226748435-172.17.0.11-1596933895601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-1a39b32d-fc1a-460a-8746-ab2f9f8cc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-b458f238-6063-4c95-aaff-00240c70f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-98cd37c7-bc75-4520-a18f-97a36f5e8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-348f2f6e-2d6c-42a0-b074-f8a74560913d,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-ccee9bdd-ed50-4ff3-936d-4d522259e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-6b58b44c-f574-43a2-94e8-dec40b487ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-3514fbed-da12-4aba-bef5-767519af5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-997ad782-e174-41aa-9d73-7a348d1a125f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226748435-172.17.0.11-1596933895601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-1a39b32d-fc1a-460a-8746-ab2f9f8cc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-b458f238-6063-4c95-aaff-00240c70f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-98cd37c7-bc75-4520-a18f-97a36f5e8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-348f2f6e-2d6c-42a0-b074-f8a74560913d,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-ccee9bdd-ed50-4ff3-936d-4d522259e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-6b58b44c-f574-43a2-94e8-dec40b487ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-3514fbed-da12-4aba-bef5-767519af5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-997ad782-e174-41aa-9d73-7a348d1a125f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909608998-172.17.0.11-1596933970290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39853,DS-0bd75f13-2068-42b8-af1c-e007af63cd28,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-a1b9b940-d364-4170-86dd-fdd4bd2f60c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-c5a96bb8-f182-491a-a440-720c215efcca,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-f8c9c866-98f6-42f9-beda-0233dee15c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-17299785-bec2-4b5f-ae17-538dd216dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-7f28e441-15ce-4f2f-8d3d-bd09df3de3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-63e668c7-1b54-428a-8a09-319377dfa945,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-0e652540-8c2a-44fc-8659-0e844ea8bcb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909608998-172.17.0.11-1596933970290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39853,DS-0bd75f13-2068-42b8-af1c-e007af63cd28,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-a1b9b940-d364-4170-86dd-fdd4bd2f60c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-c5a96bb8-f182-491a-a440-720c215efcca,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-f8c9c866-98f6-42f9-beda-0233dee15c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-17299785-bec2-4b5f-ae17-538dd216dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-7f28e441-15ce-4f2f-8d3d-bd09df3de3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-63e668c7-1b54-428a-8a09-319377dfa945,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-0e652540-8c2a-44fc-8659-0e844ea8bcb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304157495-172.17.0.11-1596934039039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35392,DS-6e9fb0fe-d025-47ff-b92d-137038f0daca,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-d6b15fa8-ea4a-4976-bbd5-9db84f6136e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-337f49f0-bff6-4a02-9191-4bb0ecc0b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-0d2ef410-04a4-4f29-9ca7-8572153564cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-af1522fc-c13f-43c5-bf82-203a06c67fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-ce72fad2-4ce5-424c-a07e-f7bc5ec9f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-4e41a540-40e3-4e77-a5d1-1e05d40c9d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-5a8e7610-f684-4939-9b2c-9cb87801a710,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304157495-172.17.0.11-1596934039039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35392,DS-6e9fb0fe-d025-47ff-b92d-137038f0daca,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-d6b15fa8-ea4a-4976-bbd5-9db84f6136e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-337f49f0-bff6-4a02-9191-4bb0ecc0b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-0d2ef410-04a4-4f29-9ca7-8572153564cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-af1522fc-c13f-43c5-bf82-203a06c67fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-ce72fad2-4ce5-424c-a07e-f7bc5ec9f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-4e41a540-40e3-4e77-a5d1-1e05d40c9d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-5a8e7610-f684-4939-9b2c-9cb87801a710,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015092236-172.17.0.11-1596934231573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-5a5c3e14-fce2-40bb-b481-6d22662aecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-132cd249-3b61-4522-b998-9209ef7963bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-81ed2261-d252-42e6-b99a-8b7899d0207a,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-e028ed47-37f4-48c2-a5db-15afb4e33a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-713de2a1-ad57-4d35-9b5d-db20093499ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-254eb4eb-3531-46b6-9488-762a49c6d878,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-6e76353a-309c-4d63-93e8-5b9d231ccc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-8986360c-b9bf-41d5-83c1-faddbe5dfd85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015092236-172.17.0.11-1596934231573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-5a5c3e14-fce2-40bb-b481-6d22662aecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-132cd249-3b61-4522-b998-9209ef7963bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-81ed2261-d252-42e6-b99a-8b7899d0207a,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-e028ed47-37f4-48c2-a5db-15afb4e33a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-713de2a1-ad57-4d35-9b5d-db20093499ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-254eb4eb-3531-46b6-9488-762a49c6d878,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-6e76353a-309c-4d63-93e8-5b9d231ccc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-8986360c-b9bf-41d5-83c1-faddbe5dfd85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428518756-172.17.0.11-1596934338461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-df5b4fd5-77ec-451c-874e-6460c8d78247,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-27c562b8-434e-4ca3-a06a-8a94ea4b7f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-e7ad5414-2011-4158-ba95-26400974cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-a9e04710-cbdc-4653-bbc2-b3317fe46502,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-563f6be6-c514-4ad7-b9f2-00fe797c8698,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-276af38c-b335-433e-991e-7eb232a60b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-b9130746-643d-420b-bfec-e0335c8093d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-3a5bfc0b-3689-4d6d-a3c1-6bf3af2b4773,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428518756-172.17.0.11-1596934338461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-df5b4fd5-77ec-451c-874e-6460c8d78247,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-27c562b8-434e-4ca3-a06a-8a94ea4b7f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-e7ad5414-2011-4158-ba95-26400974cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-a9e04710-cbdc-4653-bbc2-b3317fe46502,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-563f6be6-c514-4ad7-b9f2-00fe797c8698,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-276af38c-b335-433e-991e-7eb232a60b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-b9130746-643d-420b-bfec-e0335c8093d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-3a5bfc0b-3689-4d6d-a3c1-6bf3af2b4773,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006240338-172.17.0.11-1596934411543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39442,DS-e63241b2-d141-436b-8fd9-cf67fbea0324,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-bb38130b-d693-4fac-bde5-106eb1d1d437,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-d25716c4-5395-49b2-acc9-c6bd08560335,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-77200001-0065-45d0-96e7-fd7d64e0f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-aae72a60-393d-494f-8222-2aae80f0cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-d87e8788-e825-47be-9195-deb551793336,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-e4424955-b88b-4204-944f-4db53a6be6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-1b4e6120-479f-4850-a292-baeab7fe4f70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006240338-172.17.0.11-1596934411543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39442,DS-e63241b2-d141-436b-8fd9-cf67fbea0324,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-bb38130b-d693-4fac-bde5-106eb1d1d437,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-d25716c4-5395-49b2-acc9-c6bd08560335,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-77200001-0065-45d0-96e7-fd7d64e0f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-aae72a60-393d-494f-8222-2aae80f0cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-d87e8788-e825-47be-9195-deb551793336,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-e4424955-b88b-4204-944f-4db53a6be6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-1b4e6120-479f-4850-a292-baeab7fe4f70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269204714-172.17.0.11-1596934711531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-0ba4792a-ecc1-44eb-b204-60cbc64a07c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-3d1475b1-31ac-4d50-8de3-b1e073545a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-37383702-443c-4b87-8a74-5fdbe27da72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-9271567b-4110-4069-b187-f12c64f84430,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-0e4f6406-4fd7-4854-92f4-8bd5f7954525,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-1226df57-d701-4b34-984d-eec957e24121,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-aaeb9e64-8cf6-4ea5-abfa-23d53459d838,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-5d56b72d-43f7-4856-b35f-772e4f3ec0ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269204714-172.17.0.11-1596934711531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-0ba4792a-ecc1-44eb-b204-60cbc64a07c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-3d1475b1-31ac-4d50-8de3-b1e073545a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-37383702-443c-4b87-8a74-5fdbe27da72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-9271567b-4110-4069-b187-f12c64f84430,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-0e4f6406-4fd7-4854-92f4-8bd5f7954525,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-1226df57-d701-4b34-984d-eec957e24121,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-aaeb9e64-8cf6-4ea5-abfa-23d53459d838,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-5d56b72d-43f7-4856-b35f-772e4f3ec0ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780807310-172.17.0.11-1596934796588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39372,DS-1011b712-b90b-4825-8d5b-8c6908405bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-631d9ede-8586-4403-a236-d51877599809,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-c4c87383-bfac-4d19-95bb-3ac7051c6d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-bf6f71a1-af9d-4b60-a7c3-7faf088427f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-6a7c1b77-38e3-4366-8ec4-35a528654004,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-089ac0ed-0e4d-40e9-8c48-7daa14be266b,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-0482cfd1-c097-4333-b72f-1f52b7e2c7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-49b050cf-7a61-46ca-8f07-ff6eeed0299a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780807310-172.17.0.11-1596934796588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39372,DS-1011b712-b90b-4825-8d5b-8c6908405bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-631d9ede-8586-4403-a236-d51877599809,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-c4c87383-bfac-4d19-95bb-3ac7051c6d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-bf6f71a1-af9d-4b60-a7c3-7faf088427f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-6a7c1b77-38e3-4366-8ec4-35a528654004,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-089ac0ed-0e4d-40e9-8c48-7daa14be266b,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-0482cfd1-c097-4333-b72f-1f52b7e2c7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-49b050cf-7a61-46ca-8f07-ff6eeed0299a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098089787-172.17.0.11-1596935200787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-5d135f0a-b176-48b8-b25b-ddbbfc16c167,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-8f407dc8-afc6-4d31-a455-ca115a94f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-566b28ba-100f-45c9-82bb-a2e6c1632e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-3e86fcb1-ff7a-46e5-87b6-204c081a9410,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-697e42a0-22a2-4bc4-b45b-19f3395ad901,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-8f77aa8e-2d27-40df-b8c9-7e8e96a4023c,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-bfbe4195-c565-419e-b449-f9b89e424132,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-5696d651-4c39-4eb6-a269-c04fd5a13ca4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098089787-172.17.0.11-1596935200787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-5d135f0a-b176-48b8-b25b-ddbbfc16c167,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-8f407dc8-afc6-4d31-a455-ca115a94f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-566b28ba-100f-45c9-82bb-a2e6c1632e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-3e86fcb1-ff7a-46e5-87b6-204c081a9410,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-697e42a0-22a2-4bc4-b45b-19f3395ad901,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-8f77aa8e-2d27-40df-b8c9-7e8e96a4023c,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-bfbe4195-c565-419e-b449-f9b89e424132,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-5696d651-4c39-4eb6-a269-c04fd5a13ca4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015131990-172.17.0.11-1596935231790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44900,DS-cbb59a57-1e18-47c5-a8c6-462083af61f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-a0d6f24b-de8b-4d3c-af96-67496117aa71,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-81400552-1fdc-452c-9850-dd9f4388fe51,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-2b56b4ae-d460-4427-b4b4-7672dbf80cee,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-c9a64dc3-9132-4f2e-ba34-3e8c0da55dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-ad43db99-d2e4-4fcc-89e9-8d8abfc5629e,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-6af309c8-d618-4062-b55d-4b571142232a,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-c149b843-57b1-438d-a4ed-71a8f0653c22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015131990-172.17.0.11-1596935231790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44900,DS-cbb59a57-1e18-47c5-a8c6-462083af61f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-a0d6f24b-de8b-4d3c-af96-67496117aa71,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-81400552-1fdc-452c-9850-dd9f4388fe51,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-2b56b4ae-d460-4427-b4b4-7672dbf80cee,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-c9a64dc3-9132-4f2e-ba34-3e8c0da55dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-ad43db99-d2e4-4fcc-89e9-8d8abfc5629e,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-6af309c8-d618-4062-b55d-4b571142232a,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-c149b843-57b1-438d-a4ed-71a8f0653c22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213075322-172.17.0.11-1596935313637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-abc36b35-183e-40ec-a3a1-bf23548508c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-02e58af8-81c0-43b6-b28a-85700cd796d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-bb8efb72-121f-4ff3-83f0-23a0b5d5bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e174b5a1-6c8e-4761-b129-f88212264e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-18c103a4-17a3-4038-ae5b-baec96f28741,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-fd4d220c-f2c9-4ca9-a446-b5a976df487b,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-d23f76a2-eb84-4837-9909-a81eb1df1cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-d80b5dc3-03b9-4166-87eb-80c90036f1e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213075322-172.17.0.11-1596935313637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-abc36b35-183e-40ec-a3a1-bf23548508c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-02e58af8-81c0-43b6-b28a-85700cd796d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-bb8efb72-121f-4ff3-83f0-23a0b5d5bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e174b5a1-6c8e-4761-b129-f88212264e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-18c103a4-17a3-4038-ae5b-baec96f28741,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-fd4d220c-f2c9-4ca9-a446-b5a976df487b,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-d23f76a2-eb84-4837-9909-a81eb1df1cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-d80b5dc3-03b9-4166-87eb-80c90036f1e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366212332-172.17.0.11-1596935777086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-de308b94-3432-4b3c-886d-097cee7d1e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-7d15eff0-d5d0-4428-88c7-d34dd87561a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-bdb38eef-6778-4fb5-8260-0526f23fe3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-5ea0c8d5-f60f-45d7-81a5-ab181456177d,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-6330a032-3a8d-4358-ab7e-58ac2a05d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-271ca779-6e24-4b3a-b218-c7449210e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-7c4fe6aa-32b2-418d-ada4-ee79b0df8640,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-c8b378ef-6884-4e37-8c23-ce22b32b13d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366212332-172.17.0.11-1596935777086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-de308b94-3432-4b3c-886d-097cee7d1e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-7d15eff0-d5d0-4428-88c7-d34dd87561a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-bdb38eef-6778-4fb5-8260-0526f23fe3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-5ea0c8d5-f60f-45d7-81a5-ab181456177d,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-6330a032-3a8d-4358-ab7e-58ac2a05d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-271ca779-6e24-4b3a-b218-c7449210e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-7c4fe6aa-32b2-418d-ada4-ee79b0df8640,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-c8b378ef-6884-4e37-8c23-ce22b32b13d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746552353-172.17.0.11-1596935879011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-1f690835-942e-4639-b421-6e5da956b538,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-0a26f199-e6e9-45c9-b858-35b42c9fc58f,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-a01dfff9-90a3-41be-9f5f-9d62c3a2830f,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-d81efd8e-2226-45cf-9274-c8f06e772d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-e5351a24-2382-4c5c-8e22-cdf08a6dac53,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-ebf57c0e-e6eb-4d6c-a355-d492019dcc18,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-0f7c21a4-bfb4-4eeb-8f15-d565c73601db,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-4ca51ebf-e8ad-4511-b860-e8610173375a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746552353-172.17.0.11-1596935879011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-1f690835-942e-4639-b421-6e5da956b538,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-0a26f199-e6e9-45c9-b858-35b42c9fc58f,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-a01dfff9-90a3-41be-9f5f-9d62c3a2830f,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-d81efd8e-2226-45cf-9274-c8f06e772d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-e5351a24-2382-4c5c-8e22-cdf08a6dac53,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-ebf57c0e-e6eb-4d6c-a355-d492019dcc18,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-0f7c21a4-bfb4-4eeb-8f15-d565c73601db,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-4ca51ebf-e8ad-4511-b860-e8610173375a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530934943-172.17.0.11-1596935918974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-6d864d49-2ded-4540-971d-3df591bee072,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-345b556f-7b24-4e4b-a9bf-cc935cd3a085,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-3b44fd2b-9f34-46b6-b6a3-96d7e0f068df,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-3aec9fd5-4f1e-41a7-9abc-4dff799ce2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-c6dd5cb5-c910-4df2-92b0-1ec66970f7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7667fe08-8380-410c-b713-75e53370fe35,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-0d57d91f-008c-4bad-bf9e-5e7688a56e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-34039feb-d912-4ee6-8302-bd6924de31df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530934943-172.17.0.11-1596935918974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-6d864d49-2ded-4540-971d-3df591bee072,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-345b556f-7b24-4e4b-a9bf-cc935cd3a085,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-3b44fd2b-9f34-46b6-b6a3-96d7e0f068df,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-3aec9fd5-4f1e-41a7-9abc-4dff799ce2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-c6dd5cb5-c910-4df2-92b0-1ec66970f7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7667fe08-8380-410c-b713-75e53370fe35,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-0d57d91f-008c-4bad-bf9e-5e7688a56e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-34039feb-d912-4ee6-8302-bd6924de31df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393689243-172.17.0.11-1596936068965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35199,DS-ac85f202-058a-4a6e-83f5-1cc2fbc75cef,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-11869fed-c237-4806-bfe9-abc3cdcadc40,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-1626a8f8-a612-4543-b9d6-ce97dfe16e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-9ae3b470-23c2-48ff-8fde-d752e2b107f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-e7debb8d-ee37-4a12-b903-431c24f31d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-280989ac-d603-45d2-bdab-c296cf6b0360,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-404db90a-3dd7-4c5e-92f4-395f4076bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2a4d2166-70df-4f4a-9a61-5c59ce3c1c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393689243-172.17.0.11-1596936068965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35199,DS-ac85f202-058a-4a6e-83f5-1cc2fbc75cef,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-11869fed-c237-4806-bfe9-abc3cdcadc40,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-1626a8f8-a612-4543-b9d6-ce97dfe16e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-9ae3b470-23c2-48ff-8fde-d752e2b107f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-e7debb8d-ee37-4a12-b903-431c24f31d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-280989ac-d603-45d2-bdab-c296cf6b0360,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-404db90a-3dd7-4c5e-92f4-395f4076bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2a4d2166-70df-4f4a-9a61-5c59ce3c1c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199056502-172.17.0.11-1596936213420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43187,DS-73c29b99-d624-4157-9e4a-ddff2f8ecde2,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-729f475e-8e64-404f-9bcd-7e5360483346,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-c22e3f81-be2c-4981-ba92-109702d19a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-8682ba06-1a35-4260-b913-5b744310b848,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-85ec14ed-651b-4d08-95f3-475c09172f01,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b735f5e4-6d73-4381-b7bf-896de236289a,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-c6915e3f-1721-41a6-8772-3f25dd054681,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-62487f4c-81b1-4e80-a181-1b2ba88ce6c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199056502-172.17.0.11-1596936213420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43187,DS-73c29b99-d624-4157-9e4a-ddff2f8ecde2,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-729f475e-8e64-404f-9bcd-7e5360483346,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-c22e3f81-be2c-4981-ba92-109702d19a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-8682ba06-1a35-4260-b913-5b744310b848,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-85ec14ed-651b-4d08-95f3-475c09172f01,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b735f5e4-6d73-4381-b7bf-896de236289a,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-c6915e3f-1721-41a6-8772-3f25dd054681,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-62487f4c-81b1-4e80-a181-1b2ba88ce6c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152311998-172.17.0.11-1596936382849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-5ca23a9a-00ae-4ddb-ab55-3f510cbd603b,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-0da53647-8b23-4754-b2c2-39ed3fbfb26c,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-37e8c5b6-977b-44be-a519-bf4af7ab2ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-e956d03c-32e1-4fe3-9192-a41193c666e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-1051ee84-d685-473d-8998-e4a39932e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-8f4fa6b3-b022-4ad3-a157-89dd7ae9cc23,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-ce9b9a05-d245-4b42-94da-38b5f953cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-55bb07e7-4f8b-4843-bd45-b9acde59fb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152311998-172.17.0.11-1596936382849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-5ca23a9a-00ae-4ddb-ab55-3f510cbd603b,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-0da53647-8b23-4754-b2c2-39ed3fbfb26c,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-37e8c5b6-977b-44be-a519-bf4af7ab2ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-e956d03c-32e1-4fe3-9192-a41193c666e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-1051ee84-d685-473d-8998-e4a39932e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-8f4fa6b3-b022-4ad3-a157-89dd7ae9cc23,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-ce9b9a05-d245-4b42-94da-38b5f953cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-55bb07e7-4f8b-4843-bd45-b9acde59fb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491222859-172.17.0.11-1596936544404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-83577de9-39e5-4582-8803-d244284c325d,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-2e94f44f-9860-4132-add9-50dbe47fc06b,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-f9150177-a4b2-4f9b-8af4-b6fccab4aabb,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-759b66c2-7277-4ce3-9f7a-a2d85b700f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-b7173d30-9a51-4d4d-8b4f-21104abcbfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-09aef1d9-86bb-4fdc-b517-ab005a0a3f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-9c2c49a2-f14c-47af-9514-f704508e3037,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-5796651f-f371-4fbb-b077-c573c2261aeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491222859-172.17.0.11-1596936544404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-83577de9-39e5-4582-8803-d244284c325d,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-2e94f44f-9860-4132-add9-50dbe47fc06b,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-f9150177-a4b2-4f9b-8af4-b6fccab4aabb,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-759b66c2-7277-4ce3-9f7a-a2d85b700f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-b7173d30-9a51-4d4d-8b4f-21104abcbfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-09aef1d9-86bb-4fdc-b517-ab005a0a3f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-9c2c49a2-f14c-47af-9514-f704508e3037,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-5796651f-f371-4fbb-b077-c573c2261aeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849859772-172.17.0.11-1596936578977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45322,DS-d1e9bad4-fb4f-4933-9bed-e6d23ee3971e,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-242e3768-1fc9-4ed8-b944-073697646a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-3fdedc9a-9249-48dc-a736-4b46bb79beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-fac85b1b-0c96-46bb-a447-451b8c79bff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-f746a6fb-f506-44d5-bdf7-43dbc39ab06a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-dea5801a-6b1d-4f67-960a-a9ad5a38661e,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-0267fb8d-12ce-460d-b5f5-d87cb7e4a569,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-2745fbb0-883a-4d56-a0bf-4a7a53ea031c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849859772-172.17.0.11-1596936578977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45322,DS-d1e9bad4-fb4f-4933-9bed-e6d23ee3971e,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-242e3768-1fc9-4ed8-b944-073697646a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-3fdedc9a-9249-48dc-a736-4b46bb79beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-fac85b1b-0c96-46bb-a447-451b8c79bff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-f746a6fb-f506-44d5-bdf7-43dbc39ab06a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-dea5801a-6b1d-4f67-960a-a9ad5a38661e,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-0267fb8d-12ce-460d-b5f5-d87cb7e4a569,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-2745fbb0-883a-4d56-a0bf-4a7a53ea031c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225023423-172.17.0.11-1596936865155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-32154254-5af2-41bd-a34d-af01efa4affb,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-db191f69-4115-4662-bbd9-c48e261b0118,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-24142420-d824-4a0f-becd-e52f0c7adba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-cf8b0f2d-c2ab-4bdc-b12b-a921932ae0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-5747593b-4af8-4e4f-9cdf-3801b7a46e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-9d36f59e-e15e-4260-bc4d-e2a6862cc780,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-d1dd3150-9aba-4237-994c-11ac01c7c703,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-eaf2ac14-c8ec-491f-b14b-9f125815b746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225023423-172.17.0.11-1596936865155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-32154254-5af2-41bd-a34d-af01efa4affb,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-db191f69-4115-4662-bbd9-c48e261b0118,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-24142420-d824-4a0f-becd-e52f0c7adba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-cf8b0f2d-c2ab-4bdc-b12b-a921932ae0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-5747593b-4af8-4e4f-9cdf-3801b7a46e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-9d36f59e-e15e-4260-bc4d-e2a6862cc780,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-d1dd3150-9aba-4237-994c-11ac01c7c703,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-eaf2ac14-c8ec-491f-b14b-9f125815b746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672916728-172.17.0.11-1596936939990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-b555d0a1-8708-4194-adab-15baf8c7b677,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-23575c8f-12f4-4c0f-b8dc-daf6ad6e738e,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-c1ea8bf4-6de1-4385-8c29-c3821b30b656,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-745d7238-f6e2-4965-8f71-06bf339aaaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-42836d00-08cc-4598-b9da-67c4deac7916,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-e5f96ef0-2e85-465e-bf96-db1fa3095d39,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-f09a95c9-2dae-41ec-b959-843f8ac4b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-df547b5c-7440-422a-b829-216c15358890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672916728-172.17.0.11-1596936939990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-b555d0a1-8708-4194-adab-15baf8c7b677,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-23575c8f-12f4-4c0f-b8dc-daf6ad6e738e,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-c1ea8bf4-6de1-4385-8c29-c3821b30b656,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-745d7238-f6e2-4965-8f71-06bf339aaaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-42836d00-08cc-4598-b9da-67c4deac7916,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-e5f96ef0-2e85-465e-bf96-db1fa3095d39,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-f09a95c9-2dae-41ec-b959-843f8ac4b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-df547b5c-7440-422a-b829-216c15358890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215904086-172.17.0.11-1596937543172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-8d8b9f9c-1da1-4e63-b183-a6ddb0912cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-54a5d149-1e5e-4180-bfec-8cd33dc4516d,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-4d9c6e5a-19ee-4660-9417-53ba3fe8cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-5ea963ef-6881-48e5-bb37-6805383dad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-be4c4a75-9026-46b0-be38-321547692ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-52a7a8c4-713a-4848-9a86-4c8b1648dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-8339ea80-f275-4a9f-9e65-615cfee5ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-7eae1b91-98cb-46bb-9900-22ae0bff4f27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215904086-172.17.0.11-1596937543172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-8d8b9f9c-1da1-4e63-b183-a6ddb0912cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-54a5d149-1e5e-4180-bfec-8cd33dc4516d,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-4d9c6e5a-19ee-4660-9417-53ba3fe8cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-5ea963ef-6881-48e5-bb37-6805383dad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-be4c4a75-9026-46b0-be38-321547692ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-52a7a8c4-713a-4848-9a86-4c8b1648dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-8339ea80-f275-4a9f-9e65-615cfee5ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-7eae1b91-98cb-46bb-9900-22ae0bff4f27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6151596-172.17.0.11-1596937580054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-407bf7c7-ca12-41ef-b2ad-46ae6e34c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-fb77fbb0-6c8b-4360-862c-aa42b449b52a,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-44d10329-17ef-4c73-98e5-bff4ad4e07ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-90d92ed6-218e-410f-b833-1a5cb8855549,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-483a9e15-8283-47e8-8679-926faec01512,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-302fb295-8cee-4f18-8dc1-94ceb3eddd97,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-b8942e34-36f8-4ce9-8ef8-eac3685ec77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-57c66e0b-5b82-4194-9e1c-728e6897f0f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6151596-172.17.0.11-1596937580054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-407bf7c7-ca12-41ef-b2ad-46ae6e34c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-fb77fbb0-6c8b-4360-862c-aa42b449b52a,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-44d10329-17ef-4c73-98e5-bff4ad4e07ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-90d92ed6-218e-410f-b833-1a5cb8855549,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-483a9e15-8283-47e8-8679-926faec01512,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-302fb295-8cee-4f18-8dc1-94ceb3eddd97,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-b8942e34-36f8-4ce9-8ef8-eac3685ec77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-57c66e0b-5b82-4194-9e1c-728e6897f0f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282278612-172.17.0.11-1596937612897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-f8c55575-a966-41f6-8cc8-5c2748dc7f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-a87f72c2-833e-471f-9309-690e106eedde,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-a03acdd8-5319-47d7-a573-bbbb86bb7620,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-f55e6f86-e736-4054-83ae-986f179a26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-5b230a95-b55a-4b16-a829-abe0fd2fca80,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-2598bbe9-b008-487f-b64d-b1be576c3942,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-4905097a-1dec-4d84-97f2-1d30af4ce8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-b42ad205-5202-41da-80d2-3651a914570b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282278612-172.17.0.11-1596937612897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-f8c55575-a966-41f6-8cc8-5c2748dc7f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-a87f72c2-833e-471f-9309-690e106eedde,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-a03acdd8-5319-47d7-a573-bbbb86bb7620,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-f55e6f86-e736-4054-83ae-986f179a26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-5b230a95-b55a-4b16-a829-abe0fd2fca80,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-2598bbe9-b008-487f-b64d-b1be576c3942,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-4905097a-1dec-4d84-97f2-1d30af4ce8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-b42ad205-5202-41da-80d2-3651a914570b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981439986-172.17.0.11-1596937654654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35999,DS-7c1c53f4-da33-4441-98ff-ef6f830607d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-5de28476-094d-49d7-befb-8cf4edffd54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-1ba0b252-5768-4b22-ad17-d3fd4b684879,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-bcb73ca8-64ad-4317-b3b7-247094fa1ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-2ed078cd-655c-409c-a24e-ffbdc5f6736f,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-f35bb4d1-1038-41ba-b4b9-6868639799da,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-2c351099-bf56-4ba0-921a-5351fea016cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-3028ba16-2335-4920-b680-d0746bdec978,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981439986-172.17.0.11-1596937654654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35999,DS-7c1c53f4-da33-4441-98ff-ef6f830607d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-5de28476-094d-49d7-befb-8cf4edffd54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-1ba0b252-5768-4b22-ad17-d3fd4b684879,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-bcb73ca8-64ad-4317-b3b7-247094fa1ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-2ed078cd-655c-409c-a24e-ffbdc5f6736f,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-f35bb4d1-1038-41ba-b4b9-6868639799da,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-2c351099-bf56-4ba0-921a-5351fea016cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-3028ba16-2335-4920-b680-d0746bdec978,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466239119-172.17.0.11-1596937860176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-516e8e26-7547-48ee-9cc1-d926c7133d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-e3d5f070-5368-4d31-8d6d-c7aa8864bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-e1080075-ae3d-4679-b254-7ea3b66f8848,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-53525cb3-c14d-4593-9431-bee96860c162,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-2d40db7a-ee81-41f1-a6e2-813ee05ca443,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-b1e42b23-a9cd-433e-9e59-d3b51765cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-dd66f669-df19-43dc-be50-f13d3d03c652,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-2b3e9b5e-18b3-4a24-a645-6f7c69ec01da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466239119-172.17.0.11-1596937860176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-516e8e26-7547-48ee-9cc1-d926c7133d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-e3d5f070-5368-4d31-8d6d-c7aa8864bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-e1080075-ae3d-4679-b254-7ea3b66f8848,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-53525cb3-c14d-4593-9431-bee96860c162,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-2d40db7a-ee81-41f1-a6e2-813ee05ca443,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-b1e42b23-a9cd-433e-9e59-d3b51765cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-dd66f669-df19-43dc-be50-f13d3d03c652,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-2b3e9b5e-18b3-4a24-a645-6f7c69ec01da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828881296-172.17.0.11-1596937895595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-74416de4-0007-4884-b272-61609b515f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-9ec17197-89b8-483d-ad03-c352b9b00fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-69ebefe2-5f5e-4cd1-afea-22b7aeb2d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-7b64f14a-d765-4d6d-81cc-82aa6476be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-2c3eb769-a8ce-481f-9ba9-644f02a3b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-ee26876e-7a88-4b2f-a165-cdca2bd4cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-0ff19e89-078b-488e-921b-735dbd78ebbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-d0f8f0b2-8887-4abc-be1e-ac2a219b0499,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828881296-172.17.0.11-1596937895595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-74416de4-0007-4884-b272-61609b515f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-9ec17197-89b8-483d-ad03-c352b9b00fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-69ebefe2-5f5e-4cd1-afea-22b7aeb2d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-7b64f14a-d765-4d6d-81cc-82aa6476be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-2c3eb769-a8ce-481f-9ba9-644f02a3b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-ee26876e-7a88-4b2f-a165-cdca2bd4cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-0ff19e89-078b-488e-921b-735dbd78ebbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-d0f8f0b2-8887-4abc-be1e-ac2a219b0499,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589167054-172.17.0.11-1596937974735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43278,DS-bed1f713-03cb-47ff-82f6-2a39412f509b,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-a30f6d80-c231-4f6c-9e4c-91d8f93f8c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-1405db0a-d18c-4188-ae86-0e346ccda9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-bd6d315a-53a5-48de-9fde-3506c6afc74d,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-3f5223a2-1a28-4b40-9e67-fec6c708b106,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-9e6cea5f-c3a1-47f2-b53d-52ddaab632ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-10896b66-e9ed-4e9b-bb59-bfb658feb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-67d22f2f-3560-47a3-b7a2-c2be51551dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589167054-172.17.0.11-1596937974735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43278,DS-bed1f713-03cb-47ff-82f6-2a39412f509b,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-a30f6d80-c231-4f6c-9e4c-91d8f93f8c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-1405db0a-d18c-4188-ae86-0e346ccda9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-bd6d315a-53a5-48de-9fde-3506c6afc74d,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-3f5223a2-1a28-4b40-9e67-fec6c708b106,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-9e6cea5f-c3a1-47f2-b53d-52ddaab632ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-10896b66-e9ed-4e9b-bb59-bfb658feb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-67d22f2f-3560-47a3-b7a2-c2be51551dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124508580-172.17.0.11-1596938267888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-09b7ba28-b3bd-45f7-b4b0-8435b0367d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-612f5e9f-0166-40fe-b0b6-adee93c9a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-72e88858-0070-4d21-9816-bf8e41f9e7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-16b814ba-8c71-41ac-9881-53db19e46922,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-d417cb98-842d-47a9-bc01-a781e818b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-5c39c4e3-33c0-4534-bcce-8ba02b9e7a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-5cb8575f-5ed1-4f92-a81c-72164f56b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-f8ee9c84-7024-4fac-a547-d11ac8b5cc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124508580-172.17.0.11-1596938267888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-09b7ba28-b3bd-45f7-b4b0-8435b0367d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-612f5e9f-0166-40fe-b0b6-adee93c9a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-72e88858-0070-4d21-9816-bf8e41f9e7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-16b814ba-8c71-41ac-9881-53db19e46922,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-d417cb98-842d-47a9-bc01-a781e818b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-5c39c4e3-33c0-4534-bcce-8ba02b9e7a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-5cb8575f-5ed1-4f92-a81c-72164f56b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-f8ee9c84-7024-4fac-a547-d11ac8b5cc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5418
