reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721424325-172.17.0.14-1596967821068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-57130312-5ce8-44a1-99d9-7b00ce63eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-0732aa73-5747-42d6-8a8a-03e7b7c4109b,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-a4b8ba20-823f-419d-94c7-77ecc3e073cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-a9d84603-501a-4e53-9f4b-b12a1a9aa7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-1d1b0e33-903a-4c9d-af7c-5a729683dad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-d8b551e4-07d7-44f3-8edc-5add25f0f534,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-9e700135-97e2-42be-885d-bc1a1d58c946,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-d8bad5f6-3342-4250-b383-16160da37ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721424325-172.17.0.14-1596967821068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-57130312-5ce8-44a1-99d9-7b00ce63eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-0732aa73-5747-42d6-8a8a-03e7b7c4109b,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-a4b8ba20-823f-419d-94c7-77ecc3e073cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-a9d84603-501a-4e53-9f4b-b12a1a9aa7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-1d1b0e33-903a-4c9d-af7c-5a729683dad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-d8b551e4-07d7-44f3-8edc-5add25f0f534,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-9e700135-97e2-42be-885d-bc1a1d58c946,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-d8bad5f6-3342-4250-b383-16160da37ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827667818-172.17.0.14-1596967960458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-88be796c-bf89-44fb-9169-f6d8e9970844,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-82aa3b0a-d20f-41be-9547-0ce169d219de,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-cb011cb5-d143-4217-aaa1-cfff4094c518,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-7447d7e7-9bed-4251-9b29-f4437d454c71,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-f6e7399a-cc1f-4baa-8234-df0b7861d378,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-ab652eb4-7927-42d8-82f2-bd39fc73889d,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-9e9141c8-95e0-47ee-aafc-8999f5aad7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-bf1b90fa-76a0-4632-8e75-e0efddfb06f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827667818-172.17.0.14-1596967960458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-88be796c-bf89-44fb-9169-f6d8e9970844,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-82aa3b0a-d20f-41be-9547-0ce169d219de,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-cb011cb5-d143-4217-aaa1-cfff4094c518,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-7447d7e7-9bed-4251-9b29-f4437d454c71,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-f6e7399a-cc1f-4baa-8234-df0b7861d378,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-ab652eb4-7927-42d8-82f2-bd39fc73889d,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-9e9141c8-95e0-47ee-aafc-8999f5aad7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-bf1b90fa-76a0-4632-8e75-e0efddfb06f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298796559-172.17.0.14-1596968589152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-6e164d6a-7714-47ec-826c-ca98e6d54fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-e5150fa1-db4d-4bc0-83a6-c94c7cef8259,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-dbd31108-7549-4cbe-82dd-b9ef234aaddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-2095184d-d297-42d2-9898-8ad924c0a44a,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-d9c21da1-8a63-417c-bc24-881af6f96731,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-ef4bfd32-b8ce-432c-ae4f-c32403626701,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-f627cb52-184c-425c-b012-0c460c2c835c,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-586c7ba1-02f0-4581-8d43-39ee0756471b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298796559-172.17.0.14-1596968589152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-6e164d6a-7714-47ec-826c-ca98e6d54fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-e5150fa1-db4d-4bc0-83a6-c94c7cef8259,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-dbd31108-7549-4cbe-82dd-b9ef234aaddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-2095184d-d297-42d2-9898-8ad924c0a44a,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-d9c21da1-8a63-417c-bc24-881af6f96731,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-ef4bfd32-b8ce-432c-ae4f-c32403626701,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-f627cb52-184c-425c-b012-0c460c2c835c,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-586c7ba1-02f0-4581-8d43-39ee0756471b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219879755-172.17.0.14-1596968744517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-f14a5fe1-dcbf-42b1-b4f3-c86d4b990087,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-130b8dfb-6d45-4df0-8820-3165afacdaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-964ae06c-2b37-4b8d-bc6c-1071900c7e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-0748de88-73b2-4727-a513-422ef6b42670,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-a5b2a24c-7fb7-4b57-bd46-185040407f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-8d11ac2a-4b02-4d06-8933-e7e9af33a535,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-af771619-ecbf-4c90-b772-b613cb5fb490,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-f5ae6b02-31a3-4f9a-8104-5699e82d7fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219879755-172.17.0.14-1596968744517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-f14a5fe1-dcbf-42b1-b4f3-c86d4b990087,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-130b8dfb-6d45-4df0-8820-3165afacdaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-964ae06c-2b37-4b8d-bc6c-1071900c7e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-0748de88-73b2-4727-a513-422ef6b42670,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-a5b2a24c-7fb7-4b57-bd46-185040407f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-8d11ac2a-4b02-4d06-8933-e7e9af33a535,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-af771619-ecbf-4c90-b772-b613cb5fb490,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-f5ae6b02-31a3-4f9a-8104-5699e82d7fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934201684-172.17.0.14-1596968791990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39664,DS-7de4bd4b-f81c-454a-8be0-675cba99f938,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-0a35473c-8b6f-4af2-ad7e-e210b3350d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ab04f29e-1db9-4232-a3d3-ada4b9c1ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-d5043ef7-d5bb-4cc3-bf9b-ba318ec13a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-ff4d4989-634f-4a55-8fdb-2b45039a7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-0104d6d5-c9e4-4b59-97ca-e3cf5c758c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-0b736633-d081-490d-a035-7be79fe83c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-dcc7a9e9-ccfe-449e-8b38-6ce930a461aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934201684-172.17.0.14-1596968791990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39664,DS-7de4bd4b-f81c-454a-8be0-675cba99f938,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-0a35473c-8b6f-4af2-ad7e-e210b3350d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ab04f29e-1db9-4232-a3d3-ada4b9c1ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-d5043ef7-d5bb-4cc3-bf9b-ba318ec13a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-ff4d4989-634f-4a55-8fdb-2b45039a7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-0104d6d5-c9e4-4b59-97ca-e3cf5c758c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-0b736633-d081-490d-a035-7be79fe83c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-dcc7a9e9-ccfe-449e-8b38-6ce930a461aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622676881-172.17.0.14-1596968842727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-9ffa58d8-11e0-48e0-8385-f069369b2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-5aed645a-aee6-4d3a-a650-a1fc67a9664f,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-7c9d27d2-e101-4312-8921-a76b5480b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-ab951f3a-ca90-4c55-95c9-5c0747bff8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-463d7059-8e74-4a3a-9ac9-31c10e765e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-e3f799f4-213b-4d68-9f34-35b64db45c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-a5f8fbee-83ac-40ea-a057-0056699441be,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5767ecc7-b2af-45cd-8f05-5f8e376da9ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622676881-172.17.0.14-1596968842727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-9ffa58d8-11e0-48e0-8385-f069369b2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-5aed645a-aee6-4d3a-a650-a1fc67a9664f,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-7c9d27d2-e101-4312-8921-a76b5480b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-ab951f3a-ca90-4c55-95c9-5c0747bff8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-463d7059-8e74-4a3a-9ac9-31c10e765e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-e3f799f4-213b-4d68-9f34-35b64db45c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-a5f8fbee-83ac-40ea-a057-0056699441be,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5767ecc7-b2af-45cd-8f05-5f8e376da9ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283856377-172.17.0.14-1596969037435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-ded21154-b1bd-4967-b1f8-41018e23cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-54f44ef6-26ee-47c9-9a10-cedb49cc2a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-21e22b0d-ac93-4a36-b06c-60b37bfc3cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-158b36a7-4a8c-401f-befb-6b453e0f18d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-3a7918fd-67da-49ed-9621-0e6ccc379472,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-c8921881-a60a-4218-a13e-07c97131ba10,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-a742200e-846e-4d8d-875f-e4d06655c327,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-266924ae-44d7-45e4-a95b-c02529d99c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283856377-172.17.0.14-1596969037435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-ded21154-b1bd-4967-b1f8-41018e23cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-54f44ef6-26ee-47c9-9a10-cedb49cc2a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-21e22b0d-ac93-4a36-b06c-60b37bfc3cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-158b36a7-4a8c-401f-befb-6b453e0f18d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-3a7918fd-67da-49ed-9621-0e6ccc379472,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-c8921881-a60a-4218-a13e-07c97131ba10,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-a742200e-846e-4d8d-875f-e4d06655c327,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-266924ae-44d7-45e4-a95b-c02529d99c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082761505-172.17.0.14-1596969618849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-4b3d4424-f5d2-4129-8e5c-e8e27613bc95,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-31d88254-26e4-4b7c-8c65-9ac778a7b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-04f18932-fea0-4ad2-8b77-697eb19e2570,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-e903e26b-d333-4be6-88df-b0a7f32d32b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-a37fda33-c2e4-4d8b-aee6-e31cde9fcc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-f7b35fdc-b800-43e3-a117-3b1152415763,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-b471470f-e307-48e8-bea9-3a3412e7e1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-58a67b06-8251-47a3-9be3-212fe5af4548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082761505-172.17.0.14-1596969618849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-4b3d4424-f5d2-4129-8e5c-e8e27613bc95,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-31d88254-26e4-4b7c-8c65-9ac778a7b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-04f18932-fea0-4ad2-8b77-697eb19e2570,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-e903e26b-d333-4be6-88df-b0a7f32d32b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-a37fda33-c2e4-4d8b-aee6-e31cde9fcc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-f7b35fdc-b800-43e3-a117-3b1152415763,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-b471470f-e307-48e8-bea9-3a3412e7e1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-58a67b06-8251-47a3-9be3-212fe5af4548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927931854-172.17.0.14-1596970111054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-c7c38964-baee-4894-a901-47a37b89f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-906dd9b3-b1d3-4871-a0be-d40a6f0728d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-194f4062-2304-41ca-a730-9e4e0f92505f,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-437313f2-688b-48a1-a918-2c3aaba16850,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-0d7e235c-b3ae-4747-b0d9-d29532209bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-8377e77b-22c3-49e6-89f7-fb6df996ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-0bc5a8c7-4ab9-4732-9039-881b326f805a,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-34795b64-77a5-4289-a0be-dc6abe612135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927931854-172.17.0.14-1596970111054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-c7c38964-baee-4894-a901-47a37b89f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-906dd9b3-b1d3-4871-a0be-d40a6f0728d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-194f4062-2304-41ca-a730-9e4e0f92505f,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-437313f2-688b-48a1-a918-2c3aaba16850,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-0d7e235c-b3ae-4747-b0d9-d29532209bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-8377e77b-22c3-49e6-89f7-fb6df996ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-0bc5a8c7-4ab9-4732-9039-881b326f805a,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-34795b64-77a5-4289-a0be-dc6abe612135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010524595-172.17.0.14-1596970480418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-1c1923df-fd4e-4ff4-b463-c0777db3dd45,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-4d507a3c-b015-4f8f-bce0-fcb0419726f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-7c8301c6-d215-4644-b012-e9198ebf0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-e5ac5fb8-157c-4a1b-9b93-7ec8b937fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-8fa71095-ef76-403e-8e10-4cd97a301c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-1e191b47-81c5-4c63-8438-b3ff967d81e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-b5364d9f-caa4-4fac-8b0f-1776de15543b,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-2007705b-abb3-4e90-8eea-01f70034aab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010524595-172.17.0.14-1596970480418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-1c1923df-fd4e-4ff4-b463-c0777db3dd45,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-4d507a3c-b015-4f8f-bce0-fcb0419726f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-7c8301c6-d215-4644-b012-e9198ebf0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-e5ac5fb8-157c-4a1b-9b93-7ec8b937fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-8fa71095-ef76-403e-8e10-4cd97a301c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-1e191b47-81c5-4c63-8438-b3ff967d81e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-b5364d9f-caa4-4fac-8b0f-1776de15543b,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-2007705b-abb3-4e90-8eea-01f70034aab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836784305-172.17.0.14-1596970630580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46775,DS-80e08f29-ad51-4065-9f3d-58d4185d65bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-2b298894-cc0e-4b1b-9d29-b4aa32f6712c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-28afd09c-09de-45bd-acf1-1be710964552,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-9f6f6fb3-7f0e-49be-9e48-4e5558016b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-76c53e03-ce44-4b15-9547-267977bd94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-93ec8a7f-877d-4883-b13a-683b5d016f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-6b6cdf22-262b-44db-8cb5-f25e6dc0fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-62611481-57e7-4e42-9bfd-b70d61300632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836784305-172.17.0.14-1596970630580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46775,DS-80e08f29-ad51-4065-9f3d-58d4185d65bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-2b298894-cc0e-4b1b-9d29-b4aa32f6712c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-28afd09c-09de-45bd-acf1-1be710964552,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-9f6f6fb3-7f0e-49be-9e48-4e5558016b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-76c53e03-ce44-4b15-9547-267977bd94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-93ec8a7f-877d-4883-b13a-683b5d016f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-6b6cdf22-262b-44db-8cb5-f25e6dc0fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-62611481-57e7-4e42-9bfd-b70d61300632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559597929-172.17.0.14-1596971041408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-ffd4083c-aea2-422c-a674-09ec6fb50f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-bf6e02dc-4890-4998-9bbc-27cf134a60f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-0d3c99d5-20fe-4d28-a471-55a8ddff8e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-c6622afa-d5b0-4df3-9fc4-aa8810cd869c,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e7d58f0f-7094-4a2d-9d02-1abc744d0b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-8ac66f56-3acf-487f-8d86-6db5953c4700,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-165560ef-cb9e-4c8a-abfb-8d8dc00e920e,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-1e6c131c-7c0b-43c1-96fc-3e9a90013025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559597929-172.17.0.14-1596971041408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-ffd4083c-aea2-422c-a674-09ec6fb50f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-bf6e02dc-4890-4998-9bbc-27cf134a60f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-0d3c99d5-20fe-4d28-a471-55a8ddff8e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-c6622afa-d5b0-4df3-9fc4-aa8810cd869c,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e7d58f0f-7094-4a2d-9d02-1abc744d0b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-8ac66f56-3acf-487f-8d86-6db5953c4700,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-165560ef-cb9e-4c8a-abfb-8d8dc00e920e,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-1e6c131c-7c0b-43c1-96fc-3e9a90013025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447054322-172.17.0.14-1596971093142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-5a9bb925-1da3-4d50-91a7-ed5f0b2dbdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-7338bdb8-866d-47c4-a783-f5f80808a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-eec5124d-6c4b-4037-adb3-6d82a3644e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-68360d98-2017-40b7-9cd1-323fc0c8e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-d8be2a43-b885-4aab-84b2-1d6a09b0fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-03cb243b-817a-4c01-9096-be981e45cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-e758e925-dcce-48d2-b8e3-c49be12465b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-bb378c8b-087a-4ad5-a728-7e9ec90d301c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447054322-172.17.0.14-1596971093142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-5a9bb925-1da3-4d50-91a7-ed5f0b2dbdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-7338bdb8-866d-47c4-a783-f5f80808a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-eec5124d-6c4b-4037-adb3-6d82a3644e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-68360d98-2017-40b7-9cd1-323fc0c8e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-d8be2a43-b885-4aab-84b2-1d6a09b0fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-03cb243b-817a-4c01-9096-be981e45cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-e758e925-dcce-48d2-b8e3-c49be12465b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-bb378c8b-087a-4ad5-a728-7e9ec90d301c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 3948
