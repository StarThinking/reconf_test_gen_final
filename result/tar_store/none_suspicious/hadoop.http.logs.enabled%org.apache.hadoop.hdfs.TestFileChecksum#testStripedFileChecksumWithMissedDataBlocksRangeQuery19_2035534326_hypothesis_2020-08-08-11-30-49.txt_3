reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962392007-172.17.0.5-1596886643749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41967,DS-48a1af9a-b513-44be-9fd9-3fed66cfe074,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-60011863-3585-4ef4-8180-d7c1ac4c5011,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-08c4ec6d-dc46-4759-b54f-4d4ed74f2375,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-d619c278-275d-4a2e-9dde-402aa1f6480a,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-82273ada-74f7-4d5c-b0b2-de884f3f7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-ea5b23e7-b611-4428-a756-4fcd0bcbb1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-8d51b014-fbf1-42dd-8fbc-18fb983608b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-a019f043-eaf8-4e7d-8390-ed3f57a555fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962392007-172.17.0.5-1596886643749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41967,DS-48a1af9a-b513-44be-9fd9-3fed66cfe074,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-60011863-3585-4ef4-8180-d7c1ac4c5011,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-08c4ec6d-dc46-4759-b54f-4d4ed74f2375,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-d619c278-275d-4a2e-9dde-402aa1f6480a,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-82273ada-74f7-4d5c-b0b2-de884f3f7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-ea5b23e7-b611-4428-a756-4fcd0bcbb1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-8d51b014-fbf1-42dd-8fbc-18fb983608b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-a019f043-eaf8-4e7d-8390-ed3f57a555fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271201307-172.17.0.5-1596886710880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-9c776e2e-8a24-4b1f-a325-a97494df7a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-2c3ec951-a160-4efd-b574-1440b29b741f,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-301b6c6a-f8c5-4f29-8ea4-1ef35987c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-643baa30-cccc-4cd2-8fe7-9935b50b2978,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-af252ec3-3902-4ded-a00d-8fc0a376f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-2e2105e3-053d-4890-ae55-b6081d225ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-93ccc292-63f8-418e-9c4d-4a7b7eb577dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-8318c096-8133-4779-b743-1761efb6fb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271201307-172.17.0.5-1596886710880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-9c776e2e-8a24-4b1f-a325-a97494df7a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-2c3ec951-a160-4efd-b574-1440b29b741f,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-301b6c6a-f8c5-4f29-8ea4-1ef35987c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-643baa30-cccc-4cd2-8fe7-9935b50b2978,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-af252ec3-3902-4ded-a00d-8fc0a376f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-2e2105e3-053d-4890-ae55-b6081d225ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-93ccc292-63f8-418e-9c4d-4a7b7eb577dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-8318c096-8133-4779-b743-1761efb6fb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300360891-172.17.0.5-1596886767621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-b56a9082-aa1d-4227-b7fb-d364086c6433,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-2a191d91-1c15-48fc-b221-de9340cf635e,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-b4141778-dd0d-4dc9-ad70-040886a8d609,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-edb2fc3e-6e16-4160-8e86-0e955fae50df,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-92975f7a-c038-4259-87f5-9e0dfbf8b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-55b81fee-0c45-4949-9fca-fd821ef57013,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-a0d06461-517d-4559-80fc-e42ee0972f00,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-e295fe68-ebdb-43eb-98a6-34a6a7b2a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300360891-172.17.0.5-1596886767621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-b56a9082-aa1d-4227-b7fb-d364086c6433,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-2a191d91-1c15-48fc-b221-de9340cf635e,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-b4141778-dd0d-4dc9-ad70-040886a8d609,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-edb2fc3e-6e16-4160-8e86-0e955fae50df,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-92975f7a-c038-4259-87f5-9e0dfbf8b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-55b81fee-0c45-4949-9fca-fd821ef57013,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-a0d06461-517d-4559-80fc-e42ee0972f00,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-e295fe68-ebdb-43eb-98a6-34a6a7b2a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222511365-172.17.0.5-1596887336672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41696,DS-81f3e6f4-a134-49ac-936f-1b35b6ad4ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-1a199c9b-4600-4da5-9d08-0b66682c3e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5f2d71bd-0c8f-439b-a11f-332b0387b51b,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-e8cc1347-ba6c-4b75-80bc-bbaab127aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-8f6455a9-c818-4740-9410-dca0b88a2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-defe3e4f-6947-405d-8ba0-3117a3c1d577,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-ed58314a-200b-420b-8fb5-1ee67747bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-b5a71f3a-b929-46a4-97b4-1db2f860ab49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222511365-172.17.0.5-1596887336672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41696,DS-81f3e6f4-a134-49ac-936f-1b35b6ad4ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-1a199c9b-4600-4da5-9d08-0b66682c3e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5f2d71bd-0c8f-439b-a11f-332b0387b51b,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-e8cc1347-ba6c-4b75-80bc-bbaab127aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-8f6455a9-c818-4740-9410-dca0b88a2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-defe3e4f-6947-405d-8ba0-3117a3c1d577,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-ed58314a-200b-420b-8fb5-1ee67747bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-b5a71f3a-b929-46a4-97b4-1db2f860ab49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18398482-172.17.0.5-1596887530989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33277,DS-0ad54040-a413-4880-b37a-d83c408e304d,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-fad8a93c-691a-4c40-856c-77b994366ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-6bc6dfb5-a033-43f2-9357-3194377ef47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-cf46f291-69eb-4f3c-884b-456a3d0e8072,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-9cefa824-1e91-434c-bfbc-ed80ae9e6eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-4c59f5d4-93b6-4e7a-baec-49603863408d,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-9d9c3d41-6f1b-4162-a69f-302312ddbb91,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-042a9667-4461-479d-b512-8548fc4eea69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18398482-172.17.0.5-1596887530989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33277,DS-0ad54040-a413-4880-b37a-d83c408e304d,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-fad8a93c-691a-4c40-856c-77b994366ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-6bc6dfb5-a033-43f2-9357-3194377ef47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-cf46f291-69eb-4f3c-884b-456a3d0e8072,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-9cefa824-1e91-434c-bfbc-ed80ae9e6eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-4c59f5d4-93b6-4e7a-baec-49603863408d,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-9d9c3d41-6f1b-4162-a69f-302312ddbb91,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-042a9667-4461-479d-b512-8548fc4eea69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924541035-172.17.0.5-1596887635488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-d2213c5f-c7fa-4c61-853b-6ea05fb9832a,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-04f96e08-3b32-4324-94c0-6e76c4f7d8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-bd4388ea-706d-4b3b-857e-1ff543caf5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-726d57ba-9c82-430a-a8d3-d09c0a9bac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-28e23598-fd2f-4a14-8113-cf0908de92bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-cd580f50-8882-4788-a8a4-fc5ed1ed76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-793b449a-8e52-4d00-b506-99c9ba5d3335,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-5f7bd8e1-4f26-4032-ae86-946ba4c85814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924541035-172.17.0.5-1596887635488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-d2213c5f-c7fa-4c61-853b-6ea05fb9832a,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-04f96e08-3b32-4324-94c0-6e76c4f7d8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-bd4388ea-706d-4b3b-857e-1ff543caf5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-726d57ba-9c82-430a-a8d3-d09c0a9bac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-28e23598-fd2f-4a14-8113-cf0908de92bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-cd580f50-8882-4788-a8a4-fc5ed1ed76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-793b449a-8e52-4d00-b506-99c9ba5d3335,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-5f7bd8e1-4f26-4032-ae86-946ba4c85814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710885738-172.17.0.5-1596887812194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-268145d4-73d7-4078-8e99-a8a4bd3a908c,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-d6e7d43e-6785-442a-a5fc-9b8246093816,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-595683c1-b3ba-40d0-9ed9-891c5881d699,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8624a202-2ce4-44c7-9a8d-5096ac1f5803,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-f074eeee-7b52-4b1b-b076-a1c613d6cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-f50d8f37-0c66-4e95-8382-34ee38ba209b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-75726da1-37ff-418f-91df-012da442ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-a0a0ee2f-c2a9-4ddf-b8a8-4fa098dad77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710885738-172.17.0.5-1596887812194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-268145d4-73d7-4078-8e99-a8a4bd3a908c,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-d6e7d43e-6785-442a-a5fc-9b8246093816,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-595683c1-b3ba-40d0-9ed9-891c5881d699,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8624a202-2ce4-44c7-9a8d-5096ac1f5803,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-f074eeee-7b52-4b1b-b076-a1c613d6cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-f50d8f37-0c66-4e95-8382-34ee38ba209b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-75726da1-37ff-418f-91df-012da442ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-a0a0ee2f-c2a9-4ddf-b8a8-4fa098dad77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548722890-172.17.0.5-1596888783936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-1f56708c-cce5-4406-a328-776b8278e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-e305227f-266d-4d20-9c24-bfbd8255441f,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-430efde3-69bc-4298-afe0-9e8d2cb12a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-82b9a281-edf3-4a25-a9f3-2cfa2fc85966,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-b413044e-dc55-4b9e-974f-287908ab73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-4a8280ca-2876-453a-ad32-b9ec6253dfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f7a23471-bc7c-41d6-9064-d560f689b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-133dce30-7bb4-4be1-bdc8-cb26900c0ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548722890-172.17.0.5-1596888783936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-1f56708c-cce5-4406-a328-776b8278e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-e305227f-266d-4d20-9c24-bfbd8255441f,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-430efde3-69bc-4298-afe0-9e8d2cb12a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-82b9a281-edf3-4a25-a9f3-2cfa2fc85966,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-b413044e-dc55-4b9e-974f-287908ab73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-4a8280ca-2876-453a-ad32-b9ec6253dfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f7a23471-bc7c-41d6-9064-d560f689b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-133dce30-7bb4-4be1-bdc8-cb26900c0ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074463591-172.17.0.5-1596888923660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-5450a365-af0d-4e43-82d5-244625f1fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-dfed6e66-5452-4dff-bc4b-98d8e9b90bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-d8fae6fd-c383-463b-8881-3bb1de461dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-39cbe161-1c01-4915-b48e-d60e2ad973ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-aed20764-13ad-4326-869c-4ec8ea3d57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-6edea7b2-2642-45d0-8899-110cd68217d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-0154a622-5711-4eb5-a62c-601050b12a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-87ee5424-f568-4498-92e9-473b2648a059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074463591-172.17.0.5-1596888923660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-5450a365-af0d-4e43-82d5-244625f1fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-dfed6e66-5452-4dff-bc4b-98d8e9b90bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-d8fae6fd-c383-463b-8881-3bb1de461dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-39cbe161-1c01-4915-b48e-d60e2ad973ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-aed20764-13ad-4326-869c-4ec8ea3d57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-6edea7b2-2642-45d0-8899-110cd68217d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-0154a622-5711-4eb5-a62c-601050b12a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-87ee5424-f568-4498-92e9-473b2648a059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292895290-172.17.0.5-1596889020172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-9d664821-1a86-4f8e-b908-cec3b0591418,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-c94c706c-b688-4077-a047-3b1446e6983d,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-7e1a3137-ebd6-4b4a-9ad9-814b53a2bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-086a13fc-69fe-47cd-94bb-697c9f9b8f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-b6ececc8-18fc-46be-ab1c-d2832591ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-29460bcd-681b-4b3c-8d5b-5eb9b06cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-8d4ba0f3-0a76-400e-a2e4-12327b19a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-bdbcd59e-19a5-44ae-8ff0-36896f028808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292895290-172.17.0.5-1596889020172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-9d664821-1a86-4f8e-b908-cec3b0591418,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-c94c706c-b688-4077-a047-3b1446e6983d,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-7e1a3137-ebd6-4b4a-9ad9-814b53a2bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-086a13fc-69fe-47cd-94bb-697c9f9b8f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-b6ececc8-18fc-46be-ab1c-d2832591ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-29460bcd-681b-4b3c-8d5b-5eb9b06cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-8d4ba0f3-0a76-400e-a2e4-12327b19a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-bdbcd59e-19a5-44ae-8ff0-36896f028808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449635590-172.17.0.5-1596889304073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-b18bf8c9-5463-40a2-b47e-07c548c8e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-873a9061-95d0-4533-81ff-4b4472ac1bea,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-4c67f480-26ea-4da4-8ef9-b1db3e3d5326,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-2cb50c00-133c-4e91-badd-c96d0118d588,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-a68a0317-5ffe-4fa7-b441-1fc27ccde724,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-4de093ba-c41c-46ce-b341-8883a6d490e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-9ceca6ea-954c-4cc1-a315-07aff6987d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-1354098f-44da-49d0-a986-7b1171cc4e1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449635590-172.17.0.5-1596889304073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-b18bf8c9-5463-40a2-b47e-07c548c8e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-873a9061-95d0-4533-81ff-4b4472ac1bea,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-4c67f480-26ea-4da4-8ef9-b1db3e3d5326,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-2cb50c00-133c-4e91-badd-c96d0118d588,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-a68a0317-5ffe-4fa7-b441-1fc27ccde724,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-4de093ba-c41c-46ce-b341-8883a6d490e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-9ceca6ea-954c-4cc1-a315-07aff6987d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-1354098f-44da-49d0-a986-7b1171cc4e1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91010376-172.17.0.5-1596889514570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-d8649c03-5ac3-4ac2-a5fa-4e515bc839ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-536df82b-96c8-4403-b0db-d825e36dff66,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-8cc57e48-7b3f-4b88-af67-d1526b98c3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-bfe05559-cd1b-4dcb-8b17-c6c84344122a,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-9b709166-5f51-4c4b-89e7-52d7c805cbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-65b88bf6-32a7-4745-99eb-07877844125a,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-6716964a-c6fb-4153-adaa-82268d5d3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-2c799902-9751-4afe-9a76-001f6eda6fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91010376-172.17.0.5-1596889514570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-d8649c03-5ac3-4ac2-a5fa-4e515bc839ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-536df82b-96c8-4403-b0db-d825e36dff66,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-8cc57e48-7b3f-4b88-af67-d1526b98c3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-bfe05559-cd1b-4dcb-8b17-c6c84344122a,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-9b709166-5f51-4c4b-89e7-52d7c805cbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-65b88bf6-32a7-4745-99eb-07877844125a,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-6716964a-c6fb-4153-adaa-82268d5d3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-2c799902-9751-4afe-9a76-001f6eda6fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996915501-172.17.0.5-1596889888360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-d6148326-2740-42f1-b45d-df738538fbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-23dc7ec4-13ee-42a0-a55f-e74b36a84387,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-9cd4af33-340d-4906-bad7-e89f38ece3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-876379aa-fc92-4f33-b1cf-98daeba0b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-7ad6b019-1f25-41a4-af00-2d9a97a98b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-972fe119-af0a-4729-b556-299edceae905,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-6bc2f509-e8d8-4de7-ba2c-ac8bf644c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-6f8642b3-af53-4a4b-83d6-e1db1803951e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996915501-172.17.0.5-1596889888360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-d6148326-2740-42f1-b45d-df738538fbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-23dc7ec4-13ee-42a0-a55f-e74b36a84387,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-9cd4af33-340d-4906-bad7-e89f38ece3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-876379aa-fc92-4f33-b1cf-98daeba0b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-7ad6b019-1f25-41a4-af00-2d9a97a98b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-972fe119-af0a-4729-b556-299edceae905,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-6bc2f509-e8d8-4de7-ba2c-ac8bf644c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-6f8642b3-af53-4a4b-83d6-e1db1803951e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549341071-172.17.0.5-1596890184638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-a2384403-7413-490e-8b4a-63297a1434d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-038ea550-b7d9-427f-87a0-6b9d489f846c,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-0a6ea21f-883b-4149-bce1-39d3c7ca6985,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0df39c65-5469-42fb-b86f-47bd049f2835,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-cd2cb2ea-2e13-4212-8c3e-fb2263398ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-b9515682-e61c-4559-a9ff-88170059a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-1bee893d-258f-4aa5-817d-ad6363f4b857,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-68c490d9-009b-4fdd-bc90-b59b8dac23b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549341071-172.17.0.5-1596890184638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-a2384403-7413-490e-8b4a-63297a1434d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-038ea550-b7d9-427f-87a0-6b9d489f846c,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-0a6ea21f-883b-4149-bce1-39d3c7ca6985,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0df39c65-5469-42fb-b86f-47bd049f2835,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-cd2cb2ea-2e13-4212-8c3e-fb2263398ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-b9515682-e61c-4559-a9ff-88170059a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-1bee893d-258f-4aa5-817d-ad6363f4b857,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-68c490d9-009b-4fdd-bc90-b59b8dac23b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278327573-172.17.0.5-1596891365143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-284b2918-5937-4f94-8424-b58eb83e6692,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-f7d694a9-ee99-408f-a957-64b9f11054d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-723e9050-1413-479c-ba8d-bc060499bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-37a3df72-5600-48f9-aa69-a897dfbaa47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-80113690-37c4-46b9-ba33-680ab746f502,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-29505920-ffee-43a5-b3aa-b897f918f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-ac94763b-6f5f-48d7-94a9-f5909c43b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-3cbb6ab3-fb66-450d-8da9-59aa9bba0b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278327573-172.17.0.5-1596891365143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-284b2918-5937-4f94-8424-b58eb83e6692,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-f7d694a9-ee99-408f-a957-64b9f11054d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-723e9050-1413-479c-ba8d-bc060499bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-37a3df72-5600-48f9-aa69-a897dfbaa47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-80113690-37c4-46b9-ba33-680ab746f502,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-29505920-ffee-43a5-b3aa-b897f918f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-ac94763b-6f5f-48d7-94a9-f5909c43b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-3cbb6ab3-fb66-450d-8da9-59aa9bba0b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454777036-172.17.0.5-1596891586561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-30ed604f-a687-4687-ad18-803a87a40f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-e455b2cd-0446-4b35-946f-2d22cb72c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-bb6168b0-71db-4a21-a678-dd796c718454,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-f45d07fd-0e6f-4542-8a35-92bb2ae76b45,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-0b5df79a-0bd4-4148-a71d-77adcdc4c3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-4483445b-6a94-4486-b524-09dbd7aee1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-ff25300a-e525-42bc-afe0-96cc6f76a578,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-bd314464-266c-47be-bf7a-00b9bc534720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454777036-172.17.0.5-1596891586561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-30ed604f-a687-4687-ad18-803a87a40f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-e455b2cd-0446-4b35-946f-2d22cb72c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-bb6168b0-71db-4a21-a678-dd796c718454,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-f45d07fd-0e6f-4542-8a35-92bb2ae76b45,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-0b5df79a-0bd4-4148-a71d-77adcdc4c3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-4483445b-6a94-4486-b524-09dbd7aee1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-ff25300a-e525-42bc-afe0-96cc6f76a578,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-bd314464-266c-47be-bf7a-00b9bc534720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5432
