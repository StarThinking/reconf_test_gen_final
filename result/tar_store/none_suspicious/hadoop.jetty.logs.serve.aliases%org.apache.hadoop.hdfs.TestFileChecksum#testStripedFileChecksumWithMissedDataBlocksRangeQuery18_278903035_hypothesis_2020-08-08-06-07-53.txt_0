reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097722536-172.17.0.20-1596867539623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-5ffc812d-9de7-41cf-a6d0-fb63442e038b,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-78f5f757-250e-46fd-9e0c-f73840cb9555,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-2c007b47-2c14-4e25-85bd-de25d3789861,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-50b254ec-e204-42c3-a0ff-e8d465cd88e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-046b4b47-2c28-4d8d-b5f1-cb1a63791110,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-f501ee7e-7c79-4661-bbaa-9768e9b9c214,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-10bde8d7-8e67-4024-9316-a97d6f1c04ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-4e964e78-f21a-4f38-9eb7-e19c5d50b13f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097722536-172.17.0.20-1596867539623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-5ffc812d-9de7-41cf-a6d0-fb63442e038b,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-78f5f757-250e-46fd-9e0c-f73840cb9555,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-2c007b47-2c14-4e25-85bd-de25d3789861,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-50b254ec-e204-42c3-a0ff-e8d465cd88e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-046b4b47-2c28-4d8d-b5f1-cb1a63791110,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-f501ee7e-7c79-4661-bbaa-9768e9b9c214,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-10bde8d7-8e67-4024-9316-a97d6f1c04ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-4e964e78-f21a-4f38-9eb7-e19c5d50b13f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910041243-172.17.0.20-1596867572937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-125f6339-891d-4cf0-9eb8-b6e4857d779d,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-731c651e-c64b-4a88-8901-2c66bbd842a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-f3ab02ec-0474-49c3-90dd-8bcf6c16921e,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-814b10b9-c975-4b1f-8c2e-80cb992c89d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-e7a83bac-ded4-4873-9040-fff97a7f0753,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8c6721ae-a096-45e6-9bfe-01b00649e820,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-51702447-674b-4121-a2da-521a0e1684d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-52fd1ecf-4e07-4adf-bd01-95f12b447a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910041243-172.17.0.20-1596867572937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-125f6339-891d-4cf0-9eb8-b6e4857d779d,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-731c651e-c64b-4a88-8901-2c66bbd842a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-f3ab02ec-0474-49c3-90dd-8bcf6c16921e,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-814b10b9-c975-4b1f-8c2e-80cb992c89d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-e7a83bac-ded4-4873-9040-fff97a7f0753,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8c6721ae-a096-45e6-9bfe-01b00649e820,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-51702447-674b-4121-a2da-521a0e1684d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-52fd1ecf-4e07-4adf-bd01-95f12b447a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686984705-172.17.0.20-1596867685934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33564,DS-c4eebe5f-d2f1-456e-a55a-1c0005582a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-51c7cba7-02f5-4ccb-8fb1-613fd26e1599,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-15e609e0-c81c-4ffc-a7b1-a174a878990a,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-7e7e4544-6e91-4da4-a95a-e4779f226f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-4a9a6e9a-6237-44a5-8f81-8629e7ae81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d7903109-9e4d-4b29-a06a-ad4e57fe9eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-7fa5709b-e945-42ba-b506-4aa2e423ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-bacf0692-7322-4f71-b989-0443d6fa5a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686984705-172.17.0.20-1596867685934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33564,DS-c4eebe5f-d2f1-456e-a55a-1c0005582a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-51c7cba7-02f5-4ccb-8fb1-613fd26e1599,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-15e609e0-c81c-4ffc-a7b1-a174a878990a,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-7e7e4544-6e91-4da4-a95a-e4779f226f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-4a9a6e9a-6237-44a5-8f81-8629e7ae81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d7903109-9e4d-4b29-a06a-ad4e57fe9eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-7fa5709b-e945-42ba-b506-4aa2e423ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-bacf0692-7322-4f71-b989-0443d6fa5a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305944391-172.17.0.20-1596867720048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-b040e74e-d556-4be5-adc7-223cc29fca7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-24af727a-2c60-4298-acb2-2312671309c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-6229b240-d8c8-483f-8405-6f29097bfda4,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-778f3f03-263d-4a2c-94b7-e4f237c2eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e4e6d812-ec4f-4315-bae0-14dca3c002e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-bd4bb07c-7f5a-427c-ab8c-b867f53a06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-5f434dfa-6306-482c-9197-5c6ced0c1b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-f0d6986e-e0cc-45c8-8505-629ceb0c8302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305944391-172.17.0.20-1596867720048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-b040e74e-d556-4be5-adc7-223cc29fca7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-24af727a-2c60-4298-acb2-2312671309c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-6229b240-d8c8-483f-8405-6f29097bfda4,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-778f3f03-263d-4a2c-94b7-e4f237c2eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e4e6d812-ec4f-4315-bae0-14dca3c002e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-bd4bb07c-7f5a-427c-ab8c-b867f53a06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-5f434dfa-6306-482c-9197-5c6ced0c1b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-f0d6986e-e0cc-45c8-8505-629ceb0c8302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677662291-172.17.0.20-1596868366029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-fa8908a0-93de-4af5-82e3-1daaeabace4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-e1b6cef5-71a6-4fd2-b4af-1363e8ea73b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-d9e54444-1b08-41ad-b7e9-4ef487ac73a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-8f032bae-719a-478a-a191-e7e32fe3a377,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-3a2222f6-63a3-4b90-93bc-eacd4668ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-1cb64915-6758-4d9b-8b36-c423a541d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-08374b19-5091-4c72-9d11-1d8a0dd322db,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-a112b81e-3760-43b5-aaa9-6be8cf9b44fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677662291-172.17.0.20-1596868366029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-fa8908a0-93de-4af5-82e3-1daaeabace4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-e1b6cef5-71a6-4fd2-b4af-1363e8ea73b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-d9e54444-1b08-41ad-b7e9-4ef487ac73a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-8f032bae-719a-478a-a191-e7e32fe3a377,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-3a2222f6-63a3-4b90-93bc-eacd4668ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-1cb64915-6758-4d9b-8b36-c423a541d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-08374b19-5091-4c72-9d11-1d8a0dd322db,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-a112b81e-3760-43b5-aaa9-6be8cf9b44fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330901581-172.17.0.20-1596868653277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-2f518b70-d1fd-4b3d-9cce-6bcf8649c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1351f557-8539-4377-a0b8-8840eaac5db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-898dbb2d-9a6f-44ef-84ff-558e6187b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-2d37b5d0-4b08-41e1-bc42-f0c801f9516c,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-2bd8f2f9-00fc-4c1e-a249-5c8363d31120,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-6b02b75b-ec98-4ebd-aa9a-d3e7d9bcb882,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-7d9b2891-8f0d-442f-a0ae-5b606dae0a56,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-1b8075c1-1f25-4b50-9542-e466e476c72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330901581-172.17.0.20-1596868653277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-2f518b70-d1fd-4b3d-9cce-6bcf8649c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1351f557-8539-4377-a0b8-8840eaac5db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-898dbb2d-9a6f-44ef-84ff-558e6187b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-2d37b5d0-4b08-41e1-bc42-f0c801f9516c,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-2bd8f2f9-00fc-4c1e-a249-5c8363d31120,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-6b02b75b-ec98-4ebd-aa9a-d3e7d9bcb882,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-7d9b2891-8f0d-442f-a0ae-5b606dae0a56,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-1b8075c1-1f25-4b50-9542-e466e476c72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465403554-172.17.0.20-1596868716342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-1cbf7d7d-33c0-4ac9-a4ad-995ba2593bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-16e7ab03-6f18-45cf-b899-342365695fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-37dbe12c-fec9-4bd0-a789-b26e5b418041,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-ea69b102-3e9a-4385-a7f1-3464cce12ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-59d96b37-5638-4091-930e-8607738bd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-15d589ee-4f76-4d99-9fdf-588f50a9ef16,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-4da48014-d5bc-443e-9055-327e4510e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-b7a569d4-4bf8-46f2-bff1-708e58048d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465403554-172.17.0.20-1596868716342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-1cbf7d7d-33c0-4ac9-a4ad-995ba2593bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-16e7ab03-6f18-45cf-b899-342365695fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-37dbe12c-fec9-4bd0-a789-b26e5b418041,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-ea69b102-3e9a-4385-a7f1-3464cce12ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-59d96b37-5638-4091-930e-8607738bd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-15d589ee-4f76-4d99-9fdf-588f50a9ef16,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-4da48014-d5bc-443e-9055-327e4510e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-b7a569d4-4bf8-46f2-bff1-708e58048d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644257402-172.17.0.20-1596868782124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36824,DS-ad6f4cc6-5ea2-4ad2-beea-d6c2e48f8a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-d41c6194-00d6-4fc0-8441-fc705b2e8fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-6b86036c-ade2-422e-abb8-455377029082,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-7537ce46-a85c-4af8-a235-55c3b17e6760,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e8f7c8cb-2f9c-4b85-a4cf-0565031d0307,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-0cf60667-43e1-4053-a6f5-1bad99cc6298,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-a8a2e8fd-8ca8-4e45-99a8-0b585a00a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-d94add2e-2900-4b9e-a587-4d6422bc0d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644257402-172.17.0.20-1596868782124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36824,DS-ad6f4cc6-5ea2-4ad2-beea-d6c2e48f8a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-d41c6194-00d6-4fc0-8441-fc705b2e8fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-6b86036c-ade2-422e-abb8-455377029082,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-7537ce46-a85c-4af8-a235-55c3b17e6760,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e8f7c8cb-2f9c-4b85-a4cf-0565031d0307,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-0cf60667-43e1-4053-a6f5-1bad99cc6298,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-a8a2e8fd-8ca8-4e45-99a8-0b585a00a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-d94add2e-2900-4b9e-a587-4d6422bc0d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307823539-172.17.0.20-1596869393219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-2eb41285-3b6f-4daf-b693-6f10b831819b,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-e51733ce-a1cc-40bb-a9fb-5b89d0499487,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-d653cd25-098a-455e-a694-eed7dae7027a,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-3dd0c851-2a41-47a6-b668-e43e43de85a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-ba7d9993-0f93-4049-8f94-90cec8f0e832,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-ac77da4a-070d-4104-9b3a-8998992a9fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-e546e608-7326-4cb5-ace1-62a36667f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-c9f7a20c-0495-4d5e-9bde-f14438ce8d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307823539-172.17.0.20-1596869393219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-2eb41285-3b6f-4daf-b693-6f10b831819b,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-e51733ce-a1cc-40bb-a9fb-5b89d0499487,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-d653cd25-098a-455e-a694-eed7dae7027a,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-3dd0c851-2a41-47a6-b668-e43e43de85a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-ba7d9993-0f93-4049-8f94-90cec8f0e832,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-ac77da4a-070d-4104-9b3a-8998992a9fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-e546e608-7326-4cb5-ace1-62a36667f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-c9f7a20c-0495-4d5e-9bde-f14438ce8d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434452005-172.17.0.20-1596870904436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-704e9073-1ce7-43fd-988b-92096d4dbeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-c948bc6f-86be-4da3-a478-7a4713a1a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-ea49960d-ee5a-4833-af3e-926acd5f7853,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-d41eee21-610d-47ad-a3d1-ced741f08020,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-3a129f4b-2c05-4a41-9eeb-5b752fd08c69,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-6d872e78-1d01-42c8-80af-639ca3338181,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-52997a64-5298-40f7-98a7-62b1f9801ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-a0f253c2-9efa-41c3-b811-68c4850a4959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434452005-172.17.0.20-1596870904436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-704e9073-1ce7-43fd-988b-92096d4dbeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-c948bc6f-86be-4da3-a478-7a4713a1a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-ea49960d-ee5a-4833-af3e-926acd5f7853,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-d41eee21-610d-47ad-a3d1-ced741f08020,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-3a129f4b-2c05-4a41-9eeb-5b752fd08c69,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-6d872e78-1d01-42c8-80af-639ca3338181,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-52997a64-5298-40f7-98a7-62b1f9801ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-a0f253c2-9efa-41c3-b811-68c4850a4959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678487563-172.17.0.20-1596871357201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-a120cfcf-c68a-499f-9ab2-0d2c2d01bb94,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-71ac10f2-5822-4c5e-910b-896bd4304831,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d48a7c39-4f68-45fa-96ec-20d90a32ca26,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-b03eedcd-ffd6-4700-8173-20117c5108ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-1c2506d8-25e5-456d-9cf1-920b93a3c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-1985242a-9728-4958-ae0b-7d229088988e,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-185a74f9-babe-40bb-8342-8ef870f3a772,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-1a146a9e-75d9-4745-a8aa-88409edca939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678487563-172.17.0.20-1596871357201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-a120cfcf-c68a-499f-9ab2-0d2c2d01bb94,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-71ac10f2-5822-4c5e-910b-896bd4304831,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d48a7c39-4f68-45fa-96ec-20d90a32ca26,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-b03eedcd-ffd6-4700-8173-20117c5108ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-1c2506d8-25e5-456d-9cf1-920b93a3c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-1985242a-9728-4958-ae0b-7d229088988e,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-185a74f9-babe-40bb-8342-8ef870f3a772,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-1a146a9e-75d9-4745-a8aa-88409edca939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129923905-172.17.0.20-1596871728216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-44b97ea6-c6d4-4eef-9fca-b1a09de26dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-76385d0e-e239-4640-be32-22d32c8fce1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-d9330157-1072-40e4-9bf8-ad9506e3527d,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-d6241e2e-7df5-4ab4-8f3c-664bd17b6c54,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-923ee9f7-9189-4c96-80d0-cebcba6a57d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-f86654f7-5743-42f1-bc20-2d56c80b20ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-30ba114e-2ef4-4f90-9243-75097b56531d,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-7761ebbc-8609-41ea-9b9e-61b9aad848e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129923905-172.17.0.20-1596871728216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-44b97ea6-c6d4-4eef-9fca-b1a09de26dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-76385d0e-e239-4640-be32-22d32c8fce1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-d9330157-1072-40e4-9bf8-ad9506e3527d,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-d6241e2e-7df5-4ab4-8f3c-664bd17b6c54,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-923ee9f7-9189-4c96-80d0-cebcba6a57d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-f86654f7-5743-42f1-bc20-2d56c80b20ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-30ba114e-2ef4-4f90-9243-75097b56531d,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-7761ebbc-8609-41ea-9b9e-61b9aad848e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938017800-172.17.0.20-1596871874999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42167,DS-b1066ad3-3008-4ce0-b15e-c6334a5140f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-cffa1034-43cb-480c-9af2-d1dc44cefcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3fda9145-63c8-4f8d-9c1e-379d8cec95c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-003c0b9a-2da2-4dcb-910f-9301e31b3d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-4258fed3-1dbb-4d24-9b8b-750414f8f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-66a52be0-f42b-4fa1-95d6-ef0a87d6a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-925ef6c5-10c2-493a-bba3-542db739af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-a7a6a561-294e-4e04-b2b3-1169ce38892c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938017800-172.17.0.20-1596871874999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42167,DS-b1066ad3-3008-4ce0-b15e-c6334a5140f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-cffa1034-43cb-480c-9af2-d1dc44cefcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3fda9145-63c8-4f8d-9c1e-379d8cec95c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-003c0b9a-2da2-4dcb-910f-9301e31b3d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-4258fed3-1dbb-4d24-9b8b-750414f8f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-66a52be0-f42b-4fa1-95d6-ef0a87d6a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-925ef6c5-10c2-493a-bba3-542db739af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-a7a6a561-294e-4e04-b2b3-1169ce38892c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307538657-172.17.0.20-1596871942530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-15f99161-25d5-4a9a-bb4d-36ca0167fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-456ad498-5315-4d66-b6ec-4e99e30e17e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-17e78d12-acfd-484c-b54d-793442caacb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-7daed005-fe90-4802-a171-d9adfc49dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-77e73191-48d9-4cdd-bb8c-25f7bfc1cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-75799885-68fa-4bc9-8df4-244d7ca0523f,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-331b922d-f6f2-4e65-9bdf-6511acabe88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-559526a7-47f6-4274-b34f-252362829764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307538657-172.17.0.20-1596871942530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-15f99161-25d5-4a9a-bb4d-36ca0167fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-456ad498-5315-4d66-b6ec-4e99e30e17e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-17e78d12-acfd-484c-b54d-793442caacb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-7daed005-fe90-4802-a171-d9adfc49dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-77e73191-48d9-4cdd-bb8c-25f7bfc1cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-75799885-68fa-4bc9-8df4-244d7ca0523f,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-331b922d-f6f2-4e65-9bdf-6511acabe88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-559526a7-47f6-4274-b34f-252362829764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5223
