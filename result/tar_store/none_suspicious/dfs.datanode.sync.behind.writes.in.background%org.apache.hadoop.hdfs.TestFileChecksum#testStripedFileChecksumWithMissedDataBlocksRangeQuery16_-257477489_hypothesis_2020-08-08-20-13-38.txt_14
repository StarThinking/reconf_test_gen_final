reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834743773-172.17.0.21-1596917908233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-091442ff-7dc3-4be1-8681-e89ede00744e,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-c369edb6-21bb-42de-b4b0-0fea1bd1ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-fc3aff6a-5b83-4830-aeca-ae1a72b86d21,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-dd01c99f-f976-4bb7-92ba-a26e113e6cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-0ccb5e8e-57c8-43f0-a765-fc96ea1fe266,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-9d874f0d-6364-4600-8f50-7316944c5faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-5b79393f-a41b-443f-9900-4f74a92c84c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-63714a7b-d351-487e-8f66-e574ef034833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834743773-172.17.0.21-1596917908233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-091442ff-7dc3-4be1-8681-e89ede00744e,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-c369edb6-21bb-42de-b4b0-0fea1bd1ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-fc3aff6a-5b83-4830-aeca-ae1a72b86d21,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-dd01c99f-f976-4bb7-92ba-a26e113e6cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-0ccb5e8e-57c8-43f0-a765-fc96ea1fe266,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-9d874f0d-6364-4600-8f50-7316944c5faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-5b79393f-a41b-443f-9900-4f74a92c84c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-63714a7b-d351-487e-8f66-e574ef034833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100698361-172.17.0.21-1596917981503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-e7e68567-cae1-48b1-a67b-69cf6e8401a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-781e984b-7995-4cbd-8ef1-225b8e1b1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-e432711b-7823-43a0-a2a1-f9fefd1e2981,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-3749b09d-55f5-47e6-a60e-c98d17fcfa79,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-37ef5279-6c9f-4458-add5-20d1181a77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-3c575efc-3270-4336-943c-a7dc13b36160,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-f2be8f47-4b80-434f-a701-3612f0d8be17,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-87dd1d16-61e9-4d85-8d71-9ed5fcecacb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100698361-172.17.0.21-1596917981503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-e7e68567-cae1-48b1-a67b-69cf6e8401a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-781e984b-7995-4cbd-8ef1-225b8e1b1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-e432711b-7823-43a0-a2a1-f9fefd1e2981,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-3749b09d-55f5-47e6-a60e-c98d17fcfa79,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-37ef5279-6c9f-4458-add5-20d1181a77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-3c575efc-3270-4336-943c-a7dc13b36160,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-f2be8f47-4b80-434f-a701-3612f0d8be17,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-87dd1d16-61e9-4d85-8d71-9ed5fcecacb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538978855-172.17.0.21-1596918908581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-8c991dc8-a7a1-40bf-9038-5b86ebcc4a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-0d755ac0-9ccf-4e4a-865d-efdf3c99b032,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-7d9d6767-3478-4982-813c-1afe496dca42,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b0339972-d619-429c-a7d2-e16234db960a,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-93d2b6f8-158e-4197-ac96-9c39c7979e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-4eabd94e-3ad6-4838-a893-8b477a1d038e,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-f4a1cc4c-4b66-477e-b21e-89faccfc9348,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-d27ab5ca-7387-40de-8048-ae36663abb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538978855-172.17.0.21-1596918908581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-8c991dc8-a7a1-40bf-9038-5b86ebcc4a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-0d755ac0-9ccf-4e4a-865d-efdf3c99b032,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-7d9d6767-3478-4982-813c-1afe496dca42,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b0339972-d619-429c-a7d2-e16234db960a,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-93d2b6f8-158e-4197-ac96-9c39c7979e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-4eabd94e-3ad6-4838-a893-8b477a1d038e,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-f4a1cc4c-4b66-477e-b21e-89faccfc9348,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-d27ab5ca-7387-40de-8048-ae36663abb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468499077-172.17.0.21-1596919067298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-7efe0468-ac64-415c-8e31-291f2d4c59a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-d3cb7c5f-3443-40fc-af7a-a1fcb7135538,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-df26ae27-37f2-4308-bc95-4825cf0621a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-58d4f3b0-9ff8-4e4e-89a8-916c9dac9151,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-4cf26303-1624-4594-a188-b146629121ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-4c365462-9f43-4f52-b2b5-e961fc5572cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-4324aac1-f361-4d00-802f-6dc8a29eb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-9054aaea-a8a1-4759-ad3d-c3163c1f8d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468499077-172.17.0.21-1596919067298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-7efe0468-ac64-415c-8e31-291f2d4c59a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-d3cb7c5f-3443-40fc-af7a-a1fcb7135538,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-df26ae27-37f2-4308-bc95-4825cf0621a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-58d4f3b0-9ff8-4e4e-89a8-916c9dac9151,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-4cf26303-1624-4594-a188-b146629121ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-4c365462-9f43-4f52-b2b5-e961fc5572cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-4324aac1-f361-4d00-802f-6dc8a29eb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-9054aaea-a8a1-4759-ad3d-c3163c1f8d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371784875-172.17.0.21-1596919175294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-dd317511-a640-4c8a-b458-c66b7274a48d,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-08df142d-5cb3-41da-9f33-fc678e4cf6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-dfb18cfe-b29d-48c4-bac0-7ec11105770e,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-93750b34-0dc6-4aef-8709-733a6ac0ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-c9345f13-dc8e-40e8-b4de-e53e1c6dcbda,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-e9865136-53e3-4431-9ebc-be9c5d9a8a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-909f9696-be47-437d-b993-e4b740134104,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-b59bc3ca-a12d-4555-8997-a023fcf9a555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371784875-172.17.0.21-1596919175294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-dd317511-a640-4c8a-b458-c66b7274a48d,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-08df142d-5cb3-41da-9f33-fc678e4cf6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-dfb18cfe-b29d-48c4-bac0-7ec11105770e,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-93750b34-0dc6-4aef-8709-733a6ac0ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-c9345f13-dc8e-40e8-b4de-e53e1c6dcbda,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-e9865136-53e3-4431-9ebc-be9c5d9a8a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-909f9696-be47-437d-b993-e4b740134104,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-b59bc3ca-a12d-4555-8997-a023fcf9a555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967848114-172.17.0.21-1596919288908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-18a7fc09-00b3-444f-b635-acbeeaeefe18,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-53ed3536-410b-4ae9-bb7c-ec86d38f56e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-59f6d084-d687-4eb1-93bf-72558074b109,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-814c559e-e9f8-435b-9384-4e08fb34019c,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-7e7f20b2-acae-4e44-81d5-54ca61040194,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-e0f5ef19-e4e7-4561-8c2d-768146c933a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-1fc386d7-378c-447c-889a-91a53bf6ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-03c4f05d-6cc9-4ef2-99dd-72032cc8f91c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967848114-172.17.0.21-1596919288908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-18a7fc09-00b3-444f-b635-acbeeaeefe18,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-53ed3536-410b-4ae9-bb7c-ec86d38f56e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-59f6d084-d687-4eb1-93bf-72558074b109,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-814c559e-e9f8-435b-9384-4e08fb34019c,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-7e7f20b2-acae-4e44-81d5-54ca61040194,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-e0f5ef19-e4e7-4561-8c2d-768146c933a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-1fc386d7-378c-447c-889a-91a53bf6ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-03c4f05d-6cc9-4ef2-99dd-72032cc8f91c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179438102-172.17.0.21-1596919543340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-27745e72-7eb9-4a81-9990-028e1fd5e572,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-6bfc1682-e86f-4097-bbff-f8242d32331b,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-e7aec932-b580-4494-8773-df9649b7877b,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-76841cee-7c3b-4593-8027-ca00b0edfd27,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-58a621e4-c9d0-4933-b1f3-1312f122aecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-30954097-935f-46ee-bfe1-47d0b6120b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-94593c89-60ee-4514-8347-3b66b19ed7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-e6b18eb7-49f5-4ceb-8ca0-3866385c7dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179438102-172.17.0.21-1596919543340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-27745e72-7eb9-4a81-9990-028e1fd5e572,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-6bfc1682-e86f-4097-bbff-f8242d32331b,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-e7aec932-b580-4494-8773-df9649b7877b,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-76841cee-7c3b-4593-8027-ca00b0edfd27,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-58a621e4-c9d0-4933-b1f3-1312f122aecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-30954097-935f-46ee-bfe1-47d0b6120b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-94593c89-60ee-4514-8347-3b66b19ed7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-e6b18eb7-49f5-4ceb-8ca0-3866385c7dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570795252-172.17.0.21-1596919894459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44810,DS-db81109d-21e6-4dd5-a09b-1daa70edf1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-67fae3e1-7e09-40fd-8e8e-b6820b40d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-20fc5506-1aef-421e-b764-11702face1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-c9ca40b7-efc3-4ebb-8475-9c09af610a50,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-c47d96ea-5949-437a-8280-552ef5610893,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-1e0ab8b6-7249-421d-affc-ed180a79bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-f1051528-19e8-493a-a6f1-79ad004bc7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f68bf420-f235-453e-968f-b95d45ba5ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570795252-172.17.0.21-1596919894459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44810,DS-db81109d-21e6-4dd5-a09b-1daa70edf1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-67fae3e1-7e09-40fd-8e8e-b6820b40d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-20fc5506-1aef-421e-b764-11702face1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-c9ca40b7-efc3-4ebb-8475-9c09af610a50,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-c47d96ea-5949-437a-8280-552ef5610893,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-1e0ab8b6-7249-421d-affc-ed180a79bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-f1051528-19e8-493a-a6f1-79ad004bc7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f68bf420-f235-453e-968f-b95d45ba5ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647304529-172.17.0.21-1596920139028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-dd529789-04ac-4857-aa58-f40fe84c3786,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-047c5ae2-dcb6-4bb7-a6d5-3ffd4ee8a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-d6d8bfa2-962c-488c-8665-525b924c942b,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-d9c4c0ea-4060-467a-a268-c57dbccea154,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-3eac8a20-aa0b-45b6-a71b-fde66d2b3bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-8936e3e3-5f15-4eab-a3bf-a54ce4b999a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-dbe63f8d-9966-49ea-bbbc-472860266be6,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-26e5a50e-a7ea-4699-88f8-fa7d93c6dd0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647304529-172.17.0.21-1596920139028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-dd529789-04ac-4857-aa58-f40fe84c3786,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-047c5ae2-dcb6-4bb7-a6d5-3ffd4ee8a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-d6d8bfa2-962c-488c-8665-525b924c942b,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-d9c4c0ea-4060-467a-a268-c57dbccea154,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-3eac8a20-aa0b-45b6-a71b-fde66d2b3bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-8936e3e3-5f15-4eab-a3bf-a54ce4b999a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-dbe63f8d-9966-49ea-bbbc-472860266be6,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-26e5a50e-a7ea-4699-88f8-fa7d93c6dd0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214331611-172.17.0.21-1596920354251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35563,DS-12383ba9-32b5-46a7-8976-4d027cfecf25,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-6ece5c56-0710-46d9-b945-921082f2a346,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-ebedfb78-0c03-4e71-ab9b-7c294d7f314f,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-cab008c5-cbc1-4bc7-a845-4a7162910fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-204f249b-8b83-4ea8-88d1-f771c7ba43cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-99c244dd-45e3-41d6-8264-501b80337a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-ca4a2b9c-ea5c-4861-b693-f7650d774279,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-924d3997-1f75-48d7-9265-b8dd5cae5263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214331611-172.17.0.21-1596920354251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35563,DS-12383ba9-32b5-46a7-8976-4d027cfecf25,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-6ece5c56-0710-46d9-b945-921082f2a346,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-ebedfb78-0c03-4e71-ab9b-7c294d7f314f,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-cab008c5-cbc1-4bc7-a845-4a7162910fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-204f249b-8b83-4ea8-88d1-f771c7ba43cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-99c244dd-45e3-41d6-8264-501b80337a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-ca4a2b9c-ea5c-4861-b693-f7650d774279,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-924d3997-1f75-48d7-9265-b8dd5cae5263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276720949-172.17.0.21-1596920523739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-168d74ba-b69d-4380-804b-757207bed14f,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-bd1b6744-3789-41ed-b3ee-263ac591069c,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-8a388d7e-4b5f-494d-a09c-f33337ae39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-c9621708-c683-4a71-bd57-2dcd3d6a5bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-d25debef-67bc-46eb-b8a9-1558ecc38913,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-933ffa8d-8e18-4a08-bb58-d369c134aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-29ebadff-14d7-410d-8189-74bfef7be90e,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-975b3631-317c-41f2-9f05-d7736a35e6f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276720949-172.17.0.21-1596920523739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-168d74ba-b69d-4380-804b-757207bed14f,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-bd1b6744-3789-41ed-b3ee-263ac591069c,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-8a388d7e-4b5f-494d-a09c-f33337ae39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-c9621708-c683-4a71-bd57-2dcd3d6a5bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-d25debef-67bc-46eb-b8a9-1558ecc38913,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-933ffa8d-8e18-4a08-bb58-d369c134aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-29ebadff-14d7-410d-8189-74bfef7be90e,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-975b3631-317c-41f2-9f05-d7736a35e6f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894250653-172.17.0.21-1596920653023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-e7361fbb-c8a2-4005-abbb-47d84af014c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a1357415-158d-49de-afd6-0eec76d5bdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-e388c88d-2db8-453c-aec1-e6f7621f17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-8da6de96-510f-4140-84a2-3329fa9241d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-df66f533-52ea-4ade-b9c3-6680b917988a,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-483760cd-3e86-44b6-a33e-4891133c0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-09ff1bc1-2142-40ab-9d2d-d3002e9e5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-2636ce19-1096-460a-863c-aaf208bccceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894250653-172.17.0.21-1596920653023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-e7361fbb-c8a2-4005-abbb-47d84af014c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a1357415-158d-49de-afd6-0eec76d5bdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-e388c88d-2db8-453c-aec1-e6f7621f17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-8da6de96-510f-4140-84a2-3329fa9241d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-df66f533-52ea-4ade-b9c3-6680b917988a,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-483760cd-3e86-44b6-a33e-4891133c0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-09ff1bc1-2142-40ab-9d2d-d3002e9e5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-2636ce19-1096-460a-863c-aaf208bccceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189951089-172.17.0.21-1596920681697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-06a0975f-d60a-436d-9f99-94df8bb5a2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-5b92ec80-5b70-420d-a9f1-56008abd1441,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-b21d666f-9324-41de-a34d-950a4e45435f,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-fe4382c5-9b39-4ee2-a1a1-672be3776244,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-6371a0c2-bdea-49e5-9939-00e3a89d2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-05557827-9405-418a-8067-aee3d286e988,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-9da81c51-ed11-4b08-8e93-b55292679280,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-0bd9fb0c-6606-478c-b4ed-01f0ee91a34b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189951089-172.17.0.21-1596920681697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-06a0975f-d60a-436d-9f99-94df8bb5a2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-5b92ec80-5b70-420d-a9f1-56008abd1441,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-b21d666f-9324-41de-a34d-950a4e45435f,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-fe4382c5-9b39-4ee2-a1a1-672be3776244,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-6371a0c2-bdea-49e5-9939-00e3a89d2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-05557827-9405-418a-8067-aee3d286e988,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-9da81c51-ed11-4b08-8e93-b55292679280,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-0bd9fb0c-6606-478c-b4ed-01f0ee91a34b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249963509-172.17.0.21-1596920709631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-573117b6-c554-46b8-88c3-152f23afb863,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-78404c03-e05f-4620-9468-02cb454a2df5,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-1b421712-4067-4816-a67a-631431a6c9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-14b4aed5-2c90-49d4-b270-8c8514b2a779,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-d8e4e4b2-3d64-40d3-853a-fbd0197c277b,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-3c99e6d0-54e3-42a1-ae41-41d839ec0fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-98b04e8e-1cb9-4cd8-a0a7-a5aad584386c,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-c4fc90e7-f84a-4ad2-8db3-07a7ea599f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249963509-172.17.0.21-1596920709631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-573117b6-c554-46b8-88c3-152f23afb863,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-78404c03-e05f-4620-9468-02cb454a2df5,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-1b421712-4067-4816-a67a-631431a6c9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-14b4aed5-2c90-49d4-b270-8c8514b2a779,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-d8e4e4b2-3d64-40d3-853a-fbd0197c277b,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-3c99e6d0-54e3-42a1-ae41-41d839ec0fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-98b04e8e-1cb9-4cd8-a0a7-a5aad584386c,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-c4fc90e7-f84a-4ad2-8db3-07a7ea599f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316486247-172.17.0.21-1596920955851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-5c9e95ba-ba33-4bc7-bb31-821f27e3e604,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-808c95e3-79af-4940-bc46-60c3ffc1b493,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-d10b4e6e-8810-4248-bef9-4308eb727b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-6c6f2073-f91a-48a9-bec3-667365bf36aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-828de7d7-aaf0-4c6f-86be-88d6396f6761,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-12b69261-8ff5-4ca3-a022-6d55d723bc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-4f9a5734-fa5b-4794-a831-b394b6082fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-feba13ae-d2f2-4346-ae5f-c3c12287a245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316486247-172.17.0.21-1596920955851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-5c9e95ba-ba33-4bc7-bb31-821f27e3e604,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-808c95e3-79af-4940-bc46-60c3ffc1b493,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-d10b4e6e-8810-4248-bef9-4308eb727b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-6c6f2073-f91a-48a9-bec3-667365bf36aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-828de7d7-aaf0-4c6f-86be-88d6396f6761,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-12b69261-8ff5-4ca3-a022-6d55d723bc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-4f9a5734-fa5b-4794-a831-b394b6082fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-feba13ae-d2f2-4346-ae5f-c3c12287a245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561179161-172.17.0.21-1596921262336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40981,DS-1c88687f-ef3c-48b8-89bd-92d1384db0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-c0fd3103-1199-496e-83d7-343da078ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-72b92169-2732-4471-a9e1-dcd1966c0955,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-d8c1d511-9f83-4422-977e-8c1a8c44df73,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-a322517f-88a7-49b2-93e2-7754faac105e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-ce466c47-36b9-4598-bd6f-a24de6a979e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-312c6225-a91c-4baf-9bf0-e5d322969c29,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-f2210738-0bee-4cb5-8e8e-3d5345a3a4ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561179161-172.17.0.21-1596921262336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40981,DS-1c88687f-ef3c-48b8-89bd-92d1384db0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-c0fd3103-1199-496e-83d7-343da078ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-72b92169-2732-4471-a9e1-dcd1966c0955,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-d8c1d511-9f83-4422-977e-8c1a8c44df73,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-a322517f-88a7-49b2-93e2-7754faac105e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-ce466c47-36b9-4598-bd6f-a24de6a979e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-312c6225-a91c-4baf-9bf0-e5d322969c29,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-f2210738-0bee-4cb5-8e8e-3d5345a3a4ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500339373-172.17.0.21-1596921338212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-4dabb6b4-62b3-4161-a627-4498b968be55,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-273c85e5-4ddf-496d-8e60-0cdab26ec42f,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5c6cd630-5439-4bdd-bc23-976f00953405,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-44ba5b7f-8202-44df-b188-ca6af512efc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-4f40768b-ab4b-48bb-b499-1aa0a2760cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-8088671d-45d2-49c1-8d8c-7a620afa5a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-2be2aa1d-7fb1-4970-8f55-b4a603209a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-c69f7223-ec72-4c86-8670-526de35cdbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500339373-172.17.0.21-1596921338212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-4dabb6b4-62b3-4161-a627-4498b968be55,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-273c85e5-4ddf-496d-8e60-0cdab26ec42f,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5c6cd630-5439-4bdd-bc23-976f00953405,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-44ba5b7f-8202-44df-b188-ca6af512efc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-4f40768b-ab4b-48bb-b499-1aa0a2760cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-8088671d-45d2-49c1-8d8c-7a620afa5a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-2be2aa1d-7fb1-4970-8f55-b4a603209a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-c69f7223-ec72-4c86-8670-526de35cdbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98180642-172.17.0.21-1596921852125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-3623bf06-874c-4af7-a657-08e004403c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-fffd0246-7764-4d4c-b556-1d7d22fdd05c,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-8d6e9ad5-9b45-4215-a258-5580f7868564,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-1f64078f-58e9-4018-b1cd-08bee5ac04f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-25c1aab6-ba36-4f62-9661-48ced05df499,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-b353bf1e-bbc6-4b64-a042-76e4c970cb49,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-486e5c1c-bd9d-4649-bd6b-c8128d0cd624,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-690cd0c8-eb41-4e75-aea2-749fed02eb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98180642-172.17.0.21-1596921852125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-3623bf06-874c-4af7-a657-08e004403c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-fffd0246-7764-4d4c-b556-1d7d22fdd05c,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-8d6e9ad5-9b45-4215-a258-5580f7868564,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-1f64078f-58e9-4018-b1cd-08bee5ac04f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-25c1aab6-ba36-4f62-9661-48ced05df499,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-b353bf1e-bbc6-4b64-a042-76e4c970cb49,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-486e5c1c-bd9d-4649-bd6b-c8128d0cd624,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-690cd0c8-eb41-4e75-aea2-749fed02eb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638214342-172.17.0.21-1596922356975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-d92800fa-91e2-4278-a622-7f9d0c83b2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-e5d0156f-a2a0-45fb-8bb7-1a3b35a356dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-ebea03a7-33f9-4b94-8cd8-70b6829a9644,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-3e59358f-38da-4db4-9f20-629d8395c2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-8c38fe6b-fbdc-49f0-a170-ed3a3c2a40de,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-2011fad0-1fd2-4e75-8ec6-547db1a70b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-b7cd17bb-a67a-4f90-8836-27d1a6d1f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-20373275-ec8d-4fbd-9852-50296904fd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638214342-172.17.0.21-1596922356975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-d92800fa-91e2-4278-a622-7f9d0c83b2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-e5d0156f-a2a0-45fb-8bb7-1a3b35a356dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-ebea03a7-33f9-4b94-8cd8-70b6829a9644,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-3e59358f-38da-4db4-9f20-629d8395c2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-8c38fe6b-fbdc-49f0-a170-ed3a3c2a40de,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-2011fad0-1fd2-4e75-8ec6-547db1a70b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-b7cd17bb-a67a-4f90-8836-27d1a6d1f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-20373275-ec8d-4fbd-9852-50296904fd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186658836-172.17.0.21-1596922545463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-d8b190b9-1214-41fb-9f4d-fbcd7292e595,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-4140b585-9a91-4d4b-b1fa-88085439f40f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-aba89fb0-6fc6-4999-a9e5-b99bf4af55ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-cda12dc3-e076-4708-95d3-1982fe20df86,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-bfc368a1-8c6b-4ac5-825a-976d7fdf9421,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-ea234a18-d31d-486b-880a-28cf040f5428,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-8622082c-e52b-4e07-9a0b-6278079084a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-6a3d9c6c-0f13-4c01-bf76-745c94d2765d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186658836-172.17.0.21-1596922545463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-d8b190b9-1214-41fb-9f4d-fbcd7292e595,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-4140b585-9a91-4d4b-b1fa-88085439f40f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-aba89fb0-6fc6-4999-a9e5-b99bf4af55ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-cda12dc3-e076-4708-95d3-1982fe20df86,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-bfc368a1-8c6b-4ac5-825a-976d7fdf9421,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-ea234a18-d31d-486b-880a-28cf040f5428,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-8622082c-e52b-4e07-9a0b-6278079084a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-6a3d9c6c-0f13-4c01-bf76-745c94d2765d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966417254-172.17.0.21-1596922696077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-1bf2bff7-b3e2-427f-9867-a4785e8e34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-174182c5-a328-4b79-9a49-d3c140ddef89,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-1b0af7ae-5253-4db3-826f-39de56873e43,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-553a4ebc-0198-4fc6-8046-6bde352c5f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-21158f67-5442-43e9-9981-d107ac054442,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-53826618-d9c3-4e27-b093-a6a08cce443c,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-c1ee0540-c223-444b-9140-bbb2c1b5ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-b6ae8d13-b51a-4b26-93c7-10613f266c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966417254-172.17.0.21-1596922696077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-1bf2bff7-b3e2-427f-9867-a4785e8e34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-174182c5-a328-4b79-9a49-d3c140ddef89,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-1b0af7ae-5253-4db3-826f-39de56873e43,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-553a4ebc-0198-4fc6-8046-6bde352c5f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-21158f67-5442-43e9-9981-d107ac054442,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-53826618-d9c3-4e27-b093-a6a08cce443c,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-c1ee0540-c223-444b-9140-bbb2c1b5ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-b6ae8d13-b51a-4b26-93c7-10613f266c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656401485-172.17.0.21-1596922801014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-61d5b495-a624-431b-a72a-c96e5d4f44b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-f01d2f50-f1a6-4975-9a00-b378bea4f018,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-4db539e4-0493-45d6-b4bb-644fa77d71e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-b970fd04-af8b-419b-a0a5-f78d92e084ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-d7c5c78d-e2da-47c6-ad3d-4bd6cee34e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-2de70e9a-b9ab-4667-a44d-3b9bebc396a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-c9a3095f-86ef-4ef4-82cf-2acee27dbff0,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-d1160abd-776a-4d26-b43a-1a6dd470bb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656401485-172.17.0.21-1596922801014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-61d5b495-a624-431b-a72a-c96e5d4f44b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-f01d2f50-f1a6-4975-9a00-b378bea4f018,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-4db539e4-0493-45d6-b4bb-644fa77d71e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-b970fd04-af8b-419b-a0a5-f78d92e084ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-d7c5c78d-e2da-47c6-ad3d-4bd6cee34e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-2de70e9a-b9ab-4667-a44d-3b9bebc396a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-c9a3095f-86ef-4ef4-82cf-2acee27dbff0,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-d1160abd-776a-4d26-b43a-1a6dd470bb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5244
