reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100409748-172.17.0.19-1596987951687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36158,DS-e69e3706-3a31-4102-b1a4-dcef4a4fdf39,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-4899b886-ca3a-495c-9aa6-6aa744df6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-c76cee8b-dfc9-4cb5-b787-fe8db1386910,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-566f8970-9a13-4ab2-b8db-4551f35bde1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-465119c8-6a96-4122-ae3e-247695e920b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-650f677d-f4f1-44ad-84e1-999e44aeb386,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-9f75e472-8aa8-42ba-a427-fdf653c6e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-aaad3c63-9e8c-449e-aeac-03e2813087a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100409748-172.17.0.19-1596987951687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36158,DS-e69e3706-3a31-4102-b1a4-dcef4a4fdf39,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-4899b886-ca3a-495c-9aa6-6aa744df6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-c76cee8b-dfc9-4cb5-b787-fe8db1386910,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-566f8970-9a13-4ab2-b8db-4551f35bde1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-465119c8-6a96-4122-ae3e-247695e920b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-650f677d-f4f1-44ad-84e1-999e44aeb386,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-9f75e472-8aa8-42ba-a427-fdf653c6e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-aaad3c63-9e8c-449e-aeac-03e2813087a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189017316-172.17.0.19-1596987991074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-5c87edf1-5577-4f85-aac2-63919c137994,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-354dfba1-0697-4821-8862-53403499aa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-a5d620da-99ca-479c-9712-d627a28363d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-348915ac-3cff-4e7a-87ec-c8bdf7e2b028,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c76ac651-e5fc-4c6b-9308-1a23f87edf97,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-f9398a3e-c66f-4c8d-b84f-8d3c9ddc0652,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-aa2c13c8-e2b1-49b6-a773-4b639336f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-ecff23d7-b596-49e5-98a6-dc9f6af1bae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189017316-172.17.0.19-1596987991074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-5c87edf1-5577-4f85-aac2-63919c137994,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-354dfba1-0697-4821-8862-53403499aa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-a5d620da-99ca-479c-9712-d627a28363d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-348915ac-3cff-4e7a-87ec-c8bdf7e2b028,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c76ac651-e5fc-4c6b-9308-1a23f87edf97,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-f9398a3e-c66f-4c8d-b84f-8d3c9ddc0652,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-aa2c13c8-e2b1-49b6-a773-4b639336f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-ecff23d7-b596-49e5-98a6-dc9f6af1bae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800454664-172.17.0.19-1596988525831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-92f4d2ff-a677-4900-ac83-2e828ad76a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-eda0ae83-4f5d-4db8-873a-e8ee01220d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-5cd21e72-6aa2-48a7-871b-b23004bd660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-c6b4ff0b-ef3d-451e-ac9f-79ebae44b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-9c0f35c6-bea8-43ee-8cf0-f365df6a8f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-2e27e662-f35e-40ad-972e-29d1aa5b976e,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-48a25dd3-0cbe-4664-add0-23570d8c7127,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-bbc9be5d-2948-4764-8a30-7067275709ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800454664-172.17.0.19-1596988525831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-92f4d2ff-a677-4900-ac83-2e828ad76a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-eda0ae83-4f5d-4db8-873a-e8ee01220d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-5cd21e72-6aa2-48a7-871b-b23004bd660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-c6b4ff0b-ef3d-451e-ac9f-79ebae44b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-9c0f35c6-bea8-43ee-8cf0-f365df6a8f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-2e27e662-f35e-40ad-972e-29d1aa5b976e,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-48a25dd3-0cbe-4664-add0-23570d8c7127,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-bbc9be5d-2948-4764-8a30-7067275709ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745621715-172.17.0.19-1596988631035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-66f91d4f-a4f3-447c-b48c-0ca9d5cc8d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-2293eddc-9459-4312-a8cf-7b0e30167155,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-038553b3-4728-4f83-9309-70fc5bfa72ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-20eacb35-74b4-4805-b6a6-12a9df36d3de,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-8500ebbb-57c6-48a1-9afd-95fe2bf67e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-7d63b581-f090-433d-936d-8d17cbb34939,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-dcb91837-ca7b-4584-a51c-3dc234c1a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-0334f20f-0774-4377-a670-7f6749b3cb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745621715-172.17.0.19-1596988631035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-66f91d4f-a4f3-447c-b48c-0ca9d5cc8d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-2293eddc-9459-4312-a8cf-7b0e30167155,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-038553b3-4728-4f83-9309-70fc5bfa72ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-20eacb35-74b4-4805-b6a6-12a9df36d3de,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-8500ebbb-57c6-48a1-9afd-95fe2bf67e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-7d63b581-f090-433d-936d-8d17cbb34939,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-dcb91837-ca7b-4584-a51c-3dc234c1a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-0334f20f-0774-4377-a670-7f6749b3cb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841128221-172.17.0.19-1596988712120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-3ba32a59-6a61-48cd-ab11-8316b279f024,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-0abdd3cf-a6ef-4ddd-b3b0-089c341127a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-3e13e5cd-4179-4813-8326-d76e3f6ab91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-2889aad5-6ff2-421a-8208-9fdfd2d31835,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-6546ef18-fd41-431e-a995-d80c3d4d3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-8e15a676-3b5b-473b-a1ac-73378d860e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-e7f71e52-c2c9-4def-9fff-3acd7eea17a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-4bbb1812-a4d4-4012-b65b-071b9efeaa5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841128221-172.17.0.19-1596988712120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-3ba32a59-6a61-48cd-ab11-8316b279f024,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-0abdd3cf-a6ef-4ddd-b3b0-089c341127a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-3e13e5cd-4179-4813-8326-d76e3f6ab91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-2889aad5-6ff2-421a-8208-9fdfd2d31835,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-6546ef18-fd41-431e-a995-d80c3d4d3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-8e15a676-3b5b-473b-a1ac-73378d860e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-e7f71e52-c2c9-4def-9fff-3acd7eea17a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-4bbb1812-a4d4-4012-b65b-071b9efeaa5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917045955-172.17.0.19-1596989666510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-a2331ab1-4208-4442-8ecb-ceedb6346679,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-5f74e5d7-00e2-4007-b542-0d7e51073205,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-6b21f458-ac0f-41e7-80b6-168845895043,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-a46704f9-18a1-4537-af3b-d0cb2f47b150,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-2e979e93-3cda-43d2-9c7c-61738f471407,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-c07c899e-69b3-439d-9c09-bd3aa18d7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-dd264ad5-58a9-42cb-bcde-aeebb5664122,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-b4b9e9bb-e4be-42f7-a080-2b0c1254e6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917045955-172.17.0.19-1596989666510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-a2331ab1-4208-4442-8ecb-ceedb6346679,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-5f74e5d7-00e2-4007-b542-0d7e51073205,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-6b21f458-ac0f-41e7-80b6-168845895043,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-a46704f9-18a1-4537-af3b-d0cb2f47b150,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-2e979e93-3cda-43d2-9c7c-61738f471407,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-c07c899e-69b3-439d-9c09-bd3aa18d7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-dd264ad5-58a9-42cb-bcde-aeebb5664122,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-b4b9e9bb-e4be-42f7-a080-2b0c1254e6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456166609-172.17.0.19-1596989830651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-6c10d887-cee0-4aa1-ab0e-adedd509c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-ba62c5da-fa01-4d1e-947d-d6fe7dde41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-68d1dba5-c33c-4cdf-8c5c-e66ab4c679eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-92f13b12-8205-427d-97c3-83537b659d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d682f86c-da2a-4348-bea3-97ce52243fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-961f72e5-fe19-4be2-a26c-069d9573b392,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-6910baef-1fad-4c34-bc04-0aae1fd34c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-3bc04443-3e4c-4ae1-86e6-9232d79e6051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456166609-172.17.0.19-1596989830651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-6c10d887-cee0-4aa1-ab0e-adedd509c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-ba62c5da-fa01-4d1e-947d-d6fe7dde41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-68d1dba5-c33c-4cdf-8c5c-e66ab4c679eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-92f13b12-8205-427d-97c3-83537b659d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d682f86c-da2a-4348-bea3-97ce52243fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-961f72e5-fe19-4be2-a26c-069d9573b392,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-6910baef-1fad-4c34-bc04-0aae1fd34c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-3bc04443-3e4c-4ae1-86e6-9232d79e6051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603153602-172.17.0.19-1596989847324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35742,DS-c252755d-5279-4e50-a0d7-670155706996,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-af891956-dbd4-45ea-bc49-b2b9c0505b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-8726d2bf-f4c6-4222-a2ee-22f5cf20da7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-1dd601b6-dd82-46a3-9c1f-6b0de40c45a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-25fd4622-9abe-4c2f-af95-4af62dab2b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ee3e97a8-3322-41ed-b8a9-52f4b2615a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-fa2d6587-5eec-4e0c-ae9b-7c351d94bc89,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-332de17a-96ba-4e35-91d6-d5b779e16688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603153602-172.17.0.19-1596989847324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35742,DS-c252755d-5279-4e50-a0d7-670155706996,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-af891956-dbd4-45ea-bc49-b2b9c0505b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-8726d2bf-f4c6-4222-a2ee-22f5cf20da7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-1dd601b6-dd82-46a3-9c1f-6b0de40c45a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-25fd4622-9abe-4c2f-af95-4af62dab2b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ee3e97a8-3322-41ed-b8a9-52f4b2615a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-fa2d6587-5eec-4e0c-ae9b-7c351d94bc89,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-332de17a-96ba-4e35-91d6-d5b779e16688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509121257-172.17.0.19-1596990077083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-360f7531-6141-4b1b-8b7e-ed9307c40fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-2809fd43-7294-4662-9077-c9efc14f03d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-c28ee258-f915-4c1a-a110-dbe0725c8382,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-2553f2ea-665a-44f0-8c5e-0609e8e613a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-a894ac80-d1ce-428d-aff2-420e4b8e2570,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ef01c058-21a4-4961-8cfc-bd39913d3d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-63f2278c-ead6-465a-bd0b-9bcac424c29c,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-31d951bc-8cc0-4e77-a8ef-35c94f4b80fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509121257-172.17.0.19-1596990077083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-360f7531-6141-4b1b-8b7e-ed9307c40fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-2809fd43-7294-4662-9077-c9efc14f03d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-c28ee258-f915-4c1a-a110-dbe0725c8382,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-2553f2ea-665a-44f0-8c5e-0609e8e613a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-a894ac80-d1ce-428d-aff2-420e4b8e2570,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ef01c058-21a4-4961-8cfc-bd39913d3d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-63f2278c-ead6-465a-bd0b-9bcac424c29c,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-31d951bc-8cc0-4e77-a8ef-35c94f4b80fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616785864-172.17.0.19-1596990289373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-e7cdbadd-ab30-4c8a-96f0-afe51b12bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-6612ed4d-c892-42e9-99f3-90c1b04a9a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-1111e4b5-a05d-4881-8d71-85fffd487d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-6c90a49f-9aaa-4a8d-a21e-ca5a68c174eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-3e8e137b-ccdb-4145-821b-f5fa6957a2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-e3645dd3-bc63-4c80-b96f-10b64678aad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-97cc557b-2d00-4c00-8a6d-a979819ef9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-1bc4b00b-3947-4373-a4e5-a1a30d95412a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616785864-172.17.0.19-1596990289373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-e7cdbadd-ab30-4c8a-96f0-afe51b12bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-6612ed4d-c892-42e9-99f3-90c1b04a9a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-1111e4b5-a05d-4881-8d71-85fffd487d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-6c90a49f-9aaa-4a8d-a21e-ca5a68c174eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-3e8e137b-ccdb-4145-821b-f5fa6957a2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-e3645dd3-bc63-4c80-b96f-10b64678aad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-97cc557b-2d00-4c00-8a6d-a979819ef9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-1bc4b00b-3947-4373-a4e5-a1a30d95412a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692508944-172.17.0.19-1596990372915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44127,DS-26cfb72c-1fc6-44e8-8970-70a0835c7c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-5a64f8aa-6321-4a71-a7eb-4bd171b7d45a,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-90cea805-d464-455e-a4a7-a91600e1eae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-3adbd931-7d97-49a9-80b3-49ef2f160b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-68af49af-24dd-4426-ac4e-9ec7dade9854,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-cc6d7dc3-e6b9-451d-a2eb-ea7eed06f928,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-97407277-6b76-443c-87d7-73f56365cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-b7d9c417-7104-432c-9f6f-32cbadf6a6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692508944-172.17.0.19-1596990372915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44127,DS-26cfb72c-1fc6-44e8-8970-70a0835c7c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-5a64f8aa-6321-4a71-a7eb-4bd171b7d45a,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-90cea805-d464-455e-a4a7-a91600e1eae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-3adbd931-7d97-49a9-80b3-49ef2f160b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-68af49af-24dd-4426-ac4e-9ec7dade9854,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-cc6d7dc3-e6b9-451d-a2eb-ea7eed06f928,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-97407277-6b76-443c-87d7-73f56365cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-b7d9c417-7104-432c-9f6f-32cbadf6a6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 2518
