reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443987425-172.17.0.10-1596920849126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-535974df-65bb-41d5-9018-f731f83e07ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-635a7099-3e80-461f-b6cd-68629729f963,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-7c25ca17-f3ff-4857-9101-1adc37f0669f,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-0406fab9-61dc-4072-9628-09a2b0c20e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-1d7f31f1-e301-4796-b989-effebf243370,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-116c8e35-388c-4c8d-a60d-07d9ebc341f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-78672260-d262-4bfc-9c50-e93c9c9bae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-44294e81-d823-4fb5-9dc1-42045cc1f6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443987425-172.17.0.10-1596920849126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-535974df-65bb-41d5-9018-f731f83e07ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-635a7099-3e80-461f-b6cd-68629729f963,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-7c25ca17-f3ff-4857-9101-1adc37f0669f,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-0406fab9-61dc-4072-9628-09a2b0c20e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-1d7f31f1-e301-4796-b989-effebf243370,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-116c8e35-388c-4c8d-a60d-07d9ebc341f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-78672260-d262-4bfc-9c50-e93c9c9bae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-44294e81-d823-4fb5-9dc1-42045cc1f6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700641350-172.17.0.10-1596920917795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-aa9ea54d-e9a8-4faa-b0c1-6d7eda2e23d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-a029306f-b9ef-44de-b63e-c6ccdb294986,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-580b0d37-c17a-478a-98e2-a81ae229a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-cf1c459e-6ffa-40df-b04b-ffbcdedd40dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-ac2f3f0b-e1d3-49b4-8929-1096f60c343f,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d9d85545-6963-4260-8086-3c1616ada00a,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-031328d0-dd6d-4863-8fe3-cc8905a80e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-ccfbbad6-a47f-4f50-8c2d-449ff2cc0c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700641350-172.17.0.10-1596920917795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-aa9ea54d-e9a8-4faa-b0c1-6d7eda2e23d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-a029306f-b9ef-44de-b63e-c6ccdb294986,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-580b0d37-c17a-478a-98e2-a81ae229a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-cf1c459e-6ffa-40df-b04b-ffbcdedd40dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-ac2f3f0b-e1d3-49b4-8929-1096f60c343f,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d9d85545-6963-4260-8086-3c1616ada00a,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-031328d0-dd6d-4863-8fe3-cc8905a80e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-ccfbbad6-a47f-4f50-8c2d-449ff2cc0c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201374586-172.17.0.10-1596921634737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46257,DS-689092ce-969d-49d2-b0ef-b784ed822d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-507960ba-ebbf-4482-9367-81aa30cd7357,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-7a2b1355-2dae-45bf-bf2a-fc701f00b704,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-357aedc4-7330-4fdd-8caf-17a156abea6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-f448d2dd-9ba8-4fca-8343-17087fb354e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-a30103e2-1934-4bd4-8a2b-3b599cb492cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-1e790bb3-611c-4ffe-85d8-cac20d652bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-f73e5306-80d8-4e1c-b456-36864632654f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201374586-172.17.0.10-1596921634737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46257,DS-689092ce-969d-49d2-b0ef-b784ed822d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-507960ba-ebbf-4482-9367-81aa30cd7357,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-7a2b1355-2dae-45bf-bf2a-fc701f00b704,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-357aedc4-7330-4fdd-8caf-17a156abea6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-f448d2dd-9ba8-4fca-8343-17087fb354e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-a30103e2-1934-4bd4-8a2b-3b599cb492cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-1e790bb3-611c-4ffe-85d8-cac20d652bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-f73e5306-80d8-4e1c-b456-36864632654f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211136579-172.17.0.10-1596922328893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-18da8360-f7d2-469d-ae93-de6a18debbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-de9fc461-c4a6-49df-b4e8-c2861c267125,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-89685e73-3052-4f9e-9cf4-5bf4a60afedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-fb756dc8-afc7-4f0e-9b01-b59a003b620e,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-47980ab2-6bc8-45a4-b066-57b1305cfb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-cbed2b68-7184-4bc0-ae6c-baa85571d605,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-e2aa5a83-4286-4366-8185-bf754392a567,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-80c3b9e5-de65-4f6e-bf98-0ef6ffbefbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211136579-172.17.0.10-1596922328893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-18da8360-f7d2-469d-ae93-de6a18debbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-de9fc461-c4a6-49df-b4e8-c2861c267125,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-89685e73-3052-4f9e-9cf4-5bf4a60afedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-fb756dc8-afc7-4f0e-9b01-b59a003b620e,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-47980ab2-6bc8-45a4-b066-57b1305cfb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-cbed2b68-7184-4bc0-ae6c-baa85571d605,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-e2aa5a83-4286-4366-8185-bf754392a567,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-80c3b9e5-de65-4f6e-bf98-0ef6ffbefbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275116417-172.17.0.10-1596923262555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42865,DS-cb0a848d-e33a-4582-baaf-858ef86d4283,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-0d60f3d3-c24d-4754-a757-fce35667ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-7da5f9c9-2068-4664-81df-1a6f0918f461,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-e534b5d9-e1da-4da2-ab6f-8e263a3fab38,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-f069efe0-682c-43ed-ba00-ecccfb4a6378,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-f36d934e-dcff-49f4-b6d1-c305af66187f,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-fed5c9b4-744b-47df-95f3-e44e8d60f896,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8e89ebfb-5ea4-4a9c-82a0-641e00cce433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275116417-172.17.0.10-1596923262555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42865,DS-cb0a848d-e33a-4582-baaf-858ef86d4283,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-0d60f3d3-c24d-4754-a757-fce35667ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-7da5f9c9-2068-4664-81df-1a6f0918f461,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-e534b5d9-e1da-4da2-ab6f-8e263a3fab38,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-f069efe0-682c-43ed-ba00-ecccfb4a6378,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-f36d934e-dcff-49f4-b6d1-c305af66187f,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-fed5c9b4-744b-47df-95f3-e44e8d60f896,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8e89ebfb-5ea4-4a9c-82a0-641e00cce433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-182117506-172.17.0.10-1596923403216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-1a6db1aa-a42d-4e88-92c5-81ba2f476778,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-60caad8a-772e-47d0-9ebe-2b071efb7dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-73914a38-9b4e-4200-bc71-bf48b712500c,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-c96ab03c-0fef-404f-a018-1de2efd63a81,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-3ed7554e-bf65-419c-8dfc-5cc161627dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-1e2f35f0-975b-47f6-a517-37ed57bcdf52,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-c3ab47c2-492d-45a2-8a77-1f0d0d329523,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-c41d6872-6f70-47d4-8555-78434f0113ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-182117506-172.17.0.10-1596923403216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-1a6db1aa-a42d-4e88-92c5-81ba2f476778,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-60caad8a-772e-47d0-9ebe-2b071efb7dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-73914a38-9b4e-4200-bc71-bf48b712500c,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-c96ab03c-0fef-404f-a018-1de2efd63a81,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-3ed7554e-bf65-419c-8dfc-5cc161627dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-1e2f35f0-975b-47f6-a517-37ed57bcdf52,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-c3ab47c2-492d-45a2-8a77-1f0d0d329523,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-c41d6872-6f70-47d4-8555-78434f0113ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305247512-172.17.0.10-1596924019424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-93ec0d61-0625-4560-86f8-380854ed14f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-c0acc4e4-8b87-4f9e-8776-1eb44b47819f,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-55670111-664b-4884-9a4b-f806a01ad9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-a9a6adfb-e697-4125-9a5d-387daa6e253c,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-b91a78dc-0c3a-4615-85f3-ebf1320c4ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-60449e6d-ef3b-48a6-b9d0-8bde36fb3854,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-b55de82a-cc6d-4beb-936b-a636815d9aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-7c42dbc4-c030-477e-98ef-467a8cc338a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305247512-172.17.0.10-1596924019424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-93ec0d61-0625-4560-86f8-380854ed14f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-c0acc4e4-8b87-4f9e-8776-1eb44b47819f,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-55670111-664b-4884-9a4b-f806a01ad9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-a9a6adfb-e697-4125-9a5d-387daa6e253c,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-b91a78dc-0c3a-4615-85f3-ebf1320c4ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-60449e6d-ef3b-48a6-b9d0-8bde36fb3854,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-b55de82a-cc6d-4beb-936b-a636815d9aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-7c42dbc4-c030-477e-98ef-467a8cc338a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58192116-172.17.0.10-1596924081226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-6cd480b7-47e6-455e-a6dc-3986e06f89af,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-c5f62ec6-8185-475c-a78d-b9e3b8d549ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-15f79a93-67ee-4e58-a6ca-9ce64ac99bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-27ef75dd-d040-4af7-88dd-becbfa909085,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-47a9dc32-ed1f-41ac-a047-288f99ccdab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-b937ff63-9a87-45a5-ba1f-e9b047701776,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-44cd0b1c-630a-4f5e-b4ff-ef50fc957aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-1374bfce-b251-4911-b6d0-b1803d550ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58192116-172.17.0.10-1596924081226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-6cd480b7-47e6-455e-a6dc-3986e06f89af,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-c5f62ec6-8185-475c-a78d-b9e3b8d549ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-15f79a93-67ee-4e58-a6ca-9ce64ac99bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-27ef75dd-d040-4af7-88dd-becbfa909085,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-47a9dc32-ed1f-41ac-a047-288f99ccdab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-b937ff63-9a87-45a5-ba1f-e9b047701776,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-44cd0b1c-630a-4f5e-b4ff-ef50fc957aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-1374bfce-b251-4911-b6d0-b1803d550ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348900068-172.17.0.10-1596924187110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-3feacc2c-948a-48ff-9c9b-39902a799537,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-b88aab3a-f71f-47dd-b644-9ebaddd65730,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-099e0ae2-b1b0-4171-9f75-b8fbfc8803ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-b32e6eb8-2657-4c9f-a42e-ec660722c0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-08d2098f-607c-4f41-9cfe-ced69e1f3a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-d6e27065-a8b0-4e38-ac64-e689bab334c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-d7849646-d9a8-4eb2-a628-e3b6f6612384,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-38d8bcc8-a212-44c7-bea3-e40c54626411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348900068-172.17.0.10-1596924187110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-3feacc2c-948a-48ff-9c9b-39902a799537,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-b88aab3a-f71f-47dd-b644-9ebaddd65730,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-099e0ae2-b1b0-4171-9f75-b8fbfc8803ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-b32e6eb8-2657-4c9f-a42e-ec660722c0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-08d2098f-607c-4f41-9cfe-ced69e1f3a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-d6e27065-a8b0-4e38-ac64-e689bab334c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-d7849646-d9a8-4eb2-a628-e3b6f6612384,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-38d8bcc8-a212-44c7-bea3-e40c54626411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890200860-172.17.0.10-1596924671005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-30672a12-2d53-4598-bf45-e658c412cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-61d369fa-01ec-485a-9576-de82c62088c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-bb6e8179-91fe-4c80-9cd7-061374fc83b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ff3e1fac-178a-4997-ba6f-e73c88aabdba,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-f251ec76-5d7b-46f0-b56a-84430eeffe94,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-5fbba8a5-1a35-4eef-bb02-36a22cdf063d,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-dbde2497-6616-4ccd-8ca4-caec1f8a389b,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-2a5ff828-43f4-46dd-9757-6c212aea68f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890200860-172.17.0.10-1596924671005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-30672a12-2d53-4598-bf45-e658c412cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-61d369fa-01ec-485a-9576-de82c62088c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-bb6e8179-91fe-4c80-9cd7-061374fc83b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ff3e1fac-178a-4997-ba6f-e73c88aabdba,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-f251ec76-5d7b-46f0-b56a-84430eeffe94,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-5fbba8a5-1a35-4eef-bb02-36a22cdf063d,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-dbde2497-6616-4ccd-8ca4-caec1f8a389b,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-2a5ff828-43f4-46dd-9757-6c212aea68f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112255664-172.17.0.10-1596924903826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-22c7135b-0e34-4eb3-9e46-c981eda58497,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-061dc594-6548-433b-986c-c0aedeb24101,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-9c741bf6-cdc9-4431-9b6f-97d98bc27c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-08fee121-fa66-4d5f-b2f7-12b391c4d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-381781d4-cdf1-41e9-a4b5-9eff826caa55,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-cde6dab1-d4e8-4e8c-af8b-474bfbbd1cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-d18e9169-30e6-4824-8f99-65e60c950337,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-7efa5573-dc66-40ff-b379-198dd75595a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112255664-172.17.0.10-1596924903826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-22c7135b-0e34-4eb3-9e46-c981eda58497,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-061dc594-6548-433b-986c-c0aedeb24101,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-9c741bf6-cdc9-4431-9b6f-97d98bc27c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-08fee121-fa66-4d5f-b2f7-12b391c4d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-381781d4-cdf1-41e9-a4b5-9eff826caa55,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-cde6dab1-d4e8-4e8c-af8b-474bfbbd1cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-d18e9169-30e6-4824-8f99-65e60c950337,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-7efa5573-dc66-40ff-b379-198dd75595a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497806493-172.17.0.10-1596925616104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38204,DS-e0c5595d-a1cf-443f-8ceb-e135641848b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-2666add7-dd11-406b-9458-98582d0cccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-a5e5c599-4771-4a3e-b62a-b4521f97d768,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-c661b817-d76b-4cc6-b3d8-ff7e9cd0a633,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-cc03a0b1-1725-4815-9983-633158599e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-b3857bee-5ff7-4cf6-8711-be9efe3d94a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-c878ba9c-2272-492a-b24c-7f1023a09f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-be635f4d-ae6b-4d84-a0b3-b8a70582837a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497806493-172.17.0.10-1596925616104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38204,DS-e0c5595d-a1cf-443f-8ceb-e135641848b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-2666add7-dd11-406b-9458-98582d0cccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-a5e5c599-4771-4a3e-b62a-b4521f97d768,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-c661b817-d76b-4cc6-b3d8-ff7e9cd0a633,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-cc03a0b1-1725-4815-9983-633158599e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-b3857bee-5ff7-4cf6-8711-be9efe3d94a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-c878ba9c-2272-492a-b24c-7f1023a09f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-be635f4d-ae6b-4d84-a0b3-b8a70582837a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 4981
