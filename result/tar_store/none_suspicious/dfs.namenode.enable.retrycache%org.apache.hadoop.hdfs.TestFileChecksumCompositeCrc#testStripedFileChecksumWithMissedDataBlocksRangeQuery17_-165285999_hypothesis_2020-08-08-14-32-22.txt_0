reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798429962-172.17.0.2-1596898109060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-cc3666ee-7f6e-458b-a9e0-4bf8f2c2f9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-a9755ceb-ffd3-443d-ac57-e352565ab27c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-9572d87b-52ea-491b-be4d-84a17cfb435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-eb5d24f0-1476-430f-b09a-36be7b72a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-dde4d87f-08d1-436b-98c1-e902b69f4098,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-1041abea-e636-4cad-be5f-4c4d303816e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-ce75d56a-0db0-48c4-a502-b9266670d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-f958b6f3-cf5b-4fdf-86e7-cc7c4c3212a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798429962-172.17.0.2-1596898109060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-cc3666ee-7f6e-458b-a9e0-4bf8f2c2f9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-a9755ceb-ffd3-443d-ac57-e352565ab27c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-9572d87b-52ea-491b-be4d-84a17cfb435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-eb5d24f0-1476-430f-b09a-36be7b72a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-dde4d87f-08d1-436b-98c1-e902b69f4098,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-1041abea-e636-4cad-be5f-4c4d303816e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-ce75d56a-0db0-48c4-a502-b9266670d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-f958b6f3-cf5b-4fdf-86e7-cc7c4c3212a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471434591-172.17.0.2-1596898178923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35589,DS-77c0fa92-5c98-4139-8fb9-7bfb6a5ba1db,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-62411782-5b7d-43df-8fd6-eb9b1f3f1772,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-dcc4129b-0e50-452a-8866-677f3f9e4341,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-446d0d21-cb3d-4a75-8716-24e7e16ec667,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-b89d2fc4-d03c-4e01-a0a9-753aa87dacd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-8f8e9729-7b30-4dfe-84c4-e8432dd5733a,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-642d60c0-4e59-45db-95e6-9adf2c99a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-4c9c86f6-490c-42ae-97d7-48ddf7d18fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471434591-172.17.0.2-1596898178923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35589,DS-77c0fa92-5c98-4139-8fb9-7bfb6a5ba1db,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-62411782-5b7d-43df-8fd6-eb9b1f3f1772,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-dcc4129b-0e50-452a-8866-677f3f9e4341,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-446d0d21-cb3d-4a75-8716-24e7e16ec667,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-b89d2fc4-d03c-4e01-a0a9-753aa87dacd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-8f8e9729-7b30-4dfe-84c4-e8432dd5733a,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-642d60c0-4e59-45db-95e6-9adf2c99a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-4c9c86f6-490c-42ae-97d7-48ddf7d18fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044876869-172.17.0.2-1596898240739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-131f087f-4503-4910-a21c-1b554e671d89,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-0997678a-eebe-436e-8b2a-af44a53756e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-f859a420-033e-4168-aa44-ff6579ec75b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-2e8ad09d-4e72-45cf-9ebe-cbf3f8844597,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-252c3ea5-a36f-4298-b077-4438c5c99025,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-e207f91a-9b59-4ed8-89c8-f8f5b723e0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-9e9ce633-93dc-496f-915e-e253c09fc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-41be2ba8-3a07-487c-ac85-37506b34c2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044876869-172.17.0.2-1596898240739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-131f087f-4503-4910-a21c-1b554e671d89,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-0997678a-eebe-436e-8b2a-af44a53756e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-f859a420-033e-4168-aa44-ff6579ec75b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-2e8ad09d-4e72-45cf-9ebe-cbf3f8844597,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-252c3ea5-a36f-4298-b077-4438c5c99025,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-e207f91a-9b59-4ed8-89c8-f8f5b723e0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-9e9ce633-93dc-496f-915e-e253c09fc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-41be2ba8-3a07-487c-ac85-37506b34c2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769193936-172.17.0.2-1596898273398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-62de9f99-bf55-49cc-8be9-e11144c79049,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-87a8253e-e8a8-441e-a497-7edfb8734a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-ad23a143-7381-41a1-be41-8a57014f441e,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-44300dea-e27c-46d6-8650-2f954f27760b,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-5588db09-c1d5-4eac-bb94-34354148ac56,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-41f8ce0a-1996-4b99-be26-c124bec2eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-41a5c4a1-a2f3-4670-b0e7-97f75e3cf2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-dddc2b8e-c2c7-4ae8-8028-8175a9eb6d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769193936-172.17.0.2-1596898273398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-62de9f99-bf55-49cc-8be9-e11144c79049,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-87a8253e-e8a8-441e-a497-7edfb8734a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-ad23a143-7381-41a1-be41-8a57014f441e,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-44300dea-e27c-46d6-8650-2f954f27760b,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-5588db09-c1d5-4eac-bb94-34354148ac56,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-41f8ce0a-1996-4b99-be26-c124bec2eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-41a5c4a1-a2f3-4670-b0e7-97f75e3cf2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-dddc2b8e-c2c7-4ae8-8028-8175a9eb6d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712240001-172.17.0.2-1596898375839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-afdc5411-e4df-4e1c-9f60-f5ec02af9283,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-f6bce347-1716-4ef8-b359-8091d0e2aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-6221714e-6eb5-4bc8-8cc7-56af98974a12,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-4d839347-ddbb-424c-a9ba-8cff4125d041,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-fc663d43-e695-44a5-9f17-6ad5d3f840ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-786e190f-4d00-4853-8af3-b3d8d7cb4bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-b05eb9b1-54b3-4c4c-abc1-94491e61dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-20bf2ddc-a5c1-4f6f-a91d-ffed295e2b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712240001-172.17.0.2-1596898375839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-afdc5411-e4df-4e1c-9f60-f5ec02af9283,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-f6bce347-1716-4ef8-b359-8091d0e2aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-6221714e-6eb5-4bc8-8cc7-56af98974a12,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-4d839347-ddbb-424c-a9ba-8cff4125d041,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-fc663d43-e695-44a5-9f17-6ad5d3f840ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-786e190f-4d00-4853-8af3-b3d8d7cb4bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-b05eb9b1-54b3-4c4c-abc1-94491e61dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-20bf2ddc-a5c1-4f6f-a91d-ffed295e2b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629700398-172.17.0.2-1596899757635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43611,DS-2e19e6fc-66c1-40cc-a190-646f247399d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-ddc0cb9b-f0b0-4e7f-a61d-528b9704059e,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-5ef88935-aa59-4eb7-8969-35539ed4f26f,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-be24815b-09cd-4ac5-8a58-8162da2708a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-3d2ce9e1-357b-42fe-abaa-0bbfc33cd98e,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-ea98b0ee-70cd-4d6e-b9d0-489e16de2f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-f195ab79-fa81-442b-9808-561adcefe03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-b165ae4d-b28b-4c0b-b82c-31183d574ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629700398-172.17.0.2-1596899757635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43611,DS-2e19e6fc-66c1-40cc-a190-646f247399d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-ddc0cb9b-f0b0-4e7f-a61d-528b9704059e,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-5ef88935-aa59-4eb7-8969-35539ed4f26f,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-be24815b-09cd-4ac5-8a58-8162da2708a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-3d2ce9e1-357b-42fe-abaa-0bbfc33cd98e,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-ea98b0ee-70cd-4d6e-b9d0-489e16de2f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-f195ab79-fa81-442b-9808-561adcefe03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-b165ae4d-b28b-4c0b-b82c-31183d574ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159784523-172.17.0.2-1596899896244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-ba4bca62-2eac-4d91-b4cf-3281d8b5402b,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d83bb10f-83e8-4c14-84e6-7eaf9c2eb7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-8c094e9a-6560-46b7-8130-8fbfd4f0a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-a795b335-8885-4549-8f1a-b5c7b8822112,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-82180737-2fe4-4383-854c-fa59abff55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-a59bd27a-d6c5-48ca-913f-ea7754675e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-be53013a-ffeb-441d-9b60-664e4abdc1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-a4a9565e-492d-4b01-82cf-fe23ce4be1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159784523-172.17.0.2-1596899896244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-ba4bca62-2eac-4d91-b4cf-3281d8b5402b,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d83bb10f-83e8-4c14-84e6-7eaf9c2eb7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-8c094e9a-6560-46b7-8130-8fbfd4f0a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-a795b335-8885-4549-8f1a-b5c7b8822112,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-82180737-2fe4-4383-854c-fa59abff55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-a59bd27a-d6c5-48ca-913f-ea7754675e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-be53013a-ffeb-441d-9b60-664e4abdc1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-a4a9565e-492d-4b01-82cf-fe23ce4be1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769981954-172.17.0.2-1596899994760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-53345741-a5dd-4108-a820-b76b89543b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-6b0f0c1d-5f94-40e6-bd3d-68537527ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-692d1382-84a5-4899-8b06-5b5053a8a760,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-a913c441-9d1a-42fc-b954-63f779071690,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-89e9b69e-b1ae-4ad7-986a-91d1bc309d92,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-1cf09dcf-d450-40ef-a220-4c4bfffcafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-e12d4515-d415-4182-8d2c-010f7110276c,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-fba1b3f5-bd4b-4173-9056-995ac381bbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769981954-172.17.0.2-1596899994760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-53345741-a5dd-4108-a820-b76b89543b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-6b0f0c1d-5f94-40e6-bd3d-68537527ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-692d1382-84a5-4899-8b06-5b5053a8a760,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-a913c441-9d1a-42fc-b954-63f779071690,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-89e9b69e-b1ae-4ad7-986a-91d1bc309d92,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-1cf09dcf-d450-40ef-a220-4c4bfffcafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-e12d4515-d415-4182-8d2c-010f7110276c,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-fba1b3f5-bd4b-4173-9056-995ac381bbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124695221-172.17.0.2-1596900346270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36087,DS-c625a4a1-489f-4601-b568-9b10bfd0b707,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-a4883ff6-f1eb-4e12-8dc9-047ef393d769,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-5ffaa95b-1b08-431e-930f-7cccbe724c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-9b940ed4-7aa4-4beb-a80b-8c843fdfabc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-c0efbddc-0505-4ea4-b463-23a0663b56ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-4ce5a944-8c34-40bb-9143-e77a46014d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-06684c90-af7e-4d3f-bcc7-7f0b6e551f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-bad4ad8c-0187-4e47-96ea-54f51a17a38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124695221-172.17.0.2-1596900346270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36087,DS-c625a4a1-489f-4601-b568-9b10bfd0b707,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-a4883ff6-f1eb-4e12-8dc9-047ef393d769,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-5ffaa95b-1b08-431e-930f-7cccbe724c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-9b940ed4-7aa4-4beb-a80b-8c843fdfabc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-c0efbddc-0505-4ea4-b463-23a0663b56ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-4ce5a944-8c34-40bb-9143-e77a46014d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-06684c90-af7e-4d3f-bcc7-7f0b6e551f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-bad4ad8c-0187-4e47-96ea-54f51a17a38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882257466-172.17.0.2-1596900732925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-5bb10a88-6bc8-466f-80b6-9d6e8eb8b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-b0c930b6-3f9b-437c-bda8-c635d8bb83bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-caf47f4b-5368-4f36-ab99-4c5807940c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-5fa8e8e3-b704-4c6e-be7b-84161a9a3807,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-eef060ba-e6d2-4033-b1c1-105feaef118a,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-3e8772ba-3326-4e5c-bd87-efc809498305,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-c86b24af-8f53-4446-a4aa-462986c27d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-9c4a15f7-a924-4109-958d-14fb3e9ea6f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882257466-172.17.0.2-1596900732925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-5bb10a88-6bc8-466f-80b6-9d6e8eb8b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-b0c930b6-3f9b-437c-bda8-c635d8bb83bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-caf47f4b-5368-4f36-ab99-4c5807940c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-5fa8e8e3-b704-4c6e-be7b-84161a9a3807,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-eef060ba-e6d2-4033-b1c1-105feaef118a,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-3e8772ba-3326-4e5c-bd87-efc809498305,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-c86b24af-8f53-4446-a4aa-462986c27d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-9c4a15f7-a924-4109-958d-14fb3e9ea6f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134905011-172.17.0.2-1596902000961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-44f46552-d15f-42d9-a880-98d1e6a40fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-2e967cd1-bdf2-49a7-84cf-397fcda56b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-e384734f-f99b-4fc5-8d0c-4ea788b63b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-3718eb5d-e922-4b59-8464-14729b68a917,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-725e02dc-261b-487f-bf55-ed62ac9e8956,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-b26cee72-bd1a-4a52-b048-916be6ccc76b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-3b8b4b8f-f680-409a-90f5-80c7f30b6297,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-6548cb14-5c32-45c5-a5e7-f954ff00c7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134905011-172.17.0.2-1596902000961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-44f46552-d15f-42d9-a880-98d1e6a40fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-2e967cd1-bdf2-49a7-84cf-397fcda56b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-e384734f-f99b-4fc5-8d0c-4ea788b63b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-3718eb5d-e922-4b59-8464-14729b68a917,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-725e02dc-261b-487f-bf55-ed62ac9e8956,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-b26cee72-bd1a-4a52-b048-916be6ccc76b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-3b8b4b8f-f680-409a-90f5-80c7f30b6297,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-6548cb14-5c32-45c5-a5e7-f954ff00c7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293924643-172.17.0.2-1596902031251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-cc5c1421-84ec-4356-8b97-b8d5f24125d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-cc79e9ee-91d4-4e3c-abb7-43f2f3ddbf88,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-ea101a35-8cb4-4fc4-956d-04e4fc83ef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-98b18aa4-ccba-47b1-a0a0-ba2a9a3b99ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-86c99545-6065-4b51-9838-c373e19e1305,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-aed0bcdb-ef71-4caf-99ee-e8cbdb984046,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-e7d0bac9-b100-44f6-a41a-66190c6241e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-008a1cad-841f-4db0-acf4-40704093d3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293924643-172.17.0.2-1596902031251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-cc5c1421-84ec-4356-8b97-b8d5f24125d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-cc79e9ee-91d4-4e3c-abb7-43f2f3ddbf88,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-ea101a35-8cb4-4fc4-956d-04e4fc83ef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-98b18aa4-ccba-47b1-a0a0-ba2a9a3b99ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-86c99545-6065-4b51-9838-c373e19e1305,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-aed0bcdb-ef71-4caf-99ee-e8cbdb984046,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-e7d0bac9-b100-44f6-a41a-66190c6241e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-008a1cad-841f-4db0-acf4-40704093d3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542198336-172.17.0.2-1596902067580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34477,DS-020c90c0-930c-4017-8fb2-787724b8b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-8178b64f-fe73-4822-bf67-da328acdc40f,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-c1e35b6d-e7ea-46e8-b58e-a9ddf2d4369f,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-e50f0756-8b70-4398-a3d5-68c6fdac593a,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-2568c808-709f-40c2-a3d9-cc04ed2f548a,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-cc904730-dcfa-4742-8fad-c35dd9b85e63,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-f64d0082-3020-4de5-a815-c7477388ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-16057cb3-3adb-4fed-a97e-015dded0ca88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542198336-172.17.0.2-1596902067580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34477,DS-020c90c0-930c-4017-8fb2-787724b8b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-8178b64f-fe73-4822-bf67-da328acdc40f,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-c1e35b6d-e7ea-46e8-b58e-a9ddf2d4369f,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-e50f0756-8b70-4398-a3d5-68c6fdac593a,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-2568c808-709f-40c2-a3d9-cc04ed2f548a,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-cc904730-dcfa-4742-8fad-c35dd9b85e63,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-f64d0082-3020-4de5-a815-c7477388ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-16057cb3-3adb-4fed-a97e-015dded0ca88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426598646-172.17.0.2-1596902139757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38322,DS-c20a0154-8109-46a0-8986-c6da3f00bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-40a6d44d-4d66-4288-8e5b-b134b1de2636,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-3eff39ea-1c40-4c1b-b03b-e6ab633074ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-fa8810f3-f516-42c8-bbdc-86d57939eecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-52f8846f-e331-4871-9f84-d1a60d4a683e,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-2fa9ec93-c9fd-4409-8367-549f3062124c,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-ea768d05-f5ee-426b-bc08-31801f0a6ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5b8466aa-598a-4346-8b33-86d6cf54740e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426598646-172.17.0.2-1596902139757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38322,DS-c20a0154-8109-46a0-8986-c6da3f00bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-40a6d44d-4d66-4288-8e5b-b134b1de2636,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-3eff39ea-1c40-4c1b-b03b-e6ab633074ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-fa8810f3-f516-42c8-bbdc-86d57939eecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-52f8846f-e331-4871-9f84-d1a60d4a683e,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-2fa9ec93-c9fd-4409-8367-549f3062124c,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-ea768d05-f5ee-426b-bc08-31801f0a6ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5b8466aa-598a-4346-8b33-86d6cf54740e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5049
