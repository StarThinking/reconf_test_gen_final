reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372401008-172.17.0.13-1596935573706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36388,DS-a39c911a-0a98-4574-aa60-335211a5622d,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-2b64d501-9e04-4096-838e-2bc4f2fb5a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-cf33d26c-7fd3-4cc9-a5c3-86f14bc90700,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-68e1c08a-db48-4dcf-9c77-dc34ae5a91cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-468452d1-165b-4ace-91f4-b1502eac9431,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-455cb178-0333-4711-a9eb-7d118de09aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-bafc898f-0f97-4622-a496-84373d37a70f,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-8d0d4dda-a7fb-4789-b0e9-9e3107feaf45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372401008-172.17.0.13-1596935573706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36388,DS-a39c911a-0a98-4574-aa60-335211a5622d,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-2b64d501-9e04-4096-838e-2bc4f2fb5a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-cf33d26c-7fd3-4cc9-a5c3-86f14bc90700,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-68e1c08a-db48-4dcf-9c77-dc34ae5a91cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-468452d1-165b-4ace-91f4-b1502eac9431,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-455cb178-0333-4711-a9eb-7d118de09aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-bafc898f-0f97-4622-a496-84373d37a70f,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-8d0d4dda-a7fb-4789-b0e9-9e3107feaf45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915852546-172.17.0.13-1596935854177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45123,DS-c8ed7f40-30d3-4161-aaab-3a209656e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-3354173f-e571-4c80-8c57-f2353ebfaa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-9c81805c-7205-47b0-af15-1c6403066e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-270234e4-8775-4b64-8490-213688bf8f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-21bf960b-9b83-47ef-a14c-83293e8c7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-1ed20f10-18ba-43ac-ada4-db60c88a121d,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-0cb20f95-27f2-4b88-a709-36b7fe14d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-1a6db71c-815a-47f8-9a94-05aa9de4e96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915852546-172.17.0.13-1596935854177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45123,DS-c8ed7f40-30d3-4161-aaab-3a209656e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-3354173f-e571-4c80-8c57-f2353ebfaa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-9c81805c-7205-47b0-af15-1c6403066e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-270234e4-8775-4b64-8490-213688bf8f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-21bf960b-9b83-47ef-a14c-83293e8c7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-1ed20f10-18ba-43ac-ada4-db60c88a121d,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-0cb20f95-27f2-4b88-a709-36b7fe14d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-1a6db71c-815a-47f8-9a94-05aa9de4e96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353937143-172.17.0.13-1596936123588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-371b902c-773f-4ad3-8086-6d8bd1140b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-6fed3228-4368-48ca-9215-588931d3c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-542e5a97-227c-4cfd-b4a1-f4ff0fe55dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-ba730c10-7172-4c45-8a17-7146b600f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-c501d86a-9846-4553-91bf-cf9808839471,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-e350f8f5-037c-42b4-a456-af6566f6e58b,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-bb22c4df-a479-4605-adbb-d45283372c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-ca81be19-c5a6-4ad0-b6f5-d1028a0750a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353937143-172.17.0.13-1596936123588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-371b902c-773f-4ad3-8086-6d8bd1140b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-6fed3228-4368-48ca-9215-588931d3c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-542e5a97-227c-4cfd-b4a1-f4ff0fe55dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-ba730c10-7172-4c45-8a17-7146b600f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-c501d86a-9846-4553-91bf-cf9808839471,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-e350f8f5-037c-42b4-a456-af6566f6e58b,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-bb22c4df-a479-4605-adbb-d45283372c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-ca81be19-c5a6-4ad0-b6f5-d1028a0750a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100115847-172.17.0.13-1596936228732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46710,DS-5ee87391-e807-4d20-8f83-d3943228c593,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-9a630558-0747-41ed-ad4a-1d742537ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-6d09690e-da91-411b-ab3d-81a38a76e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-650aea8a-e72e-48dc-817b-48701bd61bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-e53ed102-49e5-466e-9ec4-ea4bf0b336bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-69f052dd-8f79-40d6-8c8e-ab57e8062f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-fcd4949d-abc8-4c7c-b8d4-1cf54e12b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-0811a99a-f674-429b-ab0c-38cb33049156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100115847-172.17.0.13-1596936228732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46710,DS-5ee87391-e807-4d20-8f83-d3943228c593,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-9a630558-0747-41ed-ad4a-1d742537ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-6d09690e-da91-411b-ab3d-81a38a76e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-650aea8a-e72e-48dc-817b-48701bd61bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-e53ed102-49e5-466e-9ec4-ea4bf0b336bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-69f052dd-8f79-40d6-8c8e-ab57e8062f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-fcd4949d-abc8-4c7c-b8d4-1cf54e12b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-0811a99a-f674-429b-ab0c-38cb33049156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247492510-172.17.0.13-1596936266512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43069,DS-e141844f-c3ac-41af-ae33-971e4611ed73,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-4a29badf-873a-4531-bf55-edefd09684d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-c693329a-7d43-44e9-a8c8-ec3ff2798802,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-f8ab1519-86ee-40ec-be0b-bf07f4d40e66,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-ada9ee14-899a-4dfa-a70e-7db7e7943f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-a830f49d-ea75-4bc7-a97f-6963f41be2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-4d30adf1-0450-4c79-9cb8-0591bab9d5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-8ddac049-9577-497e-a6e3-5f720587ae15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247492510-172.17.0.13-1596936266512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43069,DS-e141844f-c3ac-41af-ae33-971e4611ed73,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-4a29badf-873a-4531-bf55-edefd09684d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-c693329a-7d43-44e9-a8c8-ec3ff2798802,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-f8ab1519-86ee-40ec-be0b-bf07f4d40e66,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-ada9ee14-899a-4dfa-a70e-7db7e7943f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-a830f49d-ea75-4bc7-a97f-6963f41be2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-4d30adf1-0450-4c79-9cb8-0591bab9d5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-8ddac049-9577-497e-a6e3-5f720587ae15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921040986-172.17.0.13-1596936851020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-8ff5a890-ccb5-4693-839a-d99bc3d83fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-79f1c7a1-9636-4ba9-8f0e-c6d169263835,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-1dc77c73-22f3-49b9-b4d3-beb110b3ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-5cef1fe3-a129-4861-ad49-1990f0042136,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-420a3002-aa88-415c-8369-75675f330369,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-3a49a47a-1f0c-4225-84a9-116003addd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-93293cb5-bc68-4845-9c9f-bab4bf75b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-13a667d1-1eef-4ee5-a937-d0da65ba7f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921040986-172.17.0.13-1596936851020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-8ff5a890-ccb5-4693-839a-d99bc3d83fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-79f1c7a1-9636-4ba9-8f0e-c6d169263835,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-1dc77c73-22f3-49b9-b4d3-beb110b3ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-5cef1fe3-a129-4861-ad49-1990f0042136,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-420a3002-aa88-415c-8369-75675f330369,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-3a49a47a-1f0c-4225-84a9-116003addd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-93293cb5-bc68-4845-9c9f-bab4bf75b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-13a667d1-1eef-4ee5-a937-d0da65ba7f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590622039-172.17.0.13-1596936922770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-6b74c98e-708d-4805-ab03-8e5aec13b08c,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-b539088c-bd0e-4997-87bc-8d12a84749c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-a4db420d-64a1-41e3-9e99-b87a8ee6e3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-c1e776a2-1fff-4a46-84d0-15af932c15e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-eedfd1d4-c832-4769-a463-23a2c98ec14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-4d4e020c-28ea-46c4-a678-6e85a22b4999,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-193698df-a91e-45f5-aa0c-49ca3ede1607,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-c42053a1-9eac-42a4-bdf3-61367d8a6839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590622039-172.17.0.13-1596936922770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-6b74c98e-708d-4805-ab03-8e5aec13b08c,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-b539088c-bd0e-4997-87bc-8d12a84749c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-a4db420d-64a1-41e3-9e99-b87a8ee6e3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-c1e776a2-1fff-4a46-84d0-15af932c15e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-eedfd1d4-c832-4769-a463-23a2c98ec14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-4d4e020c-28ea-46c4-a678-6e85a22b4999,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-193698df-a91e-45f5-aa0c-49ca3ede1607,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-c42053a1-9eac-42a4-bdf3-61367d8a6839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467718219-172.17.0.13-1596936991117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-010a9935-c5b2-4c7c-9907-1a2bde8dfceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-1b30e630-e5cf-493c-8981-c41d82502773,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-dbbe80dd-2f88-4d96-9c29-976ebf6e5158,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-91399556-d47b-40b6-b0c8-fe45a5ce2716,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-653324ac-15b8-4417-8429-d5e7c0dc5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-1a116cb5-b3c9-48dc-812b-25082e6a1733,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-1f998c40-8eb4-49fa-85d6-205a3ebed822,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-840ed70f-6796-4653-9ad5-f629506801de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467718219-172.17.0.13-1596936991117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-010a9935-c5b2-4c7c-9907-1a2bde8dfceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-1b30e630-e5cf-493c-8981-c41d82502773,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-dbbe80dd-2f88-4d96-9c29-976ebf6e5158,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-91399556-d47b-40b6-b0c8-fe45a5ce2716,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-653324ac-15b8-4417-8429-d5e7c0dc5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-1a116cb5-b3c9-48dc-812b-25082e6a1733,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-1f998c40-8eb4-49fa-85d6-205a3ebed822,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-840ed70f-6796-4653-9ad5-f629506801de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230100678-172.17.0.13-1596937304893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-8a251ff2-913f-409d-b025-08f4bc578327,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-b9924319-f983-4208-951c-b6bb62384d56,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-acd8ce32-c7a6-4b23-8e4c-09472d2eb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-4215b0a6-b74d-4e33-89ac-068b0995ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-5faa65bc-442d-400d-8ee9-92905edf2bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2dfa1b01-88f7-4bf4-bdef-b500454ba5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-8e1999e9-d7b4-4d26-9a3e-77ad051a8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-f9cc1ac8-b9be-4ea6-80da-8d25196c6358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230100678-172.17.0.13-1596937304893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-8a251ff2-913f-409d-b025-08f4bc578327,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-b9924319-f983-4208-951c-b6bb62384d56,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-acd8ce32-c7a6-4b23-8e4c-09472d2eb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-4215b0a6-b74d-4e33-89ac-068b0995ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-5faa65bc-442d-400d-8ee9-92905edf2bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2dfa1b01-88f7-4bf4-bdef-b500454ba5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-8e1999e9-d7b4-4d26-9a3e-77ad051a8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-f9cc1ac8-b9be-4ea6-80da-8d25196c6358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278570526-172.17.0.13-1596937401611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-da11a2b2-17ca-4a91-9360-9c0d32b52d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-9c5afe18-cf2e-4796-9c1b-4b062ef5a833,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-a4dc0282-3744-4b47-a95f-2b7d7c5360ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-6c06a25c-0142-4dab-a585-536f32d49234,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-bc8fb62e-40e4-4670-bc34-3876f7771c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-7adafd0d-1fe0-4631-b810-8b57a8c95707,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-bc017fb5-59b2-4f42-850c-dfe83564484a,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-82202431-36a2-4b4a-b0f7-59778fe73a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278570526-172.17.0.13-1596937401611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-da11a2b2-17ca-4a91-9360-9c0d32b52d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-9c5afe18-cf2e-4796-9c1b-4b062ef5a833,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-a4dc0282-3744-4b47-a95f-2b7d7c5360ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-6c06a25c-0142-4dab-a585-536f32d49234,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-bc8fb62e-40e4-4670-bc34-3876f7771c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-7adafd0d-1fe0-4631-b810-8b57a8c95707,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-bc017fb5-59b2-4f42-850c-dfe83564484a,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-82202431-36a2-4b4a-b0f7-59778fe73a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210912784-172.17.0.13-1596937665093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-ffb1fd36-42a4-4c95-af97-784dd622fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-41c6b040-d497-468d-9314-442ee46fa4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8839a7a3-7910-4e0a-9bb4-71773fda73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-6cdf630b-7848-41f6-8df4-2966fc66d96d,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-fa88fe82-d477-4ce1-9119-c215e7004b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-2de63c14-d793-488c-9370-f3079b52b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-48d8401d-744f-461e-9e48-38627f30b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-42f66230-4297-4714-b335-f503afabfec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210912784-172.17.0.13-1596937665093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-ffb1fd36-42a4-4c95-af97-784dd622fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-41c6b040-d497-468d-9314-442ee46fa4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8839a7a3-7910-4e0a-9bb4-71773fda73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-6cdf630b-7848-41f6-8df4-2966fc66d96d,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-fa88fe82-d477-4ce1-9119-c215e7004b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-2de63c14-d793-488c-9370-f3079b52b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-48d8401d-744f-461e-9e48-38627f30b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-42f66230-4297-4714-b335-f503afabfec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063565673-172.17.0.13-1596937706723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-780427f7-a741-4ff8-98f7-4b27da2e0271,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-bbaea2c2-9ea0-47e1-b326-51bf0ef15efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-d2f9c62d-334e-457c-815a-e7eaccd9e993,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8477c96b-b2c8-401d-ba59-2d0984cf191c,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-0f2429e8-96b3-4b0e-a3bd-ca44549894a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-7bdf1f19-f545-476a-9079-2ceb91aad5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-2f0daf9a-d1de-4666-babe-fefd31e993ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-674bca80-d15d-4ab2-baaa-3cb609dfe3ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063565673-172.17.0.13-1596937706723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-780427f7-a741-4ff8-98f7-4b27da2e0271,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-bbaea2c2-9ea0-47e1-b326-51bf0ef15efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-d2f9c62d-334e-457c-815a-e7eaccd9e993,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8477c96b-b2c8-401d-ba59-2d0984cf191c,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-0f2429e8-96b3-4b0e-a3bd-ca44549894a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-7bdf1f19-f545-476a-9079-2ceb91aad5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-2f0daf9a-d1de-4666-babe-fefd31e993ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-674bca80-d15d-4ab2-baaa-3cb609dfe3ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352530746-172.17.0.13-1596938092146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46362,DS-6d6c5fda-1632-4444-90b4-dfd9207600f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-f066433f-1836-4c20-912c-5c3b74d90a93,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-bfcba95c-6189-400a-b281-b0a94fe5a4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-c7c7c7a0-b781-47bc-ad17-c9d56b703cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-30ee44d7-8d3a-4b4b-b273-d8ca4bd94c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-bcfc3b31-4011-41f7-99c7-b6e884090681,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-286f07da-b97e-41e1-87a6-7f4e328b9c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-91804cee-ac03-4e0c-ac5a-0ba4b6ec69b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352530746-172.17.0.13-1596938092146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46362,DS-6d6c5fda-1632-4444-90b4-dfd9207600f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-f066433f-1836-4c20-912c-5c3b74d90a93,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-bfcba95c-6189-400a-b281-b0a94fe5a4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-c7c7c7a0-b781-47bc-ad17-c9d56b703cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-30ee44d7-8d3a-4b4b-b273-d8ca4bd94c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-bcfc3b31-4011-41f7-99c7-b6e884090681,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-286f07da-b97e-41e1-87a6-7f4e328b9c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-91804cee-ac03-4e0c-ac5a-0ba4b6ec69b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699430198-172.17.0.13-1596938226235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-d9632d3f-8591-41e7-8a6b-844c86447bea,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-74bf9983-3565-4df8-9b42-5c49d0990c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-fb02f978-53e1-4330-bf9b-48a3e7d236fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4f9bc51d-07f4-4078-9f26-a925cba96e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-dd27825e-7f3b-4a5a-ac66-f9287b67aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-4c9ce895-4b3e-4e17-95b9-a0c2941b33e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-b75d7280-dd33-44ca-b317-6a0edcddc48c,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-81750539-2643-4791-904e-02f9aa3f062b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699430198-172.17.0.13-1596938226235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-d9632d3f-8591-41e7-8a6b-844c86447bea,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-74bf9983-3565-4df8-9b42-5c49d0990c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-fb02f978-53e1-4330-bf9b-48a3e7d236fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4f9bc51d-07f4-4078-9f26-a925cba96e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-dd27825e-7f3b-4a5a-ac66-f9287b67aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-4c9ce895-4b3e-4e17-95b9-a0c2941b33e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-b75d7280-dd33-44ca-b317-6a0edcddc48c,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-81750539-2643-4791-904e-02f9aa3f062b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99835619-172.17.0.13-1596938410995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38112,DS-20e06b97-bcdf-42fc-a934-a494479e0cab,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-94204dec-9069-4c08-88dc-a931e99f8074,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-08d1e2f1-8f59-4b37-b8d2-7d26ef5023fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-cfd21914-1e96-4379-bf4f-82c581221de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-5d57cede-5288-47bd-ada9-2b808f708ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-2155aade-5db3-4fd1-855f-86848613d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-3cc85fb3-4c11-4864-bb86-d0317a1044be,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-69ef94e1-d333-4c5b-8413-d4b4e68eb851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99835619-172.17.0.13-1596938410995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38112,DS-20e06b97-bcdf-42fc-a934-a494479e0cab,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-94204dec-9069-4c08-88dc-a931e99f8074,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-08d1e2f1-8f59-4b37-b8d2-7d26ef5023fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-cfd21914-1e96-4379-bf4f-82c581221de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-5d57cede-5288-47bd-ada9-2b808f708ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-2155aade-5db3-4fd1-855f-86848613d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-3cc85fb3-4c11-4864-bb86-d0317a1044be,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-69ef94e1-d333-4c5b-8413-d4b4e68eb851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472115965-172.17.0.13-1596939068567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-3353e33c-3187-4593-b0d2-933ecf5dfddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-f51f866b-142a-42bd-80f0-3ddaabeea575,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-4288abc7-d3ba-4eae-a641-b4b5deb54678,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-2a739fe7-97aa-48c7-8cf6-b012ea9a77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-6d542634-e661-4bcd-91ac-ddc83f72d658,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-17583c50-d307-44ef-8b8c-385ecd5df553,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-c7656dd8-9bb4-407c-ad41-0318a878caa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-246c63c0-4834-47e3-a9c9-f32aca1a8861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472115965-172.17.0.13-1596939068567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-3353e33c-3187-4593-b0d2-933ecf5dfddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-f51f866b-142a-42bd-80f0-3ddaabeea575,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-4288abc7-d3ba-4eae-a641-b4b5deb54678,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-2a739fe7-97aa-48c7-8cf6-b012ea9a77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-6d542634-e661-4bcd-91ac-ddc83f72d658,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-17583c50-d307-44ef-8b8c-385ecd5df553,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-c7656dd8-9bb4-407c-ad41-0318a878caa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-246c63c0-4834-47e3-a9c9-f32aca1a8861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781329107-172.17.0.13-1596939244998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-bfba380a-2aef-45e0-b966-3b3a23d99109,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-3fb4884c-197c-4d29-aea5-5ea9646b153f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ca83cc3b-4068-409f-a1c0-350a9dfb86b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-58e98cb0-cee9-4f6a-86b4-420e91ab53e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-180fc0da-2727-4b18-ade8-c6005f028822,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-d175cfaa-75fa-452f-8ff0-cfa058f4d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-d779137c-6a72-4ae3-b6df-956346332ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-63cdb2ef-7f35-4f41-89e8-02bb0e50dda4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781329107-172.17.0.13-1596939244998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-bfba380a-2aef-45e0-b966-3b3a23d99109,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-3fb4884c-197c-4d29-aea5-5ea9646b153f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ca83cc3b-4068-409f-a1c0-350a9dfb86b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-58e98cb0-cee9-4f6a-86b4-420e91ab53e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-180fc0da-2727-4b18-ade8-c6005f028822,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-d175cfaa-75fa-452f-8ff0-cfa058f4d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-d779137c-6a72-4ae3-b6df-956346332ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-63cdb2ef-7f35-4f41-89e8-02bb0e50dda4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948609220-172.17.0.13-1596939318985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-f3bb4ec7-b9c0-4825-83a5-8b9be52c045f,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-7078622c-ab76-4ba0-8da9-7ebfe56c36f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-42505296-a5dc-48ea-b23d-3e959627e480,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-81cd9540-f757-433f-9bdd-53192f96ce55,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-6223e0ef-ba78-4051-a14d-1ac20f26a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-d389f57d-b3f6-45fb-88d2-73999e997682,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-4629aa25-f835-4f09-92a6-5614ed1e358f,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-aa5a7929-c5f8-4931-ac05-88b12644ec9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948609220-172.17.0.13-1596939318985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-f3bb4ec7-b9c0-4825-83a5-8b9be52c045f,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-7078622c-ab76-4ba0-8da9-7ebfe56c36f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-42505296-a5dc-48ea-b23d-3e959627e480,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-81cd9540-f757-433f-9bdd-53192f96ce55,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-6223e0ef-ba78-4051-a14d-1ac20f26a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-d389f57d-b3f6-45fb-88d2-73999e997682,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-4629aa25-f835-4f09-92a6-5614ed1e358f,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-aa5a7929-c5f8-4931-ac05-88b12644ec9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913572446-172.17.0.13-1596939357193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-49401eae-2d9c-4396-8434-0eec3848c7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-e71add0f-7f3b-4691-94d0-12357691016d,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-99082958-512f-47fd-9e8d-45e8944db6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-b5d383b1-7dc5-4656-b906-30ebca8a7f70,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-3d93d9b6-f5b9-45a4-988b-7bd6b85c6f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-a691e8c1-2ff0-420d-b648-a8d0233a1685,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-284ef4f8-9fc7-43d9-9767-15d700291b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-2d1bff7c-96ff-482b-8c43-b1e1f62a9c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913572446-172.17.0.13-1596939357193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-49401eae-2d9c-4396-8434-0eec3848c7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-e71add0f-7f3b-4691-94d0-12357691016d,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-99082958-512f-47fd-9e8d-45e8944db6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-b5d383b1-7dc5-4656-b906-30ebca8a7f70,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-3d93d9b6-f5b9-45a4-988b-7bd6b85c6f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-a691e8c1-2ff0-420d-b648-a8d0233a1685,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-284ef4f8-9fc7-43d9-9767-15d700291b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-2d1bff7c-96ff-482b-8c43-b1e1f62a9c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798009155-172.17.0.13-1596940080868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36883,DS-de8f232a-021f-4f53-ada0-3cab2fc7297b,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-14deb47b-6047-46bf-b100-a8a341283e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-21e1c564-d4c4-4f53-a3e2-f642cde5cce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-0cbfb3a3-e0bc-4523-a506-eee1807ce7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-4747a744-6f33-408a-8570-399d8b6b419b,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-eb7bf543-8676-466c-ae07-c960db4e5d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-e8a5497c-d574-4aa7-8445-3b306651dc59,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-4c273269-3394-490d-aa36-3a5d4d8c6bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798009155-172.17.0.13-1596940080868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36883,DS-de8f232a-021f-4f53-ada0-3cab2fc7297b,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-14deb47b-6047-46bf-b100-a8a341283e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-21e1c564-d4c4-4f53-a3e2-f642cde5cce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-0cbfb3a3-e0bc-4523-a506-eee1807ce7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-4747a744-6f33-408a-8570-399d8b6b419b,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-eb7bf543-8676-466c-ae07-c960db4e5d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-e8a5497c-d574-4aa7-8445-3b306651dc59,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-4c273269-3394-490d-aa36-3a5d4d8c6bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685252896-172.17.0.13-1596940175721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-61f24684-8a4e-42b6-9039-b2a0418a063d,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-52ff0ce1-6ccc-49a3-a4bc-acf9581ffaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-a5fe747c-6467-44f6-a1fb-4dae18af3964,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-4ebc814e-a57e-4e47-9e0a-354685a8784f,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-684a8394-45f6-4be7-9d0a-013d2ddcc025,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-f420cd86-4560-4908-ae91-ca2789e2be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-36205b40-d0ff-4293-8082-e5b8b980768e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-0c04b535-e852-462c-b999-4779bcc1767c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685252896-172.17.0.13-1596940175721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-61f24684-8a4e-42b6-9039-b2a0418a063d,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-52ff0ce1-6ccc-49a3-a4bc-acf9581ffaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-a5fe747c-6467-44f6-a1fb-4dae18af3964,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-4ebc814e-a57e-4e47-9e0a-354685a8784f,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-684a8394-45f6-4be7-9d0a-013d2ddcc025,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-f420cd86-4560-4908-ae91-ca2789e2be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-36205b40-d0ff-4293-8082-e5b8b980768e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-0c04b535-e852-462c-b999-4779bcc1767c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337468358-172.17.0.13-1596940329308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-271476f4-917a-48da-9948-fa8a8637566c,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-95c7c77a-d177-491b-be88-6a80d4e086ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-82ad2d4e-8599-405f-8060-846a677dcc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-02c31a8a-b9b9-4535-938a-0f1c52998996,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-5133c61d-20f4-4396-b40a-721173bf896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-3d52f37c-272d-4e48-9922-f476660ab870,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-43eedb7c-aa30-4be4-b586-21cb260a4f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-0c1f9502-5952-400d-b3ee-427bf61d48a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337468358-172.17.0.13-1596940329308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-271476f4-917a-48da-9948-fa8a8637566c,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-95c7c77a-d177-491b-be88-6a80d4e086ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-82ad2d4e-8599-405f-8060-846a677dcc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-02c31a8a-b9b9-4535-938a-0f1c52998996,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-5133c61d-20f4-4396-b40a-721173bf896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-3d52f37c-272d-4e48-9922-f476660ab870,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-43eedb7c-aa30-4be4-b586-21cb260a4f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-0c1f9502-5952-400d-b3ee-427bf61d48a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5227
