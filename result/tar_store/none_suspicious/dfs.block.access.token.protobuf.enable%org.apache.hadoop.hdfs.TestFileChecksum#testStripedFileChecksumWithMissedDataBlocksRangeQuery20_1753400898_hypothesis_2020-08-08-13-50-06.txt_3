reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552666525-172.17.0.21-1596894904420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-8646ee04-02ff-4455-af39-74271cb06881,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-1078f98d-5818-49a4-b13b-a0d9a80956b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-75dc1d43-ddeb-4d22-b2a2-46f4f3b9adfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-eba1400a-d5f9-4c9c-88fc-41242700ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-aa23f5fe-db7a-429d-9d11-e8883db2a131,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-51f55c93-6500-41e7-8c0e-2d3e03c8511f,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-ee17db10-1b62-4812-9862-65c9961c34b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-56edb078-152d-4d49-8a50-b25fa3b83977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552666525-172.17.0.21-1596894904420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-8646ee04-02ff-4455-af39-74271cb06881,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-1078f98d-5818-49a4-b13b-a0d9a80956b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-75dc1d43-ddeb-4d22-b2a2-46f4f3b9adfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-eba1400a-d5f9-4c9c-88fc-41242700ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-aa23f5fe-db7a-429d-9d11-e8883db2a131,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-51f55c93-6500-41e7-8c0e-2d3e03c8511f,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-ee17db10-1b62-4812-9862-65c9961c34b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-56edb078-152d-4d49-8a50-b25fa3b83977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547842647-172.17.0.21-1596895317240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-985aee52-e802-4639-83d2-78b3d6c67c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-05722488-9643-4a2a-8dbe-e48376095c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-48b1d830-70e7-4f71-b21f-795de669cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-a71e1ca1-7731-42d6-b9b0-580345b7a499,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-867209c4-f370-43ba-a9b6-e0c32a3ca60e,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-af883ea3-2626-4d8e-84a9-45fb74cea910,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-4fb7e883-b51c-4027-a3b1-9755e75417bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-b08973ec-e131-4c5c-b6e1-4f5460ecf814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547842647-172.17.0.21-1596895317240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-985aee52-e802-4639-83d2-78b3d6c67c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-05722488-9643-4a2a-8dbe-e48376095c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-48b1d830-70e7-4f71-b21f-795de669cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-a71e1ca1-7731-42d6-b9b0-580345b7a499,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-867209c4-f370-43ba-a9b6-e0c32a3ca60e,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-af883ea3-2626-4d8e-84a9-45fb74cea910,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-4fb7e883-b51c-4027-a3b1-9755e75417bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-b08973ec-e131-4c5c-b6e1-4f5460ecf814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874443307-172.17.0.21-1596895901804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-6dfe653b-a014-42c5-8284-97188b412a03,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-eef7d786-8648-48f8-98fc-4ccf4183e722,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-60efe027-0328-4192-b2c5-262c8e8ed312,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-589a2160-2b8b-4ca2-a2aa-a59b8aa88390,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-b6dae48b-0bfa-4a04-adf2-e295fcba9d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-7bff6077-da1f-465a-928f-52ac7027958d,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-71f4d9a2-db13-48a0-b0d2-4ca5345c89c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-16b621e4-2598-48fb-80e7-d0bf7ca48a61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874443307-172.17.0.21-1596895901804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-6dfe653b-a014-42c5-8284-97188b412a03,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-eef7d786-8648-48f8-98fc-4ccf4183e722,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-60efe027-0328-4192-b2c5-262c8e8ed312,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-589a2160-2b8b-4ca2-a2aa-a59b8aa88390,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-b6dae48b-0bfa-4a04-adf2-e295fcba9d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-7bff6077-da1f-465a-928f-52ac7027958d,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-71f4d9a2-db13-48a0-b0d2-4ca5345c89c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-16b621e4-2598-48fb-80e7-d0bf7ca48a61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401079731-172.17.0.21-1596896063219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-c461fb2f-8bfc-46c8-aba3-1ce2667b1820,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-9113bfb4-9aef-45e5-bcb8-0c0c1f808e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-5cb296bb-3a0a-4963-bba3-a8ee4fcefbec,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-3bc45bc3-cff7-49a0-8aa8-80ff9fc2b443,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-b73345ee-7bd6-4a8f-9610-211a3a6ecef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-f03e9c1b-9af0-4ecf-ae16-4c5b0363cc01,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-578d53be-9b6c-421b-86d9-c1d4c80af2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-458f53bc-6772-42c6-90ea-7e75ef526f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401079731-172.17.0.21-1596896063219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-c461fb2f-8bfc-46c8-aba3-1ce2667b1820,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-9113bfb4-9aef-45e5-bcb8-0c0c1f808e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-5cb296bb-3a0a-4963-bba3-a8ee4fcefbec,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-3bc45bc3-cff7-49a0-8aa8-80ff9fc2b443,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-b73345ee-7bd6-4a8f-9610-211a3a6ecef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-f03e9c1b-9af0-4ecf-ae16-4c5b0363cc01,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-578d53be-9b6c-421b-86d9-c1d4c80af2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-458f53bc-6772-42c6-90ea-7e75ef526f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483978542-172.17.0.21-1596896373331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43529,DS-97cbc939-3ba8-4792-8d0f-2861279fd039,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-25491ce9-98ac-4d93-a088-fa66894359b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-abb57a23-1ca9-4e94-a149-e373f7b6f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-a89879bc-85a3-45e3-bbbf-ced1d96e58e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-dfe19bcb-1a33-4083-b31c-3dbff3581b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-a2a2200a-0634-44af-a192-c40ecb37d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-434efaf9-424d-4cce-9ecf-baefe30fecce,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-675df37e-d503-4d2f-adb7-d05d2a64d8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483978542-172.17.0.21-1596896373331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43529,DS-97cbc939-3ba8-4792-8d0f-2861279fd039,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-25491ce9-98ac-4d93-a088-fa66894359b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-abb57a23-1ca9-4e94-a149-e373f7b6f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-a89879bc-85a3-45e3-bbbf-ced1d96e58e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-dfe19bcb-1a33-4083-b31c-3dbff3581b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-a2a2200a-0634-44af-a192-c40ecb37d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-434efaf9-424d-4cce-9ecf-baefe30fecce,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-675df37e-d503-4d2f-adb7-d05d2a64d8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422211450-172.17.0.21-1596897786837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-8cf213d8-072a-423a-b859-bca2a8eaca99,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-ca2a0e10-56a7-407b-9b55-bca6e64240d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-40289db7-0a3f-4e7e-80b8-5830520adf28,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-6a73d65d-8af2-4a11-8860-333ce19211dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-39caefd1-570c-42f6-8671-4027137835c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-2a1e97f1-0f47-408c-962f-191b13c6991b,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7a6afdc0-32df-4e45-be84-957f152c0520,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-a468b9d8-7b3c-48be-be5d-55282eb9d5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422211450-172.17.0.21-1596897786837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-8cf213d8-072a-423a-b859-bca2a8eaca99,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-ca2a0e10-56a7-407b-9b55-bca6e64240d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-40289db7-0a3f-4e7e-80b8-5830520adf28,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-6a73d65d-8af2-4a11-8860-333ce19211dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-39caefd1-570c-42f6-8671-4027137835c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-2a1e97f1-0f47-408c-962f-191b13c6991b,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7a6afdc0-32df-4e45-be84-957f152c0520,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-a468b9d8-7b3c-48be-be5d-55282eb9d5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18441075-172.17.0.21-1596898471500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-b5bcad5a-621d-4d97-9b57-020e0b8e9b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-246654ad-f847-4d3e-b927-885df1e85059,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-55a712eb-9175-418b-9465-b8746a2dc293,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-b590a3cd-d6dc-4e5c-82dd-6a3af4a2c4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-af14b294-7bd6-4961-899b-bd99314f0cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-9a6fe1c7-ba6f-49db-a036-e964a4bc2873,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-bb70c44e-ab59-4a99-aefe-cb9a5d1ef41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-e96e2eb1-98a7-4cee-aa49-de7ac92dcdcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18441075-172.17.0.21-1596898471500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-b5bcad5a-621d-4d97-9b57-020e0b8e9b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-246654ad-f847-4d3e-b927-885df1e85059,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-55a712eb-9175-418b-9465-b8746a2dc293,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-b590a3cd-d6dc-4e5c-82dd-6a3af4a2c4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-af14b294-7bd6-4961-899b-bd99314f0cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-9a6fe1c7-ba6f-49db-a036-e964a4bc2873,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-bb70c44e-ab59-4a99-aefe-cb9a5d1ef41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-e96e2eb1-98a7-4cee-aa49-de7ac92dcdcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153935585-172.17.0.21-1596898904345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-18ceb88f-7e56-471d-9a1c-918cd58a601e,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-e7d7c38c-1760-4a34-b03a-ccd9f6066503,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-80fbff50-2de2-4d94-a99a-01da3aca7df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-4e074fe9-beb9-47b7-a365-06ef5e7a022c,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-f22b91e5-b5b5-4e23-a6ff-fdd4818ec9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-5d27a0d9-7554-4e10-8719-038e67dc38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-861a8427-08d8-4185-8151-d57909bf6ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5a242cb2-c36a-4094-ac07-449ccd995148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153935585-172.17.0.21-1596898904345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-18ceb88f-7e56-471d-9a1c-918cd58a601e,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-e7d7c38c-1760-4a34-b03a-ccd9f6066503,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-80fbff50-2de2-4d94-a99a-01da3aca7df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-4e074fe9-beb9-47b7-a365-06ef5e7a022c,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-f22b91e5-b5b5-4e23-a6ff-fdd4818ec9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-5d27a0d9-7554-4e10-8719-038e67dc38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-861a8427-08d8-4185-8151-d57909bf6ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5a242cb2-c36a-4094-ac07-449ccd995148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461588899-172.17.0.21-1596899002802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-577b8f49-31f2-4547-92b6-1e1e99a7b3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-c75c0012-7859-42cb-a7ea-67b1a738308f,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-9989e53f-f3e3-44b9-a230-66a7cdf97dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-d0e89033-fb91-4b7e-8453-821a7416c453,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-54eef7c6-2865-48cf-bb36-350c7dffe295,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-4482bd5e-4e85-433e-a6bc-3ac1404f2212,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-a7c4dc3b-2d1a-49f7-b069-a88e43e9425c,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-7792afc3-594b-47fa-b5b2-560871d98c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461588899-172.17.0.21-1596899002802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-577b8f49-31f2-4547-92b6-1e1e99a7b3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-c75c0012-7859-42cb-a7ea-67b1a738308f,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-9989e53f-f3e3-44b9-a230-66a7cdf97dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-d0e89033-fb91-4b7e-8453-821a7416c453,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-54eef7c6-2865-48cf-bb36-350c7dffe295,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-4482bd5e-4e85-433e-a6bc-3ac1404f2212,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-a7c4dc3b-2d1a-49f7-b069-a88e43e9425c,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-7792afc3-594b-47fa-b5b2-560871d98c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858999536-172.17.0.21-1596899309435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-8af536d9-d843-479c-a73b-fbf685ab9ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-10ae6d1c-91e9-42f3-918c-a37599708c78,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-0a46ad16-4ed5-4ed7-a9a4-25c0d49d2b60,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-e93671c1-d59a-4899-9ddd-d7903b485a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-98b3a56e-146e-4987-a59f-0d87c4cb6826,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-c786275b-7fd4-4ba6-b778-8e0254f14b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-c32fba1b-4121-47bb-aa3e-c45e93682f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-e951a2ed-373b-428c-b4d6-1e1d0f65db3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858999536-172.17.0.21-1596899309435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-8af536d9-d843-479c-a73b-fbf685ab9ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-10ae6d1c-91e9-42f3-918c-a37599708c78,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-0a46ad16-4ed5-4ed7-a9a4-25c0d49d2b60,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-e93671c1-d59a-4899-9ddd-d7903b485a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-98b3a56e-146e-4987-a59f-0d87c4cb6826,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-c786275b-7fd4-4ba6-b778-8e0254f14b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-c32fba1b-4121-47bb-aa3e-c45e93682f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-e951a2ed-373b-428c-b4d6-1e1d0f65db3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629410438-172.17.0.21-1596899496065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35568,DS-5d560e15-7c78-4285-ad1c-a451d0e6c728,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-73c03d8e-83af-410d-83e4-f58c6828a146,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-690f27b0-fec5-4d3d-b57e-c58eb14813dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-0c65fa52-84aa-4c88-bca7-f4ccae00d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-51345683-c82a-4c10-8cd1-1554997df9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-68f5bc51-09d6-46da-aabc-ebb9310a2ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-3598377a-5e0c-49a3-80f8-1788aa5b8937,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-690c7eae-ee83-45dc-aba8-b811c46190ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629410438-172.17.0.21-1596899496065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35568,DS-5d560e15-7c78-4285-ad1c-a451d0e6c728,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-73c03d8e-83af-410d-83e4-f58c6828a146,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-690f27b0-fec5-4d3d-b57e-c58eb14813dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-0c65fa52-84aa-4c88-bca7-f4ccae00d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-51345683-c82a-4c10-8cd1-1554997df9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-68f5bc51-09d6-46da-aabc-ebb9310a2ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-3598377a-5e0c-49a3-80f8-1788aa5b8937,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-690c7eae-ee83-45dc-aba8-b811c46190ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 0 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: v1v2 failure didn't occur
Total execution time in seconds : 5180
