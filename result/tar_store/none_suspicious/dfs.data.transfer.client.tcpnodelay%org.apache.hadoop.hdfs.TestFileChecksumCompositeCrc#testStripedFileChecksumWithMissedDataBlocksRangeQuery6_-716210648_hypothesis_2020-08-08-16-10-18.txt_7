reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699246240-172.17.0.9-1596903100162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-0d1df1e5-4b7c-427d-9c9d-d7b5aee967ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-e917fab7-6eba-4e10-a39f-8ccee6738a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-4e83df62-c0aa-41f4-a2d7-ce8e389960cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-2a6f7e46-a829-46e8-bb12-63e4642eda5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-69f04c73-2c5f-47b9-be2d-d3eb34048229,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-97aa8a72-286a-4b07-8f03-53cd72204ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-3b38792e-3ae7-48b0-a6aa-9f37bd70f695,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-5ccb94ab-9455-4444-9c2f-8ffbea1f3b0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699246240-172.17.0.9-1596903100162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-0d1df1e5-4b7c-427d-9c9d-d7b5aee967ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-e917fab7-6eba-4e10-a39f-8ccee6738a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-4e83df62-c0aa-41f4-a2d7-ce8e389960cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-2a6f7e46-a829-46e8-bb12-63e4642eda5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-69f04c73-2c5f-47b9-be2d-d3eb34048229,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-97aa8a72-286a-4b07-8f03-53cd72204ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-3b38792e-3ae7-48b0-a6aa-9f37bd70f695,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-5ccb94ab-9455-4444-9c2f-8ffbea1f3b0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520642485-172.17.0.9-1596903165954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-dd3bba95-670d-42da-9cc7-ee8bf725f5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-de9e73d5-e55d-49a1-9fbe-6af879191f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-0da816c8-e84c-4754-bd88-af0cb0101e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-af518448-cc3b-4998-873f-257130c792ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-6a2086cc-e31b-4ec7-baf9-14668c119986,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-86e59bbb-b5b6-4ee2-acef-43197e75de98,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-c0c435b5-3b92-45b5-b550-d24cac086fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-53140915-5422-4629-a915-4c7104657701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520642485-172.17.0.9-1596903165954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-dd3bba95-670d-42da-9cc7-ee8bf725f5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-de9e73d5-e55d-49a1-9fbe-6af879191f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-0da816c8-e84c-4754-bd88-af0cb0101e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-af518448-cc3b-4998-873f-257130c792ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-6a2086cc-e31b-4ec7-baf9-14668c119986,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-86e59bbb-b5b6-4ee2-acef-43197e75de98,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-c0c435b5-3b92-45b5-b550-d24cac086fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-53140915-5422-4629-a915-4c7104657701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854655486-172.17.0.9-1596903331827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-7d4bed7b-f8a1-48b7-b103-43ffc79933ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-6b5bc3b9-184e-42f8-b2cc-4fa45bc07b15,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-f16e4c09-ca50-4599-a85c-87a04c21fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-937a12e4-9650-4760-b7a9-ef5e267a6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-dd7d280b-91b7-4c6a-9a90-7d17feb8fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-b9b54a34-13e2-40c9-a74e-9684d1663b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-2469b223-838f-486b-9e86-a022232b78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-690ef2c1-35c5-43f9-acb6-36052d9787b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854655486-172.17.0.9-1596903331827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-7d4bed7b-f8a1-48b7-b103-43ffc79933ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-6b5bc3b9-184e-42f8-b2cc-4fa45bc07b15,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-f16e4c09-ca50-4599-a85c-87a04c21fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-937a12e4-9650-4760-b7a9-ef5e267a6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-dd7d280b-91b7-4c6a-9a90-7d17feb8fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-b9b54a34-13e2-40c9-a74e-9684d1663b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-2469b223-838f-486b-9e86-a022232b78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-690ef2c1-35c5-43f9-acb6-36052d9787b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581636682-172.17.0.9-1596903576967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-e18c5d58-5774-4652-a7a5-abcedaf5f630,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-16032c4c-23c2-4360-bbdf-3f3eeac3c0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-cd72ad90-96cc-431d-9edd-f668fb82c8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-f1cb4064-7774-48ce-a557-5f1a12c32937,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-2e1cd2c4-3c75-45ad-85df-78b17b2c178e,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-2ffd625b-8d6d-4ad0-873a-e8c8d2067333,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-b77e9326-635c-4119-96aa-a037c3faf6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-36a117fc-84da-45ad-84ab-9874e30a9c29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581636682-172.17.0.9-1596903576967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-e18c5d58-5774-4652-a7a5-abcedaf5f630,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-16032c4c-23c2-4360-bbdf-3f3eeac3c0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-cd72ad90-96cc-431d-9edd-f668fb82c8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-f1cb4064-7774-48ce-a557-5f1a12c32937,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-2e1cd2c4-3c75-45ad-85df-78b17b2c178e,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-2ffd625b-8d6d-4ad0-873a-e8c8d2067333,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-b77e9326-635c-4119-96aa-a037c3faf6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-36a117fc-84da-45ad-84ab-9874e30a9c29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260774758-172.17.0.9-1596903647518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-f6a1a201-2c5e-4266-b665-78dfef9373a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-1a23529c-b8b5-4d0d-b9bb-07d2f6eee59c,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-4b887fbc-bdc8-4ab9-aa19-3d0f23e3b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-0985fb05-cd10-4009-8813-e4eea369f974,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-e2a61aaf-a4f5-4d92-8bcf-2e1a841fa435,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-3af6384b-a25a-4c1f-bc35-142c04e75d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-7294cd41-b4a2-45ec-9fdd-254dd8055e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-de74196d-3a99-40d9-b50b-b765091140f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260774758-172.17.0.9-1596903647518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-f6a1a201-2c5e-4266-b665-78dfef9373a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-1a23529c-b8b5-4d0d-b9bb-07d2f6eee59c,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-4b887fbc-bdc8-4ab9-aa19-3d0f23e3b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-0985fb05-cd10-4009-8813-e4eea369f974,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-e2a61aaf-a4f5-4d92-8bcf-2e1a841fa435,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-3af6384b-a25a-4c1f-bc35-142c04e75d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-7294cd41-b4a2-45ec-9fdd-254dd8055e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-de74196d-3a99-40d9-b50b-b765091140f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254762307-172.17.0.9-1596903728120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-c2e7f2ce-7487-4a79-a55e-fbe13107582f,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-ca934aa2-d03a-47c8-b4c9-74c46ae55ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-9411b7c4-def3-4a87-9721-e97b8f8e674d,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-4e60aeac-6b21-47c2-9e93-317bdfdc6822,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-56bdb697-2972-41bd-8ff6-ae45a8ed790d,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-3815807d-6619-4ba2-9074-96ea02bda684,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-fee2910e-9472-4f41-a9a1-762f78e8e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-6c22bffe-d249-4c52-9335-a4b769c38106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254762307-172.17.0.9-1596903728120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-c2e7f2ce-7487-4a79-a55e-fbe13107582f,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-ca934aa2-d03a-47c8-b4c9-74c46ae55ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-9411b7c4-def3-4a87-9721-e97b8f8e674d,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-4e60aeac-6b21-47c2-9e93-317bdfdc6822,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-56bdb697-2972-41bd-8ff6-ae45a8ed790d,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-3815807d-6619-4ba2-9074-96ea02bda684,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-fee2910e-9472-4f41-a9a1-762f78e8e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-6c22bffe-d249-4c52-9335-a4b769c38106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595722774-172.17.0.9-1596903768774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-6b054460-932d-4ec6-b247-f1476bcbcd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-e1227f9b-5728-4321-a4da-b5d1634ea634,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-81778ec4-a9cb-4100-aabe-d46770cc541e,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-7da235be-fcf3-4b5c-b93e-f510dc068ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-c6e5b44c-dfe9-4369-ad70-41f26136738c,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-7a6fbeac-c210-4994-bf62-a795fc367f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-2ed40168-2a12-4b7d-ad04-07e98b73250d,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-a393379b-ccd6-497d-8067-59fc4e6dc80e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595722774-172.17.0.9-1596903768774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-6b054460-932d-4ec6-b247-f1476bcbcd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-e1227f9b-5728-4321-a4da-b5d1634ea634,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-81778ec4-a9cb-4100-aabe-d46770cc541e,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-7da235be-fcf3-4b5c-b93e-f510dc068ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-c6e5b44c-dfe9-4369-ad70-41f26136738c,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-7a6fbeac-c210-4994-bf62-a795fc367f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-2ed40168-2a12-4b7d-ad04-07e98b73250d,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-a393379b-ccd6-497d-8067-59fc4e6dc80e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265880734-172.17.0.9-1596903805610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37790,DS-31fc310e-1a62-42f0-9b23-705a638de135,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-19653c48-4e62-441a-9a37-6ca03ee8e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-dcfffb07-aca3-49aa-aa0e-f31d401deefd,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-b00eacd1-fb5b-46bd-9881-41e10a939be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-b2d10037-3cbd-4d18-8a4d-12431a4082d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-be068f79-f101-442f-bf95-0d3e5878a568,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-0aef3854-6ccf-4a45-8e30-e21a9d6c3adc,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-5e57885b-1dc9-49a9-b942-bc2f24970365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265880734-172.17.0.9-1596903805610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37790,DS-31fc310e-1a62-42f0-9b23-705a638de135,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-19653c48-4e62-441a-9a37-6ca03ee8e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-dcfffb07-aca3-49aa-aa0e-f31d401deefd,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-b00eacd1-fb5b-46bd-9881-41e10a939be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-b2d10037-3cbd-4d18-8a4d-12431a4082d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-be068f79-f101-442f-bf95-0d3e5878a568,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-0aef3854-6ccf-4a45-8e30-e21a9d6c3adc,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-5e57885b-1dc9-49a9-b942-bc2f24970365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204768368-172.17.0.9-1596903838332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-7c30a2b0-29e6-4a6c-a328-c446df9d9fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-c43f3d6b-7568-4b7b-9917-f543c0ff31c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-7df4b295-f366-4c2f-ba03-b5c4c7957c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-61f9aebe-af62-4f49-ac16-2cd91aabe22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-45c4c2f6-ff3b-4261-ad30-598e16cd574c,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-48ed421d-568a-44ed-a3a8-2525c5050215,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-72080e82-8215-400f-a0c3-5d342086dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-a2089ff5-e08e-461f-8cc7-b7144e871b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204768368-172.17.0.9-1596903838332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-7c30a2b0-29e6-4a6c-a328-c446df9d9fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-c43f3d6b-7568-4b7b-9917-f543c0ff31c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-7df4b295-f366-4c2f-ba03-b5c4c7957c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-61f9aebe-af62-4f49-ac16-2cd91aabe22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-45c4c2f6-ff3b-4261-ad30-598e16cd574c,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-48ed421d-568a-44ed-a3a8-2525c5050215,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-72080e82-8215-400f-a0c3-5d342086dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-a2089ff5-e08e-461f-8cc7-b7144e871b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498743171-172.17.0.9-1596904052677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-91400951-c8f8-4c23-8cfc-b5c9e1de74c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-fdffe575-f3c5-400f-aa5a-8fa67ea74b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-8abaf7a3-c8ed-4e46-adbd-2d4c87f4d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-a49c66ab-19e7-4734-a361-a339195640d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-25d91fd3-3334-4706-8cd3-4429eafb0f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-14a8a6f3-8612-446f-aac0-20965fbf142c,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-407a3ab8-a258-4ad3-82bd-fef7b09febfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-e2ef597a-e000-46fd-9f97-c9ddf3c05d13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498743171-172.17.0.9-1596904052677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-91400951-c8f8-4c23-8cfc-b5c9e1de74c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-fdffe575-f3c5-400f-aa5a-8fa67ea74b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-8abaf7a3-c8ed-4e46-adbd-2d4c87f4d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-a49c66ab-19e7-4734-a361-a339195640d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-25d91fd3-3334-4706-8cd3-4429eafb0f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-14a8a6f3-8612-446f-aac0-20965fbf142c,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-407a3ab8-a258-4ad3-82bd-fef7b09febfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-e2ef597a-e000-46fd-9f97-c9ddf3c05d13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612415263-172.17.0.9-1596904124430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-3eb9ea90-5509-4e90-a004-f6f1e2309d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-7288fed2-570b-458b-8095-b93192633279,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-4e307c38-e69a-4a3b-ab44-b38a4a3e0e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-a73d32e2-c87d-40b5-8576-fd3b2f20d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-90b3e4a0-8ab3-4fe5-b611-b263ac08a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-9c144210-a364-4574-846c-36d0e0d869e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-6faabc08-f22a-44b5-af66-74eb64e0214c,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-a506b342-6977-46ee-bcb2-4b4a81b580c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612415263-172.17.0.9-1596904124430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-3eb9ea90-5509-4e90-a004-f6f1e2309d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-7288fed2-570b-458b-8095-b93192633279,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-4e307c38-e69a-4a3b-ab44-b38a4a3e0e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-a73d32e2-c87d-40b5-8576-fd3b2f20d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-90b3e4a0-8ab3-4fe5-b611-b263ac08a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-9c144210-a364-4574-846c-36d0e0d869e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-6faabc08-f22a-44b5-af66-74eb64e0214c,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-a506b342-6977-46ee-bcb2-4b4a81b580c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907740544-172.17.0.9-1596904785345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-4b5b7fc3-0b52-45ba-a939-8bc61d5b0116,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-ce60d2cf-1f1f-4c96-b51e-3d6318b97b12,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-5ed5c32d-50a8-4ab8-ad8c-cbd04374d735,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-1338e36d-f0da-4aa9-9900-c1b24f53b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-081fbf86-5a65-4e7b-a43f-81b6b4874b40,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-0daee6f5-bb0c-4db2-b463-72a3d3d9c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-3699836e-6e98-437f-a30c-a3f56f0577d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-2f38cb49-fec4-4d04-a2bd-50dc069b26ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907740544-172.17.0.9-1596904785345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-4b5b7fc3-0b52-45ba-a939-8bc61d5b0116,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-ce60d2cf-1f1f-4c96-b51e-3d6318b97b12,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-5ed5c32d-50a8-4ab8-ad8c-cbd04374d735,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-1338e36d-f0da-4aa9-9900-c1b24f53b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-081fbf86-5a65-4e7b-a43f-81b6b4874b40,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-0daee6f5-bb0c-4db2-b463-72a3d3d9c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-3699836e-6e98-437f-a30c-a3f56f0577d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-2f38cb49-fec4-4d04-a2bd-50dc069b26ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475667347-172.17.0.9-1596904916972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-19fb9c11-9b10-44f0-bef2-75217194330b,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-e4ae2ca0-a7ce-4dc5-82b2-3bdaa04b81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-b1e79281-5c8f-4760-b255-bede3eb31ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-f47c4de9-ba03-44c2-84d2-579ae7c4a06b,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-e19872fa-14df-4ac7-b0a3-4b678486a656,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-9203fd1d-089c-4380-81f4-5e48e9f3db83,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-a4409cb5-b84c-4085-b466-0a040eba4618,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-d9334207-79be-4b99-82ea-495be3ffc0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475667347-172.17.0.9-1596904916972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-19fb9c11-9b10-44f0-bef2-75217194330b,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-e4ae2ca0-a7ce-4dc5-82b2-3bdaa04b81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-b1e79281-5c8f-4760-b255-bede3eb31ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-f47c4de9-ba03-44c2-84d2-579ae7c4a06b,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-e19872fa-14df-4ac7-b0a3-4b678486a656,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-9203fd1d-089c-4380-81f4-5e48e9f3db83,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-a4409cb5-b84c-4085-b466-0a040eba4618,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-d9334207-79be-4b99-82ea-495be3ffc0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489384493-172.17.0.9-1596905738203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-c39ec11f-2200-46c4-932d-34a58f397b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-2d030177-e1fb-405c-bceb-eaaca72a9f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-04bcb4e4-2522-4e85-9b65-cf42e0f47ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-81eaeebc-329b-4920-993c-e7258f623a52,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-26493ef5-6e3f-4b84-b326-92e7835bf1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-273deaac-1def-4cfe-a86b-5f04950a89b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-7c21de7c-da31-45f9-b980-26e802890814,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-e29f0495-f9c3-4dda-a3e1-a9c097270e1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489384493-172.17.0.9-1596905738203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-c39ec11f-2200-46c4-932d-34a58f397b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-2d030177-e1fb-405c-bceb-eaaca72a9f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-04bcb4e4-2522-4e85-9b65-cf42e0f47ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-81eaeebc-329b-4920-993c-e7258f623a52,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-26493ef5-6e3f-4b84-b326-92e7835bf1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-273deaac-1def-4cfe-a86b-5f04950a89b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-7c21de7c-da31-45f9-b980-26e802890814,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-e29f0495-f9c3-4dda-a3e1-a9c097270e1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754783692-172.17.0.9-1596906288913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-0b560546-3847-4c9d-bc04-7892bd5006be,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-fc76e10b-3bd6-4c37-b477-c75f911f6799,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-b7f80bb2-b2a2-4ec0-a3e9-84b1f7db5c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-a794fff5-aaa6-49f5-8406-d278ba2baf07,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-b063c36d-3caa-457e-afc4-50c12936ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-d2df43b4-b206-4f46-9644-3a5dc6740f12,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-3409401c-ac13-46ba-b788-f160ac8e8626,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-9fd5fbb6-d499-42ff-809c-f11c1f961700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754783692-172.17.0.9-1596906288913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-0b560546-3847-4c9d-bc04-7892bd5006be,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-fc76e10b-3bd6-4c37-b477-c75f911f6799,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-b7f80bb2-b2a2-4ec0-a3e9-84b1f7db5c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-a794fff5-aaa6-49f5-8406-d278ba2baf07,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-b063c36d-3caa-457e-afc4-50c12936ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-d2df43b4-b206-4f46-9644-3a5dc6740f12,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-3409401c-ac13-46ba-b788-f160ac8e8626,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-9fd5fbb6-d499-42ff-809c-f11c1f961700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558918842-172.17.0.9-1596906355069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-89438970-9fd7-45b1-bcd0-e3bba96286a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-6d06f61d-b792-49e8-bc46-2f38dd838f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-b05ab86d-b34e-449f-b8d4-2f8520b4e179,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-ea2a7e4e-d42d-4288-8e6a-42ac69e19a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-1cdddd4e-d875-41ca-8490-85a5f2ca5a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-80e53985-f41b-4c88-b1bd-6aa7faead265,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-8c912155-970a-401f-a93f-b817a319910c,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e9b2bf55-1fcd-40ff-844d-9976309541cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558918842-172.17.0.9-1596906355069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-89438970-9fd7-45b1-bcd0-e3bba96286a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-6d06f61d-b792-49e8-bc46-2f38dd838f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-b05ab86d-b34e-449f-b8d4-2f8520b4e179,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-ea2a7e4e-d42d-4288-8e6a-42ac69e19a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-1cdddd4e-d875-41ca-8490-85a5f2ca5a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-80e53985-f41b-4c88-b1bd-6aa7faead265,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-8c912155-970a-401f-a93f-b817a319910c,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e9b2bf55-1fcd-40ff-844d-9976309541cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308049014-172.17.0.9-1596907119145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35646,DS-1d21730d-c263-42c0-90f9-5226e846953a,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-a1a79bee-695a-4d59-b262-4f70da1aeb05,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-d244ca4a-8f3b-44cb-92fb-e55d42398f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-75633ad1-0dd7-4933-b500-b39c9289f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-9972562e-6f8a-4ec1-b2d2-d55c334665d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-b050847d-f304-49b9-af8c-43a2c8ebf012,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-a95d0a2b-3f0c-429e-93f3-db522c818b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-1cce5d12-85ac-492a-8154-c53740ad641c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308049014-172.17.0.9-1596907119145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35646,DS-1d21730d-c263-42c0-90f9-5226e846953a,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-a1a79bee-695a-4d59-b262-4f70da1aeb05,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-d244ca4a-8f3b-44cb-92fb-e55d42398f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-75633ad1-0dd7-4933-b500-b39c9289f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-9972562e-6f8a-4ec1-b2d2-d55c334665d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-b050847d-f304-49b9-af8c-43a2c8ebf012,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-a95d0a2b-3f0c-429e-93f3-db522c818b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-1cce5d12-85ac-492a-8154-c53740ad641c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691458018-172.17.0.9-1596907193659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-cf8aed65-6db4-46c1-9f5d-ba97cfab6d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-5a94e19d-ab3a-4705-a789-db40d8527a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-c84f0112-9d23-4088-a0f0-cd8f24ca8826,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-2fbe8faa-ad99-4ad7-9409-d237ecb4ebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-0208b39a-388e-4efb-947f-b5e8c3297396,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e06d1ed4-9c54-4c72-8b5e-b4d05056ff75,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-fbdb9c27-2419-4a70-b4fa-9c9cd77be8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-7c7287ed-c59a-4bc2-ac91-249992d2a69c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691458018-172.17.0.9-1596907193659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-cf8aed65-6db4-46c1-9f5d-ba97cfab6d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-5a94e19d-ab3a-4705-a789-db40d8527a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-c84f0112-9d23-4088-a0f0-cd8f24ca8826,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-2fbe8faa-ad99-4ad7-9409-d237ecb4ebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-0208b39a-388e-4efb-947f-b5e8c3297396,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e06d1ed4-9c54-4c72-8b5e-b4d05056ff75,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-fbdb9c27-2419-4a70-b4fa-9c9cd77be8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-7c7287ed-c59a-4bc2-ac91-249992d2a69c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569816587-172.17.0.9-1596907467436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34614,DS-92020fc8-722f-422e-9d7a-9b168d924765,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-ff1f4529-c788-4ced-81d5-a978828937bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-6a3b413e-4fec-4529-ab7a-c2b24b96b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-610b1495-d979-43a0-805f-d92e2e61f475,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-521331fd-76c0-4ffb-b1b3-142f3ed4740a,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-a6c3292a-f548-45fd-adf1-7af2874d8442,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-18126612-32ee-42c6-91f7-7fe9bb6cb5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-becd030f-d5ab-4a52-933f-c19c032eed8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569816587-172.17.0.9-1596907467436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34614,DS-92020fc8-722f-422e-9d7a-9b168d924765,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-ff1f4529-c788-4ced-81d5-a978828937bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-6a3b413e-4fec-4529-ab7a-c2b24b96b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-610b1495-d979-43a0-805f-d92e2e61f475,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-521331fd-76c0-4ffb-b1b3-142f3ed4740a,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-a6c3292a-f548-45fd-adf1-7af2874d8442,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-18126612-32ee-42c6-91f7-7fe9bb6cb5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-becd030f-d5ab-4a52-933f-c19c032eed8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65009406-172.17.0.9-1596907717241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35312,DS-27693389-2639-4aa0-af94-cd2d91aad971,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-191ceae8-291e-4a97-9c1e-f82e209992a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-281bceb9-b041-4965-aa0c-d893aaff1a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-039f6d5c-8fee-403b-9dd8-b0b2c4731ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-443b078c-8b5b-4790-92d0-29647c910cac,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-b638e2b3-981d-43b9-bc08-54f5f4cc6981,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-f3fb51f3-3321-4f2f-98c9-7f0b9805000e,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-5d92124d-9772-4506-8bda-8c500d1608e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65009406-172.17.0.9-1596907717241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35312,DS-27693389-2639-4aa0-af94-cd2d91aad971,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-191ceae8-291e-4a97-9c1e-f82e209992a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-281bceb9-b041-4965-aa0c-d893aaff1a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-039f6d5c-8fee-403b-9dd8-b0b2c4731ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-443b078c-8b5b-4790-92d0-29647c910cac,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-b638e2b3-981d-43b9-bc08-54f5f4cc6981,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-f3fb51f3-3321-4f2f-98c9-7f0b9805000e,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-5d92124d-9772-4506-8bda-8c500d1608e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691546994-172.17.0.9-1596907820553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36596,DS-691b71b1-9051-4f91-b0cc-e76cf187b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-90c57750-c794-4d5d-bce1-5c25ac6d5fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-cf0702bd-7510-45e2-bd75-88077854f995,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-a79db3a9-4797-4a95-a64c-49381755f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-795213df-e437-406e-8646-a708036ff60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-23d6fe2a-5c9f-4e2c-ba5e-30404e219554,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-d30041e6-e202-4b05-957e-487a6c9a2eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-c6329700-dbfe-496f-b7ba-dad909632bd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691546994-172.17.0.9-1596907820553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36596,DS-691b71b1-9051-4f91-b0cc-e76cf187b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-90c57750-c794-4d5d-bce1-5c25ac6d5fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-cf0702bd-7510-45e2-bd75-88077854f995,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-a79db3a9-4797-4a95-a64c-49381755f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-795213df-e437-406e-8646-a708036ff60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-23d6fe2a-5c9f-4e2c-ba5e-30404e219554,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-d30041e6-e202-4b05-957e-487a6c9a2eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-c6329700-dbfe-496f-b7ba-dad909632bd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5188
