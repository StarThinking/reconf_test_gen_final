reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633792252-172.17.0.21-1596949143593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-e4ab2758-72af-45c4-aa06-0150bbb337d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-dd3bb555-9935-465b-bc2c-c8688cc40afe,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-3531dfe7-e633-4a66-b5f2-0e5977bfd0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-4d2d6b46-31f5-4059-a371-46ae5c43e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-c16465b4-c1d0-4a55-909f-a5d5d93d5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-c1a4b202-ad08-4ba6-b83d-080959ff69d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-d2687e6c-7ec0-4027-8ca4-53764cb03433,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-e86eb4c1-f77d-465d-ba72-21affbf831cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633792252-172.17.0.21-1596949143593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-e4ab2758-72af-45c4-aa06-0150bbb337d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-dd3bb555-9935-465b-bc2c-c8688cc40afe,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-3531dfe7-e633-4a66-b5f2-0e5977bfd0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-4d2d6b46-31f5-4059-a371-46ae5c43e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-c16465b4-c1d0-4a55-909f-a5d5d93d5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-c1a4b202-ad08-4ba6-b83d-080959ff69d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-d2687e6c-7ec0-4027-8ca4-53764cb03433,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-e86eb4c1-f77d-465d-ba72-21affbf831cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222835727-172.17.0.21-1596949239586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42599,DS-772c69c9-9023-4230-bd91-95bf934edcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-07881487-e907-4b7d-be85-2492c5673eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-cfe662ef-36c9-45c5-9af5-122d35abe905,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-aac81705-de80-4291-9390-da68a28cdd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-3951ce4a-9f47-4cd0-aefc-a4ec73f98f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-cb1562e9-5055-47cd-be86-2c1a263d284f,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-4dbe6b7d-6a0b-4f7f-a8e8-9e3b34ecbd01,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-527cbe54-12d3-4564-b3ee-3f7de0306bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222835727-172.17.0.21-1596949239586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42599,DS-772c69c9-9023-4230-bd91-95bf934edcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-07881487-e907-4b7d-be85-2492c5673eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-cfe662ef-36c9-45c5-9af5-122d35abe905,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-aac81705-de80-4291-9390-da68a28cdd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-3951ce4a-9f47-4cd0-aefc-a4ec73f98f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-cb1562e9-5055-47cd-be86-2c1a263d284f,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-4dbe6b7d-6a0b-4f7f-a8e8-9e3b34ecbd01,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-527cbe54-12d3-4564-b3ee-3f7de0306bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680072281-172.17.0.21-1596949503028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44489,DS-e0197e0b-09e4-4e2e-ad12-3134e0dc6bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-32272ece-968d-420c-9fbc-f75d4c7f12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-985f17fc-b5fe-4555-9b32-296084711032,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-c661c517-48da-4128-960f-30315ff21d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3d32881e-62e0-4d38-af09-b7e28ba276d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-0e965856-d131-4770-a4fc-c27461250d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-43b958b1-ebda-479f-aca3-c4df248a88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-5a2a0f24-a3e7-45f7-9342-cb99edab1044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680072281-172.17.0.21-1596949503028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44489,DS-e0197e0b-09e4-4e2e-ad12-3134e0dc6bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-32272ece-968d-420c-9fbc-f75d4c7f12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-985f17fc-b5fe-4555-9b32-296084711032,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-c661c517-48da-4128-960f-30315ff21d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3d32881e-62e0-4d38-af09-b7e28ba276d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-0e965856-d131-4770-a4fc-c27461250d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-43b958b1-ebda-479f-aca3-c4df248a88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-5a2a0f24-a3e7-45f7-9342-cb99edab1044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726417302-172.17.0.21-1596949657412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-9c95957b-daa0-443d-800b-e7c3e2a4972b,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-619de877-fdbf-4508-86f0-4e345225b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-b8656f7b-ad95-4d94-b4f4-aa0b6b8ebf02,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-3090cd5b-1b3f-4aa4-b8bd-8d3a117d2b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-3e5898b3-7b22-451c-9ae9-d095fa970efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-c55e8209-3068-437d-b699-b0f251af43bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-87a2b258-a0bd-4ec2-a6c2-b9bd5be90595,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-b6966491-4dee-4e52-b4c0-6348489822d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726417302-172.17.0.21-1596949657412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-9c95957b-daa0-443d-800b-e7c3e2a4972b,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-619de877-fdbf-4508-86f0-4e345225b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-b8656f7b-ad95-4d94-b4f4-aa0b6b8ebf02,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-3090cd5b-1b3f-4aa4-b8bd-8d3a117d2b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-3e5898b3-7b22-451c-9ae9-d095fa970efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-c55e8209-3068-437d-b699-b0f251af43bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-87a2b258-a0bd-4ec2-a6c2-b9bd5be90595,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-b6966491-4dee-4e52-b4c0-6348489822d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478372355-172.17.0.21-1596950184978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45552,DS-3ee7e6da-02db-4d60-bcc3-e74cedd9a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-b8b10d52-3845-441d-8c53-c16a15572dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-287be5c8-8edb-4b31-bc65-886eb427da23,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-338089fc-fee5-405b-b330-452cd0bdc92c,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-49328289-7ce1-4548-9c5f-6aa471ebe57c,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-e8b641b4-2ed9-43de-aebc-1f1d83a77c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-a7b440d9-ccc3-40b4-9a44-d931b367d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-2cf85efb-b7f7-4e46-ac40-f92ce53d33e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478372355-172.17.0.21-1596950184978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45552,DS-3ee7e6da-02db-4d60-bcc3-e74cedd9a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-b8b10d52-3845-441d-8c53-c16a15572dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-287be5c8-8edb-4b31-bc65-886eb427da23,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-338089fc-fee5-405b-b330-452cd0bdc92c,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-49328289-7ce1-4548-9c5f-6aa471ebe57c,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-e8b641b4-2ed9-43de-aebc-1f1d83a77c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-a7b440d9-ccc3-40b4-9a44-d931b367d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-2cf85efb-b7f7-4e46-ac40-f92ce53d33e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642859050-172.17.0.21-1596950529342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-33d0585f-9a3d-4daf-bdb6-d24d50fd9402,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-7329cf6f-0b7e-4759-b378-27c064468941,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-f5029e78-cf45-4407-aefa-fd432801b335,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-3d634837-24d9-45e3-a287-ccd015ae2b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-3f7f4f6e-b5c0-4c64-9c60-f14dae084614,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-990ae649-baf4-44e9-8331-23ba9fb0ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-cb51cac1-b5c4-4e30-ba01-553babac6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-0f394934-b056-49c8-9442-29d6d6f23f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642859050-172.17.0.21-1596950529342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-33d0585f-9a3d-4daf-bdb6-d24d50fd9402,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-7329cf6f-0b7e-4759-b378-27c064468941,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-f5029e78-cf45-4407-aefa-fd432801b335,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-3d634837-24d9-45e3-a287-ccd015ae2b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-3f7f4f6e-b5c0-4c64-9c60-f14dae084614,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-990ae649-baf4-44e9-8331-23ba9fb0ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-cb51cac1-b5c4-4e30-ba01-553babac6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-0f394934-b056-49c8-9442-29d6d6f23f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-609317212-172.17.0.21-1596950704357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-d8072312-0df8-4ab1-9eed-9301a4a30c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-16a5e3b8-0c03-4c01-9def-dc432e9c85bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-56ca13bf-26c5-4e20-8a0c-5118dff7417c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-8bb3c3b9-3267-435b-9c34-4cc2327b1501,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-e4b9e329-9184-4794-ba98-0ceac3b859d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-6c77de0c-4c17-4d0d-9b0d-32961382d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-c5ffc86f-bc25-4525-8f50-ab28af3e3deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-8500209e-e4aa-460d-91dd-b98d61fc16d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-609317212-172.17.0.21-1596950704357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-d8072312-0df8-4ab1-9eed-9301a4a30c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-16a5e3b8-0c03-4c01-9def-dc432e9c85bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-56ca13bf-26c5-4e20-8a0c-5118dff7417c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-8bb3c3b9-3267-435b-9c34-4cc2327b1501,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-e4b9e329-9184-4794-ba98-0ceac3b859d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-6c77de0c-4c17-4d0d-9b0d-32961382d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-c5ffc86f-bc25-4525-8f50-ab28af3e3deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-8500209e-e4aa-460d-91dd-b98d61fc16d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168525545-172.17.0.21-1596950835803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-0c3119a0-5f6f-4764-82ec-18006fdd5712,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-68f2e0f0-f4cd-4845-8025-c869cb931c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-ff0d4739-00f6-4b53-b622-8c0262dca0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-fb7ab2ee-4b23-450e-bc76-669f978086c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-96ce6037-d233-4960-abd7-34f3fa13cb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-77ad930b-01c5-446e-9df4-7758542a2c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-75054176-3595-45e6-8d4a-3ad9c3feb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-e69eb708-a24a-4919-bb9e-b54e7b8327a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168525545-172.17.0.21-1596950835803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-0c3119a0-5f6f-4764-82ec-18006fdd5712,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-68f2e0f0-f4cd-4845-8025-c869cb931c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-ff0d4739-00f6-4b53-b622-8c0262dca0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-fb7ab2ee-4b23-450e-bc76-669f978086c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-96ce6037-d233-4960-abd7-34f3fa13cb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-77ad930b-01c5-446e-9df4-7758542a2c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-75054176-3595-45e6-8d4a-3ad9c3feb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-e69eb708-a24a-4919-bb9e-b54e7b8327a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701784251-172.17.0.21-1596951022860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-38b0a1e0-2337-49d4-8de0-633e027452fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-a4c8b088-0c85-474e-ae30-c063ebc50bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-fafe2ec3-abe5-46f4-a7f3-5552e0fed041,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-8d1d7fd6-1a71-4b40-970f-92882bbba3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-0654ef4a-bad2-43ca-9087-4b89c52c1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-88a7700f-dff2-467e-a81e-8fff598a6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-462c8cf9-fc84-4f25-ae8d-a0ab3d377f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-c3e416d4-735d-447a-b9e3-ac8b76b9db55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701784251-172.17.0.21-1596951022860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-38b0a1e0-2337-49d4-8de0-633e027452fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-a4c8b088-0c85-474e-ae30-c063ebc50bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-fafe2ec3-abe5-46f4-a7f3-5552e0fed041,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-8d1d7fd6-1a71-4b40-970f-92882bbba3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-0654ef4a-bad2-43ca-9087-4b89c52c1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-88a7700f-dff2-467e-a81e-8fff598a6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-462c8cf9-fc84-4f25-ae8d-a0ab3d377f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-c3e416d4-735d-447a-b9e3-ac8b76b9db55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505427161-172.17.0.21-1596951087389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-80068b2e-a75c-45c0-898e-e4e66c3061fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-75db92e9-3ab0-44a2-b469-025fadb77473,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-0cb819d8-0605-47be-9e56-a68dc1891eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-b778e0bc-7a60-4829-bbc0-37d6788e4930,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-835b949a-eec0-418a-ab2e-5a5d1d9ae64f,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-9825fd36-795a-49f1-8b98-5e634f0ea89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-7b2a4bb0-f403-4201-a615-e1529adeb024,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-cd57d569-168c-4e4f-96f8-3f6454db5b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505427161-172.17.0.21-1596951087389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-80068b2e-a75c-45c0-898e-e4e66c3061fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-75db92e9-3ab0-44a2-b469-025fadb77473,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-0cb819d8-0605-47be-9e56-a68dc1891eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-b778e0bc-7a60-4829-bbc0-37d6788e4930,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-835b949a-eec0-418a-ab2e-5a5d1d9ae64f,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-9825fd36-795a-49f1-8b98-5e634f0ea89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-7b2a4bb0-f403-4201-a615-e1529adeb024,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-cd57d569-168c-4e4f-96f8-3f6454db5b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406360119-172.17.0.21-1596951121560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41509,DS-0b1fbb07-d8db-45bc-b199-d549cbc1bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-d984d187-5f99-4866-a00e-d51b17575ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-5de8ca16-a8ac-46ad-a41d-06c51f31a6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-ffae4be0-538c-4c36-b79a-cacb91d1f73f,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-a96f0f43-9503-4a32-a218-eff58f9339d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-2726dd17-5c23-4fc9-b812-869294db47e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-1274a78f-60f7-40cd-a567-408412698316,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-d252909c-9ffb-4547-9b33-29e931e8a03a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406360119-172.17.0.21-1596951121560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41509,DS-0b1fbb07-d8db-45bc-b199-d549cbc1bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-d984d187-5f99-4866-a00e-d51b17575ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-5de8ca16-a8ac-46ad-a41d-06c51f31a6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-ffae4be0-538c-4c36-b79a-cacb91d1f73f,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-a96f0f43-9503-4a32-a218-eff58f9339d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-2726dd17-5c23-4fc9-b812-869294db47e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-1274a78f-60f7-40cd-a567-408412698316,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-d252909c-9ffb-4547-9b33-29e931e8a03a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882601692-172.17.0.21-1596951183804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-9b2f9e29-c302-4b3a-aa61-046c689d6a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-4abecc74-3bcd-41c8-bcf5-19a81225272d,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-bfd26d41-d9f2-4537-9fe5-fa19911b5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-90f5bf33-1f8a-4b5d-9efa-da7bf3a87b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-78b23c3d-9a15-43e0-8144-9e28a9818a31,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-a3aedcd2-b7ab-43a3-bb5a-150799c52976,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-5c203365-b9a8-4759-aa28-ff0ffa8017e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-91dfb0cb-b19b-42f3-b240-851988f57ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882601692-172.17.0.21-1596951183804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-9b2f9e29-c302-4b3a-aa61-046c689d6a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-4abecc74-3bcd-41c8-bcf5-19a81225272d,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-bfd26d41-d9f2-4537-9fe5-fa19911b5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-90f5bf33-1f8a-4b5d-9efa-da7bf3a87b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-78b23c3d-9a15-43e0-8144-9e28a9818a31,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-a3aedcd2-b7ab-43a3-bb5a-150799c52976,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-5c203365-b9a8-4759-aa28-ff0ffa8017e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-91dfb0cb-b19b-42f3-b240-851988f57ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826563385-172.17.0.21-1596951905257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-877d18cd-87ef-48a4-b64e-0fffd3abc936,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-7026801e-460c-4d4f-827b-9ea13aa7091d,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-1560c375-a2e7-4b7d-beb8-dc15db224d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-fd842fbd-3acc-4a4d-a873-cf269d965d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-558ccc82-a342-45fe-9ed4-0bb8e6003c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-e784809d-984c-43ea-89a7-7a203a97b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-e74608ed-79c3-4d03-acc2-961da07a6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-843a0115-af43-411e-acb1-421884a6bee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826563385-172.17.0.21-1596951905257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-877d18cd-87ef-48a4-b64e-0fffd3abc936,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-7026801e-460c-4d4f-827b-9ea13aa7091d,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-1560c375-a2e7-4b7d-beb8-dc15db224d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-fd842fbd-3acc-4a4d-a873-cf269d965d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-558ccc82-a342-45fe-9ed4-0bb8e6003c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-e784809d-984c-43ea-89a7-7a203a97b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-e74608ed-79c3-4d03-acc2-961da07a6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-843a0115-af43-411e-acb1-421884a6bee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140978520-172.17.0.21-1596952461054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-99ae0d62-4f93-461c-96c0-bffb622da420,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-beb99da1-4207-40a9-9582-43e88887c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-9cd0ac10-d3d9-4969-bc51-b07bc68fa5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-411372f6-51b3-4ac1-b91c-c031bfda26f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-6614ecb6-bc97-4eb3-94eb-dbfdd1a9585c,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-6c1fb3bb-6320-45cc-a589-8729990d8413,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-9b58ecd8-b419-4488-92c1-8f6562f994f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-c49cf881-bb46-4484-800a-310a207fb662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140978520-172.17.0.21-1596952461054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-99ae0d62-4f93-461c-96c0-bffb622da420,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-beb99da1-4207-40a9-9582-43e88887c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-9cd0ac10-d3d9-4969-bc51-b07bc68fa5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-411372f6-51b3-4ac1-b91c-c031bfda26f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-6614ecb6-bc97-4eb3-94eb-dbfdd1a9585c,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-6c1fb3bb-6320-45cc-a589-8729990d8413,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-9b58ecd8-b419-4488-92c1-8f6562f994f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-c49cf881-bb46-4484-800a-310a207fb662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695140275-172.17.0.21-1596952837126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-6a34caeb-afb8-4a98-8dc1-055b5b16a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-5c892f40-4188-4f26-9a0b-45473c7dd64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-b515ee11-fde4-40b9-8881-dac19df6c6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-6779298f-10bc-407b-b5c6-3dda3b51f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-f55e282d-76ea-4586-b5fa-7cadb9c8fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-df8cf88b-23a4-412c-9b10-a7f9be80bc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-a4e3b861-b301-4880-a17a-f6533ad666ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-77d18da5-6802-41c2-9641-1e001857654d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695140275-172.17.0.21-1596952837126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-6a34caeb-afb8-4a98-8dc1-055b5b16a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-5c892f40-4188-4f26-9a0b-45473c7dd64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-b515ee11-fde4-40b9-8881-dac19df6c6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-6779298f-10bc-407b-b5c6-3dda3b51f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-f55e282d-76ea-4586-b5fa-7cadb9c8fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-df8cf88b-23a4-412c-9b10-a7f9be80bc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-a4e3b861-b301-4880-a17a-f6533ad666ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-77d18da5-6802-41c2-9641-1e001857654d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380078336-172.17.0.21-1596953108974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-76ea7be5-25b3-454d-b5f0-0e409375da88,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-9865df01-a813-498e-8007-a14028d1e621,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-0405cb02-a9c6-4350-ba49-aa338e72ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-39016793-889b-4518-8b3a-2797600341ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-08b23a18-c83c-489c-b2f4-6f72a3da602e,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-2442730b-e4d5-4fa5-95b6-d6f1dd3d5e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-2fe1ab87-18d9-4bee-9409-c12deab20b76,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-d9cea150-3ff3-4948-bf2d-46f8424f0444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380078336-172.17.0.21-1596953108974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-76ea7be5-25b3-454d-b5f0-0e409375da88,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-9865df01-a813-498e-8007-a14028d1e621,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-0405cb02-a9c6-4350-ba49-aa338e72ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-39016793-889b-4518-8b3a-2797600341ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-08b23a18-c83c-489c-b2f4-6f72a3da602e,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-2442730b-e4d5-4fa5-95b6-d6f1dd3d5e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-2fe1ab87-18d9-4bee-9409-c12deab20b76,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-d9cea150-3ff3-4948-bf2d-46f8424f0444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340649230-172.17.0.21-1596953199591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42854,DS-8108645b-c270-4a77-af22-bda587c476e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-8a417d0e-4ad7-4090-86eb-0de959adf589,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-36eab518-4a7f-48c9-9407-bab8ad36da36,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-d4dd2697-b322-4db1-b8f7-a5648721cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-3ef8c117-2636-4915-8020-40d04552d150,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-d02c17f0-4d9b-44c5-9043-e2559418567d,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-9b4dbc8c-bb64-4861-aad9-86f3b9558ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-53e3268f-c5c9-4786-92c1-38697f4b2edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340649230-172.17.0.21-1596953199591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42854,DS-8108645b-c270-4a77-af22-bda587c476e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-8a417d0e-4ad7-4090-86eb-0de959adf589,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-36eab518-4a7f-48c9-9407-bab8ad36da36,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-d4dd2697-b322-4db1-b8f7-a5648721cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-3ef8c117-2636-4915-8020-40d04552d150,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-d02c17f0-4d9b-44c5-9043-e2559418567d,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-9b4dbc8c-bb64-4861-aad9-86f3b9558ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-53e3268f-c5c9-4786-92c1-38697f4b2edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315724140-172.17.0.21-1596953328829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-de534111-1661-49b3-ad57-afc97f551b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-6feb5537-79a9-4173-a90b-e6f171d46935,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-76125509-68da-4023-8a4b-54da290d2089,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-c9fad5bb-21fd-4fb3-9f0e-528823de4319,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-6ed74156-318b-4d77-b4ec-dd4ead32731f,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-1fed0205-8a8b-4a17-b2af-be8e89da87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-57ca31b8-1ecb-4fc2-acc6-27c2c29567f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-53a306c4-493d-434e-816d-b9acb62e7757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315724140-172.17.0.21-1596953328829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-de534111-1661-49b3-ad57-afc97f551b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-6feb5537-79a9-4173-a90b-e6f171d46935,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-76125509-68da-4023-8a4b-54da290d2089,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-c9fad5bb-21fd-4fb3-9f0e-528823de4319,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-6ed74156-318b-4d77-b4ec-dd4ead32731f,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-1fed0205-8a8b-4a17-b2af-be8e89da87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-57ca31b8-1ecb-4fc2-acc6-27c2c29567f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-53a306c4-493d-434e-816d-b9acb62e7757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855934100-172.17.0.21-1596953467247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-f9b77949-04d0-40bb-9c30-c9724394bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-77fe1448-5282-4b42-8800-c55daf283c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-48c909db-369a-44cb-9ffe-ca84125d3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-0042ac3f-7f87-43f2-9425-b43a8e843031,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-dd003e96-2b8e-4441-9b7f-4c9b2db0571a,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-d314d16a-e64a-4013-991f-89f3816c4b82,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f7e37cf3-607e-45ea-a72c-c4b187cb0431,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-59101cd4-e910-420b-bc3a-257f0d4f6184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855934100-172.17.0.21-1596953467247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-f9b77949-04d0-40bb-9c30-c9724394bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-77fe1448-5282-4b42-8800-c55daf283c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-48c909db-369a-44cb-9ffe-ca84125d3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-0042ac3f-7f87-43f2-9425-b43a8e843031,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-dd003e96-2b8e-4441-9b7f-4c9b2db0571a,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-d314d16a-e64a-4013-991f-89f3816c4b82,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f7e37cf3-607e-45ea-a72c-c4b187cb0431,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-59101cd4-e910-420b-bc3a-257f0d4f6184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6226988-172.17.0.21-1596954038778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-01a025e3-545f-44ce-b2dc-ba19efbbb22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-dda95c3c-093a-4fef-9ce9-e305f3005f51,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-a861da2f-2c2e-4691-9c36-7ae76cd6d0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-e1cb4b95-03f3-4ad5-81a4-162a06ce5213,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-ce79147e-d499-4583-896e-c6dd36052014,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-92576867-3822-43b2-ba90-faaae15a17f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-183672de-e7c9-42df-baa2-65646286ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-6e8dbef4-735b-439a-8859-1f8d4dc7b329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6226988-172.17.0.21-1596954038778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-01a025e3-545f-44ce-b2dc-ba19efbbb22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-dda95c3c-093a-4fef-9ce9-e305f3005f51,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-a861da2f-2c2e-4691-9c36-7ae76cd6d0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-e1cb4b95-03f3-4ad5-81a4-162a06ce5213,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-ce79147e-d499-4583-896e-c6dd36052014,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-92576867-3822-43b2-ba90-faaae15a17f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-183672de-e7c9-42df-baa2-65646286ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-6e8dbef4-735b-439a-8859-1f8d4dc7b329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5011
