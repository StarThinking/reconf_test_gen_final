reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110971497-172.17.0.10-1596916715256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-a2b73753-eac2-44aa-ba79-1bfddc2f5945,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-747598d9-4887-402c-b4e5-bd08a7446223,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f2ea7f62-c653-49a5-8e8d-b3c7e33a2348,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-690f5d4d-dcc3-4288-8237-9893c89c7172,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-2a4f956d-b8a9-4af3-9742-f8a85dc7ceae,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-8a11aa18-7fb3-4e56-a615-208700128bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-f28c74af-8ea6-476c-b3ca-874a1c1aa673,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-940f77c7-0a1a-4b08-8dce-c9ef9f13cea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110971497-172.17.0.10-1596916715256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-a2b73753-eac2-44aa-ba79-1bfddc2f5945,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-747598d9-4887-402c-b4e5-bd08a7446223,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f2ea7f62-c653-49a5-8e8d-b3c7e33a2348,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-690f5d4d-dcc3-4288-8237-9893c89c7172,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-2a4f956d-b8a9-4af3-9742-f8a85dc7ceae,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-8a11aa18-7fb3-4e56-a615-208700128bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-f28c74af-8ea6-476c-b3ca-874a1c1aa673,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-940f77c7-0a1a-4b08-8dce-c9ef9f13cea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600151044-172.17.0.10-1596917473571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-00d5eeb8-57a8-48cc-8ce1-42842cccc40a,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-cff84a5f-b0b2-40ea-b914-2f26bb9fc547,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-475db7cb-c4ac-4f2f-8833-c9075377df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-01b0b4d2-1a21-4604-99a8-365e0b669813,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-1571c3b8-57f0-49e3-974d-36b292aa4ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-0e4a27c2-814a-45ad-b361-846d8fb3f928,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-ea2f6f43-99f0-4bc2-9337-fd51900f4e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f955bcc8-3102-4b5b-9d6e-d2fc75e824b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600151044-172.17.0.10-1596917473571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-00d5eeb8-57a8-48cc-8ce1-42842cccc40a,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-cff84a5f-b0b2-40ea-b914-2f26bb9fc547,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-475db7cb-c4ac-4f2f-8833-c9075377df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-01b0b4d2-1a21-4604-99a8-365e0b669813,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-1571c3b8-57f0-49e3-974d-36b292aa4ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-0e4a27c2-814a-45ad-b361-846d8fb3f928,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-ea2f6f43-99f0-4bc2-9337-fd51900f4e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f955bcc8-3102-4b5b-9d6e-d2fc75e824b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155195466-172.17.0.10-1596917955986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-d01f698b-abe2-4d02-801e-35896c0cfcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-1be770b6-db04-43d0-ba70-df8130260b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-9ac3c365-1aa1-49d2-91f2-f830da6084a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-fa299ef6-92ac-4096-a4ea-4141ea0e6452,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-6f17fe2d-d3d9-43af-a9e1-7ead60b8ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-14e3e49d-cc99-406d-90df-a845640a032f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-dac53f6b-7822-4f44-8882-ea2004d5c1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-edf50459-1c80-47e7-999b-f02bc7334788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155195466-172.17.0.10-1596917955986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-d01f698b-abe2-4d02-801e-35896c0cfcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-1be770b6-db04-43d0-ba70-df8130260b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-9ac3c365-1aa1-49d2-91f2-f830da6084a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-fa299ef6-92ac-4096-a4ea-4141ea0e6452,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-6f17fe2d-d3d9-43af-a9e1-7ead60b8ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-14e3e49d-cc99-406d-90df-a845640a032f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-dac53f6b-7822-4f44-8882-ea2004d5c1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-edf50459-1c80-47e7-999b-f02bc7334788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499025201-172.17.0.10-1596918072943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-5070928c-f2f3-4187-a3f1-089771c537c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-a2a104d4-594a-438d-bdea-e0b64373fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-c6befbe4-68cd-4c24-a49c-ed479b9e385b,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-46219731-76c0-4692-aeac-ebef754d5839,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-459e8f0f-17a3-4318-9585-c9d9106615d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-72ad9236-cf3d-4db7-9af7-429eb83ed7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-82e4a3e4-1418-4437-a102-db21fb2d58a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-e649ef45-beec-47fd-82c2-2bb0ba929085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499025201-172.17.0.10-1596918072943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-5070928c-f2f3-4187-a3f1-089771c537c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-a2a104d4-594a-438d-bdea-e0b64373fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-c6befbe4-68cd-4c24-a49c-ed479b9e385b,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-46219731-76c0-4692-aeac-ebef754d5839,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-459e8f0f-17a3-4318-9585-c9d9106615d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-72ad9236-cf3d-4db7-9af7-429eb83ed7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-82e4a3e4-1418-4437-a102-db21fb2d58a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-e649ef45-beec-47fd-82c2-2bb0ba929085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8832199-172.17.0.10-1596918366886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42932,DS-d207125c-4850-4947-997c-ae44359d46de,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-aae8918b-7643-41a0-b3e1-7cce26b1d597,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-59aa4480-897c-474b-85d7-8458260a47d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-cf6c928f-2899-496a-b192-f5faa004e34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-bc3de07e-35c4-4e98-be81-9fb43cb292cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-a2ef4ff3-04e9-4236-8234-d04ff68a1614,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d4e621de-282a-4f0a-995a-c42752f95063,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-85514d1c-a3ef-41f6-a92d-06411a06d480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8832199-172.17.0.10-1596918366886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42932,DS-d207125c-4850-4947-997c-ae44359d46de,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-aae8918b-7643-41a0-b3e1-7cce26b1d597,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-59aa4480-897c-474b-85d7-8458260a47d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-cf6c928f-2899-496a-b192-f5faa004e34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-bc3de07e-35c4-4e98-be81-9fb43cb292cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-a2ef4ff3-04e9-4236-8234-d04ff68a1614,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d4e621de-282a-4f0a-995a-c42752f95063,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-85514d1c-a3ef-41f6-a92d-06411a06d480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1343977421-172.17.0.10-1596918944870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39996,DS-8d110ca9-1702-49e8-9f2c-faa372ed489e,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-8eacdf53-3f1c-4cd6-be8f-619556cde6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-034cbf36-3655-4481-b809-5ef27fa324ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-9792d418-8327-4a40-9390-165833b8756c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-5b419232-4b24-40dc-8aa8-ab43c8430039,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-72fec195-374f-41b5-90bd-66a12ea5152c,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-69cfa34c-8d9c-47f3-8787-c38e11c072d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-4d3c86f8-6e24-46a8-87b8-3e0ef3ab2204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1343977421-172.17.0.10-1596918944870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39996,DS-8d110ca9-1702-49e8-9f2c-faa372ed489e,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-8eacdf53-3f1c-4cd6-be8f-619556cde6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-034cbf36-3655-4481-b809-5ef27fa324ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-9792d418-8327-4a40-9390-165833b8756c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-5b419232-4b24-40dc-8aa8-ab43c8430039,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-72fec195-374f-41b5-90bd-66a12ea5152c,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-69cfa34c-8d9c-47f3-8787-c38e11c072d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-4d3c86f8-6e24-46a8-87b8-3e0ef3ab2204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040992235-172.17.0.10-1596919041587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-7c939e91-5a0e-43ae-b002-526b12a00007,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-e75ab5fc-81be-417b-9006-5cf041181547,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-abfeefdc-51cf-460e-8aed-b158e89e8f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-c364a0d8-1261-4b36-9301-2648976ee645,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-292ee615-538a-4148-b0ff-536112c0f74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e0caa384-d4f3-4044-a917-0610f05fb0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-ed0247b3-3a12-4d52-9558-83a83b515b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-e5e0368e-cbc1-4e36-92d1-03b96ac48a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040992235-172.17.0.10-1596919041587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-7c939e91-5a0e-43ae-b002-526b12a00007,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-e75ab5fc-81be-417b-9006-5cf041181547,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-abfeefdc-51cf-460e-8aed-b158e89e8f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-c364a0d8-1261-4b36-9301-2648976ee645,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-292ee615-538a-4148-b0ff-536112c0f74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e0caa384-d4f3-4044-a917-0610f05fb0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-ed0247b3-3a12-4d52-9558-83a83b515b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-e5e0368e-cbc1-4e36-92d1-03b96ac48a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204787582-172.17.0.10-1596919071725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35913,DS-dfd0dfe1-3066-49c4-abc8-6ae2e0947d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-a5f198eb-8dee-4d08-b20f-72a3eef1a24c,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-e052b8fb-8236-4746-b6da-9c8af9eb3452,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-d418d562-99ed-4873-973e-ab59a1dea5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-b2c18e49-a78a-4a49-a367-03bbe92b5eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-0aee2c85-d8cb-4a6d-8366-79e82ff15a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-5f207c9c-6fd3-463d-88a2-01f908aecaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-640e0380-24dd-42bb-bfa0-5308da4e778c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204787582-172.17.0.10-1596919071725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35913,DS-dfd0dfe1-3066-49c4-abc8-6ae2e0947d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-a5f198eb-8dee-4d08-b20f-72a3eef1a24c,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-e052b8fb-8236-4746-b6da-9c8af9eb3452,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-d418d562-99ed-4873-973e-ab59a1dea5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-b2c18e49-a78a-4a49-a367-03bbe92b5eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-0aee2c85-d8cb-4a6d-8366-79e82ff15a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-5f207c9c-6fd3-463d-88a2-01f908aecaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-640e0380-24dd-42bb-bfa0-5308da4e778c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454258852-172.17.0.10-1596919102566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33473,DS-10095c83-5a11-49b2-a5e5-e5f69c9e8e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-b0c1a407-7c22-4878-bec9-76020e39ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-f6373418-81cc-4e77-824c-19e4ee08c80e,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-edd44658-5770-4c6c-a481-779bf3ed14b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-588bc6c6-dfac-4e81-b114-92813d2a87a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-5a96a294-9c21-463d-a054-9e31e1c0c2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-4e16f4d8-1a05-4178-8969-a0ae3e2a945b,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-affe7884-621f-4ae4-aefd-f4f3972fded6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454258852-172.17.0.10-1596919102566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33473,DS-10095c83-5a11-49b2-a5e5-e5f69c9e8e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-b0c1a407-7c22-4878-bec9-76020e39ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-f6373418-81cc-4e77-824c-19e4ee08c80e,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-edd44658-5770-4c6c-a481-779bf3ed14b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-588bc6c6-dfac-4e81-b114-92813d2a87a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-5a96a294-9c21-463d-a054-9e31e1c0c2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-4e16f4d8-1a05-4178-8969-a0ae3e2a945b,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-affe7884-621f-4ae4-aefd-f4f3972fded6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859586888-172.17.0.10-1596919469900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-b248850d-159c-45e4-8d14-2eb2341be67e,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-69f6d1ca-7cbb-4b40-9d74-ff1e8e8aeb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-eaf8a5f4-3606-40ce-b823-be42f3ba6443,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-b3f99476-d97e-45e2-a9b7-722f50275358,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-7c89eb6e-3e38-4cc9-9bad-eed57f261aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-cc447736-5999-4b79-89fa-430476141059,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-40852e09-8a35-40b8-aab7-8c484aaf1be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-5e9835b0-eb39-4cc8-a9d0-17bfa9ef584f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859586888-172.17.0.10-1596919469900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-b248850d-159c-45e4-8d14-2eb2341be67e,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-69f6d1ca-7cbb-4b40-9d74-ff1e8e8aeb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-eaf8a5f4-3606-40ce-b823-be42f3ba6443,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-b3f99476-d97e-45e2-a9b7-722f50275358,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-7c89eb6e-3e38-4cc9-9bad-eed57f261aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-cc447736-5999-4b79-89fa-430476141059,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-40852e09-8a35-40b8-aab7-8c484aaf1be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-5e9835b0-eb39-4cc8-a9d0-17bfa9ef584f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367776137-172.17.0.10-1596920483512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-4b99bcb3-d00b-4f4f-ab32-57a95c143879,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-b9e09b41-1b7b-4d87-a490-6bb5aca80d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-950f7b3d-5f03-4940-bed6-9079ed815cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-f3204617-503d-4dbe-b154-c2f1e621832c,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-3db76bda-ac9c-4b4d-885f-7c4abb603866,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-2f48dd47-d4be-4ea3-9979-af340ade81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-7324c553-257b-492e-81a0-d2aa10ab1178,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-4e791c4d-1e7a-4412-a18b-8c82803c3327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367776137-172.17.0.10-1596920483512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-4b99bcb3-d00b-4f4f-ab32-57a95c143879,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-b9e09b41-1b7b-4d87-a490-6bb5aca80d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-950f7b3d-5f03-4940-bed6-9079ed815cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-f3204617-503d-4dbe-b154-c2f1e621832c,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-3db76bda-ac9c-4b4d-885f-7c4abb603866,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-2f48dd47-d4be-4ea3-9979-af340ade81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-7324c553-257b-492e-81a0-d2aa10ab1178,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-4e791c4d-1e7a-4412-a18b-8c82803c3327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835297580-172.17.0.10-1596920912512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-6f9a1c66-a46f-4343-b1a6-61e8d6332f24,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-e02ce33d-d69e-41ed-b94b-6b638cc4f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5ff0c069-1bdc-4581-8e0f-c23a11a15970,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-678255f5-cbf3-475b-af4a-1c2ba255e54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-89828c0b-4318-46aa-b57a-599488604d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-1ab78c4c-90ec-4d01-89cf-c35aad9f5b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-4dfb3171-153b-4546-b807-ed4f272be5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-97767898-ca6d-4856-aa0a-0426c1b27e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835297580-172.17.0.10-1596920912512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-6f9a1c66-a46f-4343-b1a6-61e8d6332f24,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-e02ce33d-d69e-41ed-b94b-6b638cc4f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5ff0c069-1bdc-4581-8e0f-c23a11a15970,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-678255f5-cbf3-475b-af4a-1c2ba255e54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-89828c0b-4318-46aa-b57a-599488604d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-1ab78c4c-90ec-4d01-89cf-c35aad9f5b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-4dfb3171-153b-4546-b807-ed4f272be5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-97767898-ca6d-4856-aa0a-0426c1b27e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878913883-172.17.0.10-1596921197272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36970,DS-33a8e12c-28be-4187-b751-6b35a97f32d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-17dd470a-74fa-428b-a99f-27c2c9f4e860,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-5acba987-1e90-46e3-884a-12b50b4203d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-b02d4bbc-d6f6-46a6-8e41-d1c3ecf7e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-d85895f3-fa7e-46d0-9e51-aae7eef9c810,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-0b3a9f8d-9417-4fba-abc4-f282c1c14015,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-9bf13686-840c-451d-a35a-b0beee6add29,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-ed99926f-ea88-491a-b90c-88ac77cb1e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878913883-172.17.0.10-1596921197272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36970,DS-33a8e12c-28be-4187-b751-6b35a97f32d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-17dd470a-74fa-428b-a99f-27c2c9f4e860,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-5acba987-1e90-46e3-884a-12b50b4203d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-b02d4bbc-d6f6-46a6-8e41-d1c3ecf7e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-d85895f3-fa7e-46d0-9e51-aae7eef9c810,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-0b3a9f8d-9417-4fba-abc4-f282c1c14015,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-9bf13686-840c-451d-a35a-b0beee6add29,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-ed99926f-ea88-491a-b90c-88ac77cb1e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5215
