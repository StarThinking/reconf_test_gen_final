reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751607470-172.17.0.6-1596949155441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-fbdc78ae-a40b-41bc-8eb0-bf09d900d872,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-a4130267-2f66-40f4-8b6a-47f5048bc317,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-9b2f1595-3fce-48a9-80b8-78641b7e7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-13c9c840-b76e-479f-b8c7-0e18486e179d,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-96bdfc83-f131-4d57-9804-9e2d99986a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-a501c60d-4aca-4bbe-802f-c7e228bd4e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-cdbacfc0-eb32-41bc-ad71-303dff6e56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-41e9ace4-ef4d-4829-ad3c-b94e632a9780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751607470-172.17.0.6-1596949155441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-fbdc78ae-a40b-41bc-8eb0-bf09d900d872,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-a4130267-2f66-40f4-8b6a-47f5048bc317,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-9b2f1595-3fce-48a9-80b8-78641b7e7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-13c9c840-b76e-479f-b8c7-0e18486e179d,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-96bdfc83-f131-4d57-9804-9e2d99986a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-a501c60d-4aca-4bbe-802f-c7e228bd4e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-cdbacfc0-eb32-41bc-ad71-303dff6e56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-41e9ace4-ef4d-4829-ad3c-b94e632a9780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119826037-172.17.0.6-1596949962155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-556f9f8e-a599-4654-86c7-743b05993b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-65793b00-0440-412e-9e1a-d3f48e8a234a,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-3f808d21-32d4-464c-aa87-f926b4b8a5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-566f2a3e-7d90-4cdf-96a6-813b1a1b1286,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2beb5f5a-077d-48df-b631-f63f87e22a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-9d850a87-b870-4798-83a3-69d5530a6408,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-4f82a20f-70b6-4d7b-aa17-c8ecc5f5d3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-9cdd59c8-f0df-4d5a-aa96-b786e0415456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119826037-172.17.0.6-1596949962155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-556f9f8e-a599-4654-86c7-743b05993b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-65793b00-0440-412e-9e1a-d3f48e8a234a,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-3f808d21-32d4-464c-aa87-f926b4b8a5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-566f2a3e-7d90-4cdf-96a6-813b1a1b1286,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2beb5f5a-077d-48df-b631-f63f87e22a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-9d850a87-b870-4798-83a3-69d5530a6408,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-4f82a20f-70b6-4d7b-aa17-c8ecc5f5d3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-9cdd59c8-f0df-4d5a-aa96-b786e0415456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115299200-172.17.0.6-1596950005413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37664,DS-52a74b5c-6fc1-4e5a-887f-a8d5315f7bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-ec5461cd-d387-480e-9e3e-e26db7af7a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-1ca1112b-13a2-4a7e-affc-badb8c2b763a,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-da9e6eaf-e214-4195-8fb8-20d1960c7ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-4b95f4d6-0e6e-4bf1-a951-7bf9502146d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-3d8f44aa-ea17-4be0-90ab-baf4f2267a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-999219e6-a0b3-464e-afda-1b64f90cc310,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-81623f92-f753-4504-b936-d25fccc40fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115299200-172.17.0.6-1596950005413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37664,DS-52a74b5c-6fc1-4e5a-887f-a8d5315f7bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-ec5461cd-d387-480e-9e3e-e26db7af7a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-1ca1112b-13a2-4a7e-affc-badb8c2b763a,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-da9e6eaf-e214-4195-8fb8-20d1960c7ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-4b95f4d6-0e6e-4bf1-a951-7bf9502146d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-3d8f44aa-ea17-4be0-90ab-baf4f2267a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-999219e6-a0b3-464e-afda-1b64f90cc310,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-81623f92-f753-4504-b936-d25fccc40fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492791088-172.17.0.6-1596950043678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34846,DS-da995942-f01b-4588-919f-7830c921ba70,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-811274ce-1dd8-4113-9d01-6f88503e48fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-159790e0-f413-4dfc-a16a-9ecd263c048c,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-c44f8928-f9d7-4010-a017-ac07c28d27ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-3d7b8c98-cba2-4336-a976-c5383300a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-d19b6c72-cb55-45b2-a582-692ffe9f7769,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-15c10894-51e2-4ad6-8763-961d665a4048,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-94070bbd-8d92-4fbb-82f1-a6ed8cb7a952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492791088-172.17.0.6-1596950043678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34846,DS-da995942-f01b-4588-919f-7830c921ba70,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-811274ce-1dd8-4113-9d01-6f88503e48fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-159790e0-f413-4dfc-a16a-9ecd263c048c,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-c44f8928-f9d7-4010-a017-ac07c28d27ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-3d7b8c98-cba2-4336-a976-c5383300a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-d19b6c72-cb55-45b2-a582-692ffe9f7769,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-15c10894-51e2-4ad6-8763-961d665a4048,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-94070bbd-8d92-4fbb-82f1-a6ed8cb7a952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996020513-172.17.0.6-1596950272851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39267,DS-e093d59f-3919-42fd-8c6d-f12e82ff5525,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-0d70b4f7-4fb6-411c-8835-fbb6bcd84f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-fc32aa2e-8fae-4c1f-9fc2-7ac7b5d9db67,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-ca45b3e3-22c7-4a96-96b5-a4fc3bba6ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-8a55947d-3932-4751-82e3-5a3833b66a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5ec7eac9-e629-4cb4-9956-5d587d9760e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-93332ccc-0c96-46e4-8974-7617b3dbf01e,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-0b203dcb-46d0-4f5b-82b1-85f60587ce08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996020513-172.17.0.6-1596950272851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39267,DS-e093d59f-3919-42fd-8c6d-f12e82ff5525,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-0d70b4f7-4fb6-411c-8835-fbb6bcd84f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-fc32aa2e-8fae-4c1f-9fc2-7ac7b5d9db67,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-ca45b3e3-22c7-4a96-96b5-a4fc3bba6ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-8a55947d-3932-4751-82e3-5a3833b66a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5ec7eac9-e629-4cb4-9956-5d587d9760e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-93332ccc-0c96-46e4-8974-7617b3dbf01e,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-0b203dcb-46d0-4f5b-82b1-85f60587ce08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508372824-172.17.0.6-1596951458174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-43059fd6-30bb-450c-85f0-ac9641bb72fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-72cd97f1-4869-4ca2-ab84-3f76079f8b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-adda0564-0477-4401-bfd6-6c2832fbaf99,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-9bc535b9-dcd2-4fc3-9214-2f032513c10b,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-1f64811a-a3a8-41f5-ba3c-c1fa4e92b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-fa255a4b-dac3-423b-8cd6-a82bb3aea1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-09d9ce8d-ea3f-443d-b678-4f871f623977,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-9f90b835-0f27-47fc-849e-66d2d2a43c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508372824-172.17.0.6-1596951458174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-43059fd6-30bb-450c-85f0-ac9641bb72fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-72cd97f1-4869-4ca2-ab84-3f76079f8b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-adda0564-0477-4401-bfd6-6c2832fbaf99,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-9bc535b9-dcd2-4fc3-9214-2f032513c10b,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-1f64811a-a3a8-41f5-ba3c-c1fa4e92b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-fa255a4b-dac3-423b-8cd6-a82bb3aea1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-09d9ce8d-ea3f-443d-b678-4f871f623977,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-9f90b835-0f27-47fc-849e-66d2d2a43c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528212664-172.17.0.6-1596952519918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-0432cdc1-2486-474a-aacc-db8cb9010f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-fd3494e9-b2dc-487b-9fb5-571f7fe7c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-7f0cf1bb-1b31-4823-acd7-f929bb4146cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-fb7ffbfe-f0f0-41d6-adec-0cd74cdf1405,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-504bf195-1a11-480c-b060-9d763717dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-c08bb6d2-d365-4946-b5e0-ded71079d42f,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-65c76856-ed63-4f13-b6ae-5387945bdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-f243c217-d5d7-4e68-92e3-22dc5a3d9c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528212664-172.17.0.6-1596952519918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-0432cdc1-2486-474a-aacc-db8cb9010f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-fd3494e9-b2dc-487b-9fb5-571f7fe7c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-7f0cf1bb-1b31-4823-acd7-f929bb4146cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-fb7ffbfe-f0f0-41d6-adec-0cd74cdf1405,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-504bf195-1a11-480c-b060-9d763717dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-c08bb6d2-d365-4946-b5e0-ded71079d42f,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-65c76856-ed63-4f13-b6ae-5387945bdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-f243c217-d5d7-4e68-92e3-22dc5a3d9c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959750178-172.17.0.6-1596953145953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36514,DS-9f3dad2f-9693-43fc-87eb-4536d83f36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-fa948d29-947c-4d64-b567-fb4231170ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-83be175e-f87c-4e3a-b53f-1c7ea6b23ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-4d65eca2-06c6-48ea-af6a-f695ad931a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-253d5d36-0d8a-44e7-99d2-5b80f70ad1db,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-ec261856-5ae2-4b50-85f2-55317dce2420,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-c76b0fa3-c605-4939-9bf7-e3e29c57c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-4d913b2e-6b4c-48e0-8e28-0173d04722dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959750178-172.17.0.6-1596953145953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36514,DS-9f3dad2f-9693-43fc-87eb-4536d83f36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-fa948d29-947c-4d64-b567-fb4231170ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-83be175e-f87c-4e3a-b53f-1c7ea6b23ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-4d65eca2-06c6-48ea-af6a-f695ad931a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-253d5d36-0d8a-44e7-99d2-5b80f70ad1db,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-ec261856-5ae2-4b50-85f2-55317dce2420,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-c76b0fa3-c605-4939-9bf7-e3e29c57c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-4d913b2e-6b4c-48e0-8e28-0173d04722dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368282216-172.17.0.6-1596953234865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36609,DS-c80bc4a3-2635-43f3-9349-416064c46c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-cc97e75a-7e02-45d7-9b91-998dec3a457c,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-ea803910-b06e-4a77-b320-1b3b1cf95913,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-1d0b80fc-7c11-4d00-959a-7d0c8ada2b65,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-88384f87-a603-4d09-9d7c-8ee0b3463a01,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-525f807c-e3f7-4d43-8432-0d7b83c53345,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-e154c358-1c4a-4ad2-9dfc-22d088a28b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-0c62936c-721d-4286-8e1c-1f8d29dbf4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368282216-172.17.0.6-1596953234865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36609,DS-c80bc4a3-2635-43f3-9349-416064c46c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-cc97e75a-7e02-45d7-9b91-998dec3a457c,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-ea803910-b06e-4a77-b320-1b3b1cf95913,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-1d0b80fc-7c11-4d00-959a-7d0c8ada2b65,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-88384f87-a603-4d09-9d7c-8ee0b3463a01,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-525f807c-e3f7-4d43-8432-0d7b83c53345,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-e154c358-1c4a-4ad2-9dfc-22d088a28b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-0c62936c-721d-4286-8e1c-1f8d29dbf4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983867816-172.17.0.6-1596953394115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-7673f45d-6abb-4df3-a156-148fa1c9419e,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-0b5c974c-396b-4e9b-9d8f-1830d05e79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-f24ff2a2-41b5-477f-af92-e92d800de290,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-8fd4bbe1-646b-40f7-934f-a66603864e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-017571a7-aeaa-40fd-967a-a9d687c56509,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-1d557db5-7ae8-49a8-8d0b-f6cecadff608,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-fdbfa303-b2c0-4919-978f-7134d589cc29,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-b8c116cd-c675-4f46-8740-24cdc4941178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983867816-172.17.0.6-1596953394115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-7673f45d-6abb-4df3-a156-148fa1c9419e,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-0b5c974c-396b-4e9b-9d8f-1830d05e79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-f24ff2a2-41b5-477f-af92-e92d800de290,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-8fd4bbe1-646b-40f7-934f-a66603864e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-017571a7-aeaa-40fd-967a-a9d687c56509,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-1d557db5-7ae8-49a8-8d0b-f6cecadff608,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-fdbfa303-b2c0-4919-978f-7134d589cc29,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-b8c116cd-c675-4f46-8740-24cdc4941178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588002795-172.17.0.6-1596953477337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-0d9adfa6-47f2-4544-8587-307c3315c3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-a7cb8609-2629-432f-a4e5-4e654dc4b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-ec5f2e0b-3e0a-4d2b-ac1d-2ca27052f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-b7e82c87-aa1d-479e-853b-16371b951883,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-193a21ff-cc66-4764-82c5-b9bc5d4d8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-f7362db5-6f5c-46b3-94f4-e0263b270e21,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-9cc7e73d-9032-41d2-893a-6cc512d8d654,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-7ba36907-39b2-486e-9ef0-0083180426c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588002795-172.17.0.6-1596953477337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-0d9adfa6-47f2-4544-8587-307c3315c3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-a7cb8609-2629-432f-a4e5-4e654dc4b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-ec5f2e0b-3e0a-4d2b-ac1d-2ca27052f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-b7e82c87-aa1d-479e-853b-16371b951883,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-193a21ff-cc66-4764-82c5-b9bc5d4d8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-f7362db5-6f5c-46b3-94f4-e0263b270e21,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-9cc7e73d-9032-41d2-893a-6cc512d8d654,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-7ba36907-39b2-486e-9ef0-0083180426c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644483719-172.17.0.6-1596953521767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-b9e09cb2-31ef-4d7d-b64e-13f156afb38d,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-d15ec57b-854a-48f4-ae1c-5e496963c796,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-abd74a74-f26b-47c9-a97e-88a846c385c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-fd638243-308b-4e76-aed8-3e60ac9600ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-13dd08c9-8baa-42e8-adcd-15059b64cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-10c17e36-14c6-4537-8b4e-04e12dae0323,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-562c7a7d-c96e-4bed-b38c-a9e8d27c49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-3f15a41e-cd7d-4864-8333-329128443bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644483719-172.17.0.6-1596953521767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-b9e09cb2-31ef-4d7d-b64e-13f156afb38d,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-d15ec57b-854a-48f4-ae1c-5e496963c796,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-abd74a74-f26b-47c9-a97e-88a846c385c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-fd638243-308b-4e76-aed8-3e60ac9600ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-13dd08c9-8baa-42e8-adcd-15059b64cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-10c17e36-14c6-4537-8b4e-04e12dae0323,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-562c7a7d-c96e-4bed-b38c-a9e8d27c49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-3f15a41e-cd7d-4864-8333-329128443bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846993948-172.17.0.6-1596953666913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-8b662f59-498d-42b2-a104-d3b08b96e554,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-3fa7a5ab-f42b-4e07-9f7c-8913cf273c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-0c2ffa42-bc43-40e8-a27d-e358bc87e01f,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-1d85c5fa-439b-4333-911a-5d2510da8b67,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-c960eff1-d113-4d32-a770-ffcf84dd8638,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-3a037900-98ea-47ee-ae83-890b95de2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-b405ae6b-e8cb-4e97-9356-3c16d102f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-58e0f737-695c-43df-9412-c4ffb9b2a660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846993948-172.17.0.6-1596953666913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-8b662f59-498d-42b2-a104-d3b08b96e554,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-3fa7a5ab-f42b-4e07-9f7c-8913cf273c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-0c2ffa42-bc43-40e8-a27d-e358bc87e01f,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-1d85c5fa-439b-4333-911a-5d2510da8b67,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-c960eff1-d113-4d32-a770-ffcf84dd8638,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-3a037900-98ea-47ee-ae83-890b95de2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-b405ae6b-e8cb-4e97-9356-3c16d102f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-58e0f737-695c-43df-9412-c4ffb9b2a660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183914695-172.17.0.6-1596954124472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-5f3bf1fb-b9d3-4ed7-b80f-4e22b1776111,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-4d8d6dac-c5ff-4dca-86a4-cb44884ef035,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-745ae17d-e615-4699-9801-95aa316d9a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-d8de9fbf-1963-4dc6-a56b-485a751a8b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-e824180b-a764-460f-9b99-efbcd2808a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-adc81f83-bfb7-4fcf-95a2-7c5af211e45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-7a74e08e-dbe4-415c-b037-eb6ffbb4e8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-ee921e3a-4126-4045-a5fb-39c576468422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183914695-172.17.0.6-1596954124472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-5f3bf1fb-b9d3-4ed7-b80f-4e22b1776111,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-4d8d6dac-c5ff-4dca-86a4-cb44884ef035,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-745ae17d-e615-4699-9801-95aa316d9a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-d8de9fbf-1963-4dc6-a56b-485a751a8b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-e824180b-a764-460f-9b99-efbcd2808a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-adc81f83-bfb7-4fcf-95a2-7c5af211e45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-7a74e08e-dbe4-415c-b037-eb6ffbb4e8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-ee921e3a-4126-4045-a5fb-39c576468422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989355279-172.17.0.6-1596954211194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-c43e39b1-9233-44fb-859a-4e6d6fee2d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-d6795c96-1ba6-478c-904c-afa072e67a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-5f5ca3c2-3f44-42cf-8735-1c133b172868,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-bbad6edf-9078-45b0-aaba-b36a2554d3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-7de77e02-4bb4-4e4e-a601-d642650f41e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-67abd54e-00c2-429d-b3f5-589b723de57b,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-6aff8383-c1ce-4218-9c2d-5f453d5a6b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-a023c627-293b-4e5e-b583-16d6421635dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989355279-172.17.0.6-1596954211194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-c43e39b1-9233-44fb-859a-4e6d6fee2d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-d6795c96-1ba6-478c-904c-afa072e67a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-5f5ca3c2-3f44-42cf-8735-1c133b172868,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-bbad6edf-9078-45b0-aaba-b36a2554d3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-7de77e02-4bb4-4e4e-a601-d642650f41e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-67abd54e-00c2-429d-b3f5-589b723de57b,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-6aff8383-c1ce-4218-9c2d-5f453d5a6b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-a023c627-293b-4e5e-b583-16d6421635dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009560597-172.17.0.6-1596954306536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33926,DS-b7c574ec-d3ad-4a0d-ba31-649f44acc282,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-364363ec-b51d-4afa-ad3f-5f8abe8fd6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-7539b21a-f742-4741-9085-1c640c00f5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-5171ccf4-0a6d-4feb-80aa-49debea70414,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-988c5d2a-adec-4dca-b070-eb6eb6e9a8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-7c2bf0e0-b33a-4436-867c-b14227991208,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-9df89ec7-a4ec-485f-86d3-65c20607dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-cbbd5447-f214-4141-94e5-a92cefff1e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009560597-172.17.0.6-1596954306536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33926,DS-b7c574ec-d3ad-4a0d-ba31-649f44acc282,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-364363ec-b51d-4afa-ad3f-5f8abe8fd6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-7539b21a-f742-4741-9085-1c640c00f5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-5171ccf4-0a6d-4feb-80aa-49debea70414,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-988c5d2a-adec-4dca-b070-eb6eb6e9a8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-7c2bf0e0-b33a-4436-867c-b14227991208,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-9df89ec7-a4ec-485f-86d3-65c20607dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-cbbd5447-f214-4141-94e5-a92cefff1e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990010754-172.17.0.6-1596954441187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36110,DS-2c8a474f-c9d2-4461-a167-40aa6284dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-6f6b6211-23cb-4e06-bc03-dcb417abe0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-515992d5-afff-4482-b1c6-0ae77a9edca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-ce8a2e7a-dfeb-4211-9361-4aaddd24ebb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-bf3a8931-3cfa-4e74-8e02-b1e4b2b60018,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-29992436-c182-4776-9d94-23985246b662,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-29740fb0-1d5a-486a-b17a-2e739b199358,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b3710103-d8b1-4711-ba41-90fc3712e1f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990010754-172.17.0.6-1596954441187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36110,DS-2c8a474f-c9d2-4461-a167-40aa6284dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-6f6b6211-23cb-4e06-bc03-dcb417abe0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-515992d5-afff-4482-b1c6-0ae77a9edca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-ce8a2e7a-dfeb-4211-9361-4aaddd24ebb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-bf3a8931-3cfa-4e74-8e02-b1e4b2b60018,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-29992436-c182-4776-9d94-23985246b662,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-29740fb0-1d5a-486a-b17a-2e739b199358,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b3710103-d8b1-4711-ba41-90fc3712e1f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346082128-172.17.0.6-1596954658387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-822a56cf-14f0-489b-bc10-71c0c1f0e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-bf5176cb-fb97-4575-96b5-af56f0040b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-19122add-da93-471e-854a-fb9a30b2cb96,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-e4503a24-7dab-43df-b29b-f857a4763b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-c794faf0-96af-4bc8-8205-06fd0f606209,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-6f2fa874-7584-4c81-8beb-9d3f24bdb328,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-51d9e9af-1ffd-4c38-bd56-b7e8481a3c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-4f434727-151e-43a6-81d4-81c61122d3bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346082128-172.17.0.6-1596954658387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-822a56cf-14f0-489b-bc10-71c0c1f0e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-bf5176cb-fb97-4575-96b5-af56f0040b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-19122add-da93-471e-854a-fb9a30b2cb96,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-e4503a24-7dab-43df-b29b-f857a4763b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-c794faf0-96af-4bc8-8205-06fd0f606209,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-6f2fa874-7584-4c81-8beb-9d3f24bdb328,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-51d9e9af-1ffd-4c38-bd56-b7e8481a3c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-4f434727-151e-43a6-81d4-81c61122d3bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6648
