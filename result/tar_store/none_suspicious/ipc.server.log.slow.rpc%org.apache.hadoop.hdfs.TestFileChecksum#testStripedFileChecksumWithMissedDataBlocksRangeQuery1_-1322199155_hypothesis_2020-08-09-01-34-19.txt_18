reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401795706-172.17.0.10-1596936951937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-64f0b02d-fa64-4a77-8a87-6f8d7839fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-1ca2056f-6f6d-4bb6-ac7c-98a891ccf8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-798c91fc-c471-44cf-81b9-f3c1f1ffac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-39a99019-f474-43d2-b74a-9890c58d378a,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-07145c2d-08d9-4ab0-b62c-81e0e3d70cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-113168a4-16b2-4199-aa8a-bdbb3b331403,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a137e5d6-b241-4c59-a839-619bf0eef7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-931ffb47-959b-4d45-a8ad-20cab6c234a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401795706-172.17.0.10-1596936951937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-64f0b02d-fa64-4a77-8a87-6f8d7839fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-1ca2056f-6f6d-4bb6-ac7c-98a891ccf8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-798c91fc-c471-44cf-81b9-f3c1f1ffac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-39a99019-f474-43d2-b74a-9890c58d378a,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-07145c2d-08d9-4ab0-b62c-81e0e3d70cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-113168a4-16b2-4199-aa8a-bdbb3b331403,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a137e5d6-b241-4c59-a839-619bf0eef7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-931ffb47-959b-4d45-a8ad-20cab6c234a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184009370-172.17.0.10-1596937386642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-1a40f0df-b5f9-47fb-86c7-ed497dfe8f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-c173bf40-e679-4e8b-bccd-e0c95f836845,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-4b9f69f5-d4e1-41b0-bcda-9dfe82ad4724,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-ae681baf-ca6c-4357-8380-e01f9b75e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-789079a5-f4eb-4860-9614-260681a49a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-bffa79dc-6b4c-4d74-8ad7-5acf59730f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-aa63f22c-ef7d-49e5-bbef-474a3d95e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-0d79f7d8-8188-405d-a848-6a50117f1ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184009370-172.17.0.10-1596937386642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-1a40f0df-b5f9-47fb-86c7-ed497dfe8f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-c173bf40-e679-4e8b-bccd-e0c95f836845,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-4b9f69f5-d4e1-41b0-bcda-9dfe82ad4724,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-ae681baf-ca6c-4357-8380-e01f9b75e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-789079a5-f4eb-4860-9614-260681a49a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-bffa79dc-6b4c-4d74-8ad7-5acf59730f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-aa63f22c-ef7d-49e5-bbef-474a3d95e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-0d79f7d8-8188-405d-a848-6a50117f1ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652485034-172.17.0.10-1596937418724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35379,DS-4871dd30-abd2-4b27-8d5a-93b46ef2473a,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-551e75dc-a066-4d34-81ff-5e8d31172df5,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-f143b774-be6b-4e8a-9b8d-e5b7bcbdc8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3db21508-bf31-4703-bf68-80639f2360fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-c92da5ae-5f07-40d0-9ef4-8dda486f2666,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-5da814aa-db27-4ab1-ab83-f3550d705f42,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-18319242-67b7-440e-bf59-38826adf7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-72573187-099d-48e2-a698-3375c011218f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652485034-172.17.0.10-1596937418724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35379,DS-4871dd30-abd2-4b27-8d5a-93b46ef2473a,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-551e75dc-a066-4d34-81ff-5e8d31172df5,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-f143b774-be6b-4e8a-9b8d-e5b7bcbdc8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3db21508-bf31-4703-bf68-80639f2360fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-c92da5ae-5f07-40d0-9ef4-8dda486f2666,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-5da814aa-db27-4ab1-ab83-f3550d705f42,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-18319242-67b7-440e-bf59-38826adf7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-72573187-099d-48e2-a698-3375c011218f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458352767-172.17.0.10-1596937546430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-a319ec02-861e-4e1f-b08c-cf7851804ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-544ca327-d97d-4e05-a39f-d2a2c67fec05,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-cc2f3c2e-317c-4f5c-a0fa-fc6a348cee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-a3715d71-6ae9-4ba8-80c7-6fdb46689399,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-58abde51-99f0-46b3-b197-8bf3694ba8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-ec242714-cbc5-48e3-900f-a2ce1f7a1ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-03ecf676-deb4-4672-8b26-da43da6b05f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-717e6829-86fc-4aca-898b-c1ea8c2fff92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458352767-172.17.0.10-1596937546430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-a319ec02-861e-4e1f-b08c-cf7851804ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-544ca327-d97d-4e05-a39f-d2a2c67fec05,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-cc2f3c2e-317c-4f5c-a0fa-fc6a348cee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-a3715d71-6ae9-4ba8-80c7-6fdb46689399,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-58abde51-99f0-46b3-b197-8bf3694ba8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-ec242714-cbc5-48e3-900f-a2ce1f7a1ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-03ecf676-deb4-4672-8b26-da43da6b05f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-717e6829-86fc-4aca-898b-c1ea8c2fff92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12638498-172.17.0.10-1596937801346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43952,DS-0111ec69-787f-4b97-b278-303acb13fdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-8f662bd4-e073-4b71-b3cc-bd2292eadd64,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-724fccc9-b7e6-4768-891a-78d23285419a,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-9a9b8924-b8f4-47a1-8fc4-df0af9f6be36,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-ef6d2044-489e-4be0-818f-6fb673c510d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-bf78bddd-40b2-4e75-9a7a-0a9f8b915a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-412cbb07-4a8c-41ee-bccd-83ca706f8f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-b792dc65-046c-4781-b432-cfbc8543d514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12638498-172.17.0.10-1596937801346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43952,DS-0111ec69-787f-4b97-b278-303acb13fdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-8f662bd4-e073-4b71-b3cc-bd2292eadd64,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-724fccc9-b7e6-4768-891a-78d23285419a,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-9a9b8924-b8f4-47a1-8fc4-df0af9f6be36,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-ef6d2044-489e-4be0-818f-6fb673c510d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-bf78bddd-40b2-4e75-9a7a-0a9f8b915a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-412cbb07-4a8c-41ee-bccd-83ca706f8f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-b792dc65-046c-4781-b432-cfbc8543d514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072360808-172.17.0.10-1596938217900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-c3777770-3702-4f61-8eb0-b44c98ca209e,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-64f926c2-77ce-4146-8cb1-dc1ff5abe800,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-99f966c3-0eb7-4630-8654-4aa73a8fa5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-b1648732-bc16-40a7-9ddd-73df8e63502e,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-f5dc3cee-8534-4f3a-97f8-2095afd1d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-fcd771d0-f608-4fe4-9426-71c454a3e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-ae7318d8-6aea-4b9d-8b21-03636e26c107,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-dbd072c8-56bb-4745-9192-fa141213e557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072360808-172.17.0.10-1596938217900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-c3777770-3702-4f61-8eb0-b44c98ca209e,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-64f926c2-77ce-4146-8cb1-dc1ff5abe800,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-99f966c3-0eb7-4630-8654-4aa73a8fa5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-b1648732-bc16-40a7-9ddd-73df8e63502e,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-f5dc3cee-8534-4f3a-97f8-2095afd1d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-fcd771d0-f608-4fe4-9426-71c454a3e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-ae7318d8-6aea-4b9d-8b21-03636e26c107,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-dbd072c8-56bb-4745-9192-fa141213e557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252502677-172.17.0.10-1596938497668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-3af1da00-a007-462b-b2ad-94b3224e9828,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-91251fb0-211b-4b05-a0c2-8baa84f62f73,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-7c695586-3b15-4f29-ace0-8230d9a44466,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-eeb368f7-d302-4ead-bc70-7f1144680e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-595fb370-d553-4f12-96fc-e75ed05cb524,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-6bc6ee01-f8c7-4bfd-9d63-61916d72f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-a2b8c0db-a197-46e6-9eb1-5cc3c5b43952,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-bb858980-c14f-44a9-84dd-3981a356e003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252502677-172.17.0.10-1596938497668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-3af1da00-a007-462b-b2ad-94b3224e9828,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-91251fb0-211b-4b05-a0c2-8baa84f62f73,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-7c695586-3b15-4f29-ace0-8230d9a44466,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-eeb368f7-d302-4ead-bc70-7f1144680e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-595fb370-d553-4f12-96fc-e75ed05cb524,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-6bc6ee01-f8c7-4bfd-9d63-61916d72f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-a2b8c0db-a197-46e6-9eb1-5cc3c5b43952,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-bb858980-c14f-44a9-84dd-3981a356e003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359796947-172.17.0.10-1596938885343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-7b518e6e-b7ac-495a-ad66-17433160423a,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-36afc4f5-f2fc-4927-994d-9965523a2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-099c4d14-174c-4a59-9a45-b1073ddd2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-10c896d2-1639-413b-bfde-761d0f6794f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-4cabf836-4983-47a8-9be8-43a54366b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-4da2f1a4-d565-4a14-a348-3261d2e19624,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-e03ba4e9-5bd9-4500-9c6b-1017d2b96360,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-5b121047-c5ce-4121-ad07-9c2783d6d383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359796947-172.17.0.10-1596938885343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-7b518e6e-b7ac-495a-ad66-17433160423a,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-36afc4f5-f2fc-4927-994d-9965523a2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-099c4d14-174c-4a59-9a45-b1073ddd2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-10c896d2-1639-413b-bfde-761d0f6794f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-4cabf836-4983-47a8-9be8-43a54366b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-4da2f1a4-d565-4a14-a348-3261d2e19624,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-e03ba4e9-5bd9-4500-9c6b-1017d2b96360,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-5b121047-c5ce-4121-ad07-9c2783d6d383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709677764-172.17.0.10-1596939053954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-ea42aeac-bf70-4e08-9b1a-4a2eb08ee134,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-8995b48e-38dd-41ba-bddb-e57b52b99c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-49782ddf-bf3e-4be3-a007-dcd8712f4064,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-90003156-0cb5-49eb-ac7c-c5244b475b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-85e955f1-ab19-483f-86db-c98324c37d37,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-21d95c4e-eb4c-4ed3-9787-9df004028bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-b1427426-0280-4a69-a6fc-a5319597efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-cbdb4ea3-9221-4bd6-ba30-a44e4cbaba87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709677764-172.17.0.10-1596939053954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-ea42aeac-bf70-4e08-9b1a-4a2eb08ee134,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-8995b48e-38dd-41ba-bddb-e57b52b99c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-49782ddf-bf3e-4be3-a007-dcd8712f4064,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-90003156-0cb5-49eb-ac7c-c5244b475b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-85e955f1-ab19-483f-86db-c98324c37d37,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-21d95c4e-eb4c-4ed3-9787-9df004028bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-b1427426-0280-4a69-a6fc-a5319597efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-cbdb4ea3-9221-4bd6-ba30-a44e4cbaba87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706181215-172.17.0.10-1596939571089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-cf17dec1-f580-4d63-81d8-042eab9e7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-b8a88518-c7e4-4435-9638-525e47b11e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-8f8eff30-52d2-41b7-9357-5fe0f6b3faf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-3580ca1d-3eb9-4bcb-9fea-1abe723bf200,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-dd4ef1a3-4466-46a9-9139-8f441c951866,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-5c6922c0-9e13-484f-9244-7222dd973092,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-532275b0-51bf-4448-9632-0e20ffc98963,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-d4c05f56-4e74-4c46-b647-2d1e9b1984d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706181215-172.17.0.10-1596939571089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-cf17dec1-f580-4d63-81d8-042eab9e7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-b8a88518-c7e4-4435-9638-525e47b11e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-8f8eff30-52d2-41b7-9357-5fe0f6b3faf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-3580ca1d-3eb9-4bcb-9fea-1abe723bf200,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-dd4ef1a3-4466-46a9-9139-8f441c951866,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-5c6922c0-9e13-484f-9244-7222dd973092,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-532275b0-51bf-4448-9632-0e20ffc98963,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-d4c05f56-4e74-4c46-b647-2d1e9b1984d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851702737-172.17.0.10-1596939687035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-dde93c45-aeb8-416c-bfe1-d53f3f0e50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-ae6ea4f5-6503-47a6-b62a-3829848394a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-44425769-5e93-40bc-8961-d2d8a8996da6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-c8c31a1f-69f1-4c9b-bce6-065c365c3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-6eb96f09-63d1-47d0-8f08-b51a5defa4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-bf2f9e20-489b-4f32-acd9-2f856004b178,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-96dabb10-8ad2-4bb6-9f74-5bab0a8d3aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-653e94b9-5e68-4e2a-a25b-6b34d7a302c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851702737-172.17.0.10-1596939687035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-dde93c45-aeb8-416c-bfe1-d53f3f0e50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-ae6ea4f5-6503-47a6-b62a-3829848394a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-44425769-5e93-40bc-8961-d2d8a8996da6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-c8c31a1f-69f1-4c9b-bce6-065c365c3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-6eb96f09-63d1-47d0-8f08-b51a5defa4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-bf2f9e20-489b-4f32-acd9-2f856004b178,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-96dabb10-8ad2-4bb6-9f74-5bab0a8d3aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-653e94b9-5e68-4e2a-a25b-6b34d7a302c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555538494-172.17.0.10-1596939816538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44034,DS-f9a371de-f119-4bc0-b3de-80154012e85c,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-3412468f-6a24-46bb-89b7-a0267ab3b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-c0d09e1a-f42b-4534-90ab-6fb57c6c399b,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-6862d207-983f-4bbf-9bfb-e93c762915a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-579c7abd-c66b-437e-82e7-f2df2d4753a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-c5eb33e7-f22f-4bad-9cfb-0ec627c4ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-5361e3a2-0972-4de2-96e9-6bb24697bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-7f39c3c7-157b-4e06-bb5d-44d92b2a8866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555538494-172.17.0.10-1596939816538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44034,DS-f9a371de-f119-4bc0-b3de-80154012e85c,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-3412468f-6a24-46bb-89b7-a0267ab3b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-c0d09e1a-f42b-4534-90ab-6fb57c6c399b,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-6862d207-983f-4bbf-9bfb-e93c762915a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-579c7abd-c66b-437e-82e7-f2df2d4753a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-c5eb33e7-f22f-4bad-9cfb-0ec627c4ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-5361e3a2-0972-4de2-96e9-6bb24697bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-7f39c3c7-157b-4e06-bb5d-44d92b2a8866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558718266-172.17.0.10-1596939895016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37103,DS-c692b470-ff55-4bf3-87cf-1dd860a664d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-050af876-3ed3-48d7-8113-5ddbf03bb2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-66311c90-121d-4ff0-8c59-6fea83b718da,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-dff7c71c-d8d7-4cd2-ac9a-b18fcadfe620,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b3d30fe4-0dc6-4cb1-af1a-2c0f2241f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-c8bf7bbd-d85c-4860-8af5-534094e39e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-e01076f8-7560-44f9-8400-03938a4f5da2,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-792f26da-83fa-4466-9198-7d9412528abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558718266-172.17.0.10-1596939895016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37103,DS-c692b470-ff55-4bf3-87cf-1dd860a664d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-050af876-3ed3-48d7-8113-5ddbf03bb2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-66311c90-121d-4ff0-8c59-6fea83b718da,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-dff7c71c-d8d7-4cd2-ac9a-b18fcadfe620,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b3d30fe4-0dc6-4cb1-af1a-2c0f2241f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-c8bf7bbd-d85c-4860-8af5-534094e39e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-e01076f8-7560-44f9-8400-03938a4f5da2,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-792f26da-83fa-4466-9198-7d9412528abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840066226-172.17.0.10-1596940010078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-829302c0-cfd3-48eb-9b3f-56fb66780e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-6fe7f13f-de42-4b7b-9b54-2c55a527f5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-e1a5b069-5556-4ed7-ad06-d51e196ff808,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-d5614a2d-2dc7-4158-bd2d-d1c6f6a249f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-0c3642c8-7841-43df-8f06-5c204428f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-f8155105-50bd-48e1-a1d4-1032c5591dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-cee9be9b-f8d3-4465-a2ce-88b3b9f68be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-126ae049-4e3c-4ed9-ac9d-6e33a7cdf894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840066226-172.17.0.10-1596940010078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-829302c0-cfd3-48eb-9b3f-56fb66780e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-6fe7f13f-de42-4b7b-9b54-2c55a527f5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-e1a5b069-5556-4ed7-ad06-d51e196ff808,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-d5614a2d-2dc7-4158-bd2d-d1c6f6a249f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-0c3642c8-7841-43df-8f06-5c204428f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-f8155105-50bd-48e1-a1d4-1032c5591dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-cee9be9b-f8d3-4465-a2ce-88b3b9f68be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-126ae049-4e3c-4ed9-ac9d-6e33a7cdf894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50172942-172.17.0.10-1596940576839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35933,DS-a4db2fd1-46c4-466a-828e-43934830b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-6621f4ed-a1ca-4974-96c5-559c533042e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-bd75b0fa-738e-42b4-aae7-f4cf0e30e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-f2e762e1-6046-441a-93d6-c9f3626a6042,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-82e6d814-d592-43c6-aafd-5b2aae27300f,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-26c6dc84-53ef-445a-bd72-9da2a9710c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-e1e6289a-093d-453b-8bd7-447418b8a335,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6a295875-bd0b-4a7c-aa59-230d1822c735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50172942-172.17.0.10-1596940576839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35933,DS-a4db2fd1-46c4-466a-828e-43934830b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-6621f4ed-a1ca-4974-96c5-559c533042e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-bd75b0fa-738e-42b4-aae7-f4cf0e30e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-f2e762e1-6046-441a-93d6-c9f3626a6042,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-82e6d814-d592-43c6-aafd-5b2aae27300f,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-26c6dc84-53ef-445a-bd72-9da2a9710c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-e1e6289a-093d-453b-8bd7-447418b8a335,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6a295875-bd0b-4a7c-aa59-230d1822c735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113398982-172.17.0.10-1596940931599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-be7122fe-1c7f-4e3f-b488-bcd2f0b81f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-4b6b55b1-430c-4219-b153-836c330d3038,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-7a05c2c4-7b79-434e-8a46-e35bd41fab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-7fec975a-6d8f-4321-be6d-7fd86072fce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-91c48489-19b2-4ad4-9fd6-829afe6adfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-5f8c1145-d144-4783-a34a-7d95ae04953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-177e8240-3a7c-4966-a5ae-69d0c6091fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-1ba4f06a-0b49-4625-a647-18be8ca8f3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113398982-172.17.0.10-1596940931599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-be7122fe-1c7f-4e3f-b488-bcd2f0b81f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-4b6b55b1-430c-4219-b153-836c330d3038,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-7a05c2c4-7b79-434e-8a46-e35bd41fab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-7fec975a-6d8f-4321-be6d-7fd86072fce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-91c48489-19b2-4ad4-9fd6-829afe6adfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-5f8c1145-d144-4783-a34a-7d95ae04953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-177e8240-3a7c-4966-a5ae-69d0c6091fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-1ba4f06a-0b49-4625-a647-18be8ca8f3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656564116-172.17.0.10-1596942162978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42562,DS-2c82f984-2af5-47aa-9255-86074e0c9009,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-41da80af-89a0-430e-b86b-4d6b32050795,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-77fa6632-3d7c-4012-9598-8a2b9fd0ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-241c3738-401e-4306-97c7-ff162ad529fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-7885d6fb-f9ef-4c53-b95e-3576dea93d87,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-66294b3a-44c2-4a42-80f8-f95159323f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-f3b887dd-50b6-41a9-84cc-8f5315f932b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-237a5863-33c6-4eb1-a6f0-e38ab6127b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656564116-172.17.0.10-1596942162978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42562,DS-2c82f984-2af5-47aa-9255-86074e0c9009,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-41da80af-89a0-430e-b86b-4d6b32050795,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-77fa6632-3d7c-4012-9598-8a2b9fd0ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-241c3738-401e-4306-97c7-ff162ad529fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-7885d6fb-f9ef-4c53-b95e-3576dea93d87,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-66294b3a-44c2-4a42-80f8-f95159323f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-f3b887dd-50b6-41a9-84cc-8f5315f932b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-237a5863-33c6-4eb1-a6f0-e38ab6127b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323642402-172.17.0.10-1596942499703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-e23b3679-96ec-4518-aacc-af9faba440f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-cda8010f-f8d5-4d0e-8144-fce0e00dd280,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-b4acd102-86ca-4fbf-994c-0ee731af1ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-9a533d87-2747-4a1f-9bb3-3d0a5229536b,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-b20c3651-2400-4529-8f85-c0099bf14f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a526621c-b563-4b4a-b967-a03d2161e789,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-eaf76e16-fc06-4e3b-92fd-993a40f8e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-7497e136-e0fa-4b98-a27d-f0d0b147f7ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323642402-172.17.0.10-1596942499703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-e23b3679-96ec-4518-aacc-af9faba440f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-cda8010f-f8d5-4d0e-8144-fce0e00dd280,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-b4acd102-86ca-4fbf-994c-0ee731af1ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-9a533d87-2747-4a1f-9bb3-3d0a5229536b,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-b20c3651-2400-4529-8f85-c0099bf14f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a526621c-b563-4b4a-b967-a03d2161e789,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-eaf76e16-fc06-4e3b-92fd-993a40f8e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-7497e136-e0fa-4b98-a27d-f0d0b147f7ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6183
