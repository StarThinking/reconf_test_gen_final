reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409660480-172.17.0.10-1596902605064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38369,DS-ddc98f05-26a8-4080-a45f-a15ce5e3d58a,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-2ce59c83-a0d8-4b5e-8038-bcf4fe54f446,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-d42e5adf-8c55-4fc9-9df2-24ea1a38f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-e63857b9-a662-4013-9648-6673948ca229,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-7b17e36f-1a9b-449a-956a-3634741e223b,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-95d7832f-8dec-47b0-b9da-ef3aa0ef72f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-803a8fd9-0d0e-4e3f-bab7-d151f9f39744,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-c6ca17b7-f81c-4a62-82ee-2dfe0d43a794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409660480-172.17.0.10-1596902605064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38369,DS-ddc98f05-26a8-4080-a45f-a15ce5e3d58a,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-2ce59c83-a0d8-4b5e-8038-bcf4fe54f446,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-d42e5adf-8c55-4fc9-9df2-24ea1a38f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-e63857b9-a662-4013-9648-6673948ca229,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-7b17e36f-1a9b-449a-956a-3634741e223b,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-95d7832f-8dec-47b0-b9da-ef3aa0ef72f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-803a8fd9-0d0e-4e3f-bab7-d151f9f39744,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-c6ca17b7-f81c-4a62-82ee-2dfe0d43a794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930668798-172.17.0.10-1596903254413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-7c5feda4-dff3-448f-ac27-8f9afa073fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-9536e423-2e17-45ac-afb8-c96d03309f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-5b53cdf3-553b-4cb1-9ea9-f8acaac716cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-6cec4081-7b6f-4a81-9ed7-d4070a701b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-8f51303b-da2b-4cd7-950d-791a20a49e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-d1aad609-cd3a-420b-bec2-c6e55f178faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-c202e1aa-ebf2-43c1-be4d-34e8028e58b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-ffdde0d8-a80f-4097-b829-ded305ed8382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930668798-172.17.0.10-1596903254413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-7c5feda4-dff3-448f-ac27-8f9afa073fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-9536e423-2e17-45ac-afb8-c96d03309f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-5b53cdf3-553b-4cb1-9ea9-f8acaac716cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-6cec4081-7b6f-4a81-9ed7-d4070a701b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-8f51303b-da2b-4cd7-950d-791a20a49e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-d1aad609-cd3a-420b-bec2-c6e55f178faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-c202e1aa-ebf2-43c1-be4d-34e8028e58b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-ffdde0d8-a80f-4097-b829-ded305ed8382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478800562-172.17.0.10-1596903827043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-cc3f0c1a-b4ad-4c83-8ad2-72a6f051e616,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-72d17111-5975-4664-8b7d-02aadfb290e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-755ce6e1-0067-4939-97d7-31b641a80878,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-232c339c-af1d-4111-94cf-e2abd2fe8347,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-40b6d7a8-06e4-494d-a3ae-3c19273faa95,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-44267a9f-ce63-4c87-83b0-4a36b483ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-52a4ffc2-6e67-4d43-829c-b0a90c7081b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-bb1ca7d3-eb91-428c-9fcd-3731415be26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478800562-172.17.0.10-1596903827043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-cc3f0c1a-b4ad-4c83-8ad2-72a6f051e616,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-72d17111-5975-4664-8b7d-02aadfb290e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-755ce6e1-0067-4939-97d7-31b641a80878,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-232c339c-af1d-4111-94cf-e2abd2fe8347,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-40b6d7a8-06e4-494d-a3ae-3c19273faa95,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-44267a9f-ce63-4c87-83b0-4a36b483ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-52a4ffc2-6e67-4d43-829c-b0a90c7081b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-bb1ca7d3-eb91-428c-9fcd-3731415be26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71286086-172.17.0.10-1596903897659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-2665dabc-f247-466f-9114-1433b41c8fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-4ee786c8-8490-4ea8-ae3e-223b7ce2cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-1c72942a-b87b-45fb-b5c8-0293ed69c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-21fe4370-cb2d-4670-b974-eabff53c65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-ba09731c-18df-45b5-a66a-936b46bb6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-c8fcaeef-1b25-49d5-ae4b-5f2872754909,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-5967326f-8895-4877-9251-b457e490badd,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-621de89d-9997-432d-8821-368013bde429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71286086-172.17.0.10-1596903897659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-2665dabc-f247-466f-9114-1433b41c8fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-4ee786c8-8490-4ea8-ae3e-223b7ce2cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-1c72942a-b87b-45fb-b5c8-0293ed69c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-21fe4370-cb2d-4670-b974-eabff53c65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-ba09731c-18df-45b5-a66a-936b46bb6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-c8fcaeef-1b25-49d5-ae4b-5f2872754909,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-5967326f-8895-4877-9251-b457e490badd,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-621de89d-9997-432d-8821-368013bde429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204072909-172.17.0.10-1596904755332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-50c35f9a-51ab-4dba-b207-624bcbc6f8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-191a6593-1e74-4f3b-99eb-a836268b0043,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ae913562-cd27-4d80-bae0-540633767298,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a51b5677-2223-4de7-9f12-a967f3f4be93,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-79190475-ea70-4309-aed8-d2f8e3d5125d,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-fc3aea93-6088-4f92-8cb0-780b50dd9c83,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-4ec0ff74-e338-4d17-9607-bbaccd5816e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-6bc027ce-54f7-410c-aed0-92b189daeaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204072909-172.17.0.10-1596904755332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-50c35f9a-51ab-4dba-b207-624bcbc6f8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-191a6593-1e74-4f3b-99eb-a836268b0043,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ae913562-cd27-4d80-bae0-540633767298,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a51b5677-2223-4de7-9f12-a967f3f4be93,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-79190475-ea70-4309-aed8-d2f8e3d5125d,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-fc3aea93-6088-4f92-8cb0-780b50dd9c83,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-4ec0ff74-e338-4d17-9607-bbaccd5816e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-6bc027ce-54f7-410c-aed0-92b189daeaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388116141-172.17.0.10-1596905160416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-d8468bfd-00ec-4827-b151-b1f74f89437b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-16d1a85d-3278-4fc9-a0bd-241c6d5b2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fb2bc2c7-d17a-4ccd-af05-568b13d2965d,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-522fb847-d448-44f6-8f66-8c848f4e0e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-d8800d2b-5433-48f6-8412-0ca4c25e12af,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-a4930d97-9711-4d0c-9396-e650bf095276,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-919dc8fc-26c8-4b52-bf1e-b39e4ccd88c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-48aa651d-17b4-4503-9bef-7d5999519d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388116141-172.17.0.10-1596905160416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-d8468bfd-00ec-4827-b151-b1f74f89437b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-16d1a85d-3278-4fc9-a0bd-241c6d5b2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-fb2bc2c7-d17a-4ccd-af05-568b13d2965d,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-522fb847-d448-44f6-8f66-8c848f4e0e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-d8800d2b-5433-48f6-8412-0ca4c25e12af,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-a4930d97-9711-4d0c-9396-e650bf095276,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-919dc8fc-26c8-4b52-bf1e-b39e4ccd88c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-48aa651d-17b4-4503-9bef-7d5999519d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648599771-172.17.0.10-1596905609345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42531,DS-691cb532-1b83-495c-be7d-b7a20729f5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-da4b5ca0-8d02-44ce-b559-a8ba7f00298c,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-d7e32a83-1e62-4a31-b77b-0231a642da64,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-565f6ec6-8b4a-40b1-a56a-b81dc9b20e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-2ccf8ef1-0263-42c3-83a6-3d2c99e562c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-15f30e8a-2310-4f5e-91bf-97fae29c0605,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-2c55dab0-ae7b-444d-b778-47f668af143e,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-f8b8bf77-a0f1-46cf-a567-156aa239ce59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648599771-172.17.0.10-1596905609345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42531,DS-691cb532-1b83-495c-be7d-b7a20729f5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-da4b5ca0-8d02-44ce-b559-a8ba7f00298c,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-d7e32a83-1e62-4a31-b77b-0231a642da64,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-565f6ec6-8b4a-40b1-a56a-b81dc9b20e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-2ccf8ef1-0263-42c3-83a6-3d2c99e562c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-15f30e8a-2310-4f5e-91bf-97fae29c0605,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-2c55dab0-ae7b-444d-b778-47f668af143e,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-f8b8bf77-a0f1-46cf-a567-156aa239ce59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243710480-172.17.0.10-1596906020477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-6883e1e1-3590-42f9-96f8-f3dce783ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-69ef1635-bb1e-4ad4-b0dc-500c0f7688c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-4a7e7f22-3d00-497a-8519-876cff9dc223,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-db973670-6a8a-43f0-b4c0-bf5c829c0cae,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-1bab6eca-7827-48c2-9510-bf00fd143d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-69c7b7cb-0d50-4f3a-b49b-a05787c05f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-d9166bcd-4902-4ed1-8f70-d09dd6857177,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-e6b2586d-d99b-43e7-a139-c2e786d76a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243710480-172.17.0.10-1596906020477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-6883e1e1-3590-42f9-96f8-f3dce783ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-69ef1635-bb1e-4ad4-b0dc-500c0f7688c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-4a7e7f22-3d00-497a-8519-876cff9dc223,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-db973670-6a8a-43f0-b4c0-bf5c829c0cae,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-1bab6eca-7827-48c2-9510-bf00fd143d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-69c7b7cb-0d50-4f3a-b49b-a05787c05f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-d9166bcd-4902-4ed1-8f70-d09dd6857177,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-e6b2586d-d99b-43e7-a139-c2e786d76a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877066352-172.17.0.10-1596906278265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-52c456f7-3e7b-440e-b4e6-f4eced8e0d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-490d5169-e5d0-4115-b4dd-264ca85d194d,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-28942e12-c57d-4f3b-8e22-f1b2cf6f1ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-99030860-b710-4a41-b6ee-324e9fa98e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-e379dc64-7957-4022-82d5-47b8294151e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-23c65046-a1bd-47db-85ce-01bfdce2e48d,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-84599f99-d808-4bf5-8035-b96bf0938370,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-f73952bb-ba5e-4169-9577-10ca1c148fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877066352-172.17.0.10-1596906278265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-52c456f7-3e7b-440e-b4e6-f4eced8e0d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-490d5169-e5d0-4115-b4dd-264ca85d194d,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-28942e12-c57d-4f3b-8e22-f1b2cf6f1ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-99030860-b710-4a41-b6ee-324e9fa98e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-e379dc64-7957-4022-82d5-47b8294151e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-23c65046-a1bd-47db-85ce-01bfdce2e48d,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-84599f99-d808-4bf5-8035-b96bf0938370,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-f73952bb-ba5e-4169-9577-10ca1c148fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813787591-172.17.0.10-1596906771168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-34123568-f81c-4244-912f-792eda063f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-a5deab3b-371a-42e1-a916-107633fb4fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-d4215cb3-2064-426c-9093-61aa89b19dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-827fec15-e6f8-47d3-ae15-f6dcad355a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-9f2242d2-55a6-4ab1-a32f-ba7cdfa58bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-23f91fce-a42e-425b-9076-ad61775a8b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-f70c1ddf-2344-43cb-9dba-8194add26929,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-d2a8ed5b-b65f-4d2d-92b7-2a587d447a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813787591-172.17.0.10-1596906771168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-34123568-f81c-4244-912f-792eda063f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-a5deab3b-371a-42e1-a916-107633fb4fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-d4215cb3-2064-426c-9093-61aa89b19dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-827fec15-e6f8-47d3-ae15-f6dcad355a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-9f2242d2-55a6-4ab1-a32f-ba7cdfa58bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-23f91fce-a42e-425b-9076-ad61775a8b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-f70c1ddf-2344-43cb-9dba-8194add26929,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-d2a8ed5b-b65f-4d2d-92b7-2a587d447a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019402454-172.17.0.10-1596906962302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43501,DS-e1f5d2c0-d0c9-4740-ae1a-c955bb706065,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-42aaf2f2-d27c-4b54-b7cd-34135707ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-70d887d5-5fcf-4399-9a35-4d46cc1296a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-52b9e7ea-07e4-42d4-a551-c2373f6f7a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-654dd2c8-780f-47ef-b61f-6621b87cf9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-55bac2c8-108e-421e-8011-f69eb779f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-8bfa0b7c-9614-4324-994c-87f7d59ec0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-7940017e-b0b3-4f19-a7fa-071a70d21878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019402454-172.17.0.10-1596906962302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43501,DS-e1f5d2c0-d0c9-4740-ae1a-c955bb706065,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-42aaf2f2-d27c-4b54-b7cd-34135707ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-70d887d5-5fcf-4399-9a35-4d46cc1296a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-52b9e7ea-07e4-42d4-a551-c2373f6f7a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-654dd2c8-780f-47ef-b61f-6621b87cf9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-55bac2c8-108e-421e-8011-f69eb779f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-8bfa0b7c-9614-4324-994c-87f7d59ec0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-7940017e-b0b3-4f19-a7fa-071a70d21878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098760088-172.17.0.10-1596907180680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-df396523-cef6-434b-93b5-bc491aad335f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-21a5acb6-ae17-4d2a-9f2f-74b8cdb5ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-2a7c6581-f9a2-4e62-bbe3-9b1364b55026,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-a21db61e-0ac6-46a2-bf40-aba272f8a0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-5e81f4ce-c641-464f-9a53-34af0561eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-807bda5f-2082-4ef8-9000-7e66063f0580,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-06069e30-d894-4034-b592-a382b2016755,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-3ea6d452-d372-4250-b1be-e05dba20f838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098760088-172.17.0.10-1596907180680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-df396523-cef6-434b-93b5-bc491aad335f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-21a5acb6-ae17-4d2a-9f2f-74b8cdb5ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-2a7c6581-f9a2-4e62-bbe3-9b1364b55026,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-a21db61e-0ac6-46a2-bf40-aba272f8a0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-5e81f4ce-c641-464f-9a53-34af0561eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-807bda5f-2082-4ef8-9000-7e66063f0580,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-06069e30-d894-4034-b592-a382b2016755,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-3ea6d452-d372-4250-b1be-e05dba20f838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5482
