reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599121289-172.17.0.6-1596904179464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-dd7ed72b-2b2c-49ab-bdb5-74614d209b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-ea3920a0-29b7-499c-8d08-e12a9c0b7fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-ff704371-d952-484b-a816-ebda9cd57ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-97b335ff-d2ab-4839-9aec-9f3685f9ad82,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-074bc58d-47ea-495f-8309-e8f787ca9fab,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-b67f79d0-d825-41ad-ba19-88c7bb73d802,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-71d4ad81-d643-44de-9df8-77a086b88f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-858394fe-8177-4666-bd5a-5746d09b2876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599121289-172.17.0.6-1596904179464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-dd7ed72b-2b2c-49ab-bdb5-74614d209b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-ea3920a0-29b7-499c-8d08-e12a9c0b7fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-ff704371-d952-484b-a816-ebda9cd57ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-97b335ff-d2ab-4839-9aec-9f3685f9ad82,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-074bc58d-47ea-495f-8309-e8f787ca9fab,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-b67f79d0-d825-41ad-ba19-88c7bb73d802,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-71d4ad81-d643-44de-9df8-77a086b88f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-858394fe-8177-4666-bd5a-5746d09b2876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877699672-172.17.0.6-1596904246532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35721,DS-abbbd2bd-7aa8-4ec4-82d0-ac1b8339c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-49dfe765-ab4c-4f31-8c4d-4f6101678a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-49126c1a-cf8e-4ab6-92d5-fb14fd0ed013,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-d6ba9f35-c127-4427-8e36-038f16e47da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-2cb61dd7-dc00-43a4-8e5e-b40606632e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-77d3e87c-3725-4142-ad58-db8313ccddec,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-ea8151fe-b926-4047-a16f-2243a024fce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-ae2e32dd-e7f6-4804-be28-9e917fa2a9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877699672-172.17.0.6-1596904246532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35721,DS-abbbd2bd-7aa8-4ec4-82d0-ac1b8339c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-49dfe765-ab4c-4f31-8c4d-4f6101678a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-49126c1a-cf8e-4ab6-92d5-fb14fd0ed013,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-d6ba9f35-c127-4427-8e36-038f16e47da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-2cb61dd7-dc00-43a4-8e5e-b40606632e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-77d3e87c-3725-4142-ad58-db8313ccddec,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-ea8151fe-b926-4047-a16f-2243a024fce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-ae2e32dd-e7f6-4804-be28-9e917fa2a9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084490740-172.17.0.6-1596904540970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-4734d30b-b8d1-40ce-bdaf-1a36258af9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-3a8a6035-11d1-485a-95e8-469a3c8e8e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-889a9df2-0b03-4471-bb4c-1e136e5221ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-e6367fd3-f862-4907-803f-f69ece6bc31a,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a73a1818-de58-4aa8-972b-13fb7f873221,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-2082afd2-40fc-4ae5-890e-94b060102d40,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-c47d2599-3599-4eb0-87e5-be984a0a5844,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-8f83acb4-76d9-4b3e-8bea-cb2f14ec83da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084490740-172.17.0.6-1596904540970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-4734d30b-b8d1-40ce-bdaf-1a36258af9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-3a8a6035-11d1-485a-95e8-469a3c8e8e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-889a9df2-0b03-4471-bb4c-1e136e5221ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-e6367fd3-f862-4907-803f-f69ece6bc31a,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a73a1818-de58-4aa8-972b-13fb7f873221,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-2082afd2-40fc-4ae5-890e-94b060102d40,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-c47d2599-3599-4eb0-87e5-be984a0a5844,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-8f83acb4-76d9-4b3e-8bea-cb2f14ec83da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439282846-172.17.0.6-1596904580154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42242,DS-df0e10f1-4387-459f-8edb-ab8374660959,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-8f1ea9c1-678c-49ff-89d2-0ec37305945f,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-ba37dd27-d3e8-424c-ae41-6d69ed6fabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-9a0e1030-b35f-4430-8e28-73e5ddc7f931,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-bd306038-b4f6-4347-9087-e6c624fa7db3,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-0b0deb68-b086-4c15-85ff-d8abf1a7dc11,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-fb1dd19c-c238-4460-b70e-23d0acd9494f,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-f950ed91-dabd-48ed-80c0-0269ac398950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439282846-172.17.0.6-1596904580154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42242,DS-df0e10f1-4387-459f-8edb-ab8374660959,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-8f1ea9c1-678c-49ff-89d2-0ec37305945f,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-ba37dd27-d3e8-424c-ae41-6d69ed6fabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-9a0e1030-b35f-4430-8e28-73e5ddc7f931,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-bd306038-b4f6-4347-9087-e6c624fa7db3,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-0b0deb68-b086-4c15-85ff-d8abf1a7dc11,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-fb1dd19c-c238-4460-b70e-23d0acd9494f,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-f950ed91-dabd-48ed-80c0-0269ac398950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865930083-172.17.0.6-1596904612449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-d3366cdf-efc0-4a0f-b6d0-50885857596f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-9266cd23-0bd7-4e7e-bddc-e998f26abc31,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-2010b4c4-0b27-4a18-b063-b257a93aa482,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-984a2661-1aae-48f9-be74-c869ee060d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-87cb05cd-9bb2-4b80-9c8a-cea8e5f093ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-d8c11f90-7045-4c2a-9062-01c2f280bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-f1f585f5-f6ed-47b8-8690-193c2947fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-1a6aab5c-a9cd-43ad-9c9f-d2572e919005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865930083-172.17.0.6-1596904612449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-d3366cdf-efc0-4a0f-b6d0-50885857596f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-9266cd23-0bd7-4e7e-bddc-e998f26abc31,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-2010b4c4-0b27-4a18-b063-b257a93aa482,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-984a2661-1aae-48f9-be74-c869ee060d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-87cb05cd-9bb2-4b80-9c8a-cea8e5f093ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-d8c11f90-7045-4c2a-9062-01c2f280bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-f1f585f5-f6ed-47b8-8690-193c2947fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-1a6aab5c-a9cd-43ad-9c9f-d2572e919005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540438287-172.17.0.6-1596905916857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-367568d6-d495-45aa-abb7-6f7e14a71807,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-c336e8a2-4054-4843-8523-d27d653ff288,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-6f32085a-de84-4abf-bdca-28010856eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-e57b883b-1bb6-41b8-bc25-2b79d78a8c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-5c98500a-f43b-4eb7-8680-8a7466928de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-582655dc-1646-4836-b8fa-1af970880570,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-aaee1052-89cd-4c45-842a-ba6e677616a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-ab9dfab7-88d1-4fdf-978f-dcebc40d4273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540438287-172.17.0.6-1596905916857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-367568d6-d495-45aa-abb7-6f7e14a71807,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-c336e8a2-4054-4843-8523-d27d653ff288,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-6f32085a-de84-4abf-bdca-28010856eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-e57b883b-1bb6-41b8-bc25-2b79d78a8c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-5c98500a-f43b-4eb7-8680-8a7466928de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-582655dc-1646-4836-b8fa-1af970880570,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-aaee1052-89cd-4c45-842a-ba6e677616a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-ab9dfab7-88d1-4fdf-978f-dcebc40d4273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802457110-172.17.0.6-1596906016822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-11576ec9-6c2c-43cc-92f8-5dd24077ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-61ddbc34-7d78-4121-9897-78184ddc0da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ad3a6810-8749-422c-be02-b178b55b6e23,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-c493f7f7-3172-486d-8cb9-bccf320dee78,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-dd7e9f5a-6013-4672-ae67-89815252e1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-03f95970-065f-49e3-b10d-4be4dc51272a,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-23d9f640-f7e1-49e7-9306-e9fbc4a2ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-dce936a3-c2f4-4f22-b21f-042b8ae4c746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802457110-172.17.0.6-1596906016822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-11576ec9-6c2c-43cc-92f8-5dd24077ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-61ddbc34-7d78-4121-9897-78184ddc0da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ad3a6810-8749-422c-be02-b178b55b6e23,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-c493f7f7-3172-486d-8cb9-bccf320dee78,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-dd7e9f5a-6013-4672-ae67-89815252e1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-03f95970-065f-49e3-b10d-4be4dc51272a,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-23d9f640-f7e1-49e7-9306-e9fbc4a2ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-dce936a3-c2f4-4f22-b21f-042b8ae4c746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873208323-172.17.0.6-1596906614569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45083,DS-0db4829c-3f7a-4912-97ac-e36eaa8058f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-48e8980c-e615-42e8-a1f2-f21340c1b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-60dfa7f8-ff96-4ada-87fc-c10e22252760,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-99589b18-be91-4332-a9e0-5d16642604cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-27681e54-9420-4dcb-929c-a0ba2a076ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-d3af847c-30c9-47a9-aecc-1e945ed9b7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-6fd4cc73-2b8c-4f73-ade6-644f7d5b501b,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-51915a31-b1b3-45d5-a3e0-d0b553cf9f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873208323-172.17.0.6-1596906614569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45083,DS-0db4829c-3f7a-4912-97ac-e36eaa8058f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-48e8980c-e615-42e8-a1f2-f21340c1b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-60dfa7f8-ff96-4ada-87fc-c10e22252760,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-99589b18-be91-4332-a9e0-5d16642604cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-27681e54-9420-4dcb-929c-a0ba2a076ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-d3af847c-30c9-47a9-aecc-1e945ed9b7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-6fd4cc73-2b8c-4f73-ade6-644f7d5b501b,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-51915a31-b1b3-45d5-a3e0-d0b553cf9f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635757339-172.17.0.6-1596907100819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-7fed3e1b-0983-42ee-943a-a37356dc6afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-c38d70f8-a1d4-482c-8516-b6403606b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-952423c7-c4ab-4850-b944-dc4c470b47da,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-7831b555-c0aa-4fc4-82dd-bfaa67b6cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-696d3947-379d-4091-b607-5ceea87a2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-2edb070a-79b4-44a3-a4ac-6c5e4f7be734,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-c9dd21fd-561f-48da-a4ca-7e8f7c656083,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-c3cd11e0-be9d-4048-8307-2c6cf9c3e8a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635757339-172.17.0.6-1596907100819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-7fed3e1b-0983-42ee-943a-a37356dc6afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-c38d70f8-a1d4-482c-8516-b6403606b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-952423c7-c4ab-4850-b944-dc4c470b47da,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-7831b555-c0aa-4fc4-82dd-bfaa67b6cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-696d3947-379d-4091-b607-5ceea87a2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-2edb070a-79b4-44a3-a4ac-6c5e4f7be734,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-c9dd21fd-561f-48da-a4ca-7e8f7c656083,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-c3cd11e0-be9d-4048-8307-2c6cf9c3e8a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439304553-172.17.0.6-1596907241725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-c1fc15da-b64f-451c-9718-a11e57362029,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-52b8f76d-0920-4eb2-8bf9-75cd125f2452,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-53519448-9afe-4887-8efe-1b07f2d822c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-023b2e0f-4127-418c-a32e-769542f0aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-ea8b179e-23b9-4a86-a640-49618d06d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-3e87e31c-d986-499c-b595-ca6e68748a21,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-c5547eee-d268-4c09-9e4d-c9f94425017d,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-9e64623b-1151-4440-b951-d671f600a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439304553-172.17.0.6-1596907241725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-c1fc15da-b64f-451c-9718-a11e57362029,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-52b8f76d-0920-4eb2-8bf9-75cd125f2452,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-53519448-9afe-4887-8efe-1b07f2d822c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-023b2e0f-4127-418c-a32e-769542f0aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-ea8b179e-23b9-4a86-a640-49618d06d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-3e87e31c-d986-499c-b595-ca6e68748a21,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-c5547eee-d268-4c09-9e4d-c9f94425017d,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-9e64623b-1151-4440-b951-d671f600a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122471124-172.17.0.6-1596907344252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-317830dc-406d-40ec-8fa1-de93b3e42874,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-d1c6299a-cb7b-4720-9bd6-891ed6aa98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-c8e09bb9-ad77-47e5-aab3-1e248aaed9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-f2daca77-4d1c-41ec-9dd4-c0a44cdee5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-177bb8a1-17c5-4df3-84cf-2ed008cfc843,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-d8b0313d-84f2-4c82-b77f-eda96a99cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-471fd0da-0cc8-416f-a2b2-3b3a93b9e392,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-edc3eadf-fb66-4c2d-83a1-5fc9e68afea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122471124-172.17.0.6-1596907344252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-317830dc-406d-40ec-8fa1-de93b3e42874,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-d1c6299a-cb7b-4720-9bd6-891ed6aa98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-c8e09bb9-ad77-47e5-aab3-1e248aaed9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-f2daca77-4d1c-41ec-9dd4-c0a44cdee5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-177bb8a1-17c5-4df3-84cf-2ed008cfc843,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-d8b0313d-84f2-4c82-b77f-eda96a99cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-471fd0da-0cc8-416f-a2b2-3b3a93b9e392,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-edc3eadf-fb66-4c2d-83a1-5fc9e68afea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754845802-172.17.0.6-1596907682535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-0daaefae-488a-4acc-8c1f-ec1b55b3bbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-acb1cf02-3c70-4dc6-ae20-9633403bd754,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-302c08f8-6181-48f9-88a9-50142923d078,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-ac30ee09-6928-427b-ae07-9c1ca86a8208,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-3393eaa8-1bd2-4fb1-8be3-e1ee1ac38b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-ac60a833-8b88-456d-a4c8-9b5608d6b90a,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-eb25083a-2b51-436e-881d-6e811ced7d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-76346b63-f615-44a0-9b3d-1f58231c4082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754845802-172.17.0.6-1596907682535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-0daaefae-488a-4acc-8c1f-ec1b55b3bbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-acb1cf02-3c70-4dc6-ae20-9633403bd754,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-302c08f8-6181-48f9-88a9-50142923d078,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-ac30ee09-6928-427b-ae07-9c1ca86a8208,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-3393eaa8-1bd2-4fb1-8be3-e1ee1ac38b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-ac60a833-8b88-456d-a4c8-9b5608d6b90a,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-eb25083a-2b51-436e-881d-6e811ced7d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-76346b63-f615-44a0-9b3d-1f58231c4082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755945746-172.17.0.6-1596908035184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-bd1cf73b-f80a-4b68-af96-05e94a2fd291,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-54560a0c-6d7b-4b16-b6e4-7b9b1ce5ed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-eb2c5bd3-2848-4924-95e6-8bbdde3d26fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-ad701947-bb6e-4d77-8383-38a85c5c56dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-15f49841-2572-42a0-8bc0-581bc453c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-9340c20f-5a51-45dc-af8b-2338b5170195,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-83d41bab-9d3f-4507-b01e-8f42566c055f,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-7384aae2-69b3-4a38-8eae-246a2a0e4d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755945746-172.17.0.6-1596908035184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-bd1cf73b-f80a-4b68-af96-05e94a2fd291,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-54560a0c-6d7b-4b16-b6e4-7b9b1ce5ed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-eb2c5bd3-2848-4924-95e6-8bbdde3d26fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-ad701947-bb6e-4d77-8383-38a85c5c56dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-15f49841-2572-42a0-8bc0-581bc453c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-9340c20f-5a51-45dc-af8b-2338b5170195,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-83d41bab-9d3f-4507-b01e-8f42566c055f,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-7384aae2-69b3-4a38-8eae-246a2a0e4d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5240
