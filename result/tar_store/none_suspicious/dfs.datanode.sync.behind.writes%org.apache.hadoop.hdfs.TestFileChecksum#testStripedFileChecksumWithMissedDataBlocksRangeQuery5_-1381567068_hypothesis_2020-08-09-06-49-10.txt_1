reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297669711-172.17.0.10-1596956892586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-d754d0e6-96c8-45f1-b46f-99f909c955dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-02305c70-2bce-4f34-ab4c-cd45287ba553,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-8eb1d368-0cd5-4677-adac-9d0d50b23538,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-1ec9c6eb-4356-49a9-9187-8dfaa5fb9b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-04804ca7-3eab-43a2-af37-a4d55ddc08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-69912d14-4b1d-44a2-af55-60197ef290a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d5302b9a-0e54-41d3-9f49-0d9491b120bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-9fe9ebad-35f2-4299-b126-736683078985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297669711-172.17.0.10-1596956892586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-d754d0e6-96c8-45f1-b46f-99f909c955dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-02305c70-2bce-4f34-ab4c-cd45287ba553,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-8eb1d368-0cd5-4677-adac-9d0d50b23538,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-1ec9c6eb-4356-49a9-9187-8dfaa5fb9b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-04804ca7-3eab-43a2-af37-a4d55ddc08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-69912d14-4b1d-44a2-af55-60197ef290a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d5302b9a-0e54-41d3-9f49-0d9491b120bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-9fe9ebad-35f2-4299-b126-736683078985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396533247-172.17.0.10-1596957090593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39164,DS-7c872e2a-c6fb-4055-9722-5e662448f37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-d4a8ca62-2ef3-4c2b-b8f0-03708c8cedab,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-16d96c5a-cd48-4c8a-8cd7-7bf5facf3d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-b26e6968-7d97-448c-ae76-5bcf4e5749cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-dd724fa3-19c4-4db1-af8d-04c646d517e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-a9b66958-90d7-4524-9734-f09bc3286e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-86cb7874-633c-4017-81d3-da82ec0b9b45,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-973a652d-df93-45d5-a56e-4a401daeb16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396533247-172.17.0.10-1596957090593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39164,DS-7c872e2a-c6fb-4055-9722-5e662448f37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-d4a8ca62-2ef3-4c2b-b8f0-03708c8cedab,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-16d96c5a-cd48-4c8a-8cd7-7bf5facf3d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-b26e6968-7d97-448c-ae76-5bcf4e5749cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-dd724fa3-19c4-4db1-af8d-04c646d517e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-a9b66958-90d7-4524-9734-f09bc3286e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-86cb7874-633c-4017-81d3-da82ec0b9b45,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-973a652d-df93-45d5-a56e-4a401daeb16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119369400-172.17.0.10-1596957266265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-218aa4f1-1dca-40d4-bfcb-5f55c2f701fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-15a0dc43-f9f4-46e9-9fd6-b3991e1a78ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-bd4884be-73e5-46d0-bf9c-e073b74079b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-e49d298b-2fda-4c8c-b534-d2e5878bcfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-7676fea1-8dff-4d0e-aa61-e1ca1f132bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-bdedb456-9c99-43a8-9f8a-97eb6fc14a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-4271f864-593f-4939-802b-341ceff03002,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-06b8281d-a331-4dfb-9068-733b9833c2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119369400-172.17.0.10-1596957266265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-218aa4f1-1dca-40d4-bfcb-5f55c2f701fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-15a0dc43-f9f4-46e9-9fd6-b3991e1a78ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-bd4884be-73e5-46d0-bf9c-e073b74079b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-e49d298b-2fda-4c8c-b534-d2e5878bcfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-7676fea1-8dff-4d0e-aa61-e1ca1f132bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-bdedb456-9c99-43a8-9f8a-97eb6fc14a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-4271f864-593f-4939-802b-341ceff03002,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-06b8281d-a331-4dfb-9068-733b9833c2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523909146-172.17.0.10-1596958097850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46486,DS-5504543c-8fa0-4c91-8dfb-cf49f08f4866,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-f0968af1-5c6d-4249-9c95-c0586028bf39,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-481dac6f-0bd8-4e8d-86d9-ae3798a5014d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7e25318b-c9dc-47fd-bf11-226b80f5eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f29e9e8b-e1db-4b66-8e97-c4c0490a0a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-ebfd8045-6058-426e-8d17-94264d564562,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-f3fad434-5f96-497a-a69e-17e47d1e6708,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-ea0d11f9-f1f5-4204-8cd4-847a2168cc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523909146-172.17.0.10-1596958097850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46486,DS-5504543c-8fa0-4c91-8dfb-cf49f08f4866,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-f0968af1-5c6d-4249-9c95-c0586028bf39,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-481dac6f-0bd8-4e8d-86d9-ae3798a5014d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7e25318b-c9dc-47fd-bf11-226b80f5eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f29e9e8b-e1db-4b66-8e97-c4c0490a0a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-ebfd8045-6058-426e-8d17-94264d564562,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-f3fad434-5f96-497a-a69e-17e47d1e6708,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-ea0d11f9-f1f5-4204-8cd4-847a2168cc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998664465-172.17.0.10-1596958290419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-de88715e-2c58-4a38-8841-0f2afd5149d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-a3faa3e8-3c32-4c01-8596-bf539e1e34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-446a8ad3-2468-4685-95f7-fd5ce28f2125,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-ff7c7280-8e55-4202-bcb2-ae4c0bc62101,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-f9e17e53-7642-464f-a7bb-af89c5b0bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-088dd96e-bd59-400b-a8c5-aaf4fd9f0f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-00c10c33-d2f5-438e-b1a3-6da3a1e4b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-0742a837-4d40-4caf-bf57-b0f398c06852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998664465-172.17.0.10-1596958290419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-de88715e-2c58-4a38-8841-0f2afd5149d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-a3faa3e8-3c32-4c01-8596-bf539e1e34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-446a8ad3-2468-4685-95f7-fd5ce28f2125,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-ff7c7280-8e55-4202-bcb2-ae4c0bc62101,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-f9e17e53-7642-464f-a7bb-af89c5b0bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-088dd96e-bd59-400b-a8c5-aaf4fd9f0f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-00c10c33-d2f5-438e-b1a3-6da3a1e4b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-0742a837-4d40-4caf-bf57-b0f398c06852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4820831-172.17.0.10-1596959476278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-93c86f9a-74ab-445d-9995-e5118f7b38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-3d9de921-7355-4aa3-80ba-fa9661e32001,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-3c7d8caf-8e45-4caf-b0a5-04a94a907437,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-bfb196f2-eb83-4d7e-bc02-33e32e8bc3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-cff682f7-d550-46d5-a4e4-91d6224f8c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-23780f93-8710-4ce0-a8b5-112cc6a84445,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-bebc3935-0d63-4d40-bd8f-8e9e54e4c476,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-25a5132b-5a6c-4b23-822a-8f58a1f3a8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4820831-172.17.0.10-1596959476278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-93c86f9a-74ab-445d-9995-e5118f7b38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-3d9de921-7355-4aa3-80ba-fa9661e32001,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-3c7d8caf-8e45-4caf-b0a5-04a94a907437,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-bfb196f2-eb83-4d7e-bc02-33e32e8bc3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-cff682f7-d550-46d5-a4e4-91d6224f8c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-23780f93-8710-4ce0-a8b5-112cc6a84445,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-bebc3935-0d63-4d40-bd8f-8e9e54e4c476,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-25a5132b-5a6c-4b23-822a-8f58a1f3a8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523190425-172.17.0.10-1596959542605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38710,DS-3b480e23-9095-49e9-a2ac-d3a7a302faff,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-dc89691f-e3e3-4173-982b-d195d13d620d,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-aaddd1fa-494b-41f9-95d5-f6cd754d60f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-af391a55-18e4-4378-8925-47198780a599,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-b6b48362-96c1-4deb-b4a8-223ddf96d6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-3b32cd65-2bf2-4459-b47e-e175397761b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-f74251d1-b703-48ec-9aa9-3f3309c7ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-a489a2b0-b050-4a45-8b34-d4be98e666af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523190425-172.17.0.10-1596959542605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38710,DS-3b480e23-9095-49e9-a2ac-d3a7a302faff,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-dc89691f-e3e3-4173-982b-d195d13d620d,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-aaddd1fa-494b-41f9-95d5-f6cd754d60f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-af391a55-18e4-4378-8925-47198780a599,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-b6b48362-96c1-4deb-b4a8-223ddf96d6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-3b32cd65-2bf2-4459-b47e-e175397761b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-f74251d1-b703-48ec-9aa9-3f3309c7ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-a489a2b0-b050-4a45-8b34-d4be98e666af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109341375-172.17.0.10-1596959600466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-03915645-c02f-4989-8f4b-4ce2f837d7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-2fe0ee80-84b1-40f7-ad18-a8ce5e68518a,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-579fa1ff-cb99-4eca-bc14-605d573969d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-7d4e9e0b-d388-40ae-ba42-55a7b981445c,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-1fdb29cb-65b9-411b-9342-4413ea0d2c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-c68dc468-39e6-46a8-be00-fc8abdc52d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-6e75aec7-c456-4780-8229-67526ddffc70,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-adf25352-51ea-4101-a39b-c9137d2e2a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109341375-172.17.0.10-1596959600466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-03915645-c02f-4989-8f4b-4ce2f837d7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-2fe0ee80-84b1-40f7-ad18-a8ce5e68518a,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-579fa1ff-cb99-4eca-bc14-605d573969d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-7d4e9e0b-d388-40ae-ba42-55a7b981445c,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-1fdb29cb-65b9-411b-9342-4413ea0d2c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-c68dc468-39e6-46a8-be00-fc8abdc52d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-6e75aec7-c456-4780-8229-67526ddffc70,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-adf25352-51ea-4101-a39b-c9137d2e2a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160653217-172.17.0.10-1596959661335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-7ca42f32-c99c-4f22-b00e-42393183c722,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-9f7d6292-fa68-4901-b442-1ad001a79933,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-fe6f6fb2-cf27-46e7-96ab-f3218a9af861,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-5c0ccf90-0e80-4c5b-9030-1b5f0273f81a,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-27b0b42c-1dc5-4f2f-a7cd-1944733c33d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-6e0334df-3d9e-4704-8933-eeb1038c074d,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-37eb0583-b13f-4363-8bae-f5615b373fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-f604c419-cbfe-4100-ac1e-77bf26844436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160653217-172.17.0.10-1596959661335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-7ca42f32-c99c-4f22-b00e-42393183c722,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-9f7d6292-fa68-4901-b442-1ad001a79933,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-fe6f6fb2-cf27-46e7-96ab-f3218a9af861,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-5c0ccf90-0e80-4c5b-9030-1b5f0273f81a,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-27b0b42c-1dc5-4f2f-a7cd-1944733c33d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-6e0334df-3d9e-4704-8933-eeb1038c074d,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-37eb0583-b13f-4363-8bae-f5615b373fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-f604c419-cbfe-4100-ac1e-77bf26844436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498053791-172.17.0.10-1596959828670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-05dd70ea-e2c9-4543-b258-18c519c0de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-e513c351-ba84-40b0-99b6-519cc73c7ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-33434e3a-df7e-44c9-9271-40c6c3a23432,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-187b504a-792b-4ead-a2b0-32fa3f0a829c,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-c898140f-2367-4a62-94e3-baade2d9701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-7414549a-b5d9-408c-9890-942d39030eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-6267c161-c4e6-4511-929f-037301f7c14e,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-f63060e4-c029-49e2-8cdf-36381cd4b70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498053791-172.17.0.10-1596959828670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-05dd70ea-e2c9-4543-b258-18c519c0de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-e513c351-ba84-40b0-99b6-519cc73c7ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-33434e3a-df7e-44c9-9271-40c6c3a23432,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-187b504a-792b-4ead-a2b0-32fa3f0a829c,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-c898140f-2367-4a62-94e3-baade2d9701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-7414549a-b5d9-408c-9890-942d39030eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-6267c161-c4e6-4511-929f-037301f7c14e,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-f63060e4-c029-49e2-8cdf-36381cd4b70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50733666-172.17.0.10-1596960115985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35604,DS-b937f036-085d-46d0-aef2-9725cdc615c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-f82286d6-36f2-4855-abac-dd5b48f9bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-81f061c1-27aa-4c91-bf2d-2c68b44a2125,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-0ede7a65-5944-4891-a87f-2fde02dae4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-72eb1da8-7946-4c2a-b457-1ebec7e256f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-5eb50da2-3935-4b83-b6a2-c4cfa8085871,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-3f38127c-88f1-4f14-adac-d7601a71520b,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-426217a7-a00a-40f5-aacc-08f183dd1fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50733666-172.17.0.10-1596960115985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35604,DS-b937f036-085d-46d0-aef2-9725cdc615c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-f82286d6-36f2-4855-abac-dd5b48f9bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-81f061c1-27aa-4c91-bf2d-2c68b44a2125,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-0ede7a65-5944-4891-a87f-2fde02dae4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-72eb1da8-7946-4c2a-b457-1ebec7e256f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-5eb50da2-3935-4b83-b6a2-c4cfa8085871,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-3f38127c-88f1-4f14-adac-d7601a71520b,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-426217a7-a00a-40f5-aacc-08f183dd1fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111356109-172.17.0.10-1596960342659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-afc919e4-0871-4354-8b68-b9bb5789028b,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-c172b81e-be05-488c-95e6-4c4a6fce106d,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-4609bb0a-e801-4018-ba9b-f11f2305178e,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-447b33ce-fa63-460e-a6b6-793f40253b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-6f67e2f6-b83c-4e4b-83c8-5e68593a55bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-dbabb34f-40b5-48a5-8420-e37d24f65b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-e9b7e374-32a9-4f2c-ba25-9a7b7d87f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-67c4c853-07c3-421e-9b20-aca370f6e56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111356109-172.17.0.10-1596960342659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-afc919e4-0871-4354-8b68-b9bb5789028b,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-c172b81e-be05-488c-95e6-4c4a6fce106d,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-4609bb0a-e801-4018-ba9b-f11f2305178e,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-447b33ce-fa63-460e-a6b6-793f40253b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-6f67e2f6-b83c-4e4b-83c8-5e68593a55bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-dbabb34f-40b5-48a5-8420-e37d24f65b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-e9b7e374-32a9-4f2c-ba25-9a7b7d87f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-67c4c853-07c3-421e-9b20-aca370f6e56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4694
