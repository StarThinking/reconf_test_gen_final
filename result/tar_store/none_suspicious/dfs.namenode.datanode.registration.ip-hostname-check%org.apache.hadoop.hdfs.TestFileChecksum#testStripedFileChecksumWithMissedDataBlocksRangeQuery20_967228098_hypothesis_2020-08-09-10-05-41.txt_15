reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531660490-172.17.0.2-1596967912234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34356,DS-d4887179-3640-4b6a-97d7-bb6533fef5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-096865a5-0ac0-4c55-b088-378a62b7c94e,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-67fc02a4-5615-4aa9-b76d-142135024f05,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-de57e982-2a9e-41f9-b02e-2445f721150d,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-2de2b2e7-a566-4f2c-8fc8-4e7f1e1809e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-c1990180-2aba-4fec-9ef1-7ab301a00a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-76c97f3d-5c7f-42a8-aa1b-f5882fb86507,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-f3ada27c-d7a5-44b1-b24d-8873d87c9454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531660490-172.17.0.2-1596967912234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34356,DS-d4887179-3640-4b6a-97d7-bb6533fef5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-096865a5-0ac0-4c55-b088-378a62b7c94e,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-67fc02a4-5615-4aa9-b76d-142135024f05,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-de57e982-2a9e-41f9-b02e-2445f721150d,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-2de2b2e7-a566-4f2c-8fc8-4e7f1e1809e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-c1990180-2aba-4fec-9ef1-7ab301a00a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-76c97f3d-5c7f-42a8-aa1b-f5882fb86507,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-f3ada27c-d7a5-44b1-b24d-8873d87c9454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037233210-172.17.0.2-1596968509009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40951,DS-24ba1f71-b476-4db6-b830-8f6f0e068188,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-d06b8eab-2165-462d-9242-4b6162ac037e,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-48a4f849-aa0e-4e5d-89a2-d6921f698ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-79249548-3bde-4676-b20e-eebf119836e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-02f75f98-96b3-4641-ac92-69bf3b0806ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-7201065f-1102-44fc-9975-b379f2485242,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bbd0138d-94f2-443f-ac7c-ff0bc70d5942,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-1892f324-c963-4ab6-92d6-0b192691e375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037233210-172.17.0.2-1596968509009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40951,DS-24ba1f71-b476-4db6-b830-8f6f0e068188,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-d06b8eab-2165-462d-9242-4b6162ac037e,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-48a4f849-aa0e-4e5d-89a2-d6921f698ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-79249548-3bde-4676-b20e-eebf119836e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-02f75f98-96b3-4641-ac92-69bf3b0806ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-7201065f-1102-44fc-9975-b379f2485242,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bbd0138d-94f2-443f-ac7c-ff0bc70d5942,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-1892f324-c963-4ab6-92d6-0b192691e375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559172825-172.17.0.2-1596969529992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-0d906d04-07e8-427c-a314-851a7b0a1a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-7cb6ea3c-013f-45af-8e97-401b5e7c1be2,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-d8155659-9d0b-495e-b772-8660d994aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-bdc69f7c-7abe-441a-802c-0d5ee70beef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-612b4f65-a3b2-458d-9dab-8898d474e00c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-60011c8d-1043-4d82-9c7c-102e2ecae08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-e4025f6e-eefb-4b00-825b-093ef67bd4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-7522a126-4d3e-4a65-8764-dfdbe3ce6cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559172825-172.17.0.2-1596969529992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-0d906d04-07e8-427c-a314-851a7b0a1a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-7cb6ea3c-013f-45af-8e97-401b5e7c1be2,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-d8155659-9d0b-495e-b772-8660d994aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-bdc69f7c-7abe-441a-802c-0d5ee70beef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-612b4f65-a3b2-458d-9dab-8898d474e00c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-60011c8d-1043-4d82-9c7c-102e2ecae08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-e4025f6e-eefb-4b00-825b-093ef67bd4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-7522a126-4d3e-4a65-8764-dfdbe3ce6cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882656051-172.17.0.2-1596970078614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-fa925ae4-fc5c-40f9-9ef2-d021025125de,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-d99aa265-7fec-4077-ad6d-d8544c7c08a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-cda2bed0-ce0a-4ccc-a78a-de6cadcf74e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-5f7402c2-7666-4681-aef0-e38e1f8f3fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-6844df84-6294-4a86-be77-5bf48c9cf6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-c8155f8e-9975-4ef2-88bf-8290f74206c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-5ff6b059-2897-4d77-b224-b458988d10c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-81daf7ea-ff3a-4193-b7ca-960035eeb671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882656051-172.17.0.2-1596970078614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-fa925ae4-fc5c-40f9-9ef2-d021025125de,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-d99aa265-7fec-4077-ad6d-d8544c7c08a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-cda2bed0-ce0a-4ccc-a78a-de6cadcf74e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-5f7402c2-7666-4681-aef0-e38e1f8f3fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-6844df84-6294-4a86-be77-5bf48c9cf6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-c8155f8e-9975-4ef2-88bf-8290f74206c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-5ff6b059-2897-4d77-b224-b458988d10c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-81daf7ea-ff3a-4193-b7ca-960035eeb671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961490667-172.17.0.2-1596970619566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32772,DS-7dac7ba7-3d21-4a57-a256-dfac5135cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-c187f2ac-cbf4-48b1-9093-a01836381351,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-eca3a5c7-3c87-4eb8-b05c-bab977020879,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-09c977c5-ef7f-45b9-a7ef-8cc7f89bb26f,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-b76f34d8-272d-4a71-a394-5874dd85cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-63f10b6c-aa5e-407e-a3e1-bd924edf56e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-1723d60b-365b-45d2-ae1c-f9ed4f191d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-a62e8d7b-a67f-4523-8236-548770a93b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961490667-172.17.0.2-1596970619566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32772,DS-7dac7ba7-3d21-4a57-a256-dfac5135cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-c187f2ac-cbf4-48b1-9093-a01836381351,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-eca3a5c7-3c87-4eb8-b05c-bab977020879,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-09c977c5-ef7f-45b9-a7ef-8cc7f89bb26f,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-b76f34d8-272d-4a71-a394-5874dd85cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-63f10b6c-aa5e-407e-a3e1-bd924edf56e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-1723d60b-365b-45d2-ae1c-f9ed4f191d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-a62e8d7b-a67f-4523-8236-548770a93b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070092646-172.17.0.2-1596971214907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45284,DS-d64ff36d-7642-4c91-9cc5-d4dbdb749332,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-fd054edb-8127-4398-a906-812a040ad470,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-309cf349-a6a7-44ac-8321-3ec19b661b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-79f1c73d-d160-4c49-a757-a184dbba766a,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-fb2d3b6e-6b23-4748-9785-03570dfa4574,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-14cbf162-164a-4dda-911a-8ceb2d36fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-de594350-f041-4807-b7c3-4e9dea957092,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-5ade720e-b7df-4509-9049-d9d845f34fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070092646-172.17.0.2-1596971214907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45284,DS-d64ff36d-7642-4c91-9cc5-d4dbdb749332,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-fd054edb-8127-4398-a906-812a040ad470,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-309cf349-a6a7-44ac-8321-3ec19b661b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-79f1c73d-d160-4c49-a757-a184dbba766a,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-fb2d3b6e-6b23-4748-9785-03570dfa4574,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-14cbf162-164a-4dda-911a-8ceb2d36fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-de594350-f041-4807-b7c3-4e9dea957092,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-5ade720e-b7df-4509-9049-d9d845f34fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252796967-172.17.0.2-1596971612218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43145,DS-6ed2934b-4747-49ec-9f81-fe43135c3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-0e05e0a0-2df0-47f5-bde0-6015ef49ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-c6434dea-51e6-4a65-bc0f-09179b4f121b,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-a7138c2a-1126-426e-ab2c-3f8289d5b936,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-a495ecc1-f8ec-4049-86dd-3276df7cc03f,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-c3676f5a-97a5-471c-87d0-01919eb0cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-e69c3394-d417-4d3e-8af6-b4abe9211215,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-fa8503ec-371d-4cf3-b0ad-78870685346d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252796967-172.17.0.2-1596971612218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43145,DS-6ed2934b-4747-49ec-9f81-fe43135c3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-0e05e0a0-2df0-47f5-bde0-6015ef49ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-c6434dea-51e6-4a65-bc0f-09179b4f121b,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-a7138c2a-1126-426e-ab2c-3f8289d5b936,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-a495ecc1-f8ec-4049-86dd-3276df7cc03f,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-c3676f5a-97a5-471c-87d0-01919eb0cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-e69c3394-d417-4d3e-8af6-b4abe9211215,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-fa8503ec-371d-4cf3-b0ad-78870685346d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537598010-172.17.0.2-1596971831033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-ee28b060-87ca-4ac7-8ba3-ec6c1689772b,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-742f506c-191b-4d8c-a523-2b574537851e,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-0b83505c-9e0a-4d86-a331-5ba966478156,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-d967eb2b-14d4-44d1-993b-66509f7f9bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-da6b0ea7-3ca4-4935-bbcb-30f0999f733a,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-ce9a9c4f-4594-4d7c-ae6f-d1f8d26618f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-ee1c5ec9-d87f-40ba-857b-1bf60817b3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-5328a5fa-60db-4e20-88d6-098e0a078bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537598010-172.17.0.2-1596971831033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-ee28b060-87ca-4ac7-8ba3-ec6c1689772b,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-742f506c-191b-4d8c-a523-2b574537851e,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-0b83505c-9e0a-4d86-a331-5ba966478156,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-d967eb2b-14d4-44d1-993b-66509f7f9bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-da6b0ea7-3ca4-4935-bbcb-30f0999f733a,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-ce9a9c4f-4594-4d7c-ae6f-d1f8d26618f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-ee1c5ec9-d87f-40ba-857b-1bf60817b3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-5328a5fa-60db-4e20-88d6-098e0a078bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363129047-172.17.0.2-1596971859489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-14d24feb-bc54-4847-9b99-faddc311ebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-b0ff2061-49e4-41f7-a9d3-f4edb9e338d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-dbe47506-c13a-4507-9399-317f80afcb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-e7802bcc-da67-4d27-a89c-c93e09d64186,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-21ce4685-56ad-4a72-a798-915e5ea44d58,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-37ec74d5-5a9a-400f-96fd-2a33ea5698e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-af8f3190-602c-464b-850a-de9714704712,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-d0f4e0aa-b71c-4513-90e4-25b9c6e0f9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363129047-172.17.0.2-1596971859489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-14d24feb-bc54-4847-9b99-faddc311ebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-b0ff2061-49e4-41f7-a9d3-f4edb9e338d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-dbe47506-c13a-4507-9399-317f80afcb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-e7802bcc-da67-4d27-a89c-c93e09d64186,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-21ce4685-56ad-4a72-a798-915e5ea44d58,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-37ec74d5-5a9a-400f-96fd-2a33ea5698e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-af8f3190-602c-464b-850a-de9714704712,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-d0f4e0aa-b71c-4513-90e4-25b9c6e0f9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327548657-172.17.0.2-1596971935537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35253,DS-1ea80469-904f-4e34-a3b1-4da91fc5fe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-c83b88ae-a87d-45ca-be35-4abbfef0a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-eb0ccae2-d4b3-4a7a-94e4-1653e44210ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-a5254a02-ba2a-4a88-989e-3e00c6e35fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-ff59c697-3f4d-4f61-aa82-6bd5a4108aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-3f6b6c53-066b-45f3-9e05-dca0b38eae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a42ccc84-92bd-46da-8638-75c82daae22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-6cfc48df-ea6e-4973-88f3-aade9328b730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327548657-172.17.0.2-1596971935537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35253,DS-1ea80469-904f-4e34-a3b1-4da91fc5fe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-c83b88ae-a87d-45ca-be35-4abbfef0a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-eb0ccae2-d4b3-4a7a-94e4-1653e44210ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-a5254a02-ba2a-4a88-989e-3e00c6e35fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-ff59c697-3f4d-4f61-aa82-6bd5a4108aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-3f6b6c53-066b-45f3-9e05-dca0b38eae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a42ccc84-92bd-46da-8638-75c82daae22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-6cfc48df-ea6e-4973-88f3-aade9328b730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686717959-172.17.0.2-1596972476226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38338,DS-b7e024c4-ce52-47cd-b7c7-85d3360d0539,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-3649bda8-b6f3-4f39-852d-52184d7901c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-936ec847-4198-4c57-b4d4-47bd195c6637,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-6ee1c4f0-9580-44a7-b5ec-2e8682f17a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-e21007b5-3213-4a3a-b812-62d85c6763f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-869789a3-c647-4254-bdd3-4894cecced7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-08d7576e-112d-40ba-a95c-5eac67712187,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-df713c45-d0ba-4d3a-afff-8f4b2422468b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686717959-172.17.0.2-1596972476226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38338,DS-b7e024c4-ce52-47cd-b7c7-85d3360d0539,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-3649bda8-b6f3-4f39-852d-52184d7901c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-936ec847-4198-4c57-b4d4-47bd195c6637,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-6ee1c4f0-9580-44a7-b5ec-2e8682f17a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-e21007b5-3213-4a3a-b812-62d85c6763f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-869789a3-c647-4254-bdd3-4894cecced7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-08d7576e-112d-40ba-a95c-5eac67712187,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-df713c45-d0ba-4d3a-afff-8f4b2422468b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5180
