reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514154986-172.17.0.20-1596891500176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-15ad8f28-fb36-494d-80f3-6f840ef56061,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-23531065-a46a-4573-bc93-0389c3090e48,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-d1413353-14f9-4863-b55d-1992f87e554b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-322b4bfd-6399-42af-93de-b043c4f03f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-4ab2650d-9f4b-476e-8b6a-5e3f5fd5ea89,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-9eb94bea-f8fc-4f7d-87d6-defb6b9e0c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-6b141035-ace9-43d4-9365-5b83e1680f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-be8496c6-cd84-4c61-9e8b-35e1fde264ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514154986-172.17.0.20-1596891500176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-15ad8f28-fb36-494d-80f3-6f840ef56061,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-23531065-a46a-4573-bc93-0389c3090e48,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-d1413353-14f9-4863-b55d-1992f87e554b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-322b4bfd-6399-42af-93de-b043c4f03f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-4ab2650d-9f4b-476e-8b6a-5e3f5fd5ea89,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-9eb94bea-f8fc-4f7d-87d6-defb6b9e0c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-6b141035-ace9-43d4-9365-5b83e1680f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-be8496c6-cd84-4c61-9e8b-35e1fde264ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662434708-172.17.0.20-1596891545019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35012,DS-c7159530-e3da-4251-91fd-dd3c430a928b,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-76107a17-db88-4b71-8f4b-cce57325b819,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-92ad3d1a-c5ce-47ff-b1e1-967b47fd9abb,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-a3a39dce-2984-4a57-852d-5cabe791c372,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c8a7d57a-c862-43c8-aa22-59d0a642a558,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-6cb56b32-edca-49ba-805c-9754db4aae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-633e0d61-45ef-4d85-b433-62bccfd9472f,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-56f9d90d-150c-455c-9d6e-1340f309bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662434708-172.17.0.20-1596891545019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35012,DS-c7159530-e3da-4251-91fd-dd3c430a928b,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-76107a17-db88-4b71-8f4b-cce57325b819,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-92ad3d1a-c5ce-47ff-b1e1-967b47fd9abb,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-a3a39dce-2984-4a57-852d-5cabe791c372,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c8a7d57a-c862-43c8-aa22-59d0a642a558,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-6cb56b32-edca-49ba-805c-9754db4aae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-633e0d61-45ef-4d85-b433-62bccfd9472f,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-56f9d90d-150c-455c-9d6e-1340f309bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573229834-172.17.0.20-1596891925525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-14ebe338-4edb-456e-8e22-182e0cd46781,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-cdb8bf63-9590-4763-b0bf-6ebf49d9d736,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-13b05e32-c33d-4654-bca1-9608c43253bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-b94994a8-02cf-453a-a5fa-2c5a5af9fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-223975ff-951c-46e3-b529-37f6ec2e1b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-2c88622b-cdbe-450c-9a56-bf0994e7c471,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-a47bf322-70b9-4f99-b483-0de2ce064ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-4c698fb4-f7d7-4904-92a0-a75bd4404b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573229834-172.17.0.20-1596891925525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-14ebe338-4edb-456e-8e22-182e0cd46781,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-cdb8bf63-9590-4763-b0bf-6ebf49d9d736,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-13b05e32-c33d-4654-bca1-9608c43253bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-b94994a8-02cf-453a-a5fa-2c5a5af9fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-223975ff-951c-46e3-b529-37f6ec2e1b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-2c88622b-cdbe-450c-9a56-bf0994e7c471,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-a47bf322-70b9-4f99-b483-0de2ce064ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-4c698fb4-f7d7-4904-92a0-a75bd4404b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525600245-172.17.0.20-1596892434351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45868,DS-91698584-c5f3-4e79-9255-769dea4a1d73,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7c7cc15e-00af-4a68-8cd1-e636dd8fcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-af9daac9-1ff5-4426-a051-5d2a640f143e,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-704f36c1-caf5-4ecd-8f3b-c7988dc1aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-fcfc47ac-964d-4765-b1f9-63c600906374,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-21bcbe5e-8012-4700-9252-a69a35e175c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-ba9e7b4d-9a0d-449e-bb1c-93d3bce3c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-57390522-cbf1-4f45-901a-f781b674c001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525600245-172.17.0.20-1596892434351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45868,DS-91698584-c5f3-4e79-9255-769dea4a1d73,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7c7cc15e-00af-4a68-8cd1-e636dd8fcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-af9daac9-1ff5-4426-a051-5d2a640f143e,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-704f36c1-caf5-4ecd-8f3b-c7988dc1aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-fcfc47ac-964d-4765-b1f9-63c600906374,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-21bcbe5e-8012-4700-9252-a69a35e175c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-ba9e7b4d-9a0d-449e-bb1c-93d3bce3c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-57390522-cbf1-4f45-901a-f781b674c001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229186964-172.17.0.20-1596892784915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-62817353-2c80-4ee0-a3e5-70173039da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-0a8619b0-5c53-48ca-ac6e-17a3c681ad30,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-54f02ffc-3391-4512-a5db-e2721a18edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-b9edf2b1-60a4-42c2-8ae1-6c1e052e6c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-df263787-4ae1-46ce-8af4-9eca0c6c05cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-96c88738-69a5-4d23-80ef-2d4b535f0f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-44ca46fe-d299-4988-969d-5612286f5dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-d33d20e0-a469-4ae7-bf07-317e368aae3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229186964-172.17.0.20-1596892784915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-62817353-2c80-4ee0-a3e5-70173039da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-0a8619b0-5c53-48ca-ac6e-17a3c681ad30,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-54f02ffc-3391-4512-a5db-e2721a18edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-b9edf2b1-60a4-42c2-8ae1-6c1e052e6c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-df263787-4ae1-46ce-8af4-9eca0c6c05cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-96c88738-69a5-4d23-80ef-2d4b535f0f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-44ca46fe-d299-4988-969d-5612286f5dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-d33d20e0-a469-4ae7-bf07-317e368aae3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24700386-172.17.0.20-1596893127699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-3095a32e-a6f4-4bed-886e-0ad39de16f69,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-c3eccae1-b95b-4447-9773-5a9211a1082a,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-263999bb-8be3-4456-bc92-9bd9478ef4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ded3c1db-b440-4cb2-bf79-de6c3bc9f09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-183a3bc6-fe58-438f-9c5a-d6bab25ace61,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-27b39e53-7f10-461c-8b7b-b12799dd414e,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-e660f5ba-fda0-4094-873d-0ca691f2afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-9d588196-caab-4b41-badf-441c0f397061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24700386-172.17.0.20-1596893127699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-3095a32e-a6f4-4bed-886e-0ad39de16f69,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-c3eccae1-b95b-4447-9773-5a9211a1082a,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-263999bb-8be3-4456-bc92-9bd9478ef4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ded3c1db-b440-4cb2-bf79-de6c3bc9f09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-183a3bc6-fe58-438f-9c5a-d6bab25ace61,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-27b39e53-7f10-461c-8b7b-b12799dd414e,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-e660f5ba-fda0-4094-873d-0ca691f2afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-9d588196-caab-4b41-badf-441c0f397061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718305681-172.17.0.20-1596893159532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44449,DS-1b7c9810-2f66-45b0-b56c-9c421ffcdbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-ab8087a7-db7a-48a8-9d84-d40c715c4009,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-702d9d45-116f-4623-b9b2-356ee787eece,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-fb0c4e57-c5e1-41fc-95a5-c4ca54eee542,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-d508eeb9-0890-4ddf-8ebf-fe78454fd491,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-2da90c10-a33e-44f1-ad1c-5c394e988764,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-d5e92b9a-e5b1-4db0-b881-457054e250ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-e148f39a-9464-4035-8e45-9d6eda92a0ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718305681-172.17.0.20-1596893159532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44449,DS-1b7c9810-2f66-45b0-b56c-9c421ffcdbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-ab8087a7-db7a-48a8-9d84-d40c715c4009,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-702d9d45-116f-4623-b9b2-356ee787eece,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-fb0c4e57-c5e1-41fc-95a5-c4ca54eee542,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-d508eeb9-0890-4ddf-8ebf-fe78454fd491,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-2da90c10-a33e-44f1-ad1c-5c394e988764,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-d5e92b9a-e5b1-4db0-b881-457054e250ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-e148f39a-9464-4035-8e45-9d6eda92a0ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616464548-172.17.0.20-1596893317342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-9de22071-f9c2-4682-857b-975689c30107,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-a517dae2-95a7-4c7a-bdce-7d3e2dedf4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-96e1c697-d24f-4fc2-b888-8096bcde76ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-a21a244c-3827-4739-8776-73b7598aa7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-5ffe35cf-7ca9-4ff5-b2f2-eb0892542d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-4718f19f-e13e-44c3-a96d-9b58c940cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-70c82511-c0b9-4fa8-9a79-fd69e012a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-818d3f12-3f4f-45c3-aac5-59a797a45137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616464548-172.17.0.20-1596893317342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-9de22071-f9c2-4682-857b-975689c30107,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-a517dae2-95a7-4c7a-bdce-7d3e2dedf4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-96e1c697-d24f-4fc2-b888-8096bcde76ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-a21a244c-3827-4739-8776-73b7598aa7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-5ffe35cf-7ca9-4ff5-b2f2-eb0892542d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-4718f19f-e13e-44c3-a96d-9b58c940cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-70c82511-c0b9-4fa8-9a79-fd69e012a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-818d3f12-3f4f-45c3-aac5-59a797a45137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266858542-172.17.0.20-1596893353686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-1d9a0f88-d357-4df3-bf31-b2521eca53e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-58b032f0-a1ed-4db7-9633-de87eff374f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-3851e2ba-47a3-40ef-a27f-8dae3609351e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-c0784491-fd0d-4bed-82ce-6e35eb2f79c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-618cda87-4b25-4308-8458-400e5b317177,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-9c246233-39e7-40c1-8b7a-69cf9af0be81,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-f184e78f-b304-4494-b45d-f644c0b1d841,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-96841410-cdc3-4985-81ef-7922d9616802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266858542-172.17.0.20-1596893353686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-1d9a0f88-d357-4df3-bf31-b2521eca53e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-58b032f0-a1ed-4db7-9633-de87eff374f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-3851e2ba-47a3-40ef-a27f-8dae3609351e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-c0784491-fd0d-4bed-82ce-6e35eb2f79c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-618cda87-4b25-4308-8458-400e5b317177,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-9c246233-39e7-40c1-8b7a-69cf9af0be81,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-f184e78f-b304-4494-b45d-f644c0b1d841,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-96841410-cdc3-4985-81ef-7922d9616802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239477561-172.17.0.20-1596893764849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43401,DS-3cb0bd76-e974-48d0-9c76-aa731ce2c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-255609e8-19d0-48b1-879b-c382ba62f753,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-30f7d116-2244-47b3-972b-9d6326b49422,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-aee44dde-0962-41b2-9ab4-535a4845b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-ef1c9ef4-c9a0-4b5c-8bef-dc35cd26fd36,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-810d1c53-4989-4b1b-bdde-04b9efec53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-e01b6f2b-8751-4beb-a15b-b334916a2653,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-ab767acd-b10e-4bdc-bb43-cf1d93b1a112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239477561-172.17.0.20-1596893764849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43401,DS-3cb0bd76-e974-48d0-9c76-aa731ce2c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-255609e8-19d0-48b1-879b-c382ba62f753,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-30f7d116-2244-47b3-972b-9d6326b49422,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-aee44dde-0962-41b2-9ab4-535a4845b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-ef1c9ef4-c9a0-4b5c-8bef-dc35cd26fd36,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-810d1c53-4989-4b1b-bdde-04b9efec53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-e01b6f2b-8751-4beb-a15b-b334916a2653,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-ab767acd-b10e-4bdc-bb43-cf1d93b1a112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591337039-172.17.0.20-1596894244867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-bccc57f0-d6d6-4dc3-840f-b60cc584fe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-6d5abc04-a7a1-4d9a-b593-8c4c6987afe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-7bd5a674-bf89-41cc-a585-2f600eb23460,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-3f406a3b-d1f3-4df1-91c8-6e07acf98a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-d46370af-e8c1-41ab-9b97-f7ea07ca3027,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-a50bb12f-2bf1-4ea4-bc00-0f13660bfe68,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-5b1a4198-b5b1-4c98-8b53-3aad7cf2ec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-f27b6e89-421f-4f7d-ab46-74cd98ad3183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591337039-172.17.0.20-1596894244867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-bccc57f0-d6d6-4dc3-840f-b60cc584fe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-6d5abc04-a7a1-4d9a-b593-8c4c6987afe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-7bd5a674-bf89-41cc-a585-2f600eb23460,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-3f406a3b-d1f3-4df1-91c8-6e07acf98a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-d46370af-e8c1-41ab-9b97-f7ea07ca3027,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-a50bb12f-2bf1-4ea4-bc00-0f13660bfe68,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-5b1a4198-b5b1-4c98-8b53-3aad7cf2ec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-f27b6e89-421f-4f7d-ab46-74cd98ad3183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546783753-172.17.0.20-1596894440398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-3188692b-0fc3-414c-9ae7-f42e20ae0d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7bea6ca3-8d25-46b9-bfcd-3faed11cd90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-d0a3bf6f-016a-44ff-b37f-73f37c138f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-ba12cc44-3bdc-4d91-8eb9-986029a8fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-81c67dee-7705-4b1e-bb31-f19ec5d81580,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-46304e87-0a7c-4c83-a4e8-ebe4a4f43a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-9e30015d-1b14-4536-beed-3d59dcc8df77,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-28a66051-234d-4804-80df-822244c26b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546783753-172.17.0.20-1596894440398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-3188692b-0fc3-414c-9ae7-f42e20ae0d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7bea6ca3-8d25-46b9-bfcd-3faed11cd90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-d0a3bf6f-016a-44ff-b37f-73f37c138f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-ba12cc44-3bdc-4d91-8eb9-986029a8fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-81c67dee-7705-4b1e-bb31-f19ec5d81580,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-46304e87-0a7c-4c83-a4e8-ebe4a4f43a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-9e30015d-1b14-4536-beed-3d59dcc8df77,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-28a66051-234d-4804-80df-822244c26b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714759618-172.17.0.20-1596894655897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-bab2ecfb-e9fa-4aed-b7ea-c15e48080864,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-12c2b147-0d50-4154-8488-8aa778c9ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-99befef1-778f-4807-83df-181d1939373c,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-87b76f5c-c9eb-43a6-b1ab-7c564f65c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-7d3d9bee-444e-483e-ab2c-61bcd458b880,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-ab611236-9827-414e-a171-167cea26ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-3593a975-f860-469a-861d-77dc25d2be16,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-a565b3b9-8f28-4254-8ee0-0cd6db4c8eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714759618-172.17.0.20-1596894655897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-bab2ecfb-e9fa-4aed-b7ea-c15e48080864,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-12c2b147-0d50-4154-8488-8aa778c9ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-99befef1-778f-4807-83df-181d1939373c,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-87b76f5c-c9eb-43a6-b1ab-7c564f65c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-7d3d9bee-444e-483e-ab2c-61bcd458b880,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-ab611236-9827-414e-a171-167cea26ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-3593a975-f860-469a-861d-77dc25d2be16,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-a565b3b9-8f28-4254-8ee0-0cd6db4c8eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449621250-172.17.0.20-1596894911652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38717,DS-10855e5b-01c6-40f5-bf62-92ab6aa92995,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-8c89a8ab-c240-4096-9913-20dce297b2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-95279b25-4ac3-499f-9a28-b009f692124a,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-f74acb4e-3f21-4b35-bd19-34ecc5e73fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-4b431e1c-5555-4ba2-aa63-9c38ff6ffbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-d20c91ef-680e-4261-831b-59d577b62b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-e7dc9113-cb87-48f0-96ce-48c57846b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-cf3ed666-a392-42e9-9c1d-755992687041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449621250-172.17.0.20-1596894911652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38717,DS-10855e5b-01c6-40f5-bf62-92ab6aa92995,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-8c89a8ab-c240-4096-9913-20dce297b2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-95279b25-4ac3-499f-9a28-b009f692124a,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-f74acb4e-3f21-4b35-bd19-34ecc5e73fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-4b431e1c-5555-4ba2-aa63-9c38ff6ffbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-d20c91ef-680e-4261-831b-59d577b62b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-e7dc9113-cb87-48f0-96ce-48c57846b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-cf3ed666-a392-42e9-9c1d-755992687041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40557203-172.17.0.20-1596895066840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-7b3fff25-4c1d-4fe7-9882-a34286155ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-c1b77f74-e853-47c0-8776-9da6f5a2e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-628230e4-4b9c-4a0b-b8e6-9caef98657f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-8eaae11b-d611-4a66-b4a9-482d6c519f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-44fb241c-b36e-4c67-a509-0a51d1a518f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-869bc25f-5a0f-4415-9504-70343c0ba69a,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-b94322f8-1091-4403-bd1b-7962e09adf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-b94cd5e8-62fc-479e-bca4-129a1bc8bd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40557203-172.17.0.20-1596895066840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-7b3fff25-4c1d-4fe7-9882-a34286155ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-c1b77f74-e853-47c0-8776-9da6f5a2e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-628230e4-4b9c-4a0b-b8e6-9caef98657f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-8eaae11b-d611-4a66-b4a9-482d6c519f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-44fb241c-b36e-4c67-a509-0a51d1a518f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-869bc25f-5a0f-4415-9504-70343c0ba69a,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-b94322f8-1091-4403-bd1b-7962e09adf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-b94cd5e8-62fc-479e-bca4-129a1bc8bd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759678149-172.17.0.20-1596895338547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-53d38b14-4785-44be-8a37-ff22d8455183,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-5dacc01a-459d-44f3-89a2-df888a70e207,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-669ec486-c1ae-4144-b1f3-5a73756edafa,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-ade0404d-d40b-4799-a011-a3fae7771faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-7797901e-e8e9-4cb0-84f6-681fe6382775,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-302a83c2-1971-4449-9ec3-71ef742ca3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-313d3cc3-d486-45f7-b23d-e3fc6b4f92b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-5a74f07e-73d0-4d31-84a2-97a6f003f51a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759678149-172.17.0.20-1596895338547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-53d38b14-4785-44be-8a37-ff22d8455183,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-5dacc01a-459d-44f3-89a2-df888a70e207,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-669ec486-c1ae-4144-b1f3-5a73756edafa,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-ade0404d-d40b-4799-a011-a3fae7771faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-7797901e-e8e9-4cb0-84f6-681fe6382775,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-302a83c2-1971-4449-9ec3-71ef742ca3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-313d3cc3-d486-45f7-b23d-e3fc6b4f92b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-5a74f07e-73d0-4d31-84a2-97a6f003f51a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724889734-172.17.0.20-1596895377144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-51e4f21d-e0e6-482a-be03-48d2764918ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-94e3abf4-2bdd-4b6c-b8ec-5048b6a94512,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-a62a6b5e-05ff-4724-9ba3-ad29b70ba04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-95ecf74f-8bc2-45e1-a5ae-792520ddaa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-1ba0fc80-929b-4f0b-a81d-9317ab0fcda9,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-358fc05b-7c60-49b1-93c3-de25f468f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-60134c6a-3583-433e-923d-196591b9936b,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-a4291c6c-e9f4-4033-9f8a-c756c1ab85ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724889734-172.17.0.20-1596895377144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-51e4f21d-e0e6-482a-be03-48d2764918ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-94e3abf4-2bdd-4b6c-b8ec-5048b6a94512,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-a62a6b5e-05ff-4724-9ba3-ad29b70ba04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-95ecf74f-8bc2-45e1-a5ae-792520ddaa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-1ba0fc80-929b-4f0b-a81d-9317ab0fcda9,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-358fc05b-7c60-49b1-93c3-de25f468f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-60134c6a-3583-433e-923d-196591b9936b,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-a4291c6c-e9f4-4033-9f8a-c756c1ab85ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480913150-172.17.0.20-1596895530687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-1a0a59d3-7020-4dd5-89a3-27c270660f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-bd359e57-da05-4978-aba2-931dc521f608,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-024bcdb0-2cc8-4da4-84a7-451948059207,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-e5dc759b-5b83-4131-9d18-40a9a3aadef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-c5c2e5a5-6ae7-4949-9fae-e1ea44ab0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-36138458-ca0f-4ade-ba10-c8db5edb2868,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-4689e598-6f23-4ae2-8aaa-5ff1112e136c,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-9318e2a5-ca30-466c-9473-1cf7936bba2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480913150-172.17.0.20-1596895530687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-1a0a59d3-7020-4dd5-89a3-27c270660f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-bd359e57-da05-4978-aba2-931dc521f608,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-024bcdb0-2cc8-4da4-84a7-451948059207,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-e5dc759b-5b83-4131-9d18-40a9a3aadef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-c5c2e5a5-6ae7-4949-9fae-e1ea44ab0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-36138458-ca0f-4ade-ba10-c8db5edb2868,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-4689e598-6f23-4ae2-8aaa-5ff1112e136c,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-9318e2a5-ca30-466c-9473-1cf7936bba2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569343809-172.17.0.20-1596896246882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-446b3da6-76f5-4867-8a58-f1dfdbba2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-c10c8e28-90c1-4eef-9ef9-576ebf75a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-25c78551-7ac0-43da-9166-c0bc6ca31ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-9306bb87-a1ae-4361-aaa8-bc178b2c1452,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-07241b9f-16b7-49ea-aa64-368f7695d293,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-a1e328db-ee77-4c1a-be02-07e94ffcfee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-d6365c7c-d2a4-44de-9d4d-8fdf24b496da,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-7db67914-a222-43c2-8ae3-ea47587e068c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569343809-172.17.0.20-1596896246882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-446b3da6-76f5-4867-8a58-f1dfdbba2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-c10c8e28-90c1-4eef-9ef9-576ebf75a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-25c78551-7ac0-43da-9166-c0bc6ca31ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-9306bb87-a1ae-4361-aaa8-bc178b2c1452,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-07241b9f-16b7-49ea-aa64-368f7695d293,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-a1e328db-ee77-4c1a-be02-07e94ffcfee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-d6365c7c-d2a4-44de-9d4d-8fdf24b496da,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-7db67914-a222-43c2-8ae3-ea47587e068c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9989076-172.17.0.20-1596896813178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-ad02ba8c-f50f-475b-adcb-f4043585826c,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-9882ebc2-6bf9-47db-96a8-33c1b3716346,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-7fd7b6c2-af20-4ed9-a76f-95334f123395,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-552447c2-75d9-4610-a47d-d4e36ed754b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-1c75e72a-9f9e-4b3b-8084-a91451dabab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-c9abf23c-e614-4b80-8c97-53bb8770db98,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-f5abc0f3-f6b3-4953-a683-5b58a9c09c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-18c26ac5-ce60-4c96-bd55-f950de42062e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9989076-172.17.0.20-1596896813178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-ad02ba8c-f50f-475b-adcb-f4043585826c,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-9882ebc2-6bf9-47db-96a8-33c1b3716346,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-7fd7b6c2-af20-4ed9-a76f-95334f123395,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-552447c2-75d9-4610-a47d-d4e36ed754b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-1c75e72a-9f9e-4b3b-8084-a91451dabab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-c9abf23c-e614-4b80-8c97-53bb8770db98,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-f5abc0f3-f6b3-4953-a683-5b58a9c09c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-18c26ac5-ce60-4c96-bd55-f950de42062e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349194245-172.17.0.20-1596896851615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-39e45c33-b4d5-4419-9f4f-e26164c3a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-15ba368b-b2dc-4d3b-8926-7e0df71374fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-17637683-0629-4879-a521-f77e8a4036ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-26319549-d94e-4d0c-b841-2e9c3b73e813,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-14ede40c-f80c-4d87-9947-e61047317b21,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-6f990698-d405-4d0c-b4b9-004a43a1ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-77717eb4-8bb6-4f3e-9dba-2cb276da8660,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-10cb5407-e2ac-4e6b-be5c-a72c33ee8ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349194245-172.17.0.20-1596896851615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-39e45c33-b4d5-4419-9f4f-e26164c3a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-15ba368b-b2dc-4d3b-8926-7e0df71374fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-17637683-0629-4879-a521-f77e8a4036ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-26319549-d94e-4d0c-b841-2e9c3b73e813,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-14ede40c-f80c-4d87-9947-e61047317b21,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-6f990698-d405-4d0c-b4b9-004a43a1ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-77717eb4-8bb6-4f3e-9dba-2cb276da8660,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-10cb5407-e2ac-4e6b-be5c-a72c33ee8ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5496
