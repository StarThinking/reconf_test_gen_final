reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731162132-172.17.0.14-1596875317113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-b89df9bf-3646-48f4-9457-5ca8b89d8f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-76c22829-fa6e-41f0-ac53-ad10aa528db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-32bcf8c9-e906-4743-b94e-d60d80dc6a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-f518a230-19e5-4d3a-9ed1-3e5fb3ab8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8bcba81f-5ca8-42ca-a087-a1f5621948e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-36f71e1c-2fac-4abf-98b0-a638d46d55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-0b9932c2-51f5-4db1-b2d9-8d4f9f595621,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-85c25999-2dc9-4f39-8ba8-005b9a9d8a67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731162132-172.17.0.14-1596875317113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-b89df9bf-3646-48f4-9457-5ca8b89d8f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-76c22829-fa6e-41f0-ac53-ad10aa528db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-32bcf8c9-e906-4743-b94e-d60d80dc6a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-f518a230-19e5-4d3a-9ed1-3e5fb3ab8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8bcba81f-5ca8-42ca-a087-a1f5621948e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-36f71e1c-2fac-4abf-98b0-a638d46d55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-0b9932c2-51f5-4db1-b2d9-8d4f9f595621,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-85c25999-2dc9-4f39-8ba8-005b9a9d8a67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915339196-172.17.0.14-1596875492902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32945,DS-e4a9570a-f2fc-4726-910b-26328fc6909b,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-19d8ba38-9152-4fd9-89aa-a1e00874afe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-54c82535-9966-41f0-8fe3-fcc1e3afb8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-c780272c-7a89-4dfb-9528-14f4d8af90bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-f7525302-8f15-4160-9bd4-fe22b3462c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-546c6469-967b-4839-8bf8-fa763c1d5858,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4cbfa53b-0251-414f-b973-09f955cffbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-cb043277-ce02-436c-b779-25e1ff676947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915339196-172.17.0.14-1596875492902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32945,DS-e4a9570a-f2fc-4726-910b-26328fc6909b,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-19d8ba38-9152-4fd9-89aa-a1e00874afe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-54c82535-9966-41f0-8fe3-fcc1e3afb8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-c780272c-7a89-4dfb-9528-14f4d8af90bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-f7525302-8f15-4160-9bd4-fe22b3462c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-546c6469-967b-4839-8bf8-fa763c1d5858,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4cbfa53b-0251-414f-b973-09f955cffbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-cb043277-ce02-436c-b779-25e1ff676947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60068778-172.17.0.14-1596875570759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-2570b0f4-ed44-451d-a7d7-5d5a3016f76a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-868f1813-b53f-4ef8-959d-175f4d5de58a,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-db8d5f63-6440-4af2-8243-3d66cfd8eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-39a6d434-0c18-4eff-ba9c-f9cc0d59b480,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-01961744-c7d2-4fd6-bae0-b6e8f9d5bd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-599e92f8-f19e-4397-975d-5064a844a036,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-6badd70b-099a-4b54-bc8e-f595b8b69faa,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-763d1d1b-1ca6-40c1-9ade-41d0ed8766ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60068778-172.17.0.14-1596875570759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-2570b0f4-ed44-451d-a7d7-5d5a3016f76a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-868f1813-b53f-4ef8-959d-175f4d5de58a,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-db8d5f63-6440-4af2-8243-3d66cfd8eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-39a6d434-0c18-4eff-ba9c-f9cc0d59b480,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-01961744-c7d2-4fd6-bae0-b6e8f9d5bd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-599e92f8-f19e-4397-975d-5064a844a036,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-6badd70b-099a-4b54-bc8e-f595b8b69faa,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-763d1d1b-1ca6-40c1-9ade-41d0ed8766ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164109551-172.17.0.14-1596875617364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-028197d5-7b24-47dd-8f7b-0e789b15f372,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-a359b0e6-0171-486f-afb6-f195e33c9a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-4d1e06bc-daea-43d4-874a-48f27d8470f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-13af101d-617e-4e0a-a835-fbd89baf246e,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-265fb860-9bb6-4880-8ff4-492f91a71604,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-441a6926-c099-4494-98a1-3b1324735a86,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-3621fc05-9dbf-45a0-b27e-cc4c4bd27aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-74aa5996-2409-486b-aa85-97d8480574fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164109551-172.17.0.14-1596875617364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-028197d5-7b24-47dd-8f7b-0e789b15f372,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-a359b0e6-0171-486f-afb6-f195e33c9a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-4d1e06bc-daea-43d4-874a-48f27d8470f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-13af101d-617e-4e0a-a835-fbd89baf246e,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-265fb860-9bb6-4880-8ff4-492f91a71604,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-441a6926-c099-4494-98a1-3b1324735a86,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-3621fc05-9dbf-45a0-b27e-cc4c4bd27aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-74aa5996-2409-486b-aa85-97d8480574fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966193264-172.17.0.14-1596875857504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-d5a0f5d0-447c-4d7b-b2be-e94e2a6f2bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-fa0ed0bb-7eb6-4192-85e1-0dafbb6220e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-410fcd86-3b57-4211-b077-14d31090712f,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-c90f5b73-a5cb-48ad-976c-9412145bffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-471c7107-c2e0-401e-829c-e87b5ece3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-b619c6a5-0a94-4bac-8e3f-628e03df784e,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-23dfd507-1f65-4d26-a16c-5e857fb91505,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-3424b574-fb47-41c3-b749-bb08cd717ce9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966193264-172.17.0.14-1596875857504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-d5a0f5d0-447c-4d7b-b2be-e94e2a6f2bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-fa0ed0bb-7eb6-4192-85e1-0dafbb6220e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-410fcd86-3b57-4211-b077-14d31090712f,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-c90f5b73-a5cb-48ad-976c-9412145bffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-471c7107-c2e0-401e-829c-e87b5ece3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-b619c6a5-0a94-4bac-8e3f-628e03df784e,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-23dfd507-1f65-4d26-a16c-5e857fb91505,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-3424b574-fb47-41c3-b749-bb08cd717ce9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325551697-172.17.0.14-1596875898097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-bc76c5b4-a2b5-4224-9c82-375c3aa70b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-d47597c3-4dde-42bf-8ad3-3e12d770eb32,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-d4b1bee1-4b13-47b7-93e7-646719b161e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-eeaa2b32-a960-40ae-81fa-27d6dab9be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-5cba08cc-29b6-4fed-9ef4-2142741c1bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-2a21dbf3-8016-465c-bb86-b404cae63bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-ba5a0bc8-24a6-4291-80fd-f6598c42264e,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-797085cd-52bf-4101-bb7d-2fc83b561ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325551697-172.17.0.14-1596875898097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-bc76c5b4-a2b5-4224-9c82-375c3aa70b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-d47597c3-4dde-42bf-8ad3-3e12d770eb32,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-d4b1bee1-4b13-47b7-93e7-646719b161e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-eeaa2b32-a960-40ae-81fa-27d6dab9be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-5cba08cc-29b6-4fed-9ef4-2142741c1bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-2a21dbf3-8016-465c-bb86-b404cae63bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-ba5a0bc8-24a6-4291-80fd-f6598c42264e,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-797085cd-52bf-4101-bb7d-2fc83b561ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508048465-172.17.0.14-1596876032317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-814e6233-592a-477f-a391-561f3da4d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-84f1f091-fee2-4a50-9b2e-02bffe5975d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-4e1eea2c-3135-4a83-95a4-8f3840e9cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-15af1bc9-41cf-462d-8d91-4168eb426c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-e96060ec-8e81-4353-8f77-fbaa02603915,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-ef924fee-cf58-4a3e-a553-c4e2666b6085,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-83efc733-d373-4283-8965-1272672dc091,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-753d0a19-ad90-411b-9469-08117e85df77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508048465-172.17.0.14-1596876032317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-814e6233-592a-477f-a391-561f3da4d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-84f1f091-fee2-4a50-9b2e-02bffe5975d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-4e1eea2c-3135-4a83-95a4-8f3840e9cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-15af1bc9-41cf-462d-8d91-4168eb426c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-e96060ec-8e81-4353-8f77-fbaa02603915,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-ef924fee-cf58-4a3e-a553-c4e2666b6085,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-83efc733-d373-4283-8965-1272672dc091,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-753d0a19-ad90-411b-9469-08117e85df77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997703613-172.17.0.14-1596876416837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-e0d60b41-72ac-4f81-850f-e32fb94d6a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e548917f-f8aa-4f57-a110-53ce26aee90f,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-26f8d656-fcb7-4da9-add8-fb1c7c67a410,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-fe85f0be-1088-4348-a7f2-a1ccc7d622ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-674e9711-2791-4b7f-a71e-1cde51bf980b,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-e15b8ce6-af9e-4065-8b51-abedaa2d5060,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-bd8e59b5-90d5-424e-aded-a22a6e7fc29e,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-b906e48c-41a8-4b12-bb1c-a5e3ad3f6792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997703613-172.17.0.14-1596876416837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-e0d60b41-72ac-4f81-850f-e32fb94d6a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e548917f-f8aa-4f57-a110-53ce26aee90f,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-26f8d656-fcb7-4da9-add8-fb1c7c67a410,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-fe85f0be-1088-4348-a7f2-a1ccc7d622ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-674e9711-2791-4b7f-a71e-1cde51bf980b,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-e15b8ce6-af9e-4065-8b51-abedaa2d5060,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-bd8e59b5-90d5-424e-aded-a22a6e7fc29e,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-b906e48c-41a8-4b12-bb1c-a5e3ad3f6792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801950878-172.17.0.14-1596876646717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33998,DS-79670d06-ef7e-4498-a40a-d2de227b7269,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-21a98e8b-3da5-4c5e-9ab9-c827e2976f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-8f388565-6f8c-487c-b06f-b810ec578a90,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-98470f2b-bc80-4934-91a3-cb3b18d02d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-9d51dafb-2455-4370-bd3b-222c35850de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-4e1385ca-f01b-4b44-b8a2-60d534ee34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-da5e15ee-0e33-4401-83b7-6456775b93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-3586cb7f-4f9f-4882-aae1-f9ffd7293bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801950878-172.17.0.14-1596876646717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33998,DS-79670d06-ef7e-4498-a40a-d2de227b7269,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-21a98e8b-3da5-4c5e-9ab9-c827e2976f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-8f388565-6f8c-487c-b06f-b810ec578a90,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-98470f2b-bc80-4934-91a3-cb3b18d02d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-9d51dafb-2455-4370-bd3b-222c35850de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-4e1385ca-f01b-4b44-b8a2-60d534ee34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-da5e15ee-0e33-4401-83b7-6456775b93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-3586cb7f-4f9f-4882-aae1-f9ffd7293bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402473674-172.17.0.14-1596876686215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42759,DS-6fd520b2-3d08-4c65-afaa-9ca184a42a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-2e71a9ce-44ab-4784-973d-a8aaf233311d,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-87da8227-20c8-40e9-a05b-e2f15ec3e9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-0586209c-8e92-4852-a8ff-c5725c8afeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-0b9200bd-b8ae-4436-889b-36bc0343504b,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-8bc5a29b-65e2-4902-9b1d-0dab9793e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-2ec3780b-2e2a-4fd3-866a-646739323498,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-af0027e2-dd18-41e2-bf4a-285c3f91bffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402473674-172.17.0.14-1596876686215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42759,DS-6fd520b2-3d08-4c65-afaa-9ca184a42a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-2e71a9ce-44ab-4784-973d-a8aaf233311d,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-87da8227-20c8-40e9-a05b-e2f15ec3e9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-0586209c-8e92-4852-a8ff-c5725c8afeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-0b9200bd-b8ae-4436-889b-36bc0343504b,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-8bc5a29b-65e2-4902-9b1d-0dab9793e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-2ec3780b-2e2a-4fd3-866a-646739323498,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-af0027e2-dd18-41e2-bf4a-285c3f91bffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286680024-172.17.0.14-1596876966485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43816,DS-994676e6-3956-420c-aeac-72cbae4c822c,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-73fe43ed-ca20-463e-9dd3-da5b917a0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-47e182a7-6b89-4a00-bee5-93db5e2b65e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-329ae0fc-3b96-49f5-bdc4-6ed164ef9254,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-7879ff64-6f48-436c-8575-1c4cc62e4d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-84d93eff-8e63-4799-8f19-0c46e4672996,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-d0dee8d2-8b20-4c08-8f54-540d44c982c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-b5efad2d-f6b4-4163-8097-b7642bcda1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286680024-172.17.0.14-1596876966485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43816,DS-994676e6-3956-420c-aeac-72cbae4c822c,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-73fe43ed-ca20-463e-9dd3-da5b917a0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-47e182a7-6b89-4a00-bee5-93db5e2b65e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-329ae0fc-3b96-49f5-bdc4-6ed164ef9254,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-7879ff64-6f48-436c-8575-1c4cc62e4d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-84d93eff-8e63-4799-8f19-0c46e4672996,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-d0dee8d2-8b20-4c08-8f54-540d44c982c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-b5efad2d-f6b4-4163-8097-b7642bcda1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109673420-172.17.0.14-1596877098034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-e27945ed-facb-4b60-9766-4619841a0e13,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-b57d7768-65d2-4095-adfc-dce06afd88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-ab133420-3f5a-471a-b490-549adbe154c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-6cf74522-3ddd-4779-a665-2b57d059ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-3ae04a6b-caf7-46a8-85ec-b3faba7ff757,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-b0b1b396-9aa0-4cdc-b5cf-d8a928d93352,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-f76bca5a-b6db-4ce1-847e-66e2dad365b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-ff3de8f4-7a11-49b7-945d-a34d93f4eccf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109673420-172.17.0.14-1596877098034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-e27945ed-facb-4b60-9766-4619841a0e13,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-b57d7768-65d2-4095-adfc-dce06afd88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-ab133420-3f5a-471a-b490-549adbe154c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-6cf74522-3ddd-4779-a665-2b57d059ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-3ae04a6b-caf7-46a8-85ec-b3faba7ff757,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-b0b1b396-9aa0-4cdc-b5cf-d8a928d93352,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-f76bca5a-b6db-4ce1-847e-66e2dad365b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-ff3de8f4-7a11-49b7-945d-a34d93f4eccf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438163462-172.17.0.14-1596877417534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-553210f3-adf9-4d07-befb-1c4c4fd58469,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-cfd54d0d-23ec-4b88-9695-6e50664c0611,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-d402f857-6b19-47f9-b9c9-72cba0c7c909,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-e5457519-448f-4b92-b4c1-10826df4f1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-f9f5b682-b84a-4bcc-a6bd-a210ff232b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-0f03b8a7-1db9-4af9-9fc5-4df8056349dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-ee9b6c96-6523-4d5e-ad67-b67c94b2d735,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-27774f90-41bf-4463-8827-b7bac278c088,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438163462-172.17.0.14-1596877417534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-553210f3-adf9-4d07-befb-1c4c4fd58469,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-cfd54d0d-23ec-4b88-9695-6e50664c0611,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-d402f857-6b19-47f9-b9c9-72cba0c7c909,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-e5457519-448f-4b92-b4c1-10826df4f1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-f9f5b682-b84a-4bcc-a6bd-a210ff232b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-0f03b8a7-1db9-4af9-9fc5-4df8056349dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-ee9b6c96-6523-4d5e-ad67-b67c94b2d735,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-27774f90-41bf-4463-8827-b7bac278c088,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995456352-172.17.0.14-1596877465237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-22e21ffc-f09c-4490-9f44-a9bfb1d2641a,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-8ecb66f6-ce45-4dd6-a1ca-d1b1c893101c,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-b6b222e6-9f8d-48f6-a685-abcac1c42d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-3155c892-e977-48bd-8c6f-b44565accc36,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-ca6cf357-822c-4d19-b7da-3c1973269da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-508a528b-3262-40df-87a8-d37d28c82107,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-1c438ace-ca94-4a48-8a8b-854d20b8cca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-a163c048-427b-44f3-8748-c303a88fa92e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995456352-172.17.0.14-1596877465237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-22e21ffc-f09c-4490-9f44-a9bfb1d2641a,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-8ecb66f6-ce45-4dd6-a1ca-d1b1c893101c,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-b6b222e6-9f8d-48f6-a685-abcac1c42d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-3155c892-e977-48bd-8c6f-b44565accc36,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-ca6cf357-822c-4d19-b7da-3c1973269da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-508a528b-3262-40df-87a8-d37d28c82107,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-1c438ace-ca94-4a48-8a8b-854d20b8cca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-a163c048-427b-44f3-8748-c303a88fa92e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946825833-172.17.0.14-1596877601900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-a55afa49-0b6e-4826-a888-bcbf38941e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-c2f26852-2260-4727-bf1f-7b372e4aa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-106f7984-24a5-4414-a2dc-a1a327b27526,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-6205e79c-fac5-4332-8954-8b5b1987b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-cfb289b7-7066-4a1b-8aff-29cdf1368288,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-8ab7caaa-2643-4d51-a210-5f59dbe30c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-b803d00b-613e-4736-a97e-af8a7b1c30f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-e2c74a43-4f2a-47be-bd8f-125f85d047c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946825833-172.17.0.14-1596877601900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-a55afa49-0b6e-4826-a888-bcbf38941e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-c2f26852-2260-4727-bf1f-7b372e4aa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-106f7984-24a5-4414-a2dc-a1a327b27526,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-6205e79c-fac5-4332-8954-8b5b1987b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-cfb289b7-7066-4a1b-8aff-29cdf1368288,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-8ab7caaa-2643-4d51-a210-5f59dbe30c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-b803d00b-613e-4736-a97e-af8a7b1c30f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-e2c74a43-4f2a-47be-bd8f-125f85d047c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172761933-172.17.0.14-1596877647955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-293416b5-a067-4788-807c-61cc0b776214,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-e4767d53-e105-441c-85b9-aad5f650baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-54e8c5d8-24a3-4c16-a551-70093817d72f,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-47c3fc62-a4d2-4235-bafb-8a40eb25856e,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-f573afcd-3503-4040-97a5-d67ae72b14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-065b7ab9-264e-449b-b80c-f8187cb52d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-6054a5ae-44c9-4183-b54f-2ee507853318,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-a16ce564-20f0-403d-83a9-b27411e8f05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172761933-172.17.0.14-1596877647955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-293416b5-a067-4788-807c-61cc0b776214,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-e4767d53-e105-441c-85b9-aad5f650baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-54e8c5d8-24a3-4c16-a551-70093817d72f,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-47c3fc62-a4d2-4235-bafb-8a40eb25856e,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-f573afcd-3503-4040-97a5-d67ae72b14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-065b7ab9-264e-449b-b80c-f8187cb52d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-6054a5ae-44c9-4183-b54f-2ee507853318,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-a16ce564-20f0-403d-83a9-b27411e8f05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732631623-172.17.0.14-1596877729424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-ff411783-261c-4076-855f-eed850938d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-6eac5c0d-eecd-4b50-a888-3513ddb2ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-8973577e-949f-4aed-a5de-c6e936e70b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-55f4c516-d5d4-43a7-b71a-fd49c5b8f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-54c4d6ed-6fa2-4d73-b2c9-9e4c85697758,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-9df9cac8-bdd5-4e2c-8d58-87d80b85e4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-b0adaeae-846f-4349-9e87-f429418740eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-f0f0e0d9-2316-4caf-8c90-f2738b1ea3c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732631623-172.17.0.14-1596877729424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-ff411783-261c-4076-855f-eed850938d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-6eac5c0d-eecd-4b50-a888-3513ddb2ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-8973577e-949f-4aed-a5de-c6e936e70b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-55f4c516-d5d4-43a7-b71a-fd49c5b8f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-54c4d6ed-6fa2-4d73-b2c9-9e4c85697758,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-9df9cac8-bdd5-4e2c-8d58-87d80b85e4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-b0adaeae-846f-4349-9e87-f429418740eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-f0f0e0d9-2316-4caf-8c90-f2738b1ea3c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307610656-172.17.0.14-1596878088900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37426,DS-a840c076-b67e-48c8-8bc7-d6e168e5050d,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-496384e1-d573-440c-94cb-e5ef69c92d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-f3d8349a-1aca-4451-b7f4-7ded59120cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-0aefd445-4124-4275-b0cd-65cbba80a163,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-1f255360-1d78-4d79-bbdd-0d2f76210cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-d88eecd9-b18d-4f2c-a96b-8d3f53c2e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-55645b85-53fc-47e0-a41e-4f5c10a85be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-930abc45-84c3-4e75-b392-855b86cabd17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307610656-172.17.0.14-1596878088900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37426,DS-a840c076-b67e-48c8-8bc7-d6e168e5050d,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-496384e1-d573-440c-94cb-e5ef69c92d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-f3d8349a-1aca-4451-b7f4-7ded59120cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-0aefd445-4124-4275-b0cd-65cbba80a163,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-1f255360-1d78-4d79-bbdd-0d2f76210cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-d88eecd9-b18d-4f2c-a96b-8d3f53c2e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-55645b85-53fc-47e0-a41e-4f5c10a85be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-930abc45-84c3-4e75-b392-855b86cabd17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795942694-172.17.0.14-1596878377256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46512,DS-61991bba-608b-4efa-8203-5ede7038956f,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-84d6f5f7-01b4-49b6-babb-035ca8a87b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-2fb2db80-c44c-4abf-accb-76bef5f76c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-3892180e-25aa-4760-970a-7045913376a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-497da349-5195-4420-a6a8-f86d94ef1f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-b68106bc-5d57-44b1-9fd4-418553aff1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-a7dea668-8dc6-45ef-affb-7d67fd0a2c94,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-2dde3e34-3f4e-4436-a005-8fcda9dd13e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795942694-172.17.0.14-1596878377256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46512,DS-61991bba-608b-4efa-8203-5ede7038956f,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-84d6f5f7-01b4-49b6-babb-035ca8a87b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-2fb2db80-c44c-4abf-accb-76bef5f76c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-3892180e-25aa-4760-970a-7045913376a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-497da349-5195-4420-a6a8-f86d94ef1f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-b68106bc-5d57-44b1-9fd4-418553aff1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-a7dea668-8dc6-45ef-affb-7d67fd0a2c94,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-2dde3e34-3f4e-4436-a005-8fcda9dd13e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657641518-172.17.0.14-1596878423298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-78f8ad9b-6f71-423a-8b40-184492f7eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-fbc9a2df-f573-4454-b5d2-7e568eaf00de,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-5220dcfe-2eb4-4798-9697-df07baea5a08,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-8c40a178-c1e9-4bc8-86ff-acc7d32aa726,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-0fc8a65e-748b-415d-a601-2666110418dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-021f77e2-45b0-48de-a853-e9933f38ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-82039929-a65c-4938-b470-3bd958603a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-82ab1c6f-e678-473a-89bb-fc60bdf63221,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657641518-172.17.0.14-1596878423298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-78f8ad9b-6f71-423a-8b40-184492f7eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-fbc9a2df-f573-4454-b5d2-7e568eaf00de,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-5220dcfe-2eb4-4798-9697-df07baea5a08,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-8c40a178-c1e9-4bc8-86ff-acc7d32aa726,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-0fc8a65e-748b-415d-a601-2666110418dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-021f77e2-45b0-48de-a853-e9933f38ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-82039929-a65c-4938-b470-3bd958603a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-82ab1c6f-e678-473a-89bb-fc60bdf63221,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598610577-172.17.0.14-1596878821963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-6d78e352-29d0-434d-b10f-6e7b5078f473,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-61cf8a21-92af-4881-8c06-c0d60842f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-c54e1462-44a1-4317-8fca-6f97ea50286c,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-2dad531f-5c70-472d-bd9d-fb3d22863a89,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-e1dcbb20-0a9d-4cc7-ba2d-831ab37bcc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-f7e4c2ab-eb51-4d3d-9947-0caec6a44679,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-309e8ac7-e49e-4844-bf8e-56558a1d4d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-796d2393-3da2-492f-97fb-79350dc2334a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598610577-172.17.0.14-1596878821963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-6d78e352-29d0-434d-b10f-6e7b5078f473,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-61cf8a21-92af-4881-8c06-c0d60842f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-c54e1462-44a1-4317-8fca-6f97ea50286c,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-2dad531f-5c70-472d-bd9d-fb3d22863a89,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-e1dcbb20-0a9d-4cc7-ba2d-831ab37bcc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-f7e4c2ab-eb51-4d3d-9947-0caec6a44679,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-309e8ac7-e49e-4844-bf8e-56558a1d4d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-796d2393-3da2-492f-97fb-79350dc2334a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154073471-172.17.0.14-1596879220711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42378,DS-67737b6a-f934-415c-9241-d1aeb3ee0306,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-cd5c4240-7965-46ef-81f1-50c0fce5de02,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-305835e9-2eee-404a-a8b2-375ac3b80595,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-b66bf340-a1a8-4977-9a04-6c7ee9629350,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-10992811-3d55-4ecb-9b31-5903c0e7b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-e5c72a87-cf6f-4ddf-be72-546af2d8b205,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-6bd37a0d-5b30-491a-8c92-50e62fbbfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-81626f6c-93ae-43bf-8aa4-29ddafa9f453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154073471-172.17.0.14-1596879220711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42378,DS-67737b6a-f934-415c-9241-d1aeb3ee0306,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-cd5c4240-7965-46ef-81f1-50c0fce5de02,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-305835e9-2eee-404a-a8b2-375ac3b80595,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-b66bf340-a1a8-4977-9a04-6c7ee9629350,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-10992811-3d55-4ecb-9b31-5903c0e7b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-e5c72a87-cf6f-4ddf-be72-546af2d8b205,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-6bd37a0d-5b30-491a-8c92-50e62fbbfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-81626f6c-93ae-43bf-8aa4-29ddafa9f453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566067614-172.17.0.14-1596879279329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35965,DS-4b443937-c3f5-41f2-bcca-427963fc3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-99a5461b-8d06-4950-8994-12783fec0090,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-a80aaee0-61c1-417e-9411-ee7b13e4fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-42abaaa4-6d0a-4554-b938-4a85a475c323,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-f49d4df2-d845-4474-9871-b74a96db3873,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-821d27d4-496e-4592-b99e-13ab2dbe13f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-bb1d23fe-ff6c-439b-a193-e70bdad01ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-6698af4b-ad3a-4e81-a3ab-ab46b243e8fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566067614-172.17.0.14-1596879279329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35965,DS-4b443937-c3f5-41f2-bcca-427963fc3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-99a5461b-8d06-4950-8994-12783fec0090,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-a80aaee0-61c1-417e-9411-ee7b13e4fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-42abaaa4-6d0a-4554-b938-4a85a475c323,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-f49d4df2-d845-4474-9871-b74a96db3873,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-821d27d4-496e-4592-b99e-13ab2dbe13f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-bb1d23fe-ff6c-439b-a193-e70bdad01ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-6698af4b-ad3a-4e81-a3ab-ab46b243e8fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525824695-172.17.0.14-1596879402991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36370,DS-346abd7d-7bbf-4a94-b07b-7383f3415726,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-e48cb202-2d65-4657-8ef1-fc78e59a8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-0bf6ad12-18ac-4d6e-b8fc-a3fa65e51440,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-98c4da4a-ac19-4ea9-95f5-1205fef95529,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-031c003c-0c79-4263-a987-02e50b6d4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-09bec80a-f150-4f7d-8488-17fe9608dfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-fc554c3c-d212-4004-b21e-c7bead4322fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-131547bb-032f-49c6-a162-33a6615629a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525824695-172.17.0.14-1596879402991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36370,DS-346abd7d-7bbf-4a94-b07b-7383f3415726,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-e48cb202-2d65-4657-8ef1-fc78e59a8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-0bf6ad12-18ac-4d6e-b8fc-a3fa65e51440,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-98c4da4a-ac19-4ea9-95f5-1205fef95529,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-031c003c-0c79-4263-a987-02e50b6d4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-09bec80a-f150-4f7d-8488-17fe9608dfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-fc554c3c-d212-4004-b21e-c7bead4322fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-131547bb-032f-49c6-a162-33a6615629a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478482083-172.17.0.14-1596879542376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46583,DS-29d2a5a5-5ff9-4a21-bcfa-d361eb5889c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-2edd9930-7a00-46df-86f2-17b68fe489d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-3eedecbf-2564-4f0c-b7e4-30ca8dcf355f,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-54b7d1b9-34ba-434e-9025-66ccda02a6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-727f5a99-ddae-4a60-87b9-80e2699ec0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-921c8f9f-58d3-42fb-aeb1-5a64a1bd7e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-683f45cd-4e88-4e70-86a4-d6fd183d47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d79e27db-cea0-491f-845f-ddadea827a07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478482083-172.17.0.14-1596879542376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46583,DS-29d2a5a5-5ff9-4a21-bcfa-d361eb5889c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-2edd9930-7a00-46df-86f2-17b68fe489d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-3eedecbf-2564-4f0c-b7e4-30ca8dcf355f,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-54b7d1b9-34ba-434e-9025-66ccda02a6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-727f5a99-ddae-4a60-87b9-80e2699ec0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-921c8f9f-58d3-42fb-aeb1-5a64a1bd7e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-683f45cd-4e88-4e70-86a4-d6fd183d47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d79e27db-cea0-491f-845f-ddadea827a07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146119552-172.17.0.14-1596879633606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-46e7599f-828d-428c-8150-0416bfe0bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-40cd6c7e-d36f-4942-8902-8fef243f825e,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-ab8dfbc4-099d-4556-906b-119b80fafce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b933af4e-88d3-45ff-9c8d-e93991c9ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-9a65ccdf-58fc-4de2-9f3c-34dd07a7a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-a84c312a-093f-4ada-a2f4-13d5f281c718,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-375cb8ca-0787-46c5-ab39-379dbd98dd78,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-08b8c4bb-b634-4a70-b915-85c4aa0bfe60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146119552-172.17.0.14-1596879633606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-46e7599f-828d-428c-8150-0416bfe0bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-40cd6c7e-d36f-4942-8902-8fef243f825e,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-ab8dfbc4-099d-4556-906b-119b80fafce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b933af4e-88d3-45ff-9c8d-e93991c9ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-9a65ccdf-58fc-4de2-9f3c-34dd07a7a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-a84c312a-093f-4ada-a2f4-13d5f281c718,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-375cb8ca-0787-46c5-ab39-379dbd98dd78,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-08b8c4bb-b634-4a70-b915-85c4aa0bfe60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288733102-172.17.0.14-1596879671940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-a5830dc4-99e8-43b4-b249-2d397c335285,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-8c16b7a4-c34d-4a17-a336-3658a02727e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-db7bdbd4-3a24-4688-ad40-e21c8efb928e,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d27e3f19-c6ea-48eb-a6ee-422a16b867ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-7b7b7f99-61c4-4dbc-94bc-0eaa83154eff,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-33ccf8cc-c9fe-425e-965e-d609c7eaae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-adb0734c-9b1f-4d52-b1f1-9133fb71ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-b23e7ad6-dcce-4a19-aa81-6823f2bf4486,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288733102-172.17.0.14-1596879671940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-a5830dc4-99e8-43b4-b249-2d397c335285,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-8c16b7a4-c34d-4a17-a336-3658a02727e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-db7bdbd4-3a24-4688-ad40-e21c8efb928e,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d27e3f19-c6ea-48eb-a6ee-422a16b867ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-7b7b7f99-61c4-4dbc-94bc-0eaa83154eff,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-33ccf8cc-c9fe-425e-965e-d609c7eaae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-adb0734c-9b1f-4d52-b1f1-9133fb71ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-b23e7ad6-dcce-4a19-aa81-6823f2bf4486,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995011774-172.17.0.14-1596879763877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38969,DS-3fd6cec4-10b8-4ddd-8dbf-78c967ca7950,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-ad4b4404-f5a0-41cf-8c45-fa92504da144,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-9fb07e9c-96c1-4319-a3de-7ab158b83a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-66d9acf3-b56e-4e66-90cb-b1f2b5a4d21e,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-643a95cf-23a7-4483-b81d-98a37d1fd2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-91ccabed-7657-4820-973e-0bfd82851a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-c0bfd3b6-6c59-447a-8108-89ec7a03d34d,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-fd9701c5-f87a-4071-b654-15e392cb1bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995011774-172.17.0.14-1596879763877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38969,DS-3fd6cec4-10b8-4ddd-8dbf-78c967ca7950,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-ad4b4404-f5a0-41cf-8c45-fa92504da144,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-9fb07e9c-96c1-4319-a3de-7ab158b83a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-66d9acf3-b56e-4e66-90cb-b1f2b5a4d21e,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-643a95cf-23a7-4483-b81d-98a37d1fd2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-91ccabed-7657-4820-973e-0bfd82851a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-c0bfd3b6-6c59-447a-8108-89ec7a03d34d,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-fd9701c5-f87a-4071-b654-15e392cb1bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99963293-172.17.0.14-1596879850398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-597ac4f8-825d-483f-b8c7-c41bcf59f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-a28c6d6c-61d7-42fe-946c-f4bcc22f92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1c16a0fe-d0bd-49b7-9046-b54a7a1fc766,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-25af50f9-6575-46f2-8162-bf92f6b83387,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-ede39178-6087-460d-9daf-912950fc83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-dfa2e10e-5b54-4e8f-a32a-88767ae1b212,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-74947798-2c72-4108-970d-ea14c691b701,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-f64d6c30-ae0a-490f-9271-81070ff17eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99963293-172.17.0.14-1596879850398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-597ac4f8-825d-483f-b8c7-c41bcf59f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-a28c6d6c-61d7-42fe-946c-f4bcc22f92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1c16a0fe-d0bd-49b7-9046-b54a7a1fc766,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-25af50f9-6575-46f2-8162-bf92f6b83387,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-ede39178-6087-460d-9daf-912950fc83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-dfa2e10e-5b54-4e8f-a32a-88767ae1b212,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-74947798-2c72-4108-970d-ea14c691b701,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-f64d6c30-ae0a-490f-9271-81070ff17eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422965889-172.17.0.14-1596879894719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44779,DS-3fd653a6-53c6-414e-bfea-e04ea60fe621,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-aa1d7813-1dcf-4de7-8743-f9e355796e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-7b231c0b-c2af-4357-a4ad-2c310dcc9a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-33690418-904c-41ce-a014-6a700844a740,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-c0dc1d11-0c9a-46fd-8221-964dd5c07ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-9e53eb2e-6490-4160-aad9-8df6f2d02090,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-23da4a84-5cd5-4438-a92e-6d57c15a70b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-35cbdcff-be3f-4dcb-98e4-72e469cf240d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422965889-172.17.0.14-1596879894719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44779,DS-3fd653a6-53c6-414e-bfea-e04ea60fe621,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-aa1d7813-1dcf-4de7-8743-f9e355796e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-7b231c0b-c2af-4357-a4ad-2c310dcc9a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-33690418-904c-41ce-a014-6a700844a740,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-c0dc1d11-0c9a-46fd-8221-964dd5c07ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-9e53eb2e-6490-4160-aad9-8df6f2d02090,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-23da4a84-5cd5-4438-a92e-6d57c15a70b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-35cbdcff-be3f-4dcb-98e4-72e469cf240d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140920008-172.17.0.14-1596880085719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-64e7b47b-fb5e-40e6-b219-a259c7441d33,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-ca2f86e8-b38b-456b-b1b5-dd613052e3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-4b3c2c8c-9701-456b-91f3-708cd5fe4c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-13ea1bf6-aab4-4c99-ba2a-c8dfa2d142e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-3f6af974-d615-4cfc-b4d5-49ec7217207a,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-2cabc12c-85ba-4f98-827c-9aa6299959e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-755936bd-ef90-473d-b844-2c88fe8b343b,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-445af039-7bdc-44b5-a159-a14ec377213b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140920008-172.17.0.14-1596880085719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-64e7b47b-fb5e-40e6-b219-a259c7441d33,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-ca2f86e8-b38b-456b-b1b5-dd613052e3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-4b3c2c8c-9701-456b-91f3-708cd5fe4c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-13ea1bf6-aab4-4c99-ba2a-c8dfa2d142e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-3f6af974-d615-4cfc-b4d5-49ec7217207a,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-2cabc12c-85ba-4f98-827c-9aa6299959e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-755936bd-ef90-473d-b844-2c88fe8b343b,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-445af039-7bdc-44b5-a159-a14ec377213b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351609505-172.17.0.14-1596880310677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-662660c2-04cf-43ef-95a6-8419284cd8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-4655c4a5-d6c2-47f4-8765-a2605e863215,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-03793e88-f32b-41b9-86fe-22e053d47e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-cd43d6d9-9119-46c3-999c-f177afc723c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-5285880c-a46c-4c74-b5d4-2e949c23751b,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-91c51d26-8048-4fa9-b6fc-0493708ea3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-360f4e2e-aa81-4ab8-ba55-79b6a223913c,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-f4d1473e-088d-44e5-a7b9-792d7a4679e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351609505-172.17.0.14-1596880310677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-662660c2-04cf-43ef-95a6-8419284cd8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-4655c4a5-d6c2-47f4-8765-a2605e863215,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-03793e88-f32b-41b9-86fe-22e053d47e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-cd43d6d9-9119-46c3-999c-f177afc723c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-5285880c-a46c-4c74-b5d4-2e949c23751b,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-91c51d26-8048-4fa9-b6fc-0493708ea3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-360f4e2e-aa81-4ab8-ba55-79b6a223913c,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-f4d1473e-088d-44e5-a7b9-792d7a4679e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940376939-172.17.0.14-1596880541482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-0b8f058b-d7b0-4563-a0b5-36a6840c30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-6cbfdd20-c199-4ea7-b16a-2ee0a2fc15d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-17ebc6fc-ddf1-4c63-933b-bee88c56bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-abb65b5b-507e-44ed-81a9-fb5d3ca897e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-1dc0debd-c3eb-4da4-b283-38358dd5b85c,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-1d1f2e38-281d-47f5-97da-f2bf6c08d8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-e89f62d6-9434-4612-a98d-c230d310017e,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-a4b74a87-5d64-4baf-b92a-fddccb3f2d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940376939-172.17.0.14-1596880541482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-0b8f058b-d7b0-4563-a0b5-36a6840c30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-6cbfdd20-c199-4ea7-b16a-2ee0a2fc15d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-17ebc6fc-ddf1-4c63-933b-bee88c56bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-abb65b5b-507e-44ed-81a9-fb5d3ca897e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-1dc0debd-c3eb-4da4-b283-38358dd5b85c,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-1d1f2e38-281d-47f5-97da-f2bf6c08d8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-e89f62d6-9434-4612-a98d-c230d310017e,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-a4b74a87-5d64-4baf-b92a-fddccb3f2d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201848985-172.17.0.14-1596880633760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40497,DS-c3112aef-1047-4e00-a32c-553fcc36e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-0cb19cf6-d7bf-405d-bb6a-533eb0ec9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-03a2aa3f-37a3-45e7-902d-60a18f40d260,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-63c708aa-a309-4329-82c4-fcfb418eec86,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-57b2134c-df0b-4fec-9d5d-ec3263dc338a,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-446f8509-825e-49f7-b21f-6421b335bcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-25d26e20-3cfc-4571-8b42-e54e9d5151c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-58a282a7-14c2-4dac-86fe-fedb3110dd2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201848985-172.17.0.14-1596880633760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40497,DS-c3112aef-1047-4e00-a32c-553fcc36e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-0cb19cf6-d7bf-405d-bb6a-533eb0ec9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-03a2aa3f-37a3-45e7-902d-60a18f40d260,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-63c708aa-a309-4329-82c4-fcfb418eec86,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-57b2134c-df0b-4fec-9d5d-ec3263dc338a,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-446f8509-825e-49f7-b21f-6421b335bcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-25d26e20-3cfc-4571-8b42-e54e9d5151c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-58a282a7-14c2-4dac-86fe-fedb3110dd2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199427564-172.17.0.14-1596880674148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41912,DS-a7f6645b-2e25-4e56-a36c-1ab20fc93feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-18c285be-4f6d-4d6c-9c34-78512d7aa819,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-64a0cd8c-d9b0-4b28-ac4f-a723c0624d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-05066d40-5299-4c5c-b63d-a1b5fb3c606a,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-d07e891a-5b40-46a5-bc9e-093e537212f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-9b0130bb-9596-499a-8982-4e4d2368fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-57fe5cdc-6590-43f5-bed4-b814c26e9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-875e1465-52e3-4d11-b69f-da481061abde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199427564-172.17.0.14-1596880674148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41912,DS-a7f6645b-2e25-4e56-a36c-1ab20fc93feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-18c285be-4f6d-4d6c-9c34-78512d7aa819,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-64a0cd8c-d9b0-4b28-ac4f-a723c0624d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-05066d40-5299-4c5c-b63d-a1b5fb3c606a,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-d07e891a-5b40-46a5-bc9e-093e537212f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-9b0130bb-9596-499a-8982-4e4d2368fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-57fe5cdc-6590-43f5-bed4-b814c26e9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-875e1465-52e3-4d11-b69f-da481061abde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643243610-172.17.0.14-1596880907005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-26b41054-c935-4c67-a044-1ca09ec75860,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-d2f64957-912f-4a8b-903d-cb1b1b083f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-bfd2191e-7e17-430a-998d-738fef9ee145,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-3b2c3954-47f1-4d06-87d8-3bb451fbdddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-ba7acc4f-a9ce-40c0-ad13-7265a5ebdc70,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-6730de9f-82ee-4c73-a510-2f2e3b3963a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-c233349c-61b4-4646-9497-be892fbe6839,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-47c7858d-5055-419d-b4ca-9598aab808e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643243610-172.17.0.14-1596880907005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-26b41054-c935-4c67-a044-1ca09ec75860,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-d2f64957-912f-4a8b-903d-cb1b1b083f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-bfd2191e-7e17-430a-998d-738fef9ee145,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-3b2c3954-47f1-4d06-87d8-3bb451fbdddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-ba7acc4f-a9ce-40c0-ad13-7265a5ebdc70,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-6730de9f-82ee-4c73-a510-2f2e3b3963a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-c233349c-61b4-4646-9497-be892fbe6839,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-47c7858d-5055-419d-b4ca-9598aab808e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480402879-172.17.0.14-1596882084123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-1a9ec388-3e48-4841-9b40-8a0d5fe483d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-fae84478-45b8-4a51-81d5-76a3b3aa9abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-58b9962f-1ad4-4350-bf23-f70be4baa415,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-84be0159-d546-45bc-83e4-a19af4b29359,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-7531a0fc-c84b-4389-8452-6295ea723976,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-1d7cdc50-f57c-48e0-b9de-55fb20567f44,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-deb6876d-95dc-4d33-92bd-6d34e8201abb,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-261f9381-0edb-44ee-8241-89f0ec21d96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480402879-172.17.0.14-1596882084123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-1a9ec388-3e48-4841-9b40-8a0d5fe483d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-fae84478-45b8-4a51-81d5-76a3b3aa9abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-58b9962f-1ad4-4350-bf23-f70be4baa415,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-84be0159-d546-45bc-83e4-a19af4b29359,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-7531a0fc-c84b-4389-8452-6295ea723976,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-1d7cdc50-f57c-48e0-b9de-55fb20567f44,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-deb6876d-95dc-4d33-92bd-6d34e8201abb,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-261f9381-0edb-44ee-8241-89f0ec21d96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 6918
