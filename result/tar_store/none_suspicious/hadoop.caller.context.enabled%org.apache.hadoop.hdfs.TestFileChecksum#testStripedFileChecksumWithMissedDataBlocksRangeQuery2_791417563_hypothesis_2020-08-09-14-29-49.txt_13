reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404089562-172.17.0.14-1596983404769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39531,DS-a104860c-699d-435d-a377-7da291d71e99,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-2e27f94c-9062-449b-9c92-35d04c64f870,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3dffed34-5d09-4f89-b4c2-4b23c70580f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-2c068ee2-8615-40b7-961e-a777df69e262,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-98296f51-fcc0-457a-991f-dc2cbb2237a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-f01a950a-4833-4956-b58b-8b1deb7a1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-2aafe916-0994-4c7f-95d9-ce42dd688c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-43b0d83f-d207-4c9d-8585-828509f7608c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404089562-172.17.0.14-1596983404769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39531,DS-a104860c-699d-435d-a377-7da291d71e99,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-2e27f94c-9062-449b-9c92-35d04c64f870,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3dffed34-5d09-4f89-b4c2-4b23c70580f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-2c068ee2-8615-40b7-961e-a777df69e262,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-98296f51-fcc0-457a-991f-dc2cbb2237a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-f01a950a-4833-4956-b58b-8b1deb7a1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-2aafe916-0994-4c7f-95d9-ce42dd688c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-43b0d83f-d207-4c9d-8585-828509f7608c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552722323-172.17.0.14-1596983543549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39442,DS-b295a3e1-0072-4ab4-a408-b2961e9beed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-00ba73c5-0680-4d45-baa3-484976cbab03,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-a0be7131-79a3-4bd9-8251-bfb507ef1f21,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-401f3ac9-7883-4389-9c0f-de2f77076ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-e975b9b2-5c4d-4ffd-a996-e4adc0b100a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-fe2292f6-c3ab-46b1-8279-feb95a019fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a61595e8-d6b8-4ae0-9e79-9a725337c78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-7e983189-db58-4ffc-b61d-409a945a85d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552722323-172.17.0.14-1596983543549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39442,DS-b295a3e1-0072-4ab4-a408-b2961e9beed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-00ba73c5-0680-4d45-baa3-484976cbab03,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-a0be7131-79a3-4bd9-8251-bfb507ef1f21,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-401f3ac9-7883-4389-9c0f-de2f77076ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-e975b9b2-5c4d-4ffd-a996-e4adc0b100a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-fe2292f6-c3ab-46b1-8279-feb95a019fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a61595e8-d6b8-4ae0-9e79-9a725337c78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-7e983189-db58-4ffc-b61d-409a945a85d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538682085-172.17.0.14-1596984166068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-4a2ded6f-3559-4063-a9f1-bbd933dfa4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-56bf9946-5b35-4c76-a153-6bfbd6f9a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-08c5c751-f358-4624-8f7d-850b31c8d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-62e6afc4-595d-4b63-8e99-be826dc34baf,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-e3b79a5f-65e2-4c39-8da4-c11db8b77135,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-bfd5ccd1-7da4-4deb-9fc2-16e663410d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-a11276e5-9d94-4ad7-ab64-771a1b5761af,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-4c40c07c-1ada-4b85-8142-e343fe82533d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538682085-172.17.0.14-1596984166068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-4a2ded6f-3559-4063-a9f1-bbd933dfa4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-56bf9946-5b35-4c76-a153-6bfbd6f9a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-08c5c751-f358-4624-8f7d-850b31c8d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-62e6afc4-595d-4b63-8e99-be826dc34baf,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-e3b79a5f-65e2-4c39-8da4-c11db8b77135,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-bfd5ccd1-7da4-4deb-9fc2-16e663410d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-a11276e5-9d94-4ad7-ab64-771a1b5761af,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-4c40c07c-1ada-4b85-8142-e343fe82533d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682777794-172.17.0.14-1596984324597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-7e53c891-4e23-41cd-9db5-a27025eacaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-362fc02c-b83f-4a0f-90cf-2bf64bad7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-dc5b3a15-e59a-4310-9c97-67dc9d9b5eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8452f968-a85b-41bc-bf66-f3b95b45a6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-33f09d6f-36f8-47d4-a12f-69d4fa8b82c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-a18376e0-82a4-43c6-a79f-2e225c040643,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-4f0b9f5e-a651-4697-8d11-341ed6e72171,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-af05dae2-5b2b-4018-a3b1-2b4023fa2f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682777794-172.17.0.14-1596984324597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-7e53c891-4e23-41cd-9db5-a27025eacaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-362fc02c-b83f-4a0f-90cf-2bf64bad7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-dc5b3a15-e59a-4310-9c97-67dc9d9b5eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8452f968-a85b-41bc-bf66-f3b95b45a6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-33f09d6f-36f8-47d4-a12f-69d4fa8b82c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-a18376e0-82a4-43c6-a79f-2e225c040643,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-4f0b9f5e-a651-4697-8d11-341ed6e72171,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-af05dae2-5b2b-4018-a3b1-2b4023fa2f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753432725-172.17.0.14-1596984340652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42914,DS-c09f73a3-d7d8-4182-be54-83240254e23e,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-03111470-c723-48db-82ed-c25c8f8b73e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-9475a565-4380-442f-8e31-e7cf285cb681,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-2131828d-1eac-4ed9-acd1-ffaf5cab487d,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-97721cab-e9aa-46e1-b0a5-f173f2efcb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-cadce45d-cb12-421e-aa41-582ade6c811d,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-4bdc407e-2df4-4ba6-bd64-f02ed605f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-d45fcb64-0f62-46f4-a264-b08d3151d640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753432725-172.17.0.14-1596984340652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42914,DS-c09f73a3-d7d8-4182-be54-83240254e23e,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-03111470-c723-48db-82ed-c25c8f8b73e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-9475a565-4380-442f-8e31-e7cf285cb681,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-2131828d-1eac-4ed9-acd1-ffaf5cab487d,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-97721cab-e9aa-46e1-b0a5-f173f2efcb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-cadce45d-cb12-421e-aa41-582ade6c811d,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-4bdc407e-2df4-4ba6-bd64-f02ed605f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-d45fcb64-0f62-46f4-a264-b08d3151d640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695085631-172.17.0.14-1596984356378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46191,DS-82f50334-d5ce-4ce6-b769-74c48b8fbabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-3070c28b-218b-4bb0-9ea8-a2297a20c2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-5ce69b39-dc6b-4cfa-880f-953c1c17f122,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-fbb8567c-9999-4ed9-b638-dea27f02e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-cdd288d9-e324-47af-8181-ed81a400fa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-322cd8fa-4b17-405c-9f4a-f98af82856d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-4d024460-064f-4c48-8cdc-d9e93431e669,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-e6874727-a57e-4e9b-8455-094df2d2e840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695085631-172.17.0.14-1596984356378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46191,DS-82f50334-d5ce-4ce6-b769-74c48b8fbabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-3070c28b-218b-4bb0-9ea8-a2297a20c2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-5ce69b39-dc6b-4cfa-880f-953c1c17f122,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-fbb8567c-9999-4ed9-b638-dea27f02e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-cdd288d9-e324-47af-8181-ed81a400fa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-322cd8fa-4b17-405c-9f4a-f98af82856d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-4d024460-064f-4c48-8cdc-d9e93431e669,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-e6874727-a57e-4e9b-8455-094df2d2e840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455498572-172.17.0.14-1596984482663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45826,DS-febf2172-4a4a-4900-8148-e42adff6bca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-f60a5dbf-bb6c-4830-8374-f30476ab6eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-13f9cc36-243a-4297-80c9-bc8cd899f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-abe2a07c-3a75-4256-ad23-2149dbc143aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-122022e6-bd31-4988-8f91-4ae5881a793a,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-f1fd1727-1dae-4043-b79a-4e1bda78fc28,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-9d6e6856-497c-421a-b47d-1b6a33a0ff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-6dc3d0a3-0f25-424e-a950-40a3596bf7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455498572-172.17.0.14-1596984482663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45826,DS-febf2172-4a4a-4900-8148-e42adff6bca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-f60a5dbf-bb6c-4830-8374-f30476ab6eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-13f9cc36-243a-4297-80c9-bc8cd899f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-abe2a07c-3a75-4256-ad23-2149dbc143aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-122022e6-bd31-4988-8f91-4ae5881a793a,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-f1fd1727-1dae-4043-b79a-4e1bda78fc28,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-9d6e6856-497c-421a-b47d-1b6a33a0ff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-6dc3d0a3-0f25-424e-a950-40a3596bf7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040145670-172.17.0.14-1596984513996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33457,DS-4dd0ecc6-0829-4c73-ac95-e0ccfa69c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5f83500a-a2ef-4e60-a02a-7a2231df7d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-dcc6182c-3b58-4f51-8312-ba61d40d4018,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6206f670-2db4-48f8-a720-67f4f07e0c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-905746b2-47e3-4ee8-b72f-55088eb6163b,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-46aa7631-9877-4360-87a0-7febd26482d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1e7c5b52-4fa4-4380-ae66-59fd344fb9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-f0de3a25-5484-4656-b726-6a741a55d447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040145670-172.17.0.14-1596984513996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33457,DS-4dd0ecc6-0829-4c73-ac95-e0ccfa69c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5f83500a-a2ef-4e60-a02a-7a2231df7d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-dcc6182c-3b58-4f51-8312-ba61d40d4018,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6206f670-2db4-48f8-a720-67f4f07e0c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-905746b2-47e3-4ee8-b72f-55088eb6163b,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-46aa7631-9877-4360-87a0-7febd26482d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1e7c5b52-4fa4-4380-ae66-59fd344fb9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-f0de3a25-5484-4656-b726-6a741a55d447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545386929-172.17.0.14-1596984844635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-de8ccbbb-e5a9-4717-a410-ff0543061fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-0e0c267c-0857-4e3e-a64c-927bbb698515,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-4e3c7f2a-6ad9-4f25-81f5-5b94ab170775,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-06b8d0e2-adde-4660-a561-9abe6e44e671,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-7d9f9338-56b4-4dc0-86e3-625c88dedbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-2c635b11-0cdb-400b-a671-a4e31e9bd8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-48170b0d-808c-4a34-833b-b962e3824aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-2d03f55a-3978-41f3-8c6f-af5d822bef13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545386929-172.17.0.14-1596984844635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-de8ccbbb-e5a9-4717-a410-ff0543061fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-0e0c267c-0857-4e3e-a64c-927bbb698515,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-4e3c7f2a-6ad9-4f25-81f5-5b94ab170775,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-06b8d0e2-adde-4660-a561-9abe6e44e671,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-7d9f9338-56b4-4dc0-86e3-625c88dedbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-2c635b11-0cdb-400b-a671-a4e31e9bd8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-48170b0d-808c-4a34-833b-b962e3824aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-2d03f55a-3978-41f3-8c6f-af5d822bef13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125791622-172.17.0.14-1596985082262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35718,DS-c4c7cb0b-6ced-43e6-8a81-693eaac79d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-4657c3bb-d970-48f9-adf9-6b89f7e833c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-bb7d5472-cf8d-4190-b470-22bbad6ea8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-a2cf7258-fd39-495b-89f7-2ed324ca0ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-f037ea31-2f32-438c-aab4-56d1a98eee89,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-238751ac-1eaf-4f63-b252-2c39952dfff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-9e9e8c96-3dff-4fb9-b246-e0c455721ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-7d4fc883-c0f4-4704-bb67-ad64167ab79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125791622-172.17.0.14-1596985082262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35718,DS-c4c7cb0b-6ced-43e6-8a81-693eaac79d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-4657c3bb-d970-48f9-adf9-6b89f7e833c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-bb7d5472-cf8d-4190-b470-22bbad6ea8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-a2cf7258-fd39-495b-89f7-2ed324ca0ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-f037ea31-2f32-438c-aab4-56d1a98eee89,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-238751ac-1eaf-4f63-b252-2c39952dfff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-9e9e8c96-3dff-4fb9-b246-e0c455721ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-7d4fc883-c0f4-4704-bb67-ad64167ab79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355956015-172.17.0.14-1596985114532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32940,DS-aed8084a-f8f6-40c4-b983-568c6c8c208a,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-e65de2f9-9972-4011-8669-af8531190479,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-05f901a0-b832-4b5b-8684-c6073de7c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-2216f0e0-afa2-4e63-83e4-c8171ff0adf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-f709a7df-82d6-4d77-8373-4f62edd75b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-35cd7158-06e1-48ab-a3c4-c27ad1f57f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-f93a961c-5fba-4fc7-a76f-db743612326d,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-5c95ee3e-e551-4893-8682-ce284f905066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355956015-172.17.0.14-1596985114532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32940,DS-aed8084a-f8f6-40c4-b983-568c6c8c208a,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-e65de2f9-9972-4011-8669-af8531190479,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-05f901a0-b832-4b5b-8684-c6073de7c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-2216f0e0-afa2-4e63-83e4-c8171ff0adf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-f709a7df-82d6-4d77-8373-4f62edd75b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-35cd7158-06e1-48ab-a3c4-c27ad1f57f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-f93a961c-5fba-4fc7-a76f-db743612326d,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-5c95ee3e-e551-4893-8682-ce284f905066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511753746-172.17.0.14-1596985382151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-0704dcd1-0873-43bd-be64-8eed6d215629,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-a91fab44-8c2a-47a3-9c56-d12f5603b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-9924003b-a276-4ac0-ac39-8193f7fd4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-7426ea83-953a-4cf9-83d8-fbe85fb5a874,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-2b97734f-697d-4399-bd1d-75ff395a9e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-01dc1990-3e47-4edd-b9fd-864d821d6711,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-601c886e-be39-4d7a-b9c9-060c1b95a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-b340419e-fc9f-4787-b3eb-48255a4becee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511753746-172.17.0.14-1596985382151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-0704dcd1-0873-43bd-be64-8eed6d215629,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-a91fab44-8c2a-47a3-9c56-d12f5603b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-9924003b-a276-4ac0-ac39-8193f7fd4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-7426ea83-953a-4cf9-83d8-fbe85fb5a874,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-2b97734f-697d-4399-bd1d-75ff395a9e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-01dc1990-3e47-4edd-b9fd-864d821d6711,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-601c886e-be39-4d7a-b9c9-060c1b95a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-b340419e-fc9f-4787-b3eb-48255a4becee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082649607-172.17.0.14-1596985507984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45486,DS-f069ff69-985e-477b-9ce5-a853bad22945,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-e1318e4a-63bf-415e-8d9c-f89f65e2ee77,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-1f2fda98-811b-43d9-8df3-6172d8b88890,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-78f82834-683f-43f5-896d-d0ddcc41607e,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-e93e10fa-d9bb-43cc-adab-163025ed51c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-ab4592a7-a1bd-491c-8f51-f3d19cc7f9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-6f94107f-f5d4-49de-939e-20480534fd20,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-8819fe2f-1737-4efc-a8d6-a2968a60aacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082649607-172.17.0.14-1596985507984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45486,DS-f069ff69-985e-477b-9ce5-a853bad22945,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-e1318e4a-63bf-415e-8d9c-f89f65e2ee77,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-1f2fda98-811b-43d9-8df3-6172d8b88890,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-78f82834-683f-43f5-896d-d0ddcc41607e,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-e93e10fa-d9bb-43cc-adab-163025ed51c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-ab4592a7-a1bd-491c-8f51-f3d19cc7f9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-6f94107f-f5d4-49de-939e-20480534fd20,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-8819fe2f-1737-4efc-a8d6-a2968a60aacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142272715-172.17.0.14-1596985949758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42274,DS-cddb6fb2-355e-4056-b5e1-c9b6536df652,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-6fdf406c-c894-4f78-8b82-c74dd249d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-b0f370a3-d0a9-4e8a-ad5c-e811a1875721,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-9969adf2-865a-4b61-8b3d-390d508c3bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-a6a97b9d-3b10-4dc2-8c4b-686e60f5ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-bee2ddd7-d662-4c62-8fcd-5fd451bc0247,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-f954159f-fc09-47df-bfd0-aee017b8bc15,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-e70aa3b0-629e-4ebb-a621-218f730d0c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142272715-172.17.0.14-1596985949758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42274,DS-cddb6fb2-355e-4056-b5e1-c9b6536df652,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-6fdf406c-c894-4f78-8b82-c74dd249d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-b0f370a3-d0a9-4e8a-ad5c-e811a1875721,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-9969adf2-865a-4b61-8b3d-390d508c3bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-a6a97b9d-3b10-4dc2-8c4b-686e60f5ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-bee2ddd7-d662-4c62-8fcd-5fd451bc0247,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-f954159f-fc09-47df-bfd0-aee017b8bc15,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-e70aa3b0-629e-4ebb-a621-218f730d0c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 2633
