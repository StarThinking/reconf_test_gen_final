reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668267688-172.17.0.20-1596886672067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33161,DS-7924156f-1cbf-4898-b7a4-ec3240c37f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-13d70f87-4a03-46cd-a9d5-59b11a10ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-7278fb65-c58e-4bfc-9801-71555f64c484,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-2daa0302-b38c-4429-b0bd-ef476faa28ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-a2fccaf2-2148-4b44-aac7-897324985ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-461d9bf0-1838-45dd-805e-1d5bbfc4672b,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-18d1d76a-d4d4-4452-bc4f-f27d3ce098e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-e8c06e59-a3ca-417f-8ec8-7876caf6203d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668267688-172.17.0.20-1596886672067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33161,DS-7924156f-1cbf-4898-b7a4-ec3240c37f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-13d70f87-4a03-46cd-a9d5-59b11a10ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-7278fb65-c58e-4bfc-9801-71555f64c484,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-2daa0302-b38c-4429-b0bd-ef476faa28ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-a2fccaf2-2148-4b44-aac7-897324985ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-461d9bf0-1838-45dd-805e-1d5bbfc4672b,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-18d1d76a-d4d4-4452-bc4f-f27d3ce098e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-e8c06e59-a3ca-417f-8ec8-7876caf6203d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034688042-172.17.0.20-1596886868061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-da97a0e3-e7a3-4937-b618-1bb8f6fef5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-fe6bb120-2088-426d-aa6d-6b84265ed4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-4e8477f0-c5f5-4d70-8b0c-c189ec9cf618,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-8b1ebf41-633a-432d-9a81-2c28eec259af,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-64880eca-c743-483c-8b76-4fd798cd3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-1a3d4d73-d37b-4a66-bb1a-5666c46b7be9,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-e160fbd2-f9bc-4c86-9d5b-d99578d09257,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-7588591d-0db4-458d-8043-2ed7f77504aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034688042-172.17.0.20-1596886868061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-da97a0e3-e7a3-4937-b618-1bb8f6fef5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-fe6bb120-2088-426d-aa6d-6b84265ed4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-4e8477f0-c5f5-4d70-8b0c-c189ec9cf618,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-8b1ebf41-633a-432d-9a81-2c28eec259af,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-64880eca-c743-483c-8b76-4fd798cd3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-1a3d4d73-d37b-4a66-bb1a-5666c46b7be9,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-e160fbd2-f9bc-4c86-9d5b-d99578d09257,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-7588591d-0db4-458d-8043-2ed7f77504aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807957220-172.17.0.20-1596886915213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38731,DS-98a2685a-ed97-4b1c-a8f7-9b8f2e10945f,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-c1ef7aba-aa77-4db8-be27-3128509e0224,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-d359bdd3-a1af-4131-bc25-958963bb7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-35c074ae-ff2f-44d4-b50b-2c704ebb139f,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-2c597712-c12d-4353-aa11-112897830769,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-ad48f3f2-882c-499f-9378-15fb44fa71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-6c8a5f18-531d-41be-9f4a-63c4682dda3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-31000ac9-b10f-4175-aa01-c0f95d3b83f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807957220-172.17.0.20-1596886915213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38731,DS-98a2685a-ed97-4b1c-a8f7-9b8f2e10945f,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-c1ef7aba-aa77-4db8-be27-3128509e0224,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-d359bdd3-a1af-4131-bc25-958963bb7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-35c074ae-ff2f-44d4-b50b-2c704ebb139f,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-2c597712-c12d-4353-aa11-112897830769,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-ad48f3f2-882c-499f-9378-15fb44fa71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-6c8a5f18-531d-41be-9f4a-63c4682dda3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-31000ac9-b10f-4175-aa01-c0f95d3b83f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373228315-172.17.0.20-1596888032498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-a85c2b38-c79a-4b2d-9257-aae1eb851a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-f81263d8-30bf-45cd-87dd-0ffa83d41ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-75328f0f-af25-448b-9a85-84497df498db,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-b420f4c8-0a72-4c52-8de3-4fb74a3e9307,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-0cbc7537-30c8-44de-9e2f-e238f92eaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-b32003ec-bb10-4738-8277-d7bb45750baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-e76e72b9-c48b-4c28-a94d-bd26416bc0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-56d439df-9067-46fc-bfdf-d5bd8f2bd2b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373228315-172.17.0.20-1596888032498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-a85c2b38-c79a-4b2d-9257-aae1eb851a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-f81263d8-30bf-45cd-87dd-0ffa83d41ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-75328f0f-af25-448b-9a85-84497df498db,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-b420f4c8-0a72-4c52-8de3-4fb74a3e9307,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-0cbc7537-30c8-44de-9e2f-e238f92eaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-b32003ec-bb10-4738-8277-d7bb45750baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-e76e72b9-c48b-4c28-a94d-bd26416bc0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-56d439df-9067-46fc-bfdf-d5bd8f2bd2b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870850341-172.17.0.20-1596888385947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42056,DS-52127146-7028-41d1-9f59-d0832449d827,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-aff100c4-b854-4a14-b247-e3eb1e708a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-a2459a31-16e1-4e54-b4ed-a31c0758db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-7219672d-5897-4680-87f7-4e85bab9700e,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4ea9ad85-9a9a-44a4-bdb4-3b46fa6adb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-d758394c-6e2c-471d-88fc-680c44e7e710,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-4a51f5b3-f238-438e-a865-f3de06a9d078,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-b1f9cdfe-917d-4fe6-8b90-c8bd9f8e6632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870850341-172.17.0.20-1596888385947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42056,DS-52127146-7028-41d1-9f59-d0832449d827,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-aff100c4-b854-4a14-b247-e3eb1e708a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-a2459a31-16e1-4e54-b4ed-a31c0758db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-7219672d-5897-4680-87f7-4e85bab9700e,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4ea9ad85-9a9a-44a4-bdb4-3b46fa6adb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-d758394c-6e2c-471d-88fc-680c44e7e710,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-4a51f5b3-f238-438e-a865-f3de06a9d078,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-b1f9cdfe-917d-4fe6-8b90-c8bd9f8e6632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302699330-172.17.0.20-1596888424684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-b9abf5fd-9fcb-4675-8e1f-36af962596f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-992ac867-1603-4a08-9043-1a57ec88dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-818e2ad0-dd4c-4f90-af0c-e10d279b8927,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-02794704-9214-4657-9fe7-0669a3a16c36,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-4e8b497e-fa92-49f6-9a13-ab50df3f512c,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-ca051e05-d014-4b09-a5e6-310f1cd0ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-8553f2e8-15ae-4b3a-8311-d9ae773b2017,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-f9b3691a-8a2e-4224-909e-e12fd3c60f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302699330-172.17.0.20-1596888424684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-b9abf5fd-9fcb-4675-8e1f-36af962596f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-992ac867-1603-4a08-9043-1a57ec88dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-818e2ad0-dd4c-4f90-af0c-e10d279b8927,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-02794704-9214-4657-9fe7-0669a3a16c36,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-4e8b497e-fa92-49f6-9a13-ab50df3f512c,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-ca051e05-d014-4b09-a5e6-310f1cd0ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-8553f2e8-15ae-4b3a-8311-d9ae773b2017,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-f9b3691a-8a2e-4224-909e-e12fd3c60f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693788865-172.17.0.20-1596888591511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46801,DS-63b4ed51-bad1-4cc4-83e8-b110b2034b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-5a2f9cd5-9f85-47a8-a059-cff233fe7106,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-3688de5c-4276-4b61-838b-a11d15d5fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-6f5b09d8-6234-40af-8f02-26d99fba9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-08c46d3b-48a7-4468-92a3-7e6c5573259f,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-d2710cb3-c43b-455e-8a21-db7f05392a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2f26903c-93e7-4fd1-bcfe-f1a65dc17a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-6dd8ac6e-9993-4d0a-94c8-ba158fe54180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693788865-172.17.0.20-1596888591511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46801,DS-63b4ed51-bad1-4cc4-83e8-b110b2034b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-5a2f9cd5-9f85-47a8-a059-cff233fe7106,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-3688de5c-4276-4b61-838b-a11d15d5fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-6f5b09d8-6234-40af-8f02-26d99fba9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-08c46d3b-48a7-4468-92a3-7e6c5573259f,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-d2710cb3-c43b-455e-8a21-db7f05392a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2f26903c-93e7-4fd1-bcfe-f1a65dc17a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-6dd8ac6e-9993-4d0a-94c8-ba158fe54180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735691337-172.17.0.20-1596888797325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-f1bcd218-4327-4970-b48b-d91917f3fb42,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-5d3f206a-5766-41d6-8d36-dcb0f50417f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-1ba5f535-babd-4ae2-9860-49cbfebb8746,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-5e873662-e74c-49d2-baad-44a1e4785832,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-9394ac07-21f1-46e2-a2ab-e543644244a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-b4da1ac9-8c19-4ec1-b939-c6da5d6de0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-b01dca7c-66cd-424d-afc3-44630f3d4087,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-ec6ad95b-2d04-42f4-8230-96adec5d9a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735691337-172.17.0.20-1596888797325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-f1bcd218-4327-4970-b48b-d91917f3fb42,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-5d3f206a-5766-41d6-8d36-dcb0f50417f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-1ba5f535-babd-4ae2-9860-49cbfebb8746,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-5e873662-e74c-49d2-baad-44a1e4785832,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-9394ac07-21f1-46e2-a2ab-e543644244a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-b4da1ac9-8c19-4ec1-b939-c6da5d6de0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-b01dca7c-66cd-424d-afc3-44630f3d4087,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-ec6ad95b-2d04-42f4-8230-96adec5d9a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593171497-172.17.0.20-1596889165776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-92c126de-2573-460e-bf1c-f1432918b227,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-87464441-bbf1-454b-a4ea-434da30dadf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-0da638fc-6b80-402a-a65d-ec41902aae76,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-2ee52961-d060-453a-81af-c0bdbaeb2a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-d5d4b573-0de2-4d08-a95a-0eb4e979126f,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-a25dc544-86b9-4692-92c4-f4bfa8532d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-8ac98d06-635d-4878-a16f-76cf7cad833b,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-7a2b1dc4-0420-492a-a735-8bb7edb82d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593171497-172.17.0.20-1596889165776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-92c126de-2573-460e-bf1c-f1432918b227,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-87464441-bbf1-454b-a4ea-434da30dadf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-0da638fc-6b80-402a-a65d-ec41902aae76,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-2ee52961-d060-453a-81af-c0bdbaeb2a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-d5d4b573-0de2-4d08-a95a-0eb4e979126f,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-a25dc544-86b9-4692-92c4-f4bfa8532d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-8ac98d06-635d-4878-a16f-76cf7cad833b,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-7a2b1dc4-0420-492a-a735-8bb7edb82d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436976758-172.17.0.20-1596889213332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-eec89f19-9d49-473a-b3d6-326524113108,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-63ef7b5b-e905-49a6-adff-188013015d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-95aa368f-c798-4c84-92a1-62dba32a38ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8d619af7-5847-476f-9869-a4618da5d874,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-2f2abe53-6bb5-4759-b3a4-c82b2ddfa92d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-ee86009d-9abe-4713-a9a6-c340da5e734e,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-62d78610-f9be-4de3-9697-bfe994ab6d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-a22c655b-1a5d-4fa6-b8dd-bd3d8d1c7c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436976758-172.17.0.20-1596889213332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-eec89f19-9d49-473a-b3d6-326524113108,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-63ef7b5b-e905-49a6-adff-188013015d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-95aa368f-c798-4c84-92a1-62dba32a38ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8d619af7-5847-476f-9869-a4618da5d874,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-2f2abe53-6bb5-4759-b3a4-c82b2ddfa92d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-ee86009d-9abe-4713-a9a6-c340da5e734e,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-62d78610-f9be-4de3-9697-bfe994ab6d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-a22c655b-1a5d-4fa6-b8dd-bd3d8d1c7c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660195794-172.17.0.20-1596889267473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-d8f80765-c041-4167-aad9-84e825c38202,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-cafbd61a-069b-47d9-8630-b2f7442c4a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7436d19d-953d-4857-906e-0e9abf6801d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-9e8f4e62-d86f-4c6c-a048-c811671083f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-b651980e-c221-4638-a536-c39b1a5e7df9,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-9bd9c9d8-4a60-4583-9358-ec40521592ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-1c754b58-e04c-4955-a311-c222031dcfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-519cdd0b-4149-4be4-bad7-b4245b95c5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660195794-172.17.0.20-1596889267473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-d8f80765-c041-4167-aad9-84e825c38202,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-cafbd61a-069b-47d9-8630-b2f7442c4a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7436d19d-953d-4857-906e-0e9abf6801d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-9e8f4e62-d86f-4c6c-a048-c811671083f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-b651980e-c221-4638-a536-c39b1a5e7df9,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-9bd9c9d8-4a60-4583-9358-ec40521592ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-1c754b58-e04c-4955-a311-c222031dcfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-519cdd0b-4149-4be4-bad7-b4245b95c5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754989402-172.17.0.20-1596889355099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40642,DS-cc6470fd-dc10-4417-becf-eeb4e123e385,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-a31cb807-e190-4940-96c7-373062f5bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-be8a2173-d0db-4464-891d-83e6b19ab1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-e12f331b-1711-414a-9378-1b7e150f26e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-0e063c0e-51b3-4b29-b596-72475bbaed19,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-e189fb99-096b-4805-ba63-9de5ba1f2071,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-217d3c22-c040-408a-83f6-9edb40e4a413,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-bb28d944-ddb1-4649-aa28-55669b6e1b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754989402-172.17.0.20-1596889355099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40642,DS-cc6470fd-dc10-4417-becf-eeb4e123e385,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-a31cb807-e190-4940-96c7-373062f5bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-be8a2173-d0db-4464-891d-83e6b19ab1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-e12f331b-1711-414a-9378-1b7e150f26e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-0e063c0e-51b3-4b29-b596-72475bbaed19,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-e189fb99-096b-4805-ba63-9de5ba1f2071,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-217d3c22-c040-408a-83f6-9edb40e4a413,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-bb28d944-ddb1-4649-aa28-55669b6e1b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286920258-172.17.0.20-1596889485853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-018a243a-8b63-4115-bd0f-8621573a9cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-ebef0288-baa4-4562-bffd-c741f1cf4095,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-b100921a-ff0f-499c-b5f2-a6862a1ff9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-75ecd5e3-f290-4ae5-ac97-b48e69409988,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-8326a506-8eef-4bb6-8081-559123672b28,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-09a760d0-460b-4dc9-ab07-80542310e614,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-91fbf825-9b47-4677-be91-edde5e671c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-6a1ed918-2c65-4d30-b494-96536c7cb265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286920258-172.17.0.20-1596889485853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-018a243a-8b63-4115-bd0f-8621573a9cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-ebef0288-baa4-4562-bffd-c741f1cf4095,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-b100921a-ff0f-499c-b5f2-a6862a1ff9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-75ecd5e3-f290-4ae5-ac97-b48e69409988,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-8326a506-8eef-4bb6-8081-559123672b28,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-09a760d0-460b-4dc9-ab07-80542310e614,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-91fbf825-9b47-4677-be91-edde5e671c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-6a1ed918-2c65-4d30-b494-96536c7cb265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327080208-172.17.0.20-1596889534645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-65bb4d3d-26b0-4fbc-b86d-28b2f0d39ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-4e8473e1-ba78-4b1e-94f8-c41f356792da,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-9c609062-15ac-4cae-a9b9-e98f818ee350,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-f5a33cf3-5fc6-4f80-8613-8dc5f1a95a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-19b4c2eb-2ccd-4282-b07d-3bcc5d5ab81f,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-62fe2577-c3a6-4b18-8c4e-16af7650eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-93e594b5-f9ea-4cfc-9024-45d11d2850ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-c4d4a5ad-24cc-459b-9204-293355d5fd3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327080208-172.17.0.20-1596889534645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-65bb4d3d-26b0-4fbc-b86d-28b2f0d39ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-4e8473e1-ba78-4b1e-94f8-c41f356792da,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-9c609062-15ac-4cae-a9b9-e98f818ee350,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-f5a33cf3-5fc6-4f80-8613-8dc5f1a95a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-19b4c2eb-2ccd-4282-b07d-3bcc5d5ab81f,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-62fe2577-c3a6-4b18-8c4e-16af7650eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-93e594b5-f9ea-4cfc-9024-45d11d2850ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-c4d4a5ad-24cc-459b-9204-293355d5fd3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504856277-172.17.0.20-1596889718973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-f62b7f1e-38e4-401e-8583-634c391a4154,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-f9a73601-b45c-4fb8-8b89-2dadaea7f92e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-fb8f4895-fe2f-44a9-a873-4be45a261ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b085a1d5-fd71-4f23-950c-beeb08016e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-efcea071-f03b-46c4-9d3e-f10f2a9fe5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-70f6883a-3025-4950-a1b3-e7a4aa874d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-b7bff2c7-06ad-4179-b6d0-2290de3a56ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-d467257b-f6b7-481e-a81b-b6e37fd245e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504856277-172.17.0.20-1596889718973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-f62b7f1e-38e4-401e-8583-634c391a4154,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-f9a73601-b45c-4fb8-8b89-2dadaea7f92e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-fb8f4895-fe2f-44a9-a873-4be45a261ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b085a1d5-fd71-4f23-950c-beeb08016e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-efcea071-f03b-46c4-9d3e-f10f2a9fe5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-70f6883a-3025-4950-a1b3-e7a4aa874d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-b7bff2c7-06ad-4179-b6d0-2290de3a56ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-d467257b-f6b7-481e-a81b-b6e37fd245e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86043335-172.17.0.20-1596889842129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34389,DS-bfb109ee-b030-4d54-a119-58f5cda100a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-73f1b0eb-9ba0-4e01-8260-57877a02e893,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-1448440c-388a-4ef5-bdb8-b69b1e9d80b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-7a5c6d3e-6f4a-4288-a380-2e7d67faed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-a46a6a6a-752b-4621-8718-fe0d04681e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-afa003d3-b833-4be1-a167-549407322cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-1aa32520-d664-4bcb-8980-7d7e0b41e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-d994d0ec-b872-4132-a442-c26790a5fabd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86043335-172.17.0.20-1596889842129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34389,DS-bfb109ee-b030-4d54-a119-58f5cda100a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-73f1b0eb-9ba0-4e01-8260-57877a02e893,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-1448440c-388a-4ef5-bdb8-b69b1e9d80b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-7a5c6d3e-6f4a-4288-a380-2e7d67faed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-a46a6a6a-752b-4621-8718-fe0d04681e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-afa003d3-b833-4be1-a167-549407322cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-1aa32520-d664-4bcb-8980-7d7e0b41e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-d994d0ec-b872-4132-a442-c26790a5fabd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665326849-172.17.0.20-1596889892584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44771,DS-1a6b8ce0-5438-4db6-9c2a-309e0ddd398d,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-dd45da83-3c18-404a-ae3e-9e68666d080a,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-c92fd24b-7cbf-4f5d-a110-fb9880f6a6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fe90fe4f-da46-4c1b-99fd-b5f1ac840fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-2e0bea79-2e07-42bc-9641-ced12c747a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-ebb2e320-d550-4ec0-bf65-72f14e712b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-ea9034f9-3827-4d67-a4cc-6973c2a6c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-8e6d59e4-85cf-4784-9a77-cd8547450408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665326849-172.17.0.20-1596889892584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44771,DS-1a6b8ce0-5438-4db6-9c2a-309e0ddd398d,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-dd45da83-3c18-404a-ae3e-9e68666d080a,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-c92fd24b-7cbf-4f5d-a110-fb9880f6a6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fe90fe4f-da46-4c1b-99fd-b5f1ac840fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-2e0bea79-2e07-42bc-9641-ced12c747a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-ebb2e320-d550-4ec0-bf65-72f14e712b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-ea9034f9-3827-4d67-a4cc-6973c2a6c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-8e6d59e4-85cf-4784-9a77-cd8547450408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21243699-172.17.0.20-1596890457540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-f86d00b9-847d-47d1-8e7d-25bd32e38b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ecfba566-42bb-4638-9242-a100f3bb55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-5ce560e9-982b-4001-878e-97f0c4ca7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-21df29dc-074d-4fce-a117-cc151780df74,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-b4e3a194-6acf-4502-b4c4-080bc7a62a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-3ac6be98-be92-42ed-8c7c-fbadb41fb098,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f25b057a-c4a0-47a3-b6f8-40db779f4d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-2970084c-0cbf-481a-9416-02ebe8231dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21243699-172.17.0.20-1596890457540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-f86d00b9-847d-47d1-8e7d-25bd32e38b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ecfba566-42bb-4638-9242-a100f3bb55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-5ce560e9-982b-4001-878e-97f0c4ca7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-21df29dc-074d-4fce-a117-cc151780df74,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-b4e3a194-6acf-4502-b4c4-080bc7a62a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-3ac6be98-be92-42ed-8c7c-fbadb41fb098,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f25b057a-c4a0-47a3-b6f8-40db779f4d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-2970084c-0cbf-481a-9416-02ebe8231dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188646600-172.17.0.20-1596891556078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39955,DS-e10e76e1-4a82-4a22-a76d-37cdec663624,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-1b5cfec0-bed5-4416-9166-314de1aec85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-3543c6a6-41c9-4141-967d-4a8140de2ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-60ffe1f2-b71f-4874-99a5-7d0722c299b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-b1423d9c-0a66-4520-8150-e219ce6016d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-34a5b605-641a-4d83-843b-8bed3bef6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-e37b366e-d58e-4d8f-b99a-8b4e6a7dab52,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-5ec1ea0f-1bf3-4668-b5c7-26dad800d2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188646600-172.17.0.20-1596891556078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39955,DS-e10e76e1-4a82-4a22-a76d-37cdec663624,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-1b5cfec0-bed5-4416-9166-314de1aec85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-3543c6a6-41c9-4141-967d-4a8140de2ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-60ffe1f2-b71f-4874-99a5-7d0722c299b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-b1423d9c-0a66-4520-8150-e219ce6016d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-34a5b605-641a-4d83-843b-8bed3bef6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-e37b366e-d58e-4d8f-b99a-8b4e6a7dab52,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-5ec1ea0f-1bf3-4668-b5c7-26dad800d2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6776
