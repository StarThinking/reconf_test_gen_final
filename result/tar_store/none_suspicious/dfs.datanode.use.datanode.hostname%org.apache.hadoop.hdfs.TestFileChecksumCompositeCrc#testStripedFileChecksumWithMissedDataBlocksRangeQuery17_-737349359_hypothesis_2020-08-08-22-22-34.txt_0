reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647982641-172.17.0.13-1596926269378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-199662be-665e-4158-bb73-a9d0169685d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-7dd27f49-0595-431f-9e32-5f0f4ebf8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-bad4f279-9baf-49a3-95d7-b4adda284013,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-f575aeb7-29c9-4ce9-9a30-916c1e97e42f,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-4945db82-05fb-4750-9498-2f4641ca6f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-95e6ce17-56c0-4207-97d5-4204fc5a17a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-986fb04c-580c-4c42-9077-1fb9174dccfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-842b4744-2a7b-4e1c-bfe5-5c4453786bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647982641-172.17.0.13-1596926269378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-199662be-665e-4158-bb73-a9d0169685d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-7dd27f49-0595-431f-9e32-5f0f4ebf8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-bad4f279-9baf-49a3-95d7-b4adda284013,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-f575aeb7-29c9-4ce9-9a30-916c1e97e42f,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-4945db82-05fb-4750-9498-2f4641ca6f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-95e6ce17-56c0-4207-97d5-4204fc5a17a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-986fb04c-580c-4c42-9077-1fb9174dccfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-842b4744-2a7b-4e1c-bfe5-5c4453786bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249462031-172.17.0.13-1596926334244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-f5d3904d-e675-44c9-9837-ac125f983c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-d287274a-87f2-4b6a-91fc-ffa2fe13cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-e5997508-023f-48c1-806f-5740c467664d,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-8f801ccd-c0a3-482b-ba87-f67476a77319,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-d794f0e8-772d-4983-8a4b-a44a83d2466e,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-383dc16c-5bf4-4113-b255-16537ec749fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-92836f4a-b57a-4ed9-913f-0dfd1324a353,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-7b8226df-095b-4d18-8430-ecaef338b286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249462031-172.17.0.13-1596926334244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-f5d3904d-e675-44c9-9837-ac125f983c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-d287274a-87f2-4b6a-91fc-ffa2fe13cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-e5997508-023f-48c1-806f-5740c467664d,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-8f801ccd-c0a3-482b-ba87-f67476a77319,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-d794f0e8-772d-4983-8a4b-a44a83d2466e,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-383dc16c-5bf4-4113-b255-16537ec749fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-92836f4a-b57a-4ed9-913f-0dfd1324a353,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-7b8226df-095b-4d18-8430-ecaef338b286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734074779-172.17.0.13-1596926370911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40550,DS-639a0e15-8b7d-4de3-8226-ebe6189cb618,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-d061b4e6-979c-4f97-893a-edb529fed429,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-a446ded9-a251-40ca-90e7-7d82867c86f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-5234c1c0-0c20-4117-bcbb-dd4cef944fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-13b8a655-ec6a-40c4-8d55-128945e645a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-d63eeebb-d488-4e1f-9184-b0dc9771a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-454fc32a-7e1e-457f-ad76-ac5eb6be1934,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-12fd5e1c-846b-40fd-9a71-d1d89548471d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734074779-172.17.0.13-1596926370911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40550,DS-639a0e15-8b7d-4de3-8226-ebe6189cb618,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-d061b4e6-979c-4f97-893a-edb529fed429,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-a446ded9-a251-40ca-90e7-7d82867c86f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-5234c1c0-0c20-4117-bcbb-dd4cef944fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-13b8a655-ec6a-40c4-8d55-128945e645a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-d63eeebb-d488-4e1f-9184-b0dc9771a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-454fc32a-7e1e-457f-ad76-ac5eb6be1934,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-12fd5e1c-846b-40fd-9a71-d1d89548471d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777378918-172.17.0.13-1596926469975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-f357cb14-1acd-4b0c-ac67-13cdb9828a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-e6981cf3-4580-495a-aeb0-2855cec202e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-4a1036f9-6011-4ce3-aa3a-339431e2a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-e5a43ae5-97ef-461c-bf36-481926678653,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-86bd0902-ef9c-4e03-a3af-3a0e26b9f6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-b5bac5ba-6d60-42da-90a5-651f871f6733,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-54ad62b1-d3c4-40a7-a471-c69ceb11050d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-bbc740aa-03d8-49d1-83f8-ddff35b40b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777378918-172.17.0.13-1596926469975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-f357cb14-1acd-4b0c-ac67-13cdb9828a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-e6981cf3-4580-495a-aeb0-2855cec202e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-4a1036f9-6011-4ce3-aa3a-339431e2a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-e5a43ae5-97ef-461c-bf36-481926678653,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-86bd0902-ef9c-4e03-a3af-3a0e26b9f6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-b5bac5ba-6d60-42da-90a5-651f871f6733,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-54ad62b1-d3c4-40a7-a471-c69ceb11050d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-bbc740aa-03d8-49d1-83f8-ddff35b40b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929720104-172.17.0.13-1596926914274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35907,DS-6d0fcb94-f3b9-49a1-9232-fc35691c28d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-b5e2ecf8-78f6-47ff-8488-2eb01e2152dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9a0a521d-30f9-40e2-86df-f250ed56bf44,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-f707663e-8572-4638-a85b-43a29da6eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-e9c35943-5cf2-4772-850e-a80c824de18b,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-87a8c6cb-c97f-41b1-a610-da679eab6730,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-51e6dc47-e646-421b-900b-48bc130813a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-24e6972f-50d0-4dcb-beb7-66a560c97977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929720104-172.17.0.13-1596926914274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35907,DS-6d0fcb94-f3b9-49a1-9232-fc35691c28d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-b5e2ecf8-78f6-47ff-8488-2eb01e2152dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9a0a521d-30f9-40e2-86df-f250ed56bf44,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-f707663e-8572-4638-a85b-43a29da6eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-e9c35943-5cf2-4772-850e-a80c824de18b,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-87a8c6cb-c97f-41b1-a610-da679eab6730,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-51e6dc47-e646-421b-900b-48bc130813a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-24e6972f-50d0-4dcb-beb7-66a560c97977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910676699-172.17.0.13-1596927482280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-dd4415dc-5b90-4587-942b-bc182a18ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-d39ca904-5259-4cd9-83a6-13aa1411e534,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-d6169b53-4922-4b9e-94ac-cc301396f6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-53f0ea6c-54f0-490e-962c-3119e474a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-725dad91-cba6-486c-b8d4-349a8d4495ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-b192d568-e273-4574-926c-0fcceb19d1db,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-988222ac-9e86-45b8-a90e-0378873949ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-b55e16c2-3a26-4ceb-b4b5-175c8e1f348e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910676699-172.17.0.13-1596927482280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-dd4415dc-5b90-4587-942b-bc182a18ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-d39ca904-5259-4cd9-83a6-13aa1411e534,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-d6169b53-4922-4b9e-94ac-cc301396f6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-53f0ea6c-54f0-490e-962c-3119e474a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-725dad91-cba6-486c-b8d4-349a8d4495ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-b192d568-e273-4574-926c-0fcceb19d1db,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-988222ac-9e86-45b8-a90e-0378873949ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-b55e16c2-3a26-4ceb-b4b5-175c8e1f348e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659184369-172.17.0.13-1596927518763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-fd0f73d4-19ad-46df-b6ff-258ba9f64b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-a3ad9fb3-c935-4500-8e81-ac67e3b5ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-f3855ac1-f3c7-44c1-b5ba-63bf07772927,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-6016650b-002d-4de1-a2e2-872b588f9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-672496bd-1763-4468-93ec-cf857d5c08ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-97d266a2-6a5d-4499-8f3e-15c1962b1eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-3018f034-3561-4011-8cbc-57fddbeeacf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-52d83618-9826-41be-aaac-0a09503736a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659184369-172.17.0.13-1596927518763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-fd0f73d4-19ad-46df-b6ff-258ba9f64b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-a3ad9fb3-c935-4500-8e81-ac67e3b5ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-f3855ac1-f3c7-44c1-b5ba-63bf07772927,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-6016650b-002d-4de1-a2e2-872b588f9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-672496bd-1763-4468-93ec-cf857d5c08ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-97d266a2-6a5d-4499-8f3e-15c1962b1eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-3018f034-3561-4011-8cbc-57fddbeeacf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-52d83618-9826-41be-aaac-0a09503736a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132055765-172.17.0.13-1596927712826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-11efe56d-1041-4713-9f97-02192317ab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-c1ceb3e9-7947-4fc1-9299-c8b915bda950,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-23779663-4416-48ea-8cbf-a7fc792590e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-4bec79d7-87ac-4d8c-bde5-a1a61917d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-1ee78552-552e-47e5-b8d0-057b44b85451,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-1253be98-92e3-4904-8ce4-8543204bdee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-4f6be0a3-9c39-4003-8478-de83325716f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-f5a24b89-ca0e-49af-814b-1a1e1bb1d1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132055765-172.17.0.13-1596927712826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-11efe56d-1041-4713-9f97-02192317ab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-c1ceb3e9-7947-4fc1-9299-c8b915bda950,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-23779663-4416-48ea-8cbf-a7fc792590e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-4bec79d7-87ac-4d8c-bde5-a1a61917d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-1ee78552-552e-47e5-b8d0-057b44b85451,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-1253be98-92e3-4904-8ce4-8543204bdee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-4f6be0a3-9c39-4003-8478-de83325716f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-f5a24b89-ca0e-49af-814b-1a1e1bb1d1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053625952-172.17.0.13-1596928051280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-be5f97a3-9bc1-40ee-901b-81bf78a74dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-9a6a5262-76cd-49d7-ad92-bef1e33d778f,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-4c5c2396-5165-4e0e-a87c-fc32c2ee9603,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-4d3cb415-e6bd-4959-b6ca-24747325a728,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-e91a19ba-d9a5-42a2-8aba-961f5e5a9749,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-4f7e680d-a524-4394-92f3-e61f13609c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-e612a5ce-e577-4a2c-9089-bd00249e1502,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-050c8662-070f-41a8-b59e-fbf20967c3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053625952-172.17.0.13-1596928051280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-be5f97a3-9bc1-40ee-901b-81bf78a74dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-9a6a5262-76cd-49d7-ad92-bef1e33d778f,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-4c5c2396-5165-4e0e-a87c-fc32c2ee9603,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-4d3cb415-e6bd-4959-b6ca-24747325a728,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-e91a19ba-d9a5-42a2-8aba-961f5e5a9749,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-4f7e680d-a524-4394-92f3-e61f13609c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-e612a5ce-e577-4a2c-9089-bd00249e1502,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-050c8662-070f-41a8-b59e-fbf20967c3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443576634-172.17.0.13-1596928402714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-29cc9d7f-c64f-4dae-9e46-a0c5ec2ee9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-01b569e5-b7f8-4454-af46-bca6f723bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-da141165-9803-40ae-a6bd-d24803de041c,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-37e46b08-8fcd-4ab7-9b7e-23fde4a2cae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-cc75a4f9-1e65-436b-9645-649c0578fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-fdece7bc-8315-4e58-98fc-2952b8da3114,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-555976cf-86c6-49bd-abf3-6a7a61aeeabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-c2156de2-d1f2-4fdc-b960-e80bae6af0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443576634-172.17.0.13-1596928402714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-29cc9d7f-c64f-4dae-9e46-a0c5ec2ee9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-01b569e5-b7f8-4454-af46-bca6f723bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-da141165-9803-40ae-a6bd-d24803de041c,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-37e46b08-8fcd-4ab7-9b7e-23fde4a2cae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-cc75a4f9-1e65-436b-9645-649c0578fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-fdece7bc-8315-4e58-98fc-2952b8da3114,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-555976cf-86c6-49bd-abf3-6a7a61aeeabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-c2156de2-d1f2-4fdc-b960-e80bae6af0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098547673-172.17.0.13-1596928463445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41251,DS-2b6d12d9-2948-4995-a8c8-2c9e865a01f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-3f79d088-6a8f-47b3-b2c1-10cb5e8bf821,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-444b6e9d-a2fe-4cb2-ad1b-22ca22b120a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-f255c82a-eae7-4192-821b-768f495f6cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-70ccdf4d-fea5-4df6-b565-f22f9f2d55bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-3136a385-600a-4af6-8b49-c25460bf7e40,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-f69d4c93-22fa-4134-8d19-6dacebb9da93,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-413c26b9-7c64-4671-894d-f9db7cab511a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098547673-172.17.0.13-1596928463445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41251,DS-2b6d12d9-2948-4995-a8c8-2c9e865a01f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-3f79d088-6a8f-47b3-b2c1-10cb5e8bf821,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-444b6e9d-a2fe-4cb2-ad1b-22ca22b120a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-f255c82a-eae7-4192-821b-768f495f6cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-70ccdf4d-fea5-4df6-b565-f22f9f2d55bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-3136a385-600a-4af6-8b49-c25460bf7e40,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-f69d4c93-22fa-4134-8d19-6dacebb9da93,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-413c26b9-7c64-4671-894d-f9db7cab511a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623452224-172.17.0.13-1596928532030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-e7827848-9626-4e5d-96f2-395433e59837,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-ec52341d-353d-4d75-a23e-a5dbac69bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-59b76b35-3a02-427b-9dbc-ff2bc3158de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-c0fc752e-5e40-4a2f-a49d-f73f3fec1ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-3e5f3e8d-d534-41bf-a11d-ed278c768a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-68d7ed38-cb43-408b-a99c-a1f55a2c3eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-da7d24f2-2761-4ec5-9aae-3201c72abe47,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-25c7d620-b7c6-4f2d-b07e-3df4a70a4648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623452224-172.17.0.13-1596928532030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-e7827848-9626-4e5d-96f2-395433e59837,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-ec52341d-353d-4d75-a23e-a5dbac69bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-59b76b35-3a02-427b-9dbc-ff2bc3158de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-c0fc752e-5e40-4a2f-a49d-f73f3fec1ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-3e5f3e8d-d534-41bf-a11d-ed278c768a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-68d7ed38-cb43-408b-a99c-a1f55a2c3eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-da7d24f2-2761-4ec5-9aae-3201c72abe47,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-25c7d620-b7c6-4f2d-b07e-3df4a70a4648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852350045-172.17.0.13-1596929234769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-ef1423bb-0637-4ffb-a6db-601c7f089df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-45c95044-4ccb-4091-9756-853e240f65ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-86c4411a-c524-4676-ac00-1f6103a6a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-b27e06a0-da05-4a4e-9e64-46d5568b49de,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-7c713f8c-ff7f-4bdd-9f2c-493c22a22d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-45399c7a-2bcf-4539-abdd-42955ff255f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-6193e70d-8c10-4b8e-84b7-7e3f3b7ee35d,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-a32dc8f0-5f37-4820-ae1f-131eb5a7120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852350045-172.17.0.13-1596929234769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-ef1423bb-0637-4ffb-a6db-601c7f089df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-45c95044-4ccb-4091-9756-853e240f65ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-86c4411a-c524-4676-ac00-1f6103a6a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-b27e06a0-da05-4a4e-9e64-46d5568b49de,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-7c713f8c-ff7f-4bdd-9f2c-493c22a22d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-45399c7a-2bcf-4539-abdd-42955ff255f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-6193e70d-8c10-4b8e-84b7-7e3f3b7ee35d,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-a32dc8f0-5f37-4820-ae1f-131eb5a7120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824139015-172.17.0.13-1596929272971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-d252adfc-7462-4f36-b809-986c447eaed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-cbdedd8a-c9e7-460c-847b-340c64322d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-a7a162f4-0d73-4636-87b1-9400fe85349b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-b6ae1c96-16c1-4731-a657-d43726c8f606,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-948d93ae-13b5-4d42-904f-1f3ca763deca,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-461634e7-8467-4f71-8ac6-f2e97d198d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-f083f483-6bd8-496f-9957-f8840a64fac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-8c2bf514-9138-4b1e-87d5-3bf6b3a6366f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824139015-172.17.0.13-1596929272971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-d252adfc-7462-4f36-b809-986c447eaed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-cbdedd8a-c9e7-460c-847b-340c64322d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-a7a162f4-0d73-4636-87b1-9400fe85349b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-b6ae1c96-16c1-4731-a657-d43726c8f606,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-948d93ae-13b5-4d42-904f-1f3ca763deca,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-461634e7-8467-4f71-8ac6-f2e97d198d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-f083f483-6bd8-496f-9957-f8840a64fac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-8c2bf514-9138-4b1e-87d5-3bf6b3a6366f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989399958-172.17.0.13-1596929926895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-2d826ea3-62c0-4f58-9fcf-2d5283c4ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-24bea2a3-9d03-45ee-a9c0-5e9b4e652e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-4353718b-d55d-4e56-8f4d-3eabf1013ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-cc89ddb7-251a-4ac7-ba24-0e62efa8ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-d0a71b41-6941-4e12-944b-fd30ff3422a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-7f21652b-ceec-4c8c-bbb4-15b120278735,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-56d1e692-4b9f-430e-8001-cf2779de0828,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-4f19edc8-948f-4792-8978-c7893b9c0005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989399958-172.17.0.13-1596929926895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-2d826ea3-62c0-4f58-9fcf-2d5283c4ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-24bea2a3-9d03-45ee-a9c0-5e9b4e652e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-4353718b-d55d-4e56-8f4d-3eabf1013ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-cc89ddb7-251a-4ac7-ba24-0e62efa8ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-d0a71b41-6941-4e12-944b-fd30ff3422a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-7f21652b-ceec-4c8c-bbb4-15b120278735,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-56d1e692-4b9f-430e-8001-cf2779de0828,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-4f19edc8-948f-4792-8978-c7893b9c0005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5095
