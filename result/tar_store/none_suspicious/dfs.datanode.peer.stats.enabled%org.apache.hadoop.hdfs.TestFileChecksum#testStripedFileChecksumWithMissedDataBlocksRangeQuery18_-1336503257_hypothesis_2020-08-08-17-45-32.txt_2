reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632740771-172.17.0.4-1596909096551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-e8538f78-84db-4191-a1e4-7447f6f2644b,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-a5636a7a-e3b2-469c-8175-4e808b6764e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-d1d0e5b9-c255-42ba-9c0a-084d7f0ec874,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-90b4fb67-1058-4a2c-a8fc-8ad8eb67d212,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-2dfa67ee-160e-4389-8691-f6d029ce1882,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-4b465267-f55a-4cc1-a0a8-55a2605f2a52,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-83d48f59-83a8-4e66-904a-d4bc5668634b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-b17ff129-15b4-4ec2-b129-6ba139ec9c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632740771-172.17.0.4-1596909096551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-e8538f78-84db-4191-a1e4-7447f6f2644b,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-a5636a7a-e3b2-469c-8175-4e808b6764e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-d1d0e5b9-c255-42ba-9c0a-084d7f0ec874,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-90b4fb67-1058-4a2c-a8fc-8ad8eb67d212,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-2dfa67ee-160e-4389-8691-f6d029ce1882,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-4b465267-f55a-4cc1-a0a8-55a2605f2a52,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-83d48f59-83a8-4e66-904a-d4bc5668634b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-b17ff129-15b4-4ec2-b129-6ba139ec9c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765799330-172.17.0.4-1596909335923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42251,DS-2429439f-a686-4968-9f34-8dbcfe1d086a,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-8e0a45c3-a32d-4bba-9783-16d1fcb4037a,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-16e5a69c-f8d3-46a7-9eb9-dc7d0220fe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-5beb9a1e-19a2-4547-a843-21a6d147243e,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-8562c791-8e72-445e-b270-f8c92cb953aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-13739bc4-83c4-4268-851d-02ef49659897,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-5b940629-a31e-4a27-b003-e1d4fbf16135,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-ef4c275b-3f33-44bc-a344-4eb0c7eba527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765799330-172.17.0.4-1596909335923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42251,DS-2429439f-a686-4968-9f34-8dbcfe1d086a,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-8e0a45c3-a32d-4bba-9783-16d1fcb4037a,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-16e5a69c-f8d3-46a7-9eb9-dc7d0220fe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-5beb9a1e-19a2-4547-a843-21a6d147243e,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-8562c791-8e72-445e-b270-f8c92cb953aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-13739bc4-83c4-4268-851d-02ef49659897,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-5b940629-a31e-4a27-b003-e1d4fbf16135,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-ef4c275b-3f33-44bc-a344-4eb0c7eba527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925908502-172.17.0.4-1596909635274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-258814f8-dbcd-42fb-801f-9f700bef0bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-d0e246fd-ae6f-466a-9cd5-c3335873ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-7d42eeb9-7f39-4243-a7cc-d642b55d1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-b1150f96-c3f0-45e5-9b9d-059c9a5db99e,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-823969d5-1be5-49ca-9e9b-f22bb591f056,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-ff8935fa-de1f-4262-bc31-652de3953662,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-46cffa3c-e5ef-4115-b978-149f853d4fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-2902c213-14df-4b5b-bb9b-9114129b2486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925908502-172.17.0.4-1596909635274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-258814f8-dbcd-42fb-801f-9f700bef0bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-d0e246fd-ae6f-466a-9cd5-c3335873ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-7d42eeb9-7f39-4243-a7cc-d642b55d1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-b1150f96-c3f0-45e5-9b9d-059c9a5db99e,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-823969d5-1be5-49ca-9e9b-f22bb591f056,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-ff8935fa-de1f-4262-bc31-652de3953662,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-46cffa3c-e5ef-4115-b978-149f853d4fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-2902c213-14df-4b5b-bb9b-9114129b2486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446222210-172.17.0.4-1596909980769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-f5f5429f-a3c7-48d2-91f3-14e052dccfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-60906665-bfb4-48f9-842a-5d39ffb168e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-343b0f80-c5be-4f19-aa5e-88cf2537d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-19ab45a2-cc60-477d-acf8-69177772bb87,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-64117c95-207a-4476-bd74-957932f24d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-b79bca28-061a-430e-92e3-a9bbbba76422,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-58d436cf-0744-4cfa-9f9a-655992e089aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-613adb4e-a7e1-44f4-a968-a6b410221c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446222210-172.17.0.4-1596909980769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-f5f5429f-a3c7-48d2-91f3-14e052dccfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-60906665-bfb4-48f9-842a-5d39ffb168e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-343b0f80-c5be-4f19-aa5e-88cf2537d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-19ab45a2-cc60-477d-acf8-69177772bb87,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-64117c95-207a-4476-bd74-957932f24d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-b79bca28-061a-430e-92e3-a9bbbba76422,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-58d436cf-0744-4cfa-9f9a-655992e089aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-613adb4e-a7e1-44f4-a968-a6b410221c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104976010-172.17.0.4-1596910733770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-7635974a-0e6d-44e3-b2e8-01c4747efe90,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-46b60bcb-1a87-4d05-b08e-abcb3a5b2c24,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-cfc12115-41da-4959-944d-9cff5f9cd5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-495d3dca-1907-41f1-a580-7c6b828b8d66,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-01d2e2aa-ade2-4024-9c39-d2d0ffedf8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-95103ae4-fe12-472c-b7cc-d3181aad2e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-1cda2049-11f4-4339-804b-a86ff4405427,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-898a127b-a21a-4a7e-b1e6-ed1837097844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104976010-172.17.0.4-1596910733770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-7635974a-0e6d-44e3-b2e8-01c4747efe90,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-46b60bcb-1a87-4d05-b08e-abcb3a5b2c24,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-cfc12115-41da-4959-944d-9cff5f9cd5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-495d3dca-1907-41f1-a580-7c6b828b8d66,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-01d2e2aa-ade2-4024-9c39-d2d0ffedf8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-95103ae4-fe12-472c-b7cc-d3181aad2e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-1cda2049-11f4-4339-804b-a86ff4405427,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-898a127b-a21a-4a7e-b1e6-ed1837097844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45471958-172.17.0.4-1596910982554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-2e9fabcc-bb10-42eb-b289-91f701532bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-3cb1f67c-c9de-4bfa-96f7-f036f67ac9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a8b270aa-d840-4522-aa8c-5e7f56b4b854,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-62c85f97-88ea-4eea-8b27-8a2bda75ce21,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-f8320c27-8a66-496e-8630-bc1c9b99dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-ccb02b39-5c1f-47a9-9838-69d5da0f9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-5a988475-4e58-4a8f-b72b-8882b8b60c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-f6182591-b7ca-4b2f-ae4a-61cb4d947bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45471958-172.17.0.4-1596910982554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-2e9fabcc-bb10-42eb-b289-91f701532bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-3cb1f67c-c9de-4bfa-96f7-f036f67ac9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a8b270aa-d840-4522-aa8c-5e7f56b4b854,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-62c85f97-88ea-4eea-8b27-8a2bda75ce21,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-f8320c27-8a66-496e-8630-bc1c9b99dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-ccb02b39-5c1f-47a9-9838-69d5da0f9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-5a988475-4e58-4a8f-b72b-8882b8b60c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-f6182591-b7ca-4b2f-ae4a-61cb4d947bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956952062-172.17.0.4-1596911259882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-f96f10dc-651a-4120-b532-32f1e9ab6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-5212d0a6-683e-455c-aa21-4feef2e83835,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-cdba7725-e7b9-4e63-a8a7-9845af41b769,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-b0cba554-5c11-417e-ada6-c94fd4f4f122,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-25db2fd9-7daf-48e2-adef-34d98382414d,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-6c48928d-7c61-4bca-ae33-852d9e4c0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-110971a4-270c-44d3-a563-c75b77489094,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-ffd875f9-b991-44a2-a816-b1054e0e17d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956952062-172.17.0.4-1596911259882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-f96f10dc-651a-4120-b532-32f1e9ab6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-5212d0a6-683e-455c-aa21-4feef2e83835,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-cdba7725-e7b9-4e63-a8a7-9845af41b769,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-b0cba554-5c11-417e-ada6-c94fd4f4f122,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-25db2fd9-7daf-48e2-adef-34d98382414d,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-6c48928d-7c61-4bca-ae33-852d9e4c0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-110971a4-270c-44d3-a563-c75b77489094,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-ffd875f9-b991-44a2-a816-b1054e0e17d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706871723-172.17.0.4-1596911581459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-5796fa57-2bd9-4d01-912c-baee42bfb257,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-bb91b76d-e12e-408a-a6f1-c8259f531b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-c8472d9d-ac8a-4d9c-b7de-f80ba6a6f660,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-bd48e926-8f96-4a2f-aa39-c460d76d7601,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-784dacd4-e9ca-4364-8007-534e42ee86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-b2bb9ad2-1069-479c-94c0-74f04176bf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-c3e7946b-2191-41b2-a2fe-72a36f672bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-9601d8da-e943-4397-b8ba-8ca274d5ecf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706871723-172.17.0.4-1596911581459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-5796fa57-2bd9-4d01-912c-baee42bfb257,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-bb91b76d-e12e-408a-a6f1-c8259f531b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-c8472d9d-ac8a-4d9c-b7de-f80ba6a6f660,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-bd48e926-8f96-4a2f-aa39-c460d76d7601,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-784dacd4-e9ca-4364-8007-534e42ee86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-b2bb9ad2-1069-479c-94c0-74f04176bf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-c3e7946b-2191-41b2-a2fe-72a36f672bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-9601d8da-e943-4397-b8ba-8ca274d5ecf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042846249-172.17.0.4-1596911811402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-c571b484-9b1c-4d15-8786-2c8d3e97c627,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-3bd6f771-8d56-4100-bc00-959b0f8da3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5830d564-49cc-4ec8-b49e-05dcb0622bff,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-0a539405-c53e-4031-a9e0-4afd427442ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-dbbab70f-893d-4abb-a596-6b153137445a,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-42988154-cb90-4d5e-893f-584ca93208d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-97f95d87-02fb-43b9-a7a5-f0f2ecc0f7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-b0ad62dd-9c4e-4612-9923-3f1a4b16b2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042846249-172.17.0.4-1596911811402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-c571b484-9b1c-4d15-8786-2c8d3e97c627,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-3bd6f771-8d56-4100-bc00-959b0f8da3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5830d564-49cc-4ec8-b49e-05dcb0622bff,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-0a539405-c53e-4031-a9e0-4afd427442ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-dbbab70f-893d-4abb-a596-6b153137445a,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-42988154-cb90-4d5e-893f-584ca93208d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-97f95d87-02fb-43b9-a7a5-f0f2ecc0f7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-b0ad62dd-9c4e-4612-9923-3f1a4b16b2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201708781-172.17.0.4-1596911902364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38399,DS-f3add885-fd57-4f98-b154-23770c391f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-8f17ee00-254b-4950-8c9b-4ed9f4b61620,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-eaa87f84-6177-4123-a90a-63bc713da808,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-c0248b11-25bc-4a3a-8328-5bb6c7e9b6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-b1921a41-3831-4013-a874-8af2fa428dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-3488384b-0705-4017-b8d1-e446b29bca45,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-2376b670-1b68-4d04-a03f-1c772066bd35,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-0334041e-6d88-4c10-97dd-088c9e31080e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201708781-172.17.0.4-1596911902364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38399,DS-f3add885-fd57-4f98-b154-23770c391f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-8f17ee00-254b-4950-8c9b-4ed9f4b61620,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-eaa87f84-6177-4123-a90a-63bc713da808,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-c0248b11-25bc-4a3a-8328-5bb6c7e9b6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-b1921a41-3831-4013-a874-8af2fa428dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-3488384b-0705-4017-b8d1-e446b29bca45,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-2376b670-1b68-4d04-a03f-1c772066bd35,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-0334041e-6d88-4c10-97dd-088c9e31080e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307814003-172.17.0.4-1596912130738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43532,DS-17b38798-d56b-419a-9b8d-64eec0eb1a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-3ab64934-28ca-4562-9e7b-66ace6bc382b,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-6106d861-79a2-41d2-a167-f5c160685bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-4ca2e31b-5cad-466f-88dc-0ed28d67c482,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-dac6c28f-a222-453b-ac83-191cd029ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-966d6755-923d-474a-83ac-1506e075dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-364087e3-a96c-4395-bb5f-9185de4b9c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d21f040f-eb05-4562-90ec-7bd1a2aee12e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307814003-172.17.0.4-1596912130738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43532,DS-17b38798-d56b-419a-9b8d-64eec0eb1a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-3ab64934-28ca-4562-9e7b-66ace6bc382b,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-6106d861-79a2-41d2-a167-f5c160685bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-4ca2e31b-5cad-466f-88dc-0ed28d67c482,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-dac6c28f-a222-453b-ac83-191cd029ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-966d6755-923d-474a-83ac-1506e075dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-364087e3-a96c-4395-bb5f-9185de4b9c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d21f040f-eb05-4562-90ec-7bd1a2aee12e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454427642-172.17.0.4-1596912563070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44075,DS-5b58ad3b-23a6-43c7-bcdc-ee360cb6a4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-0280357a-60b6-4365-bc11-91462f91d269,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-86c19f93-fd21-415f-9ae7-9f6a5c42a9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-222260da-c368-469e-93fb-301ccc8e502c,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-1c7f8bfd-f1fb-42e1-a610-e4fa58eb32ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-ac6757d9-8948-46a3-914e-a5eb578adb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-90bedc18-561a-431a-8139-704cfcdebe90,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-4eb3b16d-e681-4b10-8dcc-4aadda543d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454427642-172.17.0.4-1596912563070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44075,DS-5b58ad3b-23a6-43c7-bcdc-ee360cb6a4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-0280357a-60b6-4365-bc11-91462f91d269,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-86c19f93-fd21-415f-9ae7-9f6a5c42a9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-222260da-c368-469e-93fb-301ccc8e502c,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-1c7f8bfd-f1fb-42e1-a610-e4fa58eb32ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-ac6757d9-8948-46a3-914e-a5eb578adb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-90bedc18-561a-431a-8139-704cfcdebe90,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-4eb3b16d-e681-4b10-8dcc-4aadda543d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288057381-172.17.0.4-1596912801984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38891,DS-31a127f0-1871-47e7-bfa8-c2b933f82363,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-3d6e3e46-a1f1-466f-9653-6322a71c8bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-a3c7a088-b8a8-49ff-8833-03b3cdc8c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-71d341c7-350a-413f-8cd2-d353456d1046,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-29f615e4-a094-4524-a2dd-7645bba4e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-bf041ccb-7e37-4a33-a3d3-66a269b5068e,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-1015d4ce-e094-4df8-8ddc-680c65a7a710,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-cb8899d4-c051-4c0f-8b47-fcf552699c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288057381-172.17.0.4-1596912801984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38891,DS-31a127f0-1871-47e7-bfa8-c2b933f82363,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-3d6e3e46-a1f1-466f-9653-6322a71c8bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-a3c7a088-b8a8-49ff-8833-03b3cdc8c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-71d341c7-350a-413f-8cd2-d353456d1046,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-29f615e4-a094-4524-a2dd-7645bba4e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-bf041ccb-7e37-4a33-a3d3-66a269b5068e,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-1015d4ce-e094-4df8-8ddc-680c65a7a710,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-cb8899d4-c051-4c0f-8b47-fcf552699c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145069031-172.17.0.4-1596913252778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-058a6afc-ba47-41f3-a689-31373698d930,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-c44c1f79-e365-47d9-ae9b-7cb3bd7d7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-56357175-c6f6-44eb-bfe2-eede72ca5a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-9511d595-b527-4aae-910a-b000941d6ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-fd6cdc4e-5b38-4b2d-ac61-297c6cf668a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-d5eda9e3-2c42-4578-a19b-390a306581dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-8604847d-dc71-427a-903b-2cfb991359b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-c7944516-eb1e-48ab-8eb1-e53965020994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145069031-172.17.0.4-1596913252778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-058a6afc-ba47-41f3-a689-31373698d930,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-c44c1f79-e365-47d9-ae9b-7cb3bd7d7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-56357175-c6f6-44eb-bfe2-eede72ca5a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-9511d595-b527-4aae-910a-b000941d6ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-fd6cdc4e-5b38-4b2d-ac61-297c6cf668a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-d5eda9e3-2c42-4578-a19b-390a306581dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-8604847d-dc71-427a-903b-2cfb991359b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-c7944516-eb1e-48ab-8eb1-e53965020994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037710240-172.17.0.4-1596913702342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-b403ae5d-79e7-48e8-b8bf-9301adfe8327,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-476c488c-b6b9-4db0-9023-4b01d2cbeb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-a1ad8c91-2cda-4530-be4f-f2f0de984efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-e28f480e-121b-4235-a14f-bfd3ab7c3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-bd18e1d8-28e0-474d-b904-290f74a501f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-f06d593d-8264-4b51-bcfa-0a71b917b5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2666164d-a38d-4041-8376-7abff370b179,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-30d9273c-c982-42b4-8eec-31a9dcda7885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037710240-172.17.0.4-1596913702342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-b403ae5d-79e7-48e8-b8bf-9301adfe8327,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-476c488c-b6b9-4db0-9023-4b01d2cbeb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-a1ad8c91-2cda-4530-be4f-f2f0de984efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-e28f480e-121b-4235-a14f-bfd3ab7c3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-bd18e1d8-28e0-474d-b904-290f74a501f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-f06d593d-8264-4b51-bcfa-0a71b917b5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2666164d-a38d-4041-8376-7abff370b179,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-30d9273c-c982-42b4-8eec-31a9dcda7885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4987
