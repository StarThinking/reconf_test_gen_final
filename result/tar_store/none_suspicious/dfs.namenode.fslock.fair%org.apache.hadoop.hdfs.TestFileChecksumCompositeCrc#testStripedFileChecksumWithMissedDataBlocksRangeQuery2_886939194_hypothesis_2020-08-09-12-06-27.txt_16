reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552312664-172.17.0.20-1596975005666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34500,DS-991bafd4-a4f0-4f54-8e28-ce017032ebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-dcb43e04-64e9-4e8d-9bcd-490d29476c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-b238a362-b70e-402d-a73f-482e257b54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-13c36ae6-d61a-4027-bc80-24147bdf5b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-7d600af2-e196-4079-91f7-f0506aab1b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-1fdaa9e6-7adf-4e04-ad07-fa2fc25d401f,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-d9c66a76-d8f4-42e8-bc4e-2f4f265c1e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-af64043c-a369-4229-adc5-4755383135d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552312664-172.17.0.20-1596975005666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34500,DS-991bafd4-a4f0-4f54-8e28-ce017032ebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-dcb43e04-64e9-4e8d-9bcd-490d29476c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-b238a362-b70e-402d-a73f-482e257b54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-13c36ae6-d61a-4027-bc80-24147bdf5b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-7d600af2-e196-4079-91f7-f0506aab1b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-1fdaa9e6-7adf-4e04-ad07-fa2fc25d401f,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-d9c66a76-d8f4-42e8-bc4e-2f4f265c1e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-af64043c-a369-4229-adc5-4755383135d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540632360-172.17.0.20-1596975061698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40642,DS-b04545e8-2e67-4136-b2c5-1d1b9db60fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-ede55b7a-82f6-4717-90ef-6d4d6a92599c,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-f976ea98-5f2f-4b05-b97b-6cc93dcd7de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-ca2b2098-f2aa-439f-abad-9584e912f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-01be5109-275e-44e8-a8e5-a8bf5f01000b,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-f4262160-c303-4650-99e4-c7f47f4278ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-b7d6035e-c137-49d6-a2fe-4389885dda79,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-48f5210e-5a2d-4c4d-a3c3-6ae42a6578ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540632360-172.17.0.20-1596975061698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40642,DS-b04545e8-2e67-4136-b2c5-1d1b9db60fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-ede55b7a-82f6-4717-90ef-6d4d6a92599c,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-f976ea98-5f2f-4b05-b97b-6cc93dcd7de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-ca2b2098-f2aa-439f-abad-9584e912f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-01be5109-275e-44e8-a8e5-a8bf5f01000b,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-f4262160-c303-4650-99e4-c7f47f4278ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-b7d6035e-c137-49d6-a2fe-4389885dda79,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-48f5210e-5a2d-4c4d-a3c3-6ae42a6578ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627390326-172.17.0.20-1596975189425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38606,DS-08fc61d9-eb20-4fe5-8c8a-2d0259546cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-c19e9e95-e413-4985-ab16-fd10b78061f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-f91937d2-7282-4eaa-b2dc-c2df299283dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-c6e238d9-3d08-4d29-8956-d6f6561190e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-03d83596-d6e7-483f-bc9f-261cddce7749,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-e4b4d1a2-2a70-4edc-a041-e32659b3c947,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-48fdc042-ed9a-43b1-b885-e19c9d2e8b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-6a8fd817-1b0b-41f1-ba2d-41d1104ecb16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627390326-172.17.0.20-1596975189425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38606,DS-08fc61d9-eb20-4fe5-8c8a-2d0259546cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-c19e9e95-e413-4985-ab16-fd10b78061f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-f91937d2-7282-4eaa-b2dc-c2df299283dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-c6e238d9-3d08-4d29-8956-d6f6561190e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-03d83596-d6e7-483f-bc9f-261cddce7749,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-e4b4d1a2-2a70-4edc-a041-e32659b3c947,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-48fdc042-ed9a-43b1-b885-e19c9d2e8b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-6a8fd817-1b0b-41f1-ba2d-41d1104ecb16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28855865-172.17.0.20-1596975230293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-2fa28a75-01c0-4507-8ab1-8f713f1b502f,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-fe5267f8-dc7e-480f-bc39-0a073157cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-6fdeb619-9ed7-4e62-9ea4-6469ff2cfc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-b7c5d3ba-1d60-4e96-b833-65040affe8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-eec8304b-848d-4e0b-94d6-440a80eb9157,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-e45c43fc-33c4-46f4-a0ce-e3051bb1dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-0c19bbdf-52eb-4e4b-ae5f-10eb2c771a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-e92dd2b6-9ade-4e5f-9bb9-8ba8b6e599b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28855865-172.17.0.20-1596975230293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-2fa28a75-01c0-4507-8ab1-8f713f1b502f,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-fe5267f8-dc7e-480f-bc39-0a073157cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-6fdeb619-9ed7-4e62-9ea4-6469ff2cfc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-b7c5d3ba-1d60-4e96-b833-65040affe8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-eec8304b-848d-4e0b-94d6-440a80eb9157,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-e45c43fc-33c4-46f4-a0ce-e3051bb1dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-0c19bbdf-52eb-4e4b-ae5f-10eb2c771a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-e92dd2b6-9ade-4e5f-9bb9-8ba8b6e599b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204542177-172.17.0.20-1596976144441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-9344bf7f-d846-4c9d-858f-1e90bc27324d,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-37df1fa6-6f43-4b39-927e-a55b7e50d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-c2544ae6-5ff1-49bb-ad86-ef9bdf1f6744,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-40d59764-7b43-4117-863c-e9ddf8dcb94b,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f4aa7852-16dd-4f31-a175-4a9aff7bb4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-8833a8dc-3d69-48ab-bec6-9cbfb0ed3130,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-4da92dd2-6f12-4d9b-8cbd-54f4493de08e,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-2b70a656-80e0-4bcb-b0bf-5df6e9a73269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204542177-172.17.0.20-1596976144441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-9344bf7f-d846-4c9d-858f-1e90bc27324d,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-37df1fa6-6f43-4b39-927e-a55b7e50d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-c2544ae6-5ff1-49bb-ad86-ef9bdf1f6744,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-40d59764-7b43-4117-863c-e9ddf8dcb94b,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f4aa7852-16dd-4f31-a175-4a9aff7bb4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-8833a8dc-3d69-48ab-bec6-9cbfb0ed3130,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-4da92dd2-6f12-4d9b-8cbd-54f4493de08e,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-2b70a656-80e0-4bcb-b0bf-5df6e9a73269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925059231-172.17.0.20-1596976580095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34924,DS-f4cfbfd2-d937-4bd4-9352-7d14f5dc5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-a16d41e6-a38c-46bd-b6be-7651ab5303a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-328bdec5-1436-4076-88cc-b13567414ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-6f497905-387a-478f-b0f2-49e73dedaf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-bc975d92-280e-4a84-83e2-2530196e5781,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-7a9d1070-f1cb-4b6b-84e5-d7e2d8cd0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-cdf5e288-9426-4d94-8977-522b54b59200,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-52768b3d-533e-400e-974c-0489a560a144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925059231-172.17.0.20-1596976580095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34924,DS-f4cfbfd2-d937-4bd4-9352-7d14f5dc5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-a16d41e6-a38c-46bd-b6be-7651ab5303a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-328bdec5-1436-4076-88cc-b13567414ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-6f497905-387a-478f-b0f2-49e73dedaf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-bc975d92-280e-4a84-83e2-2530196e5781,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-7a9d1070-f1cb-4b6b-84e5-d7e2d8cd0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-cdf5e288-9426-4d94-8977-522b54b59200,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-52768b3d-533e-400e-974c-0489a560a144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581025791-172.17.0.20-1596978389917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-5d4c58f1-0d06-418e-a055-ac68603c7bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-b49b8a44-dd0b-4676-bb75-5535330ee4be,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-cbe0e018-af81-44a7-91a1-100e496219fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-03b1a09e-1b46-4909-ba5a-43b93876b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-3632fdb8-4b21-49ff-b1f1-b65684a09838,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-9939b6c4-b09e-4659-be91-c8c603f10952,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-151b652d-f185-41d7-b11f-aa35af8604c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-b56c1f29-1000-4da8-ae17-b7adf1ba3a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581025791-172.17.0.20-1596978389917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-5d4c58f1-0d06-418e-a055-ac68603c7bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-b49b8a44-dd0b-4676-bb75-5535330ee4be,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-cbe0e018-af81-44a7-91a1-100e496219fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-03b1a09e-1b46-4909-ba5a-43b93876b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-3632fdb8-4b21-49ff-b1f1-b65684a09838,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-9939b6c4-b09e-4659-be91-c8c603f10952,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-151b652d-f185-41d7-b11f-aa35af8604c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-b56c1f29-1000-4da8-ae17-b7adf1ba3a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469583264-172.17.0.20-1596978442221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-b9859ddc-48f6-4781-90ca-63febecbabec,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-5e08027b-dee4-40f8-9b3c-2ecf3a11a224,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-e3f31c29-5846-48bf-937d-07ebba58555b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-3d5a5cf5-61e0-4240-997d-c6ff64714e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-6ec1278c-dd77-4e34-8a8d-fcab5a42238d,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-d1994dba-25df-419b-8dbe-d193099a9988,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-49d120fb-b497-4a49-9999-b79ccb214005,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-46258701-e6a9-412c-883b-33039cdaf996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469583264-172.17.0.20-1596978442221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-b9859ddc-48f6-4781-90ca-63febecbabec,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-5e08027b-dee4-40f8-9b3c-2ecf3a11a224,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-e3f31c29-5846-48bf-937d-07ebba58555b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-3d5a5cf5-61e0-4240-997d-c6ff64714e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-6ec1278c-dd77-4e34-8a8d-fcab5a42238d,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-d1994dba-25df-419b-8dbe-d193099a9988,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-49d120fb-b497-4a49-9999-b79ccb214005,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-46258701-e6a9-412c-883b-33039cdaf996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747761151-172.17.0.20-1596978484910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-64dbeed7-2e5e-42ad-a1bd-ae41ef8ce1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-c466c1a3-1732-4fcf-8015-8d470008bf85,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-98762d30-98fb-4a08-9c62-a86ef7e0226e,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-b95ec2ad-57ee-41bd-9691-55c2dce403fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-e746251e-3a09-4d34-a2a9-e6015a7036db,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-6a25d890-7b74-4ffa-b15f-8df42d056700,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f1d8d935-f4af-4e4a-8cec-67de550097df,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-f82972f2-7679-4e8b-8df2-c8811d0848f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747761151-172.17.0.20-1596978484910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-64dbeed7-2e5e-42ad-a1bd-ae41ef8ce1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-c466c1a3-1732-4fcf-8015-8d470008bf85,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-98762d30-98fb-4a08-9c62-a86ef7e0226e,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-b95ec2ad-57ee-41bd-9691-55c2dce403fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-e746251e-3a09-4d34-a2a9-e6015a7036db,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-6a25d890-7b74-4ffa-b15f-8df42d056700,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f1d8d935-f4af-4e4a-8cec-67de550097df,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-f82972f2-7679-4e8b-8df2-c8811d0848f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264323821-172.17.0.20-1596978608889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-41d9ced2-7c25-4953-98e5-46a073ef9c65,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-ea80ef81-e07c-428f-9b28-06180c4ad32f,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-6455855c-01c0-4ad8-a435-354bd984eaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-b73cf5df-79d2-48e7-ac63-abbe311d524e,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-87b1debe-6ce3-451a-a26d-8500795a0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-41ca85c3-91ca-4800-a56b-44e5755a00cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-dd90b106-a26d-4ab1-9338-8d85c488628e,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-486b6048-d091-41be-93a4-b7850d01576a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264323821-172.17.0.20-1596978608889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-41d9ced2-7c25-4953-98e5-46a073ef9c65,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-ea80ef81-e07c-428f-9b28-06180c4ad32f,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-6455855c-01c0-4ad8-a435-354bd984eaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-b73cf5df-79d2-48e7-ac63-abbe311d524e,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-87b1debe-6ce3-451a-a26d-8500795a0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-41ca85c3-91ca-4800-a56b-44e5755a00cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-dd90b106-a26d-4ab1-9338-8d85c488628e,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-486b6048-d091-41be-93a4-b7850d01576a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573342705-172.17.0.20-1596978731533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-8f985446-dc08-4548-bc46-c673a57a214a,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-facef0ac-e16e-46a3-8f6f-1848c3360514,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-f2d66afe-d7db-4c95-8929-73b77ed172be,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-29f6d896-01e0-4d75-b5c1-a22542c15b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-8b25f2e3-96e9-4baa-9cd2-a96cf9dda723,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-bf75f99a-c148-48cb-afd0-3fc173d10f66,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-101fa343-ea1b-4656-95c2-fec1948f1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-2e7bcac4-5fee-4dc5-9a41-b4e28c9d58f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573342705-172.17.0.20-1596978731533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-8f985446-dc08-4548-bc46-c673a57a214a,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-facef0ac-e16e-46a3-8f6f-1848c3360514,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-f2d66afe-d7db-4c95-8929-73b77ed172be,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-29f6d896-01e0-4d75-b5c1-a22542c15b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-8b25f2e3-96e9-4baa-9cd2-a96cf9dda723,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-bf75f99a-c148-48cb-afd0-3fc173d10f66,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-101fa343-ea1b-4656-95c2-fec1948f1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-2e7bcac4-5fee-4dc5-9a41-b4e28c9d58f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794426678-172.17.0.20-1596979819599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-57aeff20-36ca-4d4c-8206-a3aeb15d500d,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-4b7123b1-ab0c-4479-91c3-142db39c77c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-fb04d2e6-e2f8-491b-8647-2cfb3cfc6815,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-19487954-6ff0-4232-a6fe-0c041ecda44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-f7d2afa5-c9db-430a-a893-163ab416994a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-64497999-1d3d-4060-b3a5-df6ce1afd313,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-d42b60fe-1b0e-48cc-8e57-213e8e1d1b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-3d51a63e-9240-44d8-bcc4-922f1e0bb1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794426678-172.17.0.20-1596979819599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-57aeff20-36ca-4d4c-8206-a3aeb15d500d,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-4b7123b1-ab0c-4479-91c3-142db39c77c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-fb04d2e6-e2f8-491b-8647-2cfb3cfc6815,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-19487954-6ff0-4232-a6fe-0c041ecda44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-f7d2afa5-c9db-430a-a893-163ab416994a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-64497999-1d3d-4060-b3a5-df6ce1afd313,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-d42b60fe-1b0e-48cc-8e57-213e8e1d1b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-3d51a63e-9240-44d8-bcc4-922f1e0bb1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028660653-172.17.0.20-1596980268647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-3d63c779-3b01-4f64-99d5-50968fbe4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-be2ce98d-0eb7-4384-8465-f0ff26f9c425,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-c431d9d3-297a-4aa6-98ca-d611a625cf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-8c4ba3fb-0677-4c7b-8287-70f16c5ba3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-bcc7ebd0-ee5f-4ea9-83a0-82ed886798c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-b630e6a9-3cfa-4ee9-b06f-e75d2980a831,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-d868860a-add9-4df2-8e2b-bcf40f88423a,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-b409f7dd-a0e7-499e-97eb-ca60e3fb9e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028660653-172.17.0.20-1596980268647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-3d63c779-3b01-4f64-99d5-50968fbe4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-be2ce98d-0eb7-4384-8465-f0ff26f9c425,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-c431d9d3-297a-4aa6-98ca-d611a625cf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-8c4ba3fb-0677-4c7b-8287-70f16c5ba3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-bcc7ebd0-ee5f-4ea9-83a0-82ed886798c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-b630e6a9-3cfa-4ee9-b06f-e75d2980a831,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-d868860a-add9-4df2-8e2b-bcf40f88423a,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-b409f7dd-a0e7-499e-97eb-ca60e3fb9e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049874501-172.17.0.20-1596980612968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-58c165f1-66e0-4015-bbcf-879c5310e837,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-595be8f1-ce27-406d-a395-79622d3e355a,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-b8374c29-6857-4b55-b5c7-641650a1f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-8cde4f74-515b-4c3b-bb5a-876558fffbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a9f842be-647a-44a6-b17e-7e9bea1120f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-4abd7110-01ff-46b9-81c7-ec83b51ed47f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-af7c81d5-3c2b-4da3-9438-2c21e1b67039,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-00e9e5de-90d7-49c3-b3d7-a65d9f4641f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049874501-172.17.0.20-1596980612968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-58c165f1-66e0-4015-bbcf-879c5310e837,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-595be8f1-ce27-406d-a395-79622d3e355a,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-b8374c29-6857-4b55-b5c7-641650a1f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-8cde4f74-515b-4c3b-bb5a-876558fffbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a9f842be-647a-44a6-b17e-7e9bea1120f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-4abd7110-01ff-46b9-81c7-ec83b51ed47f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-af7c81d5-3c2b-4da3-9438-2c21e1b67039,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-00e9e5de-90d7-49c3-b3d7-a65d9f4641f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731993916-172.17.0.20-1596980746535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45720,DS-48a79c3b-9509-437e-b67b-8281adbce211,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-46b2ac45-1faf-44d4-994f-0e8562b04366,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-2fe3bac1-5817-4873-b67d-9e982090c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-14e04416-8912-4e22-a1dd-7db19d060901,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-d5b92406-4538-423c-a9e0-1aeb432e3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-184f5e75-5934-4565-8062-e523366e79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-cbd6efba-eab9-4c3c-8efa-7c32f6a76da0,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-baae4bf0-e81a-45e7-a418-6c98bc84b640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731993916-172.17.0.20-1596980746535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45720,DS-48a79c3b-9509-437e-b67b-8281adbce211,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-46b2ac45-1faf-44d4-994f-0e8562b04366,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-2fe3bac1-5817-4873-b67d-9e982090c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-14e04416-8912-4e22-a1dd-7db19d060901,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-d5b92406-4538-423c-a9e0-1aeb432e3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-184f5e75-5934-4565-8062-e523366e79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-cbd6efba-eab9-4c3c-8efa-7c32f6a76da0,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-baae4bf0-e81a-45e7-a418-6c98bc84b640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6463
