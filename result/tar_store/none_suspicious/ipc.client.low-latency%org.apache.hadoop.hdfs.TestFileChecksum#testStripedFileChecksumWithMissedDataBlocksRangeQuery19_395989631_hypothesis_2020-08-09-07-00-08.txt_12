reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27638218-172.17.0.19-1596957177701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46555,DS-0ef6d757-861d-4c3e-971b-72f62f88f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-23f33c4e-6a71-4dfa-8d3a-d9af7f6e4a82,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-8ba4f36f-63ce-4ebb-927e-c38115f3c684,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-93a442fd-bef9-4c1d-a966-a4c893692dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-d5496fec-9331-46a1-9701-ea65f68892e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-d642fa8b-abaf-4b1e-b44a-697e4750b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-778913a7-6bc6-4780-a0ea-2a7cfc6e4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-7524e3c1-abff-4cf9-91fe-9ba0e1ce1e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27638218-172.17.0.19-1596957177701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46555,DS-0ef6d757-861d-4c3e-971b-72f62f88f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-23f33c4e-6a71-4dfa-8d3a-d9af7f6e4a82,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-8ba4f36f-63ce-4ebb-927e-c38115f3c684,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-93a442fd-bef9-4c1d-a966-a4c893692dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-d5496fec-9331-46a1-9701-ea65f68892e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-d642fa8b-abaf-4b1e-b44a-697e4750b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-778913a7-6bc6-4780-a0ea-2a7cfc6e4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-7524e3c1-abff-4cf9-91fe-9ba0e1ce1e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742005563-172.17.0.19-1596957528263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-1a729a31-e6d2-4d02-b3f2-1546372eabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-71144235-d5d1-4838-897a-9b20137e88f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-d296b7b5-720d-46b1-b547-ceafc5ad9748,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-55022b27-815f-42f7-ad27-98084099e9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-c380e347-2d2f-4266-bf40-9bf1f1a1448c,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-ef14e09b-e719-4bf9-a443-a26456e323c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-998ceed4-1715-4c93-be0a-017df18cbfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-c81ccc39-2931-4b50-9ae6-28a101a7f624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742005563-172.17.0.19-1596957528263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-1a729a31-e6d2-4d02-b3f2-1546372eabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-71144235-d5d1-4838-897a-9b20137e88f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-d296b7b5-720d-46b1-b547-ceafc5ad9748,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-55022b27-815f-42f7-ad27-98084099e9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-c380e347-2d2f-4266-bf40-9bf1f1a1448c,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-ef14e09b-e719-4bf9-a443-a26456e323c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-998ceed4-1715-4c93-be0a-017df18cbfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-c81ccc39-2931-4b50-9ae6-28a101a7f624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593304721-172.17.0.19-1596957668368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39288,DS-581e9b2a-8a9f-4303-8cf0-d68d60b720c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3c1369be-3198-4f9c-81b6-73f2697da278,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-0a3a59dc-e4b7-48a0-bb1a-f8f2e3a7a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8d591ad5-2f6b-47be-8810-7b076aeff4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-33917216-4a69-4782-b95f-8cd4ebb4c0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-1a7edd33-c591-4950-874c-d9c8c5348c52,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-b44a861f-1006-4c2a-8481-9371189a61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-4f3ec454-36ed-477f-a360-080a9aba55d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593304721-172.17.0.19-1596957668368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39288,DS-581e9b2a-8a9f-4303-8cf0-d68d60b720c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3c1369be-3198-4f9c-81b6-73f2697da278,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-0a3a59dc-e4b7-48a0-bb1a-f8f2e3a7a03a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8d591ad5-2f6b-47be-8810-7b076aeff4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-33917216-4a69-4782-b95f-8cd4ebb4c0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-1a7edd33-c591-4950-874c-d9c8c5348c52,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-b44a861f-1006-4c2a-8481-9371189a61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-4f3ec454-36ed-477f-a360-080a9aba55d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388000835-172.17.0.19-1596957885676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-b0a32c84-a811-46a5-8e2f-1114fcd254f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-cbe04e70-3f35-4362-80c4-458051eb619e,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-c5f8daf5-94c0-497f-843f-bbed630fe0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-7fd8816c-41e1-4637-a581-6273a44347e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-2f621218-6b58-4938-be79-307658ff8606,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c6a3f81c-62c7-425b-a0bc-238f41d51701,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-c3a741f6-f059-46e0-b513-7a5db4b25373,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-cb7192b3-fa9e-4786-8a59-b4a61d45a005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388000835-172.17.0.19-1596957885676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-b0a32c84-a811-46a5-8e2f-1114fcd254f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-cbe04e70-3f35-4362-80c4-458051eb619e,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-c5f8daf5-94c0-497f-843f-bbed630fe0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-7fd8816c-41e1-4637-a581-6273a44347e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-2f621218-6b58-4938-be79-307658ff8606,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c6a3f81c-62c7-425b-a0bc-238f41d51701,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-c3a741f6-f059-46e0-b513-7a5db4b25373,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-cb7192b3-fa9e-4786-8a59-b4a61d45a005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11080290-172.17.0.19-1596958260754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33719,DS-781cb5d4-97d3-44f9-b55f-85ff265b0410,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-6c181eb2-8de2-4c57-ac80-ea70473bec0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-f24cc684-55ba-4e22-a800-84f6e039ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-4c0899ac-d50b-40b7-b54b-dfdf32756131,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-524d9aec-effa-4381-9c23-e8eafe2f045a,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-315f83fc-1ffa-45df-862c-a45d97ac8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-9d0eb842-f684-4d44-8b29-7f6214009d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-fb791e15-ee14-4a36-bb9e-06acc8e0eea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11080290-172.17.0.19-1596958260754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33719,DS-781cb5d4-97d3-44f9-b55f-85ff265b0410,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-6c181eb2-8de2-4c57-ac80-ea70473bec0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-f24cc684-55ba-4e22-a800-84f6e039ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-4c0899ac-d50b-40b7-b54b-dfdf32756131,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-524d9aec-effa-4381-9c23-e8eafe2f045a,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-315f83fc-1ffa-45df-862c-a45d97ac8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-9d0eb842-f684-4d44-8b29-7f6214009d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-fb791e15-ee14-4a36-bb9e-06acc8e0eea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064699446-172.17.0.19-1596958402888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40010,DS-3921cfd3-2800-47c9-ae66-cca252439ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-939a3407-2801-4d29-89ea-2c8fd6cba809,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-2c3344e8-3f53-429a-8478-1d51498ebb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-3b225cd9-1a09-44d3-bfe2-7c9310deac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-90fdb81a-ec00-498d-ac0e-6c9107e2fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-830050d6-208b-48b5-a8be-91f04d70d87e,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-51587525-6600-41db-820e-f3eba2c73dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-4aea14a8-a8cf-436a-a59c-937fde67c16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064699446-172.17.0.19-1596958402888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40010,DS-3921cfd3-2800-47c9-ae66-cca252439ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-939a3407-2801-4d29-89ea-2c8fd6cba809,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-2c3344e8-3f53-429a-8478-1d51498ebb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-3b225cd9-1a09-44d3-bfe2-7c9310deac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-90fdb81a-ec00-498d-ac0e-6c9107e2fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-830050d6-208b-48b5-a8be-91f04d70d87e,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-51587525-6600-41db-820e-f3eba2c73dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-4aea14a8-a8cf-436a-a59c-937fde67c16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850534028-172.17.0.19-1596958578139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-37973a98-62fc-4eb0-a6af-6617fe05071d,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-ca73ced7-305b-4443-9275-e7173d6b70d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-1ffa96d4-bfa6-4352-8f49-c9df58d85ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-04d1b16a-9273-44f1-802a-ac947e014961,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-c5ea0fa4-805e-40e0-bf47-cb9f646cedc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-4efb2dbd-d0f1-4d15-9679-37b52624f418,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-976a4ba0-92dd-4b63-b255-d1677cba35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-bc03a86f-ab82-42b8-9caf-4d0226a1c46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850534028-172.17.0.19-1596958578139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-37973a98-62fc-4eb0-a6af-6617fe05071d,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-ca73ced7-305b-4443-9275-e7173d6b70d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-1ffa96d4-bfa6-4352-8f49-c9df58d85ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-04d1b16a-9273-44f1-802a-ac947e014961,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-c5ea0fa4-805e-40e0-bf47-cb9f646cedc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-4efb2dbd-d0f1-4d15-9679-37b52624f418,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-976a4ba0-92dd-4b63-b255-d1677cba35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-bc03a86f-ab82-42b8-9caf-4d0226a1c46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650667376-172.17.0.19-1596958788389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-0236e4ba-face-4ea5-89b3-e38f02cbc330,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-22aff7ab-4b5c-4609-a306-9a77f9cdb0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-ff93f109-1fa5-4a60-ae59-f8f537f9a171,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-86842e17-e089-427c-851f-fb3d2a02a576,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-99d757ae-2593-4134-bd6d-a63db98af352,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-33ebfb48-6401-4a3e-99b0-8272b03ddf97,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-f4568e3a-2917-4cfe-b6b6-0c7243fed9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-d481d31e-4492-43ce-9f9a-d966a581e6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650667376-172.17.0.19-1596958788389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-0236e4ba-face-4ea5-89b3-e38f02cbc330,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-22aff7ab-4b5c-4609-a306-9a77f9cdb0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-ff93f109-1fa5-4a60-ae59-f8f537f9a171,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-86842e17-e089-427c-851f-fb3d2a02a576,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-99d757ae-2593-4134-bd6d-a63db98af352,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-33ebfb48-6401-4a3e-99b0-8272b03ddf97,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-f4568e3a-2917-4cfe-b6b6-0c7243fed9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-d481d31e-4492-43ce-9f9a-d966a581e6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106076855-172.17.0.19-1596959054758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38201,DS-15f7d280-1fcd-4eb3-b559-1461438e0362,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-625393f2-30b8-4fd6-86a8-759157066e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-f9ab4dcc-7a9c-48ed-a983-67b15cd17535,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-2f773a82-f237-4d8b-a9c3-9c888cfbb865,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8c1a24a4-a91a-4b6e-a7fc-642aa327f6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-e3c3b4c4-edba-453f-9bdc-995be949b009,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-3baab85c-4413-4485-ba99-e09892e27c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-6431ee4b-b029-4836-a6ff-ff2e606a9534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106076855-172.17.0.19-1596959054758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38201,DS-15f7d280-1fcd-4eb3-b559-1461438e0362,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-625393f2-30b8-4fd6-86a8-759157066e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-f9ab4dcc-7a9c-48ed-a983-67b15cd17535,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-2f773a82-f237-4d8b-a9c3-9c888cfbb865,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8c1a24a4-a91a-4b6e-a7fc-642aa327f6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-e3c3b4c4-edba-453f-9bdc-995be949b009,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-3baab85c-4413-4485-ba99-e09892e27c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-6431ee4b-b029-4836-a6ff-ff2e606a9534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853354173-172.17.0.19-1596959097804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-cd9f0d7f-71e5-4f84-a573-8f69447c202e,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-23be4547-6779-42b8-bc4e-f77c8c426817,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-95341d42-0d51-49b9-8d73-f0cfe9a5512c,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-a16c27c8-178f-4f98-b60d-0cd9ac6710f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-13ef5b95-1496-495a-8f49-aa44b065145a,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-55ba047b-bfab-419c-a196-5d7b72d2b0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-8c1eb0c9-bb4b-41b5-ac70-82f62af92bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-33d7818e-4a25-4050-a138-4ecf43064709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853354173-172.17.0.19-1596959097804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-cd9f0d7f-71e5-4f84-a573-8f69447c202e,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-23be4547-6779-42b8-bc4e-f77c8c426817,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-95341d42-0d51-49b9-8d73-f0cfe9a5512c,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-a16c27c8-178f-4f98-b60d-0cd9ac6710f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-13ef5b95-1496-495a-8f49-aa44b065145a,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-55ba047b-bfab-419c-a196-5d7b72d2b0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-8c1eb0c9-bb4b-41b5-ac70-82f62af92bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-33d7818e-4a25-4050-a138-4ecf43064709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294508014-172.17.0.19-1596959268226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-add04f5b-db4b-4bc6-8c0e-46e07d2f4fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-f29f0dc7-9645-4e2e-9582-4485b2563968,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-2923985e-274a-4e59-8da8-ad708ab6d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-46cb9e32-7a4d-4621-9275-2f6ba902c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-f9d21946-5642-4128-b056-0ea64ffad610,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-9db64a75-9272-424a-acb7-982bd8417228,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-8ea89287-d2a7-4805-bc9a-1233103a8d99,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-962a7866-a863-4624-b8c4-c8f93cae7442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294508014-172.17.0.19-1596959268226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-add04f5b-db4b-4bc6-8c0e-46e07d2f4fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-f29f0dc7-9645-4e2e-9582-4485b2563968,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-2923985e-274a-4e59-8da8-ad708ab6d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-46cb9e32-7a4d-4621-9275-2f6ba902c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-f9d21946-5642-4128-b056-0ea64ffad610,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-9db64a75-9272-424a-acb7-982bd8417228,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-8ea89287-d2a7-4805-bc9a-1233103a8d99,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-962a7866-a863-4624-b8c4-c8f93cae7442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254538778-172.17.0.19-1596959447766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-b0b197ac-d8d6-4b9f-8572-b76a9d1457fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-80c2088e-905a-4d37-9ccf-a9e9611af71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-f7e5bfee-af72-4cf8-b913-e94eee41e520,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-7b3ac156-53e2-4306-b34c-b842ef0c0559,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-aad778fe-4af0-40ad-a903-4ce35a817d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0ecfa291-a982-4f85-b072-7fc97322b1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-1835e55f-e1fc-433a-bc59-332b98e948a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-9bd9891b-7603-4ecc-acab-5df3a7ef0cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254538778-172.17.0.19-1596959447766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-b0b197ac-d8d6-4b9f-8572-b76a9d1457fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-80c2088e-905a-4d37-9ccf-a9e9611af71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-f7e5bfee-af72-4cf8-b913-e94eee41e520,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-7b3ac156-53e2-4306-b34c-b842ef0c0559,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-aad778fe-4af0-40ad-a903-4ce35a817d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0ecfa291-a982-4f85-b072-7fc97322b1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-1835e55f-e1fc-433a-bc59-332b98e948a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-9bd9891b-7603-4ecc-acab-5df3a7ef0cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057357080-172.17.0.19-1596959902874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-24fd2e68-2ec4-4c0b-8421-3b46654874d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-4fa76302-6292-4eeb-b022-fd8a47044e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-e2d93870-13d1-4ace-8162-4cdfd2c11160,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-4eba9e1d-ef12-4502-a00b-74999db48b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-8981cfa0-cc42-4a74-a654-50e7fd5d9285,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-361e75ec-90f1-4116-b4f7-70dc92fc7270,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-adccf9c5-90b6-444d-9d4e-ca762f712bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-1dc1a9ed-5a45-487d-90cc-5e41cb94a367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057357080-172.17.0.19-1596959902874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-24fd2e68-2ec4-4c0b-8421-3b46654874d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-4fa76302-6292-4eeb-b022-fd8a47044e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-e2d93870-13d1-4ace-8162-4cdfd2c11160,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-4eba9e1d-ef12-4502-a00b-74999db48b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-8981cfa0-cc42-4a74-a654-50e7fd5d9285,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-361e75ec-90f1-4116-b4f7-70dc92fc7270,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-adccf9c5-90b6-444d-9d4e-ca762f712bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-1dc1a9ed-5a45-487d-90cc-5e41cb94a367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806418277-172.17.0.19-1596960118842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33010,DS-edd1c01f-d0df-4a01-ba3e-2de75a33a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-d8c84537-4c2a-4007-8d87-87cbbbef8745,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-043fd8bc-032e-49e1-9d9f-50cfafa26cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-0bf0b7fb-3f0c-474b-b432-3d4c3fcb86c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-5038ca7a-aacc-47e3-9f38-94b73a24b36c,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-706042a6-5a30-496c-81d3-9bba84b4d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-0c7d1a92-31bb-48aa-9e21-8d85e698eb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-d5319dda-4bd1-4309-ac1c-6ad811ac5690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806418277-172.17.0.19-1596960118842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33010,DS-edd1c01f-d0df-4a01-ba3e-2de75a33a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-d8c84537-4c2a-4007-8d87-87cbbbef8745,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-043fd8bc-032e-49e1-9d9f-50cfafa26cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-0bf0b7fb-3f0c-474b-b432-3d4c3fcb86c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-5038ca7a-aacc-47e3-9f38-94b73a24b36c,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-706042a6-5a30-496c-81d3-9bba84b4d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-0c7d1a92-31bb-48aa-9e21-8d85e698eb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-d5319dda-4bd1-4309-ac1c-6ad811ac5690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507762479-172.17.0.19-1596960358904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-c5fff206-9e22-473a-aa86-41aa2c72dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-a983350c-c417-4d77-9da7-c6cccfd88800,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-40cb9a2e-7c67-4875-8386-bb22223104cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8e31bc0d-4337-465c-ae50-dafa27a957c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-9a5edb2a-db38-431a-ad75-53bef7845c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-f388fe6c-42ae-4df9-82fb-3efb724f399a,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-81d9f337-cede-4998-a891-07a254dbbb64,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-1f8e36f7-cef0-40b5-9303-67cf80dc3019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507762479-172.17.0.19-1596960358904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-c5fff206-9e22-473a-aa86-41aa2c72dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-a983350c-c417-4d77-9da7-c6cccfd88800,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-40cb9a2e-7c67-4875-8386-bb22223104cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8e31bc0d-4337-465c-ae50-dafa27a957c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-9a5edb2a-db38-431a-ad75-53bef7845c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-f388fe6c-42ae-4df9-82fb-3efb724f399a,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-81d9f337-cede-4998-a891-07a254dbbb64,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-1f8e36f7-cef0-40b5-9303-67cf80dc3019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490304246-172.17.0.19-1596960407823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-813e4638-55fe-434f-9b24-8d0901a948cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-32c11ab6-b2f7-4373-b146-2ce2d70f451e,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-4f5a8874-b00c-487f-aac6-5f763d2b18a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-922f9561-7580-4fe9-8210-1ce388f769e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-1b4dca42-9b82-4a87-9767-05256a1597a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-13daade0-d422-46b7-b4e1-6efb8aaaa730,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-55728612-a8d6-47f9-a5e8-27b595fce6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ae09e841-2b98-43bb-9066-a1ccb565e33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490304246-172.17.0.19-1596960407823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-813e4638-55fe-434f-9b24-8d0901a948cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-32c11ab6-b2f7-4373-b146-2ce2d70f451e,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-4f5a8874-b00c-487f-aac6-5f763d2b18a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-922f9561-7580-4fe9-8210-1ce388f769e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-1b4dca42-9b82-4a87-9767-05256a1597a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-13daade0-d422-46b7-b4e1-6efb8aaaa730,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-55728612-a8d6-47f9-a5e8-27b595fce6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ae09e841-2b98-43bb-9066-a1ccb565e33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788730550-172.17.0.19-1596960444149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-cacbefce-6206-4afd-95d5-e3497ba44087,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-fbeb4636-d6b9-479b-a1b8-f6d5dabd2005,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-f80512e8-6e28-470d-b702-2e682e09eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-36617ddc-44db-4c7b-96a6-d552d15bcb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-69c1c548-c3b6-4c7e-bce1-24ab62bc98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-8fd1c0f0-7967-4c7e-a9fa-c0a7b1b636d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-70ee0229-1269-4b7d-9624-e6504131e012,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-0d06bc49-77d2-4203-a4ab-3e1b7c192809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788730550-172.17.0.19-1596960444149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-cacbefce-6206-4afd-95d5-e3497ba44087,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-fbeb4636-d6b9-479b-a1b8-f6d5dabd2005,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-f80512e8-6e28-470d-b702-2e682e09eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-36617ddc-44db-4c7b-96a6-d552d15bcb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-69c1c548-c3b6-4c7e-bce1-24ab62bc98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-8fd1c0f0-7967-4c7e-a9fa-c0a7b1b636d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-70ee0229-1269-4b7d-9624-e6504131e012,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-0d06bc49-77d2-4203-a4ab-3e1b7c192809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123930497-172.17.0.19-1596960573394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-637da113-f311-4323-956c-3ceda348d7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-30973595-02c6-4b9f-a5e3-b5dc5d41a4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-99080bec-f462-44dc-bf6c-cff503363331,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-42bdd60b-2eba-49ad-9465-bedda5a030c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-e8214cb6-64ec-439a-a418-5af142b85b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-0cb36339-5668-4fc4-b4d7-dbc15156735d,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-a5029e20-6c32-436e-8e92-d33b2a160e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-5ec9ed4c-6502-4e16-95a1-448a81dcedd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123930497-172.17.0.19-1596960573394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-637da113-f311-4323-956c-3ceda348d7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-30973595-02c6-4b9f-a5e3-b5dc5d41a4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-99080bec-f462-44dc-bf6c-cff503363331,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-42bdd60b-2eba-49ad-9465-bedda5a030c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-e8214cb6-64ec-439a-a418-5af142b85b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-0cb36339-5668-4fc4-b4d7-dbc15156735d,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-a5029e20-6c32-436e-8e92-d33b2a160e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-5ec9ed4c-6502-4e16-95a1-448a81dcedd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504057424-172.17.0.19-1596960614005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-7e86e4f4-7760-482e-8847-5b2330388a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-7c2eb8f9-acd7-41ac-b7a7-33a5c2814f55,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-b3fbb952-9b50-48a1-bf0f-7d65f57435df,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-02fc96a2-a341-4fa5-a187-88a113651dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-e6633c57-41a4-4cd5-a8d6-06e1c7ad307c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-e1de42d5-604c-4717-9994-6ed006337b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-b429886c-9b8c-4e77-8b86-89b2cc9821f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-69c79099-4808-4f26-88fb-1426fa2677a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504057424-172.17.0.19-1596960614005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-7e86e4f4-7760-482e-8847-5b2330388a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-7c2eb8f9-acd7-41ac-b7a7-33a5c2814f55,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-b3fbb952-9b50-48a1-bf0f-7d65f57435df,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-02fc96a2-a341-4fa5-a187-88a113651dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-e6633c57-41a4-4cd5-a8d6-06e1c7ad307c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-e1de42d5-604c-4717-9994-6ed006337b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-b429886c-9b8c-4e77-8b86-89b2cc9821f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-69c79099-4808-4f26-88fb-1426fa2677a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012628672-172.17.0.19-1596960749895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-98eb8204-6445-4b19-84d4-7d88733b35c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-baa8eee6-c834-4b7b-8e12-3f79777b50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-cac6d299-a69f-4b50-8dd8-1f10a04a8896,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-86beef6d-a29c-435a-902f-db22ecbc2847,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-fd563218-b705-4fc0-9db6-a9b70cb4c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-81ce5096-d651-48e5-a6f9-3fb12a0c2e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-18211fcc-6359-465f-ace6-2512541e27ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-840188a5-016c-46ee-a76c-ffe1d6745f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012628672-172.17.0.19-1596960749895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-98eb8204-6445-4b19-84d4-7d88733b35c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-baa8eee6-c834-4b7b-8e12-3f79777b50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-cac6d299-a69f-4b50-8dd8-1f10a04a8896,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-86beef6d-a29c-435a-902f-db22ecbc2847,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-fd563218-b705-4fc0-9db6-a9b70cb4c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-81ce5096-d651-48e5-a6f9-3fb12a0c2e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-18211fcc-6359-465f-ace6-2512541e27ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-840188a5-016c-46ee-a76c-ffe1d6745f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646994701-172.17.0.19-1596960788471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-9532b8c9-16e3-4ced-9b9b-96bdd769f431,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-4e39295c-8d64-4f0c-b168-1744a901f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-69e520fb-1bdf-495d-b31a-9a1e705bc5da,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-31de6d83-215e-4f82-ac13-83cfc31ff086,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-4e1a5ff3-399c-4ccd-bc9d-54dd8a6610fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-aea24585-350e-4ea0-94f8-6f8bbe1cb77e,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-2b9efb37-d0c2-46d2-bd62-bbb1ff60bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-5f160f01-5c9f-4013-bed7-e90d4270dc9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646994701-172.17.0.19-1596960788471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-9532b8c9-16e3-4ced-9b9b-96bdd769f431,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-4e39295c-8d64-4f0c-b168-1744a901f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-69e520fb-1bdf-495d-b31a-9a1e705bc5da,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-31de6d83-215e-4f82-ac13-83cfc31ff086,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-4e1a5ff3-399c-4ccd-bc9d-54dd8a6610fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-aea24585-350e-4ea0-94f8-6f8bbe1cb77e,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-2b9efb37-d0c2-46d2-bd62-bbb1ff60bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-5f160f01-5c9f-4013-bed7-e90d4270dc9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164598142-172.17.0.19-1596961767886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-078a2caa-45a1-4bbb-9d48-716767fd3209,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-2c29e68d-3936-4743-b334-8b2ae34e73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-c6b99945-3491-4034-b43c-99e9aa366a85,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-2e47b212-f48b-46e4-8c2d-7d25298919b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-27dd04ff-5135-4705-90d2-6a504e329c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-7c2ed1d5-229a-42a6-9620-10e882c44243,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-36087260-212a-463a-97bd-73a7b986d7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-80b78e77-ae3b-4f05-a83f-ce54fd33fe09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164598142-172.17.0.19-1596961767886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-078a2caa-45a1-4bbb-9d48-716767fd3209,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-2c29e68d-3936-4743-b334-8b2ae34e73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-c6b99945-3491-4034-b43c-99e9aa366a85,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-2e47b212-f48b-46e4-8c2d-7d25298919b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-27dd04ff-5135-4705-90d2-6a504e329c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-7c2ed1d5-229a-42a6-9620-10e882c44243,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-36087260-212a-463a-97bd-73a7b986d7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-80b78e77-ae3b-4f05-a83f-ce54fd33fe09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894351660-172.17.0.19-1596961847072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-439d75f7-7633-4a5a-b9d1-c213d4e46a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-5f95be5a-ff38-4d13-a79b-6821dd93d2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-8e6720fe-4b9c-4510-b6ef-522fcd3e966a,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-65f59528-c779-4aae-977c-ddad56e7bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-02cb070c-ac96-4195-8891-0b267dd04bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-3bae8e0b-729a-47eb-92eb-a60be28c39b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-957eba24-8e16-4470-b403-ae1c35961c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-13120b5a-12ed-4998-b460-25f62250dbc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894351660-172.17.0.19-1596961847072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-439d75f7-7633-4a5a-b9d1-c213d4e46a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-5f95be5a-ff38-4d13-a79b-6821dd93d2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-8e6720fe-4b9c-4510-b6ef-522fcd3e966a,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-65f59528-c779-4aae-977c-ddad56e7bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-02cb070c-ac96-4195-8891-0b267dd04bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-3bae8e0b-729a-47eb-92eb-a60be28c39b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-957eba24-8e16-4470-b403-ae1c35961c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-13120b5a-12ed-4998-b460-25f62250dbc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428689862-172.17.0.19-1596962286212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-f25f160b-3f91-4ff5-a053-f39c85249a62,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-931603ed-d4ee-499e-b63e-028e53d30e87,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-010c9f1e-cb63-4956-a527-026cdbcd94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-05a4e5c6-8042-4f12-94d8-060e381d9337,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-c603628c-7baa-4a70-ad49-e6f2cad3b599,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-22f5c9a3-c7f8-4564-99e1-c103b8c6258e,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-686e396e-80ff-4af6-9768-5ad233a1f353,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-b513dbe6-23f5-4c92-bf76-6726064901c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428689862-172.17.0.19-1596962286212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-f25f160b-3f91-4ff5-a053-f39c85249a62,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-931603ed-d4ee-499e-b63e-028e53d30e87,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-010c9f1e-cb63-4956-a527-026cdbcd94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-05a4e5c6-8042-4f12-94d8-060e381d9337,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-c603628c-7baa-4a70-ad49-e6f2cad3b599,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-22f5c9a3-c7f8-4564-99e1-c103b8c6258e,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-686e396e-80ff-4af6-9768-5ad233a1f353,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-b513dbe6-23f5-4c92-bf76-6726064901c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457635353-172.17.0.19-1596962327644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35105,DS-facf90d9-0682-4db8-a4c0-55370ad5a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-42a021fc-7f99-4ce2-92b3-3ac048aa545d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-6491759f-bccb-45cb-bb1f-ba41899564ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-19390c2b-1aa9-4feb-a52c-1f1dab83af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-3a223470-8cc3-4c67-8ccf-a58e0020a7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-65b15e36-482c-4e55-8d26-c34a5a9f8379,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-82d51530-2c39-4512-8e5e-dfbc6c3c3fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-9d0496b9-33c6-4ca3-bbbe-6fa533d1074e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457635353-172.17.0.19-1596962327644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35105,DS-facf90d9-0682-4db8-a4c0-55370ad5a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-42a021fc-7f99-4ce2-92b3-3ac048aa545d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-6491759f-bccb-45cb-bb1f-ba41899564ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-19390c2b-1aa9-4feb-a52c-1f1dab83af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-3a223470-8cc3-4c67-8ccf-a58e0020a7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-65b15e36-482c-4e55-8d26-c34a5a9f8379,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-82d51530-2c39-4512-8e5e-dfbc6c3c3fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-9d0496b9-33c6-4ca3-bbbe-6fa533d1074e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508764149-172.17.0.19-1596962629825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46822,DS-ab865772-9076-4e3a-aa09-63b826bb6c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-3607b259-125a-44bd-9ddf-d4c72f18af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-8206bc26-8bfc-4ee1-91d7-c5d6fee41782,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-47a65d39-56ae-4a51-a9f6-5bd71edee53f,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-d8dfd5bd-2543-4697-b101-7a6b73c63b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-bb93d0bb-c3c3-4d00-a1a5-dccacbf073f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-9ef265f5-91bf-494f-be2c-25c78626cecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-3c3095dc-6604-40d1-8dad-8e05b0044257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508764149-172.17.0.19-1596962629825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46822,DS-ab865772-9076-4e3a-aa09-63b826bb6c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-3607b259-125a-44bd-9ddf-d4c72f18af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-8206bc26-8bfc-4ee1-91d7-c5d6fee41782,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-47a65d39-56ae-4a51-a9f6-5bd71edee53f,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-d8dfd5bd-2543-4697-b101-7a6b73c63b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-bb93d0bb-c3c3-4d00-a1a5-dccacbf073f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-9ef265f5-91bf-494f-be2c-25c78626cecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-3c3095dc-6604-40d1-8dad-8e05b0044257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6550
