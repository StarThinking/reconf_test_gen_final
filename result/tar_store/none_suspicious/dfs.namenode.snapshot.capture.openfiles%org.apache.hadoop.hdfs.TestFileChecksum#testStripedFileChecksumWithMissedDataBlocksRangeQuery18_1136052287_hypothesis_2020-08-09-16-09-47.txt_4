reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809267754-172.17.0.5-1596990015439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38133,DS-efa9ca58-381b-4797-922b-5d476e4529a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-b936b556-71db-4e6b-b449-7d0887c67ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-bb3bb6a6-547c-4d26-938b-c284f83e8d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-e4aaf883-2a39-43e8-baa6-dbd933c77273,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5c974272-ce40-46eb-a5a0-40bb83641865,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-defb373b-4c2f-4075-ae07-16fb364ad7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-cb5ff73e-a7fe-499b-a86a-d3575a127373,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-f0ba554a-8906-48b6-bc76-12bf315eb81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809267754-172.17.0.5-1596990015439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38133,DS-efa9ca58-381b-4797-922b-5d476e4529a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-b936b556-71db-4e6b-b449-7d0887c67ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-bb3bb6a6-547c-4d26-938b-c284f83e8d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-e4aaf883-2a39-43e8-baa6-dbd933c77273,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5c974272-ce40-46eb-a5a0-40bb83641865,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-defb373b-4c2f-4075-ae07-16fb364ad7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-cb5ff73e-a7fe-499b-a86a-d3575a127373,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-f0ba554a-8906-48b6-bc76-12bf315eb81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206050097-172.17.0.5-1596990233253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44060,DS-40730a3f-7df2-4f84-bbd6-99eed7e1c03c,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-40232327-3aa5-48f0-8dbd-439e5dd3ef13,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-3caf69b7-14cb-4717-9d1e-c876d4a649ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-1ce28b5d-5e1f-41ad-907f-eb4773e7a034,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-d606cee0-bedf-494a-b251-704eceae9536,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-28b10f3d-d759-4cec-8c9e-6c22f839b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-9ca49fd7-ab53-4387-a6c8-267a573208d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-8a62f2e2-6bb5-48a9-bedb-f09205446355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206050097-172.17.0.5-1596990233253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44060,DS-40730a3f-7df2-4f84-bbd6-99eed7e1c03c,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-40232327-3aa5-48f0-8dbd-439e5dd3ef13,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-3caf69b7-14cb-4717-9d1e-c876d4a649ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-1ce28b5d-5e1f-41ad-907f-eb4773e7a034,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-d606cee0-bedf-494a-b251-704eceae9536,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-28b10f3d-d759-4cec-8c9e-6c22f839b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-9ca49fd7-ab53-4387-a6c8-267a573208d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-8a62f2e2-6bb5-48a9-bedb-f09205446355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451993730-172.17.0.5-1596990452311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45197,DS-53cf6159-480e-475e-b942-801449dd934a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-401157c7-4d7c-4104-8475-0a989a963eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-4ba40e18-1901-4522-bc5d-2d2d55aa9411,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-72f82cb8-d61e-413e-a474-7663f1ed03cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-4d4d375b-b913-42b7-95e4-673f27d139f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-1f52b27e-0ea9-4f98-9763-6c8b86b70bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-7f7e53c1-a5db-46ec-b770-12963f2d6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-d57cbd29-432e-48b6-9970-ac074a26140d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451993730-172.17.0.5-1596990452311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45197,DS-53cf6159-480e-475e-b942-801449dd934a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-401157c7-4d7c-4104-8475-0a989a963eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-4ba40e18-1901-4522-bc5d-2d2d55aa9411,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-72f82cb8-d61e-413e-a474-7663f1ed03cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-4d4d375b-b913-42b7-95e4-673f27d139f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-1f52b27e-0ea9-4f98-9763-6c8b86b70bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-7f7e53c1-a5db-46ec-b770-12963f2d6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-d57cbd29-432e-48b6-9970-ac074a26140d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584851885-172.17.0.5-1596990669413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-46d33669-3917-44ca-97ef-1676e3bb69d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-73d9bd5e-d0e2-43bf-9e7c-e29d22e91dab,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-5e9ed7f4-1cb2-4e8a-b2f6-06576334e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-bb4cea69-9082-431f-9926-4899a23c55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-b1f31960-57ed-4eac-82fc-9aad901196a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-8162e68e-cdfa-41f0-b7d8-2a4061fd9285,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-8482c1e0-6432-4c4a-831a-195e20bfffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-b320e646-5332-46c1-978e-11d58380a050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584851885-172.17.0.5-1596990669413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-46d33669-3917-44ca-97ef-1676e3bb69d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-73d9bd5e-d0e2-43bf-9e7c-e29d22e91dab,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-5e9ed7f4-1cb2-4e8a-b2f6-06576334e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-bb4cea69-9082-431f-9926-4899a23c55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-b1f31960-57ed-4eac-82fc-9aad901196a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-8162e68e-cdfa-41f0-b7d8-2a4061fd9285,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-8482c1e0-6432-4c4a-831a-195e20bfffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-b320e646-5332-46c1-978e-11d58380a050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451133490-172.17.0.5-1596990803732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-67926c6c-39fa-41ed-9fd2-02225d519e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-bb0e2d62-8166-46cc-b4e5-46800688a184,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-7ce40f97-b5b5-4986-929e-6edd69521e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-41443754-2a9b-4429-8ca7-833446c4c725,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-b6ee0c79-9ed4-4983-9c03-d723abce8eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-aee40c85-1ed0-453c-a9c0-68b43ee21d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-fd614754-0a75-41ce-98aa-280927d4fc31,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-b5b2ee5c-cd96-4e44-8c40-34b91176c2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451133490-172.17.0.5-1596990803732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-67926c6c-39fa-41ed-9fd2-02225d519e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-bb0e2d62-8166-46cc-b4e5-46800688a184,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-7ce40f97-b5b5-4986-929e-6edd69521e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-41443754-2a9b-4429-8ca7-833446c4c725,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-b6ee0c79-9ed4-4983-9c03-d723abce8eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-aee40c85-1ed0-453c-a9c0-68b43ee21d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-fd614754-0a75-41ce-98aa-280927d4fc31,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-b5b2ee5c-cd96-4e44-8c40-34b91176c2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743563088-172.17.0.5-1596990904078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-9de67daa-bdcb-4786-8bd2-ef9c4309f963,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f0f52de5-ef19-4ecd-b9f7-c390a1a4b5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-3a5660aa-d1a6-4176-86e7-8103de0bd76b,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-25749706-6974-4fdf-9b57-3429f9843b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-014eb6ba-1bee-458a-9036-b2dc51329cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-5cbb9643-33d6-49de-a84d-f6abb0bd2391,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-d5cb8da0-6e88-43b1-aebf-ef4eb835850c,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-2ea8ad22-3a33-41a2-a641-d8d4063794fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743563088-172.17.0.5-1596990904078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-9de67daa-bdcb-4786-8bd2-ef9c4309f963,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f0f52de5-ef19-4ecd-b9f7-c390a1a4b5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-3a5660aa-d1a6-4176-86e7-8103de0bd76b,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-25749706-6974-4fdf-9b57-3429f9843b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-014eb6ba-1bee-458a-9036-b2dc51329cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-5cbb9643-33d6-49de-a84d-f6abb0bd2391,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-d5cb8da0-6e88-43b1-aebf-ef4eb835850c,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-2ea8ad22-3a33-41a2-a641-d8d4063794fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516537119-172.17.0.5-1596990953857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-a485b4ca-ac74-4c00-b1eb-7dfa3a86bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-8b239ddc-3362-45eb-94a0-6bf7ee51c8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-17ec9ff8-7771-49c6-802b-a23b96967167,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-ba3494b1-c2bc-4a0c-b9f8-e68990e7f16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-803b1ba3-626b-477a-8a71-3af300676c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-9d7e4c8a-857b-472d-8a46-de0be7600d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-2d8afbdd-fbe5-4ff4-b978-a0a309323635,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-ec059458-13d2-476c-9983-8ca8359b7731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516537119-172.17.0.5-1596990953857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-a485b4ca-ac74-4c00-b1eb-7dfa3a86bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-8b239ddc-3362-45eb-94a0-6bf7ee51c8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-17ec9ff8-7771-49c6-802b-a23b96967167,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-ba3494b1-c2bc-4a0c-b9f8-e68990e7f16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-803b1ba3-626b-477a-8a71-3af300676c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-9d7e4c8a-857b-472d-8a46-de0be7600d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-2d8afbdd-fbe5-4ff4-b978-a0a309323635,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-ec059458-13d2-476c-9983-8ca8359b7731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127745288-172.17.0.5-1596991021944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33217,DS-d3cced1a-1fdc-497f-a537-a9a79bd02dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-0e08e3c0-c6ab-4556-9baa-a6de9b92a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-50969cf2-7712-4d9e-ab39-91af79bb11ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-f18b7928-a4a6-4e26-bd9f-a083f1fc272a,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-9b7f1379-df7c-4867-bffb-f46b4a52b88e,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-5c40a021-3228-4742-803a-07798b793ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-716c18d9-3441-4e33-af89-126ae3960e10,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-60f8cc2a-0b08-458f-a054-db77bb65779d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127745288-172.17.0.5-1596991021944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33217,DS-d3cced1a-1fdc-497f-a537-a9a79bd02dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-0e08e3c0-c6ab-4556-9baa-a6de9b92a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-50969cf2-7712-4d9e-ab39-91af79bb11ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-f18b7928-a4a6-4e26-bd9f-a083f1fc272a,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-9b7f1379-df7c-4867-bffb-f46b4a52b88e,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-5c40a021-3228-4742-803a-07798b793ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-716c18d9-3441-4e33-af89-126ae3960e10,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-60f8cc2a-0b08-458f-a054-db77bb65779d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739944591-172.17.0.5-1596991122639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-35a920e8-3051-4bd2-97c8-bbf7c45b43ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-4dcd5394-ac4d-4043-b16b-face704820b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-731363ad-5a53-44c5-98cd-e0bbe911b659,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-1e5d4e65-e3d4-422c-8177-acfca8759cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-9c3c213b-1761-461f-8cd5-94cede1cc85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-b5e9bee5-26d7-4148-a6bf-4b4f948eda0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-34898f3c-22bd-4a41-bec3-c75dcc5966ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-9f917310-9b84-44cf-8482-73f41ae18986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739944591-172.17.0.5-1596991122639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-35a920e8-3051-4bd2-97c8-bbf7c45b43ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-4dcd5394-ac4d-4043-b16b-face704820b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-731363ad-5a53-44c5-98cd-e0bbe911b659,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-1e5d4e65-e3d4-422c-8177-acfca8759cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-9c3c213b-1761-461f-8cd5-94cede1cc85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-b5e9bee5-26d7-4148-a6bf-4b4f948eda0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-34898f3c-22bd-4a41-bec3-c75dcc5966ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-9f917310-9b84-44cf-8482-73f41ae18986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634705526-172.17.0.5-1596991207445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-3edcb42c-9112-4b5c-a968-c38150e393c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-58481cb2-53d8-41a4-8b95-650b20b67677,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-cf19d9dd-38ca-4209-ae39-251749c40576,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-57304f7c-d537-4552-92f0-9034722a162f,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-7c366c69-36fe-4d34-aa8d-b96e54ba9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-39b7bb85-b01c-4f4d-a660-67e7a80061fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-9816f263-b788-4657-b404-f22697ceb268,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-fda712b9-2dda-4f9c-a149-9cda59440867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634705526-172.17.0.5-1596991207445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-3edcb42c-9112-4b5c-a968-c38150e393c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-58481cb2-53d8-41a4-8b95-650b20b67677,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-cf19d9dd-38ca-4209-ae39-251749c40576,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-57304f7c-d537-4552-92f0-9034722a162f,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-7c366c69-36fe-4d34-aa8d-b96e54ba9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-39b7bb85-b01c-4f4d-a660-67e7a80061fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-9816f263-b788-4657-b404-f22697ceb268,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-fda712b9-2dda-4f9c-a149-9cda59440867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768281085-172.17.0.5-1596991224110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-e7bd9052-1dbb-4e68-9d60-d0382570bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-53a5988c-2d31-40cd-a021-3166eb8a2899,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-fd06d6e6-ddc7-4b3e-9328-8ab64825af4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-b3e71725-3dab-49be-ab4f-df95037d1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-cc50d367-d6f5-44de-9c93-9df650e4f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-9ecdaf39-521e-4b20-afad-c27c607f5366,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-3c81d995-9d55-4fb7-bbd1-e05350dc9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-eb5d8e29-6a2e-4f28-85ed-3d8c0a50c428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768281085-172.17.0.5-1596991224110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-e7bd9052-1dbb-4e68-9d60-d0382570bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-53a5988c-2d31-40cd-a021-3166eb8a2899,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-fd06d6e6-ddc7-4b3e-9328-8ab64825af4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-b3e71725-3dab-49be-ab4f-df95037d1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-cc50d367-d6f5-44de-9c93-9df650e4f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-9ecdaf39-521e-4b20-afad-c27c607f5366,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-3c81d995-9d55-4fb7-bbd1-e05350dc9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-eb5d8e29-6a2e-4f28-85ed-3d8c0a50c428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311173750-172.17.0.5-1596991478215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33718,DS-0ea9dcbf-5e2f-47fa-bcc6-6378473ff271,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-876f8d52-3a8d-4630-b32f-1b762c0b34e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-c4917112-0ec6-43c6-a2d7-c5d135e8c59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-c66def7a-4fa8-4957-95ef-02698736a577,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-42d10b5e-b6cd-489a-b0b9-9c78f23f1a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-af1342d9-597f-4118-b955-515ae2790b61,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-35115e27-cce8-4a2a-8593-726f8ca5f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-a5ae2c89-f3e1-4b0c-888c-db368d621b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311173750-172.17.0.5-1596991478215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33718,DS-0ea9dcbf-5e2f-47fa-bcc6-6378473ff271,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-876f8d52-3a8d-4630-b32f-1b762c0b34e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-c4917112-0ec6-43c6-a2d7-c5d135e8c59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-c66def7a-4fa8-4957-95ef-02698736a577,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-42d10b5e-b6cd-489a-b0b9-9c78f23f1a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-af1342d9-597f-4118-b955-515ae2790b61,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-35115e27-cce8-4a2a-8593-726f8ca5f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-a5ae2c89-f3e1-4b0c-888c-db368d621b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80482020-172.17.0.5-1596991495147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-8152430b-3a62-4fc6-a986-584250108e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-01766f73-e8b8-4cd4-ae7d-b1a62b1aa7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-ba902a45-4130-4b24-a6ac-0f6160be2166,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f132b3b4-bfa7-4ad4-9731-38a5a1f9f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-f39162cc-dd82-43b1-b340-8df3a7a4a755,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-23ff8699-425f-44ff-8fa2-7249ff4e3470,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-bcc78a2e-c340-4f78-9ab8-e6f6f895a683,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-4b65bf38-8e37-41d0-8659-c23847a1ff82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80482020-172.17.0.5-1596991495147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-8152430b-3a62-4fc6-a986-584250108e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-01766f73-e8b8-4cd4-ae7d-b1a62b1aa7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-ba902a45-4130-4b24-a6ac-0f6160be2166,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f132b3b4-bfa7-4ad4-9731-38a5a1f9f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-f39162cc-dd82-43b1-b340-8df3a7a4a755,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-23ff8699-425f-44ff-8fa2-7249ff4e3470,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-bcc78a2e-c340-4f78-9ab8-e6f6f895a683,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-4b65bf38-8e37-41d0-8659-c23847a1ff82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665933715-172.17.0.5-1596991579709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-53434a9d-6dd6-4679-8317-1e11bd6366a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-101004aa-1c8e-4195-9868-e2c04b1b54f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-f4cc06ca-19bf-4b7b-bf19-979d00cb8ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-1b2a4e8e-fc45-4352-bd53-03e540f7977c,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-13a4d2a7-a83a-421c-9e8e-0a97deddf7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-758a8452-acf8-433e-a5a1-e5fa7dad4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-dd757060-96f1-42c5-b3c5-fb40645f1635,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-dbdd6518-43ce-4e58-b640-98c524ef37c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665933715-172.17.0.5-1596991579709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-53434a9d-6dd6-4679-8317-1e11bd6366a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-101004aa-1c8e-4195-9868-e2c04b1b54f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-f4cc06ca-19bf-4b7b-bf19-979d00cb8ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-1b2a4e8e-fc45-4352-bd53-03e540f7977c,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-13a4d2a7-a83a-421c-9e8e-0a97deddf7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-758a8452-acf8-433e-a5a1-e5fa7dad4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-dd757060-96f1-42c5-b3c5-fb40645f1635,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-dbdd6518-43ce-4e58-b640-98c524ef37c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158468877-172.17.0.5-1596991646363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38404,DS-1df3ca98-2ee2-4107-9357-a730ac6408df,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-45cb3b42-40f4-4abc-85b4-e56f01f3aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-7a8ad220-8da8-415a-a459-bf621735d883,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-3d3b36d8-cef4-4d27-94a2-9fa0f38a3849,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-3c3856ef-a749-44e7-a284-ab298aa5ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-ca93adbe-e7a0-4086-90c2-46f1a73a6c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-15a1bf62-73f6-4400-9f1a-157482e0b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-e8426125-21cf-420a-a0a3-dfdf89306813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158468877-172.17.0.5-1596991646363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38404,DS-1df3ca98-2ee2-4107-9357-a730ac6408df,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-45cb3b42-40f4-4abc-85b4-e56f01f3aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-7a8ad220-8da8-415a-a459-bf621735d883,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-3d3b36d8-cef4-4d27-94a2-9fa0f38a3849,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-3c3856ef-a749-44e7-a284-ab298aa5ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-ca93adbe-e7a0-4086-90c2-46f1a73a6c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-15a1bf62-73f6-4400-9f1a-157482e0b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-e8426125-21cf-420a-a0a3-dfdf89306813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019669790-172.17.0.5-1596991696497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39297,DS-013ca982-9f1b-4ec2-97ca-d62c2da18022,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-73ec5816-f91e-43ce-8945-96db545f4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-eb6550d7-6086-40a2-91c7-e9e4f20c9f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-7313244e-1da4-4847-93ad-6ae2fff055c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-6287bbbc-1ed2-400c-801d-17aacb366e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a46dd759-f1fe-4523-9ccf-883f307224a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-289cf6cc-0139-4e9a-8983-9abe2fd91246,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c13ad713-a9ea-4918-a807-150e63a206d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019669790-172.17.0.5-1596991696497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39297,DS-013ca982-9f1b-4ec2-97ca-d62c2da18022,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-73ec5816-f91e-43ce-8945-96db545f4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-eb6550d7-6086-40a2-91c7-e9e4f20c9f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-7313244e-1da4-4847-93ad-6ae2fff055c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-6287bbbc-1ed2-400c-801d-17aacb366e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a46dd759-f1fe-4523-9ccf-883f307224a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-289cf6cc-0139-4e9a-8983-9abe2fd91246,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c13ad713-a9ea-4918-a807-150e63a206d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386158990-172.17.0.5-1596991813894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-1b71d1e5-fc09-43bb-96d7-54ec616a6392,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-1eae3789-4f23-460c-a615-a77ff824f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-1ea37ffb-1a0d-40ba-a65d-a87eabe290b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-10c3f125-dbee-4180-93d4-a56b3bd788bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-13357155-3124-4766-ba87-4c077251ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-5d49ab97-1bdf-4b7d-876f-bbd7c41b5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-3455c4ef-c42d-486c-bdca-bd3311485451,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-9ed6c573-5030-45b5-9710-61d77a1488f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386158990-172.17.0.5-1596991813894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-1b71d1e5-fc09-43bb-96d7-54ec616a6392,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-1eae3789-4f23-460c-a615-a77ff824f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-1ea37ffb-1a0d-40ba-a65d-a87eabe290b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-10c3f125-dbee-4180-93d4-a56b3bd788bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-13357155-3124-4766-ba87-4c077251ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-5d49ab97-1bdf-4b7d-876f-bbd7c41b5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-3455c4ef-c42d-486c-bdca-bd3311485451,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-9ed6c573-5030-45b5-9710-61d77a1488f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342486342-172.17.0.5-1596991933657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-38f9f4e7-55ea-436d-830d-653bc86fe16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-aa9b5603-bd62-49d7-9fd1-5ccb84219381,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-766427bd-17ae-45b7-b7f8-794dda5bee85,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-162d361d-6854-40fa-910c-7ad66ac4903f,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-460ba359-230d-4585-8dc1-bd00e80b2223,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-b17a73cb-5ce2-409a-bf97-95d66c034f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-a809f980-a77b-44b9-ac42-1f35b52c78b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-1706b52a-cb30-4e5b-8ba5-1074a495f622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342486342-172.17.0.5-1596991933657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-38f9f4e7-55ea-436d-830d-653bc86fe16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-aa9b5603-bd62-49d7-9fd1-5ccb84219381,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-766427bd-17ae-45b7-b7f8-794dda5bee85,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-162d361d-6854-40fa-910c-7ad66ac4903f,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-460ba359-230d-4585-8dc1-bd00e80b2223,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-b17a73cb-5ce2-409a-bf97-95d66c034f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-a809f980-a77b-44b9-ac42-1f35b52c78b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-1706b52a-cb30-4e5b-8ba5-1074a495f622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820421906-172.17.0.5-1596992017311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33751,DS-6f2e7fd1-efad-4e13-ac10-7e280452c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-d5fe3a3a-25e2-45a5-9a13-ba6c2172c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-e8528d17-8ba3-4886-8916-65e3931017ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-d9594704-b518-4596-b9e3-e1809ff8c885,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-bbd828d1-7869-4931-b6d0-eded4ee793ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-2d825b82-4625-43f0-92c4-e1b1dee93def,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-847ef6de-26eb-4a14-a79d-96c44177be56,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-b1ca2e15-9187-46fb-8b8d-cead600386d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820421906-172.17.0.5-1596992017311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33751,DS-6f2e7fd1-efad-4e13-ac10-7e280452c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-d5fe3a3a-25e2-45a5-9a13-ba6c2172c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-e8528d17-8ba3-4886-8916-65e3931017ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-d9594704-b518-4596-b9e3-e1809ff8c885,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-bbd828d1-7869-4931-b6d0-eded4ee793ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-2d825b82-4625-43f0-92c4-e1b1dee93def,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-847ef6de-26eb-4a14-a79d-96c44177be56,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-b1ca2e15-9187-46fb-8b8d-cead600386d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 2690
