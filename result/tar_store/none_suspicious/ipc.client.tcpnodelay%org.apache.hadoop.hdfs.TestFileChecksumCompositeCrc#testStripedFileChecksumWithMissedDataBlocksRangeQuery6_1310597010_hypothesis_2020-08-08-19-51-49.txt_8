reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739828227-172.17.0.4-1596916483852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-8d49dc20-7d1c-481c-9148-d003b39f8c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-4f284aa6-6d73-4c39-9f7a-bf71b34ef374,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-0b2c4a55-68d0-42ec-a998-298f4da20d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-eee35663-38e6-4164-8908-60a6dadf536f,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-6f64a77d-f5ae-48f5-b9c9-14696e563d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-801583f9-9eb0-4846-9e22-141c2ea98e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-27504afc-e51f-47bf-b665-ba6bca2eea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-6a764b60-208d-4367-94b1-10fc8ec8fdc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739828227-172.17.0.4-1596916483852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-8d49dc20-7d1c-481c-9148-d003b39f8c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-4f284aa6-6d73-4c39-9f7a-bf71b34ef374,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-0b2c4a55-68d0-42ec-a998-298f4da20d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-eee35663-38e6-4164-8908-60a6dadf536f,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-6f64a77d-f5ae-48f5-b9c9-14696e563d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-801583f9-9eb0-4846-9e22-141c2ea98e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-27504afc-e51f-47bf-b665-ba6bca2eea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-6a764b60-208d-4367-94b1-10fc8ec8fdc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770608248-172.17.0.4-1596916519568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-64451eec-ecf6-4fc2-8180-f3d2f6b56b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-d1d7ef33-a34a-4d9e-bc7d-4ab977e30cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-5302a8cd-20dd-4b25-a89e-3d9478b9383a,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-e18f2361-191e-49bc-9187-1b5321a9b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-cc21e53c-f243-4e30-be87-20c09467ff22,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-2ce6c01e-f1e5-46ba-9637-64d97be7e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-96d0fb70-4ff6-4095-a6ef-9882e7221b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-045b8c4d-def5-4eea-ae30-c8701d397d83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770608248-172.17.0.4-1596916519568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-64451eec-ecf6-4fc2-8180-f3d2f6b56b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-d1d7ef33-a34a-4d9e-bc7d-4ab977e30cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-5302a8cd-20dd-4b25-a89e-3d9478b9383a,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-e18f2361-191e-49bc-9187-1b5321a9b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-cc21e53c-f243-4e30-be87-20c09467ff22,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-2ce6c01e-f1e5-46ba-9637-64d97be7e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-96d0fb70-4ff6-4095-a6ef-9882e7221b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-045b8c4d-def5-4eea-ae30-c8701d397d83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66032842-172.17.0.4-1596916689636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-068c88fc-a36c-4d04-b51e-c4bef564e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-eeaf142a-f7f1-4a67-9810-2faf1b109433,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-1be49e70-73b1-4c0c-99cb-d380dfd97d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-947d36c5-c4d7-4e15-b33f-97f68b0ce89e,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-23584f91-9d8d-4409-9633-cd16d9605281,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-4c552f85-b41f-4699-9069-3cf32824828f,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-9244472f-0854-4dde-a937-aca292d9bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-471fb7fb-2158-43a3-90d1-566351362749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66032842-172.17.0.4-1596916689636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-068c88fc-a36c-4d04-b51e-c4bef564e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-eeaf142a-f7f1-4a67-9810-2faf1b109433,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-1be49e70-73b1-4c0c-99cb-d380dfd97d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-947d36c5-c4d7-4e15-b33f-97f68b0ce89e,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-23584f91-9d8d-4409-9633-cd16d9605281,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-4c552f85-b41f-4699-9069-3cf32824828f,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-9244472f-0854-4dde-a937-aca292d9bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-471fb7fb-2158-43a3-90d1-566351362749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693329532-172.17.0.4-1596916762910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-44215d98-2aee-443d-a6a7-c3def9485516,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-16f9f947-685c-4a96-9f05-12b9613c53ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-6f8b15dc-a26a-48f7-8775-fc23bc1c5ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-3365e7ca-8bbd-4ac4-afd0-7aae204a92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-b5fb2f16-eaf2-4b54-8c09-caa1af85c295,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-ae768748-9605-442a-9b7a-8da47c7cb949,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-96b6e85b-4673-4abc-b282-3099964c24f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-6d5f95c5-7bbc-4a35-be88-16f82b4e26a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693329532-172.17.0.4-1596916762910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-44215d98-2aee-443d-a6a7-c3def9485516,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-16f9f947-685c-4a96-9f05-12b9613c53ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-6f8b15dc-a26a-48f7-8775-fc23bc1c5ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-3365e7ca-8bbd-4ac4-afd0-7aae204a92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-b5fb2f16-eaf2-4b54-8c09-caa1af85c295,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-ae768748-9605-442a-9b7a-8da47c7cb949,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-96b6e85b-4673-4abc-b282-3099964c24f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-6d5f95c5-7bbc-4a35-be88-16f82b4e26a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714643089-172.17.0.4-1596916984811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40806,DS-57acefef-b483-43b3-9563-1008766cc9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7e0ea243-b384-460f-98b3-0aaccf301e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-6fc16ee5-9251-4dd8-9125-83b43ecc36f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-15d4f8fe-8b61-45a2-b0b1-2c88d99ba70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-6a9aa1f2-c7e6-4443-92f0-de158d19b1db,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-1107a68a-046c-4cbf-8c6c-0187c31439bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-98424ddd-57c4-43e2-a641-be48ac74d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-ab6ca361-9ae2-448c-90ef-5243683f33c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714643089-172.17.0.4-1596916984811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40806,DS-57acefef-b483-43b3-9563-1008766cc9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7e0ea243-b384-460f-98b3-0aaccf301e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-6fc16ee5-9251-4dd8-9125-83b43ecc36f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-15d4f8fe-8b61-45a2-b0b1-2c88d99ba70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-6a9aa1f2-c7e6-4443-92f0-de158d19b1db,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-1107a68a-046c-4cbf-8c6c-0187c31439bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-98424ddd-57c4-43e2-a641-be48ac74d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-ab6ca361-9ae2-448c-90ef-5243683f33c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171666610-172.17.0.4-1596917025617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-adfa420e-d915-4714-8942-018d96c4ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-29e3463a-4f07-475d-a79a-3a7b84b17c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-1c4e384d-f1d2-447b-9813-2c1bc36523a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-3ce27420-0bcb-4b9c-aae5-4774cb256581,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-0a1f4343-d625-4c5e-acc4-0c3749c5f3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-099b7fad-f7ca-4258-831c-47806bd94309,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-80239bcb-ff4a-4a41-969c-dc515ad01694,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-16fcb98b-62d6-4b5c-be3d-97db19cee66e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171666610-172.17.0.4-1596917025617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-adfa420e-d915-4714-8942-018d96c4ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-29e3463a-4f07-475d-a79a-3a7b84b17c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-1c4e384d-f1d2-447b-9813-2c1bc36523a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-3ce27420-0bcb-4b9c-aae5-4774cb256581,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-0a1f4343-d625-4c5e-acc4-0c3749c5f3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-099b7fad-f7ca-4258-831c-47806bd94309,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-80239bcb-ff4a-4a41-969c-dc515ad01694,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-16fcb98b-62d6-4b5c-be3d-97db19cee66e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418740356-172.17.0.4-1596917109601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-cdb46b17-e55c-4097-b635-0e619f3a3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-5ce754c7-3b1e-4462-a5a4-d5d8a01f2650,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-d673cc42-8795-4c5f-82d4-1e1192829b29,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-75df0d62-68fd-43a7-859b-af244f7ffe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-9bafa68e-ea57-4a01-97d6-73c630a9cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-bec67914-9e76-4b3d-bbad-25fba2f39f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-8e5dcef3-6bc1-4708-a8b8-25199c920bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b0fcf85b-a0c3-4b53-a074-c285748546b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418740356-172.17.0.4-1596917109601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-cdb46b17-e55c-4097-b635-0e619f3a3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-5ce754c7-3b1e-4462-a5a4-d5d8a01f2650,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-d673cc42-8795-4c5f-82d4-1e1192829b29,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-75df0d62-68fd-43a7-859b-af244f7ffe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-9bafa68e-ea57-4a01-97d6-73c630a9cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-bec67914-9e76-4b3d-bbad-25fba2f39f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-8e5dcef3-6bc1-4708-a8b8-25199c920bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b0fcf85b-a0c3-4b53-a074-c285748546b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402659462-172.17.0.4-1596917149348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-966eef30-62b9-402a-a3b6-330675709fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-f191c070-1356-4bed-b412-276efa4dc4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-60e14a3c-2182-4be6-993e-411505a07fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-68465fb4-9c57-4aa6-98c3-8d0cfd7e1afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-3899ede0-7841-4e14-b3a0-efb709860f80,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-77e4a9c6-bf77-4cf5-b2ad-ba2ac8d93fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-5119b4e3-17cd-4af4-b13b-8283c191d310,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-003636ea-83a7-4edc-8c64-e7de9c9654ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402659462-172.17.0.4-1596917149348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-966eef30-62b9-402a-a3b6-330675709fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-f191c070-1356-4bed-b412-276efa4dc4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-60e14a3c-2182-4be6-993e-411505a07fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-68465fb4-9c57-4aa6-98c3-8d0cfd7e1afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-3899ede0-7841-4e14-b3a0-efb709860f80,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-77e4a9c6-bf77-4cf5-b2ad-ba2ac8d93fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-5119b4e3-17cd-4af4-b13b-8283c191d310,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-003636ea-83a7-4edc-8c64-e7de9c9654ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552998011-172.17.0.4-1596917181493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-2b00b741-685d-4d3f-80c3-15cca7a4adb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-dd777476-613d-479c-aa72-4ed0c4fcb8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-31eb794b-f937-4172-a8b5-885f24490f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0f9bf0b0-222e-48ca-bc3f-a5f62604dc04,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-9390bd78-6394-429f-b5fc-c96424b43838,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-349b4439-5a3e-4c42-9a75-5c565b17f913,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f2a720b8-b126-4eea-bf68-fef59fa6aa89,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-8a95d14d-4ab8-474b-8772-e7690c3afa18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552998011-172.17.0.4-1596917181493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-2b00b741-685d-4d3f-80c3-15cca7a4adb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-dd777476-613d-479c-aa72-4ed0c4fcb8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-31eb794b-f937-4172-a8b5-885f24490f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0f9bf0b0-222e-48ca-bc3f-a5f62604dc04,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-9390bd78-6394-429f-b5fc-c96424b43838,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-349b4439-5a3e-4c42-9a75-5c565b17f913,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f2a720b8-b126-4eea-bf68-fef59fa6aa89,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-8a95d14d-4ab8-474b-8772-e7690c3afa18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850575589-172.17.0.4-1596917343148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42934,DS-01bce218-4f13-45a3-81de-ba0a7ed7d817,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-15c1e650-f7f8-4561-8ea5-e5eda435edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-8e252e03-e7d7-42ef-8d8e-7abdb5f57300,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-cf268842-bdcf-4fc8-a402-25f14ebdae59,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-17bcb6e0-36da-4662-853e-d150526662fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-9bc86a85-f39b-49e3-b91b-7a9dcdbc831b,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-56c953c7-95d1-4ddc-8b6c-a8dbf899deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-171a608e-81a3-4e94-b5b7-1775e6ad950f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850575589-172.17.0.4-1596917343148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42934,DS-01bce218-4f13-45a3-81de-ba0a7ed7d817,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-15c1e650-f7f8-4561-8ea5-e5eda435edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-8e252e03-e7d7-42ef-8d8e-7abdb5f57300,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-cf268842-bdcf-4fc8-a402-25f14ebdae59,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-17bcb6e0-36da-4662-853e-d150526662fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-9bc86a85-f39b-49e3-b91b-7a9dcdbc831b,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-56c953c7-95d1-4ddc-8b6c-a8dbf899deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-171a608e-81a3-4e94-b5b7-1775e6ad950f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130745207-172.17.0.4-1596917562688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-3f02f748-cdf5-4afb-a2ce-d3796ec3bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-739dac41-cdd5-4228-b026-0cb61b5e9565,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-b0d4ff1b-fdee-4fe0-a132-eba392e9d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-bff2e94b-be74-4d1f-90b8-1aa5a4111908,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-d87e238c-625c-4ab3-add2-3da990e2e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-b638df60-7959-44dd-8def-ba214f18a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-b00659da-6eb8-4424-a394-3bdab7edd882,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-4b32242b-b261-47cc-a783-0ccc4fa3e930,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130745207-172.17.0.4-1596917562688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-3f02f748-cdf5-4afb-a2ce-d3796ec3bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-739dac41-cdd5-4228-b026-0cb61b5e9565,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-b0d4ff1b-fdee-4fe0-a132-eba392e9d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-bff2e94b-be74-4d1f-90b8-1aa5a4111908,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-d87e238c-625c-4ab3-add2-3da990e2e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-b638df60-7959-44dd-8def-ba214f18a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-b00659da-6eb8-4424-a394-3bdab7edd882,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-4b32242b-b261-47cc-a783-0ccc4fa3e930,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272816467-172.17.0.4-1596917607454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-cea31fd2-2029-48a8-a2f4-4d948168aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-c4d9484b-8a14-471c-b67b-111b0b5d7be7,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-2787ea2e-9408-4f2c-adf9-2c58b5add8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-c8ae584d-609d-465e-a555-4f9f24185a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-4c548e4e-f7d1-4d6a-bb8b-9014b93f18bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-b61baf70-4115-467f-90b6-f4689d4b5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-6a22b389-7c41-4e1b-984c-dca1925db009,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-b0cccf29-f3be-49f1-bce2-060b4e99cd05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272816467-172.17.0.4-1596917607454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-cea31fd2-2029-48a8-a2f4-4d948168aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-c4d9484b-8a14-471c-b67b-111b0b5d7be7,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-2787ea2e-9408-4f2c-adf9-2c58b5add8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-c8ae584d-609d-465e-a555-4f9f24185a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-4c548e4e-f7d1-4d6a-bb8b-9014b93f18bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-b61baf70-4115-467f-90b6-f4689d4b5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-6a22b389-7c41-4e1b-984c-dca1925db009,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-b0cccf29-f3be-49f1-bce2-060b4e99cd05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356100052-172.17.0.4-1596917646712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-0d427915-0081-4f08-abdb-cbfdee391bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-bcf3dea7-0d33-4d86-a5c3-f54c9045ab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ed313646-b26e-4afd-a58f-0ccf5822289a,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-735eb168-9527-4ebb-9230-79ca8e845113,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-2e6dad00-d58e-4de4-a282-7a6b370113d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-910254f1-f309-4169-b958-c947c39693a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-d29238fc-2d66-45fc-8ddc-3684da7ec11f,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-15dcf398-2d24-4dc9-aec9-3eb37afe347f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356100052-172.17.0.4-1596917646712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-0d427915-0081-4f08-abdb-cbfdee391bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-bcf3dea7-0d33-4d86-a5c3-f54c9045ab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ed313646-b26e-4afd-a58f-0ccf5822289a,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-735eb168-9527-4ebb-9230-79ca8e845113,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-2e6dad00-d58e-4de4-a282-7a6b370113d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-910254f1-f309-4169-b958-c947c39693a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-d29238fc-2d66-45fc-8ddc-3684da7ec11f,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-15dcf398-2d24-4dc9-aec9-3eb37afe347f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758435334-172.17.0.4-1596917687683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-a34126dd-f10a-4d57-948c-2ab7bc01bfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-e812da5e-c579-45c9-af2b-0f430c7134e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-4d39cef5-216e-4ac5-a7d9-383326b28e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-60463b33-ef9a-4f39-b925-0b9dfd8b22c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-d904fe9a-e040-44e9-b98d-aa038f079392,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-5a83e97b-b71e-4554-9372-37c8aefafb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-e8f2d8a6-7ec9-4ca1-9219-efcae9828f27,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-15eeeba0-e206-4870-9502-a7b57d063c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758435334-172.17.0.4-1596917687683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-a34126dd-f10a-4d57-948c-2ab7bc01bfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-e812da5e-c579-45c9-af2b-0f430c7134e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-4d39cef5-216e-4ac5-a7d9-383326b28e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-60463b33-ef9a-4f39-b925-0b9dfd8b22c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-d904fe9a-e040-44e9-b98d-aa038f079392,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-5a83e97b-b71e-4554-9372-37c8aefafb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-e8f2d8a6-7ec9-4ca1-9219-efcae9828f27,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-15eeeba0-e206-4870-9502-a7b57d063c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133837769-172.17.0.4-1596917833962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-bcc9ef48-8efc-4a4a-b595-b2d0e1b8bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-e4e3e8eb-032c-485c-a5ae-a44cf52fe95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-21e6370e-62d7-4d85-9f5f-cb876d15bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-ed7bf225-005b-49cd-a5f4-34d5197d1930,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-101e54f4-6ba0-435e-bbed-e804ae125788,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-ecdaaa4d-7c58-4217-ba5a-39b78f66b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-f1ac2d70-fff7-4c35-9e89-46a51db087e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-fe868c3a-6439-432d-a81a-63d5a3466e17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133837769-172.17.0.4-1596917833962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-bcc9ef48-8efc-4a4a-b595-b2d0e1b8bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-e4e3e8eb-032c-485c-a5ae-a44cf52fe95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-21e6370e-62d7-4d85-9f5f-cb876d15bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-ed7bf225-005b-49cd-a5f4-34d5197d1930,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-101e54f4-6ba0-435e-bbed-e804ae125788,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-ecdaaa4d-7c58-4217-ba5a-39b78f66b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-f1ac2d70-fff7-4c35-9e89-46a51db087e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-fe868c3a-6439-432d-a81a-63d5a3466e17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578921766-172.17.0.4-1596917876357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36080,DS-61006051-8f4b-4793-ae4d-d9ee9d276ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-38fe2870-c1ea-492b-8cda-e1a7414415dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-5e507e5e-2ff3-4028-a20b-66b44037c387,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-c157ddcb-7d46-424c-8215-ad808e3962d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-9f74c8a5-e405-48ad-8b72-2b325ae7b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-cd654e3c-3724-413f-925f-c67d9848fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-8ccc9294-c937-4a6d-a926-53958a9f7228,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-46a39dac-06e6-48c7-8e08-f1e3b7099a95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578921766-172.17.0.4-1596917876357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36080,DS-61006051-8f4b-4793-ae4d-d9ee9d276ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-38fe2870-c1ea-492b-8cda-e1a7414415dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-5e507e5e-2ff3-4028-a20b-66b44037c387,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-c157ddcb-7d46-424c-8215-ad808e3962d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-9f74c8a5-e405-48ad-8b72-2b325ae7b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-cd654e3c-3724-413f-925f-c67d9848fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-8ccc9294-c937-4a6d-a926-53958a9f7228,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-46a39dac-06e6-48c7-8e08-f1e3b7099a95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69559526-172.17.0.4-1596917912136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38905,DS-fd0e8207-cc0c-4b34-a07f-bb0f11a95ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-512c7375-590f-4a5c-8971-43003802976d,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-d6ab8d5e-c7e7-4724-bf62-a4a3b9c8d936,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-a5e0a415-f768-46ce-987a-0fcab961c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-bbfe58e2-169d-4553-9875-ce24ae66fabc,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-b4510aa6-6eca-40b0-ae6f-9061d844ead6,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-6f535880-e981-4787-9eab-a8f3b37a304e,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-2ee9bfad-2876-4e35-9c04-cee308b7128e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69559526-172.17.0.4-1596917912136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38905,DS-fd0e8207-cc0c-4b34-a07f-bb0f11a95ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-512c7375-590f-4a5c-8971-43003802976d,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-d6ab8d5e-c7e7-4724-bf62-a4a3b9c8d936,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-a5e0a415-f768-46ce-987a-0fcab961c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-bbfe58e2-169d-4553-9875-ce24ae66fabc,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-b4510aa6-6eca-40b0-ae6f-9061d844ead6,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-6f535880-e981-4787-9eab-a8f3b37a304e,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-2ee9bfad-2876-4e35-9c04-cee308b7128e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688785699-172.17.0.4-1596918119709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-55ce76b4-398e-4dbc-a933-e94dd9530055,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-1a01e4af-a586-47a6-849e-187f0c7b30a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-48d4322b-79e2-4c83-8e19-df7d6580d93d,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-0b4875b3-16b8-45fc-b6a9-87438a269586,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-ef757a80-af6f-434e-b318-77c19bf93746,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-9af26232-8f4c-4d69-baf9-b098c2a0a769,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-61ba6cff-f17a-4e13-bcdf-305c5dff4903,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-eec8ec9a-2d5e-4361-9c6e-c95c6072cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688785699-172.17.0.4-1596918119709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-55ce76b4-398e-4dbc-a933-e94dd9530055,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-1a01e4af-a586-47a6-849e-187f0c7b30a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-48d4322b-79e2-4c83-8e19-df7d6580d93d,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-0b4875b3-16b8-45fc-b6a9-87438a269586,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-ef757a80-af6f-434e-b318-77c19bf93746,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-9af26232-8f4c-4d69-baf9-b098c2a0a769,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-61ba6cff-f17a-4e13-bcdf-305c5dff4903,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-eec8ec9a-2d5e-4361-9c6e-c95c6072cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871166662-172.17.0.4-1596918496319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34518,DS-63f942f2-d956-4add-83a7-de9b270101fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-9cdb62fd-fab6-4086-84b5-38f215f2348b,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-bd304364-5984-48de-bd86-49dd727961b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-dd343433-e2e7-40df-b907-2e9dadeff71c,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-5dc94fbe-739b-4576-aa5c-c273736ef5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-5bd84d3b-636d-4b5a-afc1-b25b9be3b33d,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-a6d02146-ce3d-4e96-92f2-583359c44068,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-45b40b18-bb98-48a3-9ded-f7ba52ef603c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871166662-172.17.0.4-1596918496319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34518,DS-63f942f2-d956-4add-83a7-de9b270101fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-9cdb62fd-fab6-4086-84b5-38f215f2348b,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-bd304364-5984-48de-bd86-49dd727961b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-dd343433-e2e7-40df-b907-2e9dadeff71c,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-5dc94fbe-739b-4576-aa5c-c273736ef5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-5bd84d3b-636d-4b5a-afc1-b25b9be3b33d,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-a6d02146-ce3d-4e96-92f2-583359c44068,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-45b40b18-bb98-48a3-9ded-f7ba52ef603c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266423774-172.17.0.4-1596918756577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39877,DS-5bc13e69-7d02-498a-9bcb-f3740fe15ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-1a6e706a-2436-46e8-99e8-57a29ca93adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-09c5e46f-3bda-4aa2-b516-842c9eabe027,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-2f73c7ba-e9f7-4797-8980-5e56aff799cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-03bb5989-c9ca-4a8b-beae-1515b07ae97b,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-f6a9901e-72c1-455d-b66b-040331a632ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-8b1ec2eb-116b-4eea-946d-7625b4679ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-62e539bf-8a88-4054-895c-a132a6693b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266423774-172.17.0.4-1596918756577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39877,DS-5bc13e69-7d02-498a-9bcb-f3740fe15ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-1a6e706a-2436-46e8-99e8-57a29ca93adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-09c5e46f-3bda-4aa2-b516-842c9eabe027,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-2f73c7ba-e9f7-4797-8980-5e56aff799cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-03bb5989-c9ca-4a8b-beae-1515b07ae97b,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-f6a9901e-72c1-455d-b66b-040331a632ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-8b1ec2eb-116b-4eea-946d-7625b4679ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-62e539bf-8a88-4054-895c-a132a6693b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564219252-172.17.0.4-1596919037620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35052,DS-28d1564d-3008-4290-8c8e-1d2a762b0855,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-e1e8d107-7177-439b-8067-aa1842decc13,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-f3cecce9-7e8d-4c0a-a258-6e2fa8565fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-7b8253b3-5daa-4027-88db-0e9fb0c595e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-367cd531-712c-44bd-9ac6-18e6137b2e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-163abec9-5a97-4667-8368-10fa51c29126,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-8b2b2489-89b0-4f2c-a175-9b058a051f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-21bdc62a-8892-4426-9878-69171ac23130,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564219252-172.17.0.4-1596919037620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35052,DS-28d1564d-3008-4290-8c8e-1d2a762b0855,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-e1e8d107-7177-439b-8067-aa1842decc13,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-f3cecce9-7e8d-4c0a-a258-6e2fa8565fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-7b8253b3-5daa-4027-88db-0e9fb0c595e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-367cd531-712c-44bd-9ac6-18e6137b2e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-163abec9-5a97-4667-8368-10fa51c29126,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-8b2b2489-89b0-4f2c-a175-9b058a051f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-21bdc62a-8892-4426-9878-69171ac23130,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232560507-172.17.0.4-1596919312921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-c15d8f0f-08e9-429d-a1bd-78046f80de02,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-0f43cc41-5807-4263-b5ab-5240d2203854,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-531a86f2-3183-4200-b6fd-a0fadeca01ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-8862f45f-3b86-4c0b-bf65-4e4154c92b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-3b510be2-3d8b-45af-b684-32ff1ef39d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-f2a4bd22-6e28-4cd3-b090-be66d0ee0ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-719cd3b0-3142-4cbf-90f4-f1ae7752f458,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-fe9ec166-1da9-4159-b920-cc93aa9e88a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232560507-172.17.0.4-1596919312921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-c15d8f0f-08e9-429d-a1bd-78046f80de02,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-0f43cc41-5807-4263-b5ab-5240d2203854,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-531a86f2-3183-4200-b6fd-a0fadeca01ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-8862f45f-3b86-4c0b-bf65-4e4154c92b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-3b510be2-3d8b-45af-b684-32ff1ef39d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-f2a4bd22-6e28-4cd3-b090-be66d0ee0ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-719cd3b0-3142-4cbf-90f4-f1ae7752f458,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-fe9ec166-1da9-4159-b920-cc93aa9e88a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393465640-172.17.0.4-1596919394258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-3b5aa81d-2ced-424b-a5ee-e574cdf33fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-2defcc52-0795-43ac-bf92-3026eab96e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-57170221-451b-4c40-820f-e3020e1aab8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-65483bda-9068-4eb2-8d1b-4880d18d23d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-998296fa-d659-431a-9a13-1312f1d5326b,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-b591ba4f-bde0-41dc-8919-79dd92100750,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-a5dc4c29-0f4a-4cda-bb8b-35ee6733e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-007b95b3-466c-4ac1-b5c7-ffd2d3bc3fd1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393465640-172.17.0.4-1596919394258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-3b5aa81d-2ced-424b-a5ee-e574cdf33fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-2defcc52-0795-43ac-bf92-3026eab96e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-57170221-451b-4c40-820f-e3020e1aab8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-65483bda-9068-4eb2-8d1b-4880d18d23d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-998296fa-d659-431a-9a13-1312f1d5326b,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-b591ba4f-bde0-41dc-8919-79dd92100750,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-a5dc4c29-0f4a-4cda-bb8b-35ee6733e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-007b95b3-466c-4ac1-b5c7-ffd2d3bc3fd1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019695843-172.17.0.4-1596919504741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-3660b273-9cfc-4cae-8e8e-d55e06932bed,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-bd72e1f9-f85f-441c-893b-c8a14e1fbf91,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-2c87063e-31cc-48b0-a2a7-4cf7a51fa02c,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-7a7b61bb-b390-4003-97bd-e5fcfa6f4745,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-80c7cd3a-a9ae-4e85-bc77-7009da0f030f,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-b204243c-28f0-4b9c-941a-a5bead99891b,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-a118898c-598a-4e5a-a990-1a950dc24a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-d9fbf92a-d3d8-4780-ab8d-a12a2db63691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019695843-172.17.0.4-1596919504741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-3660b273-9cfc-4cae-8e8e-d55e06932bed,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-bd72e1f9-f85f-441c-893b-c8a14e1fbf91,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-2c87063e-31cc-48b0-a2a7-4cf7a51fa02c,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-7a7b61bb-b390-4003-97bd-e5fcfa6f4745,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-80c7cd3a-a9ae-4e85-bc77-7009da0f030f,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-b204243c-28f0-4b9c-941a-a5bead99891b,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-a118898c-598a-4e5a-a990-1a950dc24a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-d9fbf92a-d3d8-4780-ab8d-a12a2db63691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24814288-172.17.0.4-1596919617962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-1bce1f60-bafa-4f4d-94fe-210d0fa47bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-9991f761-eda6-4687-8a8d-899d18f6b344,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-af8d1351-5ed0-489c-8d56-17f8f5c00ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-55eda4a5-6ef2-41fb-acc8-4554cf8ce781,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-2110bba7-0188-4c54-bffe-d354a1f50622,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-c6eccc58-51b4-4a0b-84dd-de3170e7993e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-3ca9cd96-eabc-4fb3-b9f6-916f9afd900b,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-dac48b8c-3307-4e25-98d4-a2705391f2f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24814288-172.17.0.4-1596919617962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-1bce1f60-bafa-4f4d-94fe-210d0fa47bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-9991f761-eda6-4687-8a8d-899d18f6b344,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-af8d1351-5ed0-489c-8d56-17f8f5c00ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-55eda4a5-6ef2-41fb-acc8-4554cf8ce781,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-2110bba7-0188-4c54-bffe-d354a1f50622,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-c6eccc58-51b4-4a0b-84dd-de3170e7993e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-3ca9cd96-eabc-4fb3-b9f6-916f9afd900b,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-dac48b8c-3307-4e25-98d4-a2705391f2f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087665338-172.17.0.4-1596919873533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-6200251c-518e-4d99-b3f2-b2d5fe5e4063,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-448635a3-beec-4aff-a5ba-d3fe0a39f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-8e36ef64-ec94-474b-b90b-3d6c83d7e228,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-750bca90-0278-4680-81dd-405310b6371a,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-6fe077ba-396c-43b1-9de5-76cba1ce4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-923e18fb-f482-4e5c-8b51-e45d9ddecc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-e63e52d6-a2c0-45a9-93fe-3d4afd032fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-f707c86d-e443-48c4-9585-289d49305be8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087665338-172.17.0.4-1596919873533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-6200251c-518e-4d99-b3f2-b2d5fe5e4063,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-448635a3-beec-4aff-a5ba-d3fe0a39f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-8e36ef64-ec94-474b-b90b-3d6c83d7e228,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-750bca90-0278-4680-81dd-405310b6371a,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-6fe077ba-396c-43b1-9de5-76cba1ce4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-923e18fb-f482-4e5c-8b51-e45d9ddecc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-e63e52d6-a2c0-45a9-93fe-3d4afd032fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-f707c86d-e443-48c4-9585-289d49305be8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373146546-172.17.0.4-1596920073872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-979ee35e-11a6-4a57-8e37-e126c39ddfde,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-dc1479ff-9f99-4847-90c1-3cc9556c62dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-8956577c-7d41-4d97-b153-96cd5f142021,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-d7a5004a-2a08-42df-9950-8ff1f8108878,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-f8adaf81-9e16-4e17-b23e-4de4402800bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-be9b2f19-c32b-47a7-ab62-5a9ad4564046,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-efd6fb65-cff1-442d-a980-a66ecadaa3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-a9f72f7d-0a66-431a-a3af-35833d351f00,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373146546-172.17.0.4-1596920073872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-979ee35e-11a6-4a57-8e37-e126c39ddfde,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-dc1479ff-9f99-4847-90c1-3cc9556c62dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-8956577c-7d41-4d97-b153-96cd5f142021,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-d7a5004a-2a08-42df-9950-8ff1f8108878,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-f8adaf81-9e16-4e17-b23e-4de4402800bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-be9b2f19-c32b-47a7-ab62-5a9ad4564046,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-efd6fb65-cff1-442d-a980-a66ecadaa3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-a9f72f7d-0a66-431a-a3af-35833d351f00,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037942829-172.17.0.4-1596920254176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-7f789bec-d1e5-4a09-8d93-0ea5aaaf4346,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-6df644b1-6b9c-4044-961f-aca1d3921ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-f1bc6f1f-ff66-4c64-a3d2-8f0baed21caf,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-9a7ae535-12de-44d0-a3e7-7918c3c94853,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-c0406ec2-74ed-4a1f-95f0-364a8f6b2605,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-54858703-0ccb-4863-b2ee-e3acabb4469c,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-99a2a684-d538-4491-8b54-6b5d1a955287,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-618495d3-f002-4671-b76d-9a804ace3b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037942829-172.17.0.4-1596920254176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-7f789bec-d1e5-4a09-8d93-0ea5aaaf4346,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-6df644b1-6b9c-4044-961f-aca1d3921ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-f1bc6f1f-ff66-4c64-a3d2-8f0baed21caf,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-9a7ae535-12de-44d0-a3e7-7918c3c94853,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-c0406ec2-74ed-4a1f-95f0-364a8f6b2605,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-54858703-0ccb-4863-b2ee-e3acabb4469c,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-99a2a684-d538-4491-8b54-6b5d1a955287,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-618495d3-f002-4671-b76d-9a804ace3b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813662406-172.17.0.4-1596920291428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-fa830bab-7e87-4875-9b1f-20bc55b8033b,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-67c88a43-6d4c-4969-8d17-da57825e1b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-c81e3d42-bd7d-4814-9b8a-06b669582f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-12a6422d-dfbd-44cc-ace4-c65a70ec3c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-f495eb62-2200-4ba9-b7e8-95d2cb52aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-436751fe-80b6-45f0-876f-7cafd78c7ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-3f6a80f6-2e9e-45ac-b39b-6241c6b12842,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-fa228f7c-253a-4f27-85d7-43b08318a70c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813662406-172.17.0.4-1596920291428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-fa830bab-7e87-4875-9b1f-20bc55b8033b,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-67c88a43-6d4c-4969-8d17-da57825e1b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-c81e3d42-bd7d-4814-9b8a-06b669582f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-12a6422d-dfbd-44cc-ace4-c65a70ec3c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-f495eb62-2200-4ba9-b7e8-95d2cb52aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-436751fe-80b6-45f0-876f-7cafd78c7ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-3f6a80f6-2e9e-45ac-b39b-6241c6b12842,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-fa228f7c-253a-4f27-85d7-43b08318a70c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488405753-172.17.0.4-1596920773591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-a697891b-f2a1-4b57-8697-50a80a02405d,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-f2624250-4f6e-4e61-afaf-6181bb19ca94,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-6722f245-62f1-4353-b44e-36ad46282fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-390c4216-353c-4960-9a45-a5aebc62e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-007f1a61-2f8e-47d2-823b-ddc4b1a01dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-9e4cbde1-c130-4713-8e04-04c4239d7aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-4ddabc7b-ce21-49d7-8a9b-fab83160dbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-38b14b76-21d5-4ba8-9220-dd65b7b7372b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488405753-172.17.0.4-1596920773591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-a697891b-f2a1-4b57-8697-50a80a02405d,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-f2624250-4f6e-4e61-afaf-6181bb19ca94,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-6722f245-62f1-4353-b44e-36ad46282fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-390c4216-353c-4960-9a45-a5aebc62e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-007f1a61-2f8e-47d2-823b-ddc4b1a01dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-9e4cbde1-c130-4713-8e04-04c4239d7aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-4ddabc7b-ce21-49d7-8a9b-fab83160dbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-38b14b76-21d5-4ba8-9220-dd65b7b7372b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765155621-172.17.0.4-1596920908311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-0c36a440-3ebf-4873-9748-de62f344a536,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-85e0feed-51c8-4255-8bef-73c2b8181226,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-670cc3a6-95c5-4d5a-a6ae-32230e28d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-677d9ef6-f3be-45d1-a98d-f4eba5d7e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-693e140e-bd8d-4d36-8841-e80f7d08f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-72600406-79d5-4738-ac1b-c4691ca33876,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-d0cc4502-6662-47f4-8a06-f4502591bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-92ad69b9-d3a0-44cd-a8de-91a198ca6688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765155621-172.17.0.4-1596920908311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-0c36a440-3ebf-4873-9748-de62f344a536,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-85e0feed-51c8-4255-8bef-73c2b8181226,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-670cc3a6-95c5-4d5a-a6ae-32230e28d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-677d9ef6-f3be-45d1-a98d-f4eba5d7e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-693e140e-bd8d-4d36-8841-e80f7d08f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-72600406-79d5-4738-ac1b-c4691ca33876,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-d0cc4502-6662-47f4-8a06-f4502591bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-92ad69b9-d3a0-44cd-a8de-91a198ca6688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698618993-172.17.0.4-1596920942781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-9a94c71e-cbb3-440d-9a5c-a92c2f39bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-398137f1-49ca-4001-b6ae-e03c480674f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-b411d7bd-271e-407d-a0cc-41f4719de113,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-3d16dfae-602c-406c-b57c-7442377fd371,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-2d1c17e0-e921-4596-8191-9f2a2825ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-e9c8f660-db2f-4cd4-98a5-180b68a6cc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-53917a82-9b22-4ea9-8fc9-9aafcdad379e,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-bed33cc6-b136-4b4d-bb70-8a2c4920291d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698618993-172.17.0.4-1596920942781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-9a94c71e-cbb3-440d-9a5c-a92c2f39bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-398137f1-49ca-4001-b6ae-e03c480674f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-b411d7bd-271e-407d-a0cc-41f4719de113,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-3d16dfae-602c-406c-b57c-7442377fd371,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-2d1c17e0-e921-4596-8191-9f2a2825ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-e9c8f660-db2f-4cd4-98a5-180b68a6cc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-53917a82-9b22-4ea9-8fc9-9aafcdad379e,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-bed33cc6-b136-4b4d-bb70-8a2c4920291d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195587846-172.17.0.4-1596920984235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-115a8ac5-2cdd-479e-8cb2-fb2ae2dbe48e,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1b627cc1-cc56-43b5-9240-38d5e534ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-9f8cd38b-cb4e-44ac-8391-6e9d1f3caaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-14848d11-f7e7-4b1b-9178-628a889ff4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-b6db2d69-f5c9-4403-8de2-9ce2f17a8682,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-50f1abfc-0c11-4089-875e-7caadb1a51de,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-8864b3ed-04e3-4c0a-9596-b96ad018e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-31e55d4f-46ec-43c3-a9f2-ab4a47eb89c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195587846-172.17.0.4-1596920984235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-115a8ac5-2cdd-479e-8cb2-fb2ae2dbe48e,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1b627cc1-cc56-43b5-9240-38d5e534ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-9f8cd38b-cb4e-44ac-8391-6e9d1f3caaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-14848d11-f7e7-4b1b-9178-628a889ff4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-b6db2d69-f5c9-4403-8de2-9ce2f17a8682,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-50f1abfc-0c11-4089-875e-7caadb1a51de,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-8864b3ed-04e3-4c0a-9596-b96ad018e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-31e55d4f-46ec-43c3-a9f2-ab4a47eb89c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719835392-172.17.0.4-1596921093683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-c40663c3-ce98-4861-af62-ecc52f9086b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-912bd1c4-fc0e-4357-8bb3-b3e80f9bb72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-5b0cdf67-6035-41f5-a3b8-fa14bfe9fc68,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-1551e4e2-2803-48d6-a1af-9f96c4777236,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-eadae478-84d2-43d5-a8b0-67ceccb1b920,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-1a4bd10e-d8cd-4cd4-925a-53a3d99f19a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-1f4803e2-1a3a-44cd-ab1d-252d131f1ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-d1117c90-3cca-48d8-8347-1e18269e4634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719835392-172.17.0.4-1596921093683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-c40663c3-ce98-4861-af62-ecc52f9086b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-912bd1c4-fc0e-4357-8bb3-b3e80f9bb72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-5b0cdf67-6035-41f5-a3b8-fa14bfe9fc68,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-1551e4e2-2803-48d6-a1af-9f96c4777236,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-eadae478-84d2-43d5-a8b0-67ceccb1b920,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-1a4bd10e-d8cd-4cd4-925a-53a3d99f19a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-1f4803e2-1a3a-44cd-ab1d-252d131f1ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-d1117c90-3cca-48d8-8347-1e18269e4634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768253262-172.17.0.4-1596921200003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-d288008d-760f-4039-8ab5-20211b623a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-8b17f336-df97-427f-bdda-75ae7b10bf98,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-a350244c-1b00-4e7e-8da2-6a5ae2e57914,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-4a91f0c6-60df-465c-90b1-9f3d6974431d,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-6011e8bd-af38-43b1-b94a-7098aa8ba659,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-2250a9f1-9c02-4763-910c-9c7a3a6203bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-6ed61137-047f-4b68-a0a3-3f9ee15f17d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-3f1bc208-6c3f-4451-80d8-f900eca4a77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768253262-172.17.0.4-1596921200003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-d288008d-760f-4039-8ab5-20211b623a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-8b17f336-df97-427f-bdda-75ae7b10bf98,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-a350244c-1b00-4e7e-8da2-6a5ae2e57914,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-4a91f0c6-60df-465c-90b1-9f3d6974431d,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-6011e8bd-af38-43b1-b94a-7098aa8ba659,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-2250a9f1-9c02-4763-910c-9c7a3a6203bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-6ed61137-047f-4b68-a0a3-3f9ee15f17d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-3f1bc208-6c3f-4451-80d8-f900eca4a77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5471
