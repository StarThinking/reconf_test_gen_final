reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212068936-172.17.0.16-1596895585239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33200,DS-4800d120-cb59-4ca8-b004-517eed8eb109,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-c20c9d6c-fe6c-4862-b2f8-0f1f04861e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-c5c3cb65-aa40-4c93-990b-c5d0e6180617,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-b0c46067-7e89-40a2-8347-f5db2e39d67f,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-a3c2ac1b-ba86-4c3a-bb85-b2d11406e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b5513a9f-a1c0-4d2c-9acf-ad0fbfe0314a,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-52eee559-e8f7-4d8a-b900-5d518cce4415,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-bb45d1b2-44f5-4a22-9d55-72ce6667aa97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212068936-172.17.0.16-1596895585239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33200,DS-4800d120-cb59-4ca8-b004-517eed8eb109,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-c20c9d6c-fe6c-4862-b2f8-0f1f04861e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-c5c3cb65-aa40-4c93-990b-c5d0e6180617,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-b0c46067-7e89-40a2-8347-f5db2e39d67f,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-a3c2ac1b-ba86-4c3a-bb85-b2d11406e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b5513a9f-a1c0-4d2c-9acf-ad0fbfe0314a,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-52eee559-e8f7-4d8a-b900-5d518cce4415,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-bb45d1b2-44f5-4a22-9d55-72ce6667aa97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406783482-172.17.0.16-1596895804846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-edae59c1-0bbc-433d-8445-e27b17a878ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-19d1a32c-7c8f-4353-badc-64d52ae418fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-4279189d-fc79-4d3c-b5b3-f16c52b16451,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-60238a5e-f3a3-4132-ac75-13777cfe3e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-bb078784-3c57-475f-a438-b28c2ecbbb85,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-e76a9133-a85f-4a9b-b23b-3b1fa0395653,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-6a262016-9e00-4ec4-9af7-6168e62ee150,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-8857a0b2-1510-4dce-adc0-347fdeabfec4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406783482-172.17.0.16-1596895804846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-edae59c1-0bbc-433d-8445-e27b17a878ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-19d1a32c-7c8f-4353-badc-64d52ae418fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-4279189d-fc79-4d3c-b5b3-f16c52b16451,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-60238a5e-f3a3-4132-ac75-13777cfe3e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-bb078784-3c57-475f-a438-b28c2ecbbb85,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-e76a9133-a85f-4a9b-b23b-3b1fa0395653,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-6a262016-9e00-4ec4-9af7-6168e62ee150,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-8857a0b2-1510-4dce-adc0-347fdeabfec4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838606634-172.17.0.16-1596896019395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-b1893631-d2cf-492c-8fa0-13950f22f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-cb2eb68b-5447-4f1f-ac34-976b31492b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-2971bc11-cde9-4e2b-ad6c-65d5460dd2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-460666ec-c80f-4cae-93b1-1a7233806de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-0e5e00ba-1d74-4214-9708-bb4a99a72927,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-1938300a-e38a-43e0-a852-15812d638c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-6b2e3509-57f2-4ff7-88f9-f1fcf4b9f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-7c5e4048-510a-4ecc-8615-932e93dc0c31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838606634-172.17.0.16-1596896019395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-b1893631-d2cf-492c-8fa0-13950f22f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-cb2eb68b-5447-4f1f-ac34-976b31492b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-2971bc11-cde9-4e2b-ad6c-65d5460dd2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-460666ec-c80f-4cae-93b1-1a7233806de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-0e5e00ba-1d74-4214-9708-bb4a99a72927,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-1938300a-e38a-43e0-a852-15812d638c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-6b2e3509-57f2-4ff7-88f9-f1fcf4b9f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-7c5e4048-510a-4ecc-8615-932e93dc0c31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840568970-172.17.0.16-1596896093144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42530,DS-f108a3fc-22f9-4eed-9129-4a21c8744f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-c839c768-5626-455a-9360-4eb6b5db4be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-a32a0955-df54-48d5-a72d-5e9f3045fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-bc38615f-1519-403e-90d2-45f72dd1e1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-45da79df-91c6-4a12-adc4-37a5bcdceb36,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-9b30ea36-152a-482a-b009-4c4808dd44aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-11be4178-8c14-4e94-82d2-be036103b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-2a2a8313-01b8-47a2-a1ea-6a1f630a3997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840568970-172.17.0.16-1596896093144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42530,DS-f108a3fc-22f9-4eed-9129-4a21c8744f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-c839c768-5626-455a-9360-4eb6b5db4be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-a32a0955-df54-48d5-a72d-5e9f3045fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-bc38615f-1519-403e-90d2-45f72dd1e1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-45da79df-91c6-4a12-adc4-37a5bcdceb36,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-9b30ea36-152a-482a-b009-4c4808dd44aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-11be4178-8c14-4e94-82d2-be036103b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-2a2a8313-01b8-47a2-a1ea-6a1f630a3997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017355806-172.17.0.16-1596896134385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-4f27655b-c20e-4e7c-a0f3-50ae5ddcf3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-dd826cfc-21e3-4cd1-ba9a-f3551e749cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-61d0265e-62c2-45e8-ab5c-2bc798d43f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-de3a1613-8082-4d2d-a08d-764cd8eaa095,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-8986aac7-0a96-4d95-bbc9-368400f94c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-72f77b4b-aa42-4e05-962f-c39679b453f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-0671b9a6-5588-4b7d-b302-7bd276f1a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-b772e960-c761-426c-b78a-9e835506df5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017355806-172.17.0.16-1596896134385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-4f27655b-c20e-4e7c-a0f3-50ae5ddcf3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-dd826cfc-21e3-4cd1-ba9a-f3551e749cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-61d0265e-62c2-45e8-ab5c-2bc798d43f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-de3a1613-8082-4d2d-a08d-764cd8eaa095,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-8986aac7-0a96-4d95-bbc9-368400f94c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-72f77b4b-aa42-4e05-962f-c39679b453f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-0671b9a6-5588-4b7d-b302-7bd276f1a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-b772e960-c761-426c-b78a-9e835506df5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136432424-172.17.0.16-1596896473715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-8611e53f-c7b7-40cc-8888-54fab37fac78,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-2bc07f79-55e6-4aec-a04f-bfa6c876720c,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-22d6e20d-18d8-4fd2-a5a7-0269b0063726,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-e7d146fe-648a-4f7f-ae4d-cf6f1a36ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-60cb742c-3def-4d50-8735-d7b9f07ea638,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-c47628aa-4e5f-4988-9227-791f9510d76f,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-53a958c7-0416-4274-88f6-12a0b0842040,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-cc1a39fa-98a1-4424-bce4-3651b2f8d060,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136432424-172.17.0.16-1596896473715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-8611e53f-c7b7-40cc-8888-54fab37fac78,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-2bc07f79-55e6-4aec-a04f-bfa6c876720c,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-22d6e20d-18d8-4fd2-a5a7-0269b0063726,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-e7d146fe-648a-4f7f-ae4d-cf6f1a36ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-60cb742c-3def-4d50-8735-d7b9f07ea638,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-c47628aa-4e5f-4988-9227-791f9510d76f,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-53a958c7-0416-4274-88f6-12a0b0842040,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-cc1a39fa-98a1-4424-bce4-3651b2f8d060,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462046645-172.17.0.16-1596896551738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-2c611938-1ab8-4e8c-b3a8-3d376b409673,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-043e068c-d7b4-47ee-b17a-b05c2e46a117,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-bbbe077c-4e72-49f8-8f68-7ce5e327f72f,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-be819fab-ce0a-4d16-9753-4e9978c36adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7731fb08-e118-4456-befb-c5380b58db4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-df3c7ffa-4ca2-4c6d-8ce6-495c0d4dd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-f2a0b704-fd94-496a-a065-1b236264725f,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-121b6e1a-a82f-437e-b59d-3292e5b8b8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462046645-172.17.0.16-1596896551738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-2c611938-1ab8-4e8c-b3a8-3d376b409673,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-043e068c-d7b4-47ee-b17a-b05c2e46a117,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-bbbe077c-4e72-49f8-8f68-7ce5e327f72f,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-be819fab-ce0a-4d16-9753-4e9978c36adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7731fb08-e118-4456-befb-c5380b58db4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-df3c7ffa-4ca2-4c6d-8ce6-495c0d4dd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-f2a0b704-fd94-496a-a065-1b236264725f,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-121b6e1a-a82f-437e-b59d-3292e5b8b8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647767808-172.17.0.16-1596896803215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-06c46143-a7ed-4485-83ca-41f7972d4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-63412378-4278-47c6-a425-67c657d6a6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-d3d5e3ab-2963-49c6-b9ed-701060f5ab77,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-aa562e8b-63c7-440f-ab14-b0cc5d584927,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-db5e8955-3730-42d1-b6df-8ef306936783,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-2214f2a8-3a48-4158-ab7d-a623729c9a76,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-64de2353-9ec4-4754-a7e2-d684bcb34246,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-604c4b5f-ecf2-41fe-a57f-993653183530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647767808-172.17.0.16-1596896803215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-06c46143-a7ed-4485-83ca-41f7972d4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-63412378-4278-47c6-a425-67c657d6a6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-d3d5e3ab-2963-49c6-b9ed-701060f5ab77,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-aa562e8b-63c7-440f-ab14-b0cc5d584927,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-db5e8955-3730-42d1-b6df-8ef306936783,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-2214f2a8-3a48-4158-ab7d-a623729c9a76,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-64de2353-9ec4-4754-a7e2-d684bcb34246,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-604c4b5f-ecf2-41fe-a57f-993653183530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467270529-172.17.0.16-1596897095420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-d2fd846a-e01f-4cbb-b437-38849ce7bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-dccf4f45-7ebb-40ca-9981-afee930a925b,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-614f2bd8-16c3-4f16-8339-9be3d87da559,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-00d88d61-c378-46f2-a66a-f905b3e3b8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-13ab874b-0fc2-446c-9024-4a0782c30720,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-73cf8033-eeb3-44f7-88bd-59190eccffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-a63ca550-d561-4480-ba0b-b928992853e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-77459a71-f20d-4528-8578-47a353904830,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467270529-172.17.0.16-1596897095420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-d2fd846a-e01f-4cbb-b437-38849ce7bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-dccf4f45-7ebb-40ca-9981-afee930a925b,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-614f2bd8-16c3-4f16-8339-9be3d87da559,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-00d88d61-c378-46f2-a66a-f905b3e3b8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-13ab874b-0fc2-446c-9024-4a0782c30720,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-73cf8033-eeb3-44f7-88bd-59190eccffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-a63ca550-d561-4480-ba0b-b928992853e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-77459a71-f20d-4528-8578-47a353904830,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765953589-172.17.0.16-1596897207083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-1ba14bc5-62b7-45e9-912c-2a7efe0cbcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-fbd8d671-df24-4ab5-92c3-1cc73816da59,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-a3df8478-ecb5-4704-a5bb-4ca9ab219b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-106051f7-aafb-45e8-bf9c-5d4b491a4742,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-b7a114dd-faa1-4a0d-bd5a-adef6d7bbba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-d8c79a61-3bc4-4376-ae12-986bb978653a,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-fdbd9a3b-8824-434f-a39f-f6a54488fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-4b609b99-3294-4a81-ab98-fbae0fa171f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765953589-172.17.0.16-1596897207083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-1ba14bc5-62b7-45e9-912c-2a7efe0cbcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-fbd8d671-df24-4ab5-92c3-1cc73816da59,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-a3df8478-ecb5-4704-a5bb-4ca9ab219b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-106051f7-aafb-45e8-bf9c-5d4b491a4742,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-b7a114dd-faa1-4a0d-bd5a-adef6d7bbba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-d8c79a61-3bc4-4376-ae12-986bb978653a,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-fdbd9a3b-8824-434f-a39f-f6a54488fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-4b609b99-3294-4a81-ab98-fbae0fa171f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817986851-172.17.0.16-1596897391128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-af7f950c-5de8-4bd5-92ab-47ac5055f792,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-401c7d36-1e92-4271-a488-b513df0d1f28,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-dd0df574-ebaa-4c24-ac37-443e665ed214,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-8e62e6e8-7919-4d36-ba07-6f4abe69c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-24cf6614-434d-4282-a3b4-5e51126384af,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-dade4861-796b-4f3b-a9cb-172cd37b2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-249fabb5-7a95-4308-8674-b7775e3da1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-7805e644-713b-4766-bd43-d12430969f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817986851-172.17.0.16-1596897391128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-af7f950c-5de8-4bd5-92ab-47ac5055f792,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-401c7d36-1e92-4271-a488-b513df0d1f28,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-dd0df574-ebaa-4c24-ac37-443e665ed214,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-8e62e6e8-7919-4d36-ba07-6f4abe69c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-24cf6614-434d-4282-a3b4-5e51126384af,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-dade4861-796b-4f3b-a9cb-172cd37b2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-249fabb5-7a95-4308-8674-b7775e3da1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-7805e644-713b-4766-bd43-d12430969f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597137523-172.17.0.16-1596897553523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-54405315-aec0-42cb-998b-2d2a53ffc6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-f258906e-c981-4329-b2eb-10d66375e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-86d12f9a-9419-496f-97dd-440e3588e161,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-a7e2c0b0-c483-4b9e-a219-c43245ba2abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-0c40b969-b1ea-46cc-af61-da980e0d67c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-2bd8057a-e4d4-4414-9527-128ef5fc05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-addda077-f582-4d30-a4e5-5549e721f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-9f8305f4-105d-40e2-880c-d1136a3cd3a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597137523-172.17.0.16-1596897553523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-54405315-aec0-42cb-998b-2d2a53ffc6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-f258906e-c981-4329-b2eb-10d66375e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-86d12f9a-9419-496f-97dd-440e3588e161,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-a7e2c0b0-c483-4b9e-a219-c43245ba2abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-0c40b969-b1ea-46cc-af61-da980e0d67c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-2bd8057a-e4d4-4414-9527-128ef5fc05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-addda077-f582-4d30-a4e5-5549e721f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-9f8305f4-105d-40e2-880c-d1136a3cd3a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170560841-172.17.0.16-1596897584526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34633,DS-c103ef69-dc03-4ce7-9f92-4a8ad7a23963,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-0825253f-36ce-457a-bbd0-86d437216ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-42cb5bcb-e32a-4ec9-90ec-3ea31b8e8c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-aca4f303-49ba-4789-b06f-d8c0ed46cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-0febee99-8cbf-4ba9-8755-f520bc01dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-9778b070-eb6e-4bf1-906a-9cfe754d71df,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-9c3b296c-8245-42d5-993f-bcdd33aa2613,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-bd345024-ffe8-43df-9a56-dda75610f023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170560841-172.17.0.16-1596897584526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34633,DS-c103ef69-dc03-4ce7-9f92-4a8ad7a23963,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-0825253f-36ce-457a-bbd0-86d437216ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-42cb5bcb-e32a-4ec9-90ec-3ea31b8e8c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-aca4f303-49ba-4789-b06f-d8c0ed46cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-0febee99-8cbf-4ba9-8755-f520bc01dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-9778b070-eb6e-4bf1-906a-9cfe754d71df,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-9c3b296c-8245-42d5-993f-bcdd33aa2613,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-bd345024-ffe8-43df-9a56-dda75610f023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353556722-172.17.0.16-1596897691831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44119,DS-ee6d4a8e-1846-4557-8b5f-edc2373cf8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-b55e5129-d1b1-42f8-b76f-354ec382be59,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-601c2781-0447-479c-9451-ecf5c6446d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-64dce622-8164-499f-926f-ee82da92115c,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-7aeeb59f-ef14-43d5-bd75-18b89f56a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-24729953-bb88-4a6b-a6d6-00216dc32f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-e84cb6de-f058-4408-8d8d-d377eab63478,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-f0309146-a456-4ada-873e-3849271ed135,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353556722-172.17.0.16-1596897691831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44119,DS-ee6d4a8e-1846-4557-8b5f-edc2373cf8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-b55e5129-d1b1-42f8-b76f-354ec382be59,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-601c2781-0447-479c-9451-ecf5c6446d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-64dce622-8164-499f-926f-ee82da92115c,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-7aeeb59f-ef14-43d5-bd75-18b89f56a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-24729953-bb88-4a6b-a6d6-00216dc32f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-e84cb6de-f058-4408-8d8d-d377eab63478,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-f0309146-a456-4ada-873e-3849271ed135,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167392641-172.17.0.16-1596897764613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40229,DS-c1df8db9-71fc-4b2d-985e-e7a727d5e809,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-d0326337-983e-45af-98f5-741955c6a792,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-09868242-0de9-4f41-adbf-77763f858dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-092d4d44-8d8f-476e-a089-e723f721e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-a66c2ea2-c69c-4853-9cb0-712e4b12d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-2de2b50c-53af-4874-9a18-57ad705063cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-1800b6c8-1c1b-4992-b5d7-ce5f9efd4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-b30ea826-d966-4e07-9ff8-ce8028ae0b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167392641-172.17.0.16-1596897764613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40229,DS-c1df8db9-71fc-4b2d-985e-e7a727d5e809,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-d0326337-983e-45af-98f5-741955c6a792,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-09868242-0de9-4f41-adbf-77763f858dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-092d4d44-8d8f-476e-a089-e723f721e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-a66c2ea2-c69c-4853-9cb0-712e4b12d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-2de2b50c-53af-4874-9a18-57ad705063cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-1800b6c8-1c1b-4992-b5d7-ce5f9efd4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-b30ea826-d966-4e07-9ff8-ce8028ae0b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701353920-172.17.0.16-1596897912374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-e91dd05b-8894-46f5-87b4-268563e6e85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-0304957b-543c-4045-990e-7f50bd5a0d50,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-529f3bc0-ba1d-4e9b-a89d-ecdea35a83fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-df0c5dfa-0680-4483-aa2f-5ee24e4f2506,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-f8f42288-7785-4f96-b3d6-2fb79e5dba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-cdf2d108-bea2-436c-93a7-aafb2be97554,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-73485b8b-ffdd-4adc-be5a-bdafbaa067e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-64440fbf-4c32-4ce8-b706-6f540c14c6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701353920-172.17.0.16-1596897912374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-e91dd05b-8894-46f5-87b4-268563e6e85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-0304957b-543c-4045-990e-7f50bd5a0d50,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-529f3bc0-ba1d-4e9b-a89d-ecdea35a83fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-df0c5dfa-0680-4483-aa2f-5ee24e4f2506,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-f8f42288-7785-4f96-b3d6-2fb79e5dba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-cdf2d108-bea2-436c-93a7-aafb2be97554,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-73485b8b-ffdd-4adc-be5a-bdafbaa067e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-64440fbf-4c32-4ce8-b706-6f540c14c6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744554584-172.17.0.16-1596898024520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-5a2cf80f-ca6e-46c3-a9ed-55a4c6e489f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-9a3fc920-ac01-439c-becb-04e5ec3084e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-e08f205d-6ace-4dfd-a1a5-344296f5a355,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-4495ecf2-cc12-445c-8baf-a68653c3ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-ab7c3975-c257-40a0-9e73-11fc49b26e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-e1715ddc-4e5b-4c15-b653-cd04827c2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-654657e0-e200-49b9-a29c-b498477decf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-973f05d9-dba9-41d4-99be-b27f6455c6c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744554584-172.17.0.16-1596898024520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-5a2cf80f-ca6e-46c3-a9ed-55a4c6e489f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-9a3fc920-ac01-439c-becb-04e5ec3084e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-e08f205d-6ace-4dfd-a1a5-344296f5a355,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-4495ecf2-cc12-445c-8baf-a68653c3ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-ab7c3975-c257-40a0-9e73-11fc49b26e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-e1715ddc-4e5b-4c15-b653-cd04827c2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-654657e0-e200-49b9-a29c-b498477decf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-973f05d9-dba9-41d4-99be-b27f6455c6c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239646504-172.17.0.16-1596898276328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-e3e0ad8f-90a3-44b4-8def-d8b964c8a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-9c1ffeef-399c-4e12-a6a2-d80d0e07a2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-27145900-6d0e-4454-b2e5-dd67cf5f506c,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-b97af6d9-0dde-432a-9674-1c5fd07e2f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-a1576c02-1f23-4d9d-9b02-4ab51dcf126b,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-ac24e145-8ae5-4643-8bbc-a6a92327ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-dd1a1ea3-3755-40e7-9438-d25e536c0331,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-c8dedea3-9158-430e-98bb-2f5ed1ba958e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239646504-172.17.0.16-1596898276328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-e3e0ad8f-90a3-44b4-8def-d8b964c8a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-9c1ffeef-399c-4e12-a6a2-d80d0e07a2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-27145900-6d0e-4454-b2e5-dd67cf5f506c,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-b97af6d9-0dde-432a-9674-1c5fd07e2f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-a1576c02-1f23-4d9d-9b02-4ab51dcf126b,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-ac24e145-8ae5-4643-8bbc-a6a92327ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-dd1a1ea3-3755-40e7-9438-d25e536c0331,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-c8dedea3-9158-430e-98bb-2f5ed1ba958e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538306890-172.17.0.16-1596898433227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-843c1062-49e0-4cd5-9419-a76b2789ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-6eb94fcd-bbde-421c-b98d-230120138bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-fb830aeb-853b-42ea-8590-d7b9c2d731c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-85e2c847-0ba0-44ce-a7b1-74c423741cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-06d1c2fa-38e5-40a1-8777-33b4381a517f,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-046ce4d3-a2d6-431d-8651-4cb9dd290aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-82fc0be5-f644-4f26-a9c6-f7c425a4d661,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-5a2d2f83-fe97-4b4f-90f0-7e298e4eab64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538306890-172.17.0.16-1596898433227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-843c1062-49e0-4cd5-9419-a76b2789ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-6eb94fcd-bbde-421c-b98d-230120138bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-fb830aeb-853b-42ea-8590-d7b9c2d731c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-85e2c847-0ba0-44ce-a7b1-74c423741cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-06d1c2fa-38e5-40a1-8777-33b4381a517f,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-046ce4d3-a2d6-431d-8651-4cb9dd290aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-82fc0be5-f644-4f26-a9c6-f7c425a4d661,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-5a2d2f83-fe97-4b4f-90f0-7e298e4eab64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234185518-172.17.0.16-1596898734675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38326,DS-2dcb6bea-8d94-4eca-8240-8188c842a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-61baa5e8-0f29-4677-83f6-3bf79294e7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-e0520af5-999d-4819-82f1-d56f1a7ecae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-46ba6215-3709-46ea-99a5-0749bdb07df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-8d3d1b29-a385-4997-9354-ac98451d8a66,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-d967fac8-85ff-4233-8948-d499e2b06d87,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-6fc04249-e099-49c9-a62a-e52868585b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-110c8e9e-b465-4a26-a41d-1fe85dadfbe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234185518-172.17.0.16-1596898734675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38326,DS-2dcb6bea-8d94-4eca-8240-8188c842a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-61baa5e8-0f29-4677-83f6-3bf79294e7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-e0520af5-999d-4819-82f1-d56f1a7ecae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-46ba6215-3709-46ea-99a5-0749bdb07df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-8d3d1b29-a385-4997-9354-ac98451d8a66,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-d967fac8-85ff-4233-8948-d499e2b06d87,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-6fc04249-e099-49c9-a62a-e52868585b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-110c8e9e-b465-4a26-a41d-1fe85dadfbe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746056738-172.17.0.16-1596898765749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-8e2fb648-341d-46df-99bf-4b72bd2fb372,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-d6eb499e-bf83-460d-ab23-0bfb65daa941,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-64da9b97-14db-4277-b7c3-0a7b64735e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-6d3194ea-b0eb-43b0-933f-6f91d2776abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-a769d410-1e07-475a-8146-d05cc2a05635,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-85863ec4-dba0-4f3c-8af2-81560e7a9149,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-fbbfaa13-9aca-40cf-ad40-66e57bc7b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-f3e10732-541a-443f-9d54-97f22eb0c1ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746056738-172.17.0.16-1596898765749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-8e2fb648-341d-46df-99bf-4b72bd2fb372,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-d6eb499e-bf83-460d-ab23-0bfb65daa941,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-64da9b97-14db-4277-b7c3-0a7b64735e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-6d3194ea-b0eb-43b0-933f-6f91d2776abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-a769d410-1e07-475a-8146-d05cc2a05635,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-85863ec4-dba0-4f3c-8af2-81560e7a9149,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-fbbfaa13-9aca-40cf-ad40-66e57bc7b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-f3e10732-541a-443f-9d54-97f22eb0c1ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512306165-172.17.0.16-1596898842195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35853,DS-6ccf9227-be0c-493c-b9a0-4542977760ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-68680324-a1c2-469f-8863-10fd03e8af44,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-bac711d8-bc4c-46c0-baec-71ae19e8d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-2c2d7252-0be4-4f89-ba82-5d953b44d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-e3e3b13f-5635-449f-b3d6-9dbc77b7e4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-09183e44-47c2-4a97-9c08-48ce71d1ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-0631dba4-34db-4f62-b42c-78ec13aeef97,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-d7d981f2-bf65-4e84-ab33-191f4800b925,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512306165-172.17.0.16-1596898842195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35853,DS-6ccf9227-be0c-493c-b9a0-4542977760ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-68680324-a1c2-469f-8863-10fd03e8af44,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-bac711d8-bc4c-46c0-baec-71ae19e8d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-2c2d7252-0be4-4f89-ba82-5d953b44d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-e3e3b13f-5635-449f-b3d6-9dbc77b7e4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-09183e44-47c2-4a97-9c08-48ce71d1ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-0631dba4-34db-4f62-b42c-78ec13aeef97,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-d7d981f2-bf65-4e84-ab33-191f4800b925,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772116908-172.17.0.16-1596898916243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-b38aa2a2-6ee5-452a-9b44-b08eb15a94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-bd925e6c-b52c-48c4-96f9-b2360f246909,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-26f2dc26-ff2b-4ee2-bf79-7d062d4cde97,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-cf387750-5139-4953-9f47-13957232c610,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-f6b8b185-ae07-4d4b-9832-ee153427c016,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-14b70bf3-9023-4d26-a08e-65c1d0c66698,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-5331c752-48ca-4c0b-9b18-1d421a1b5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-8c3b2705-38a9-4105-87d3-b587d7b2aab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772116908-172.17.0.16-1596898916243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-b38aa2a2-6ee5-452a-9b44-b08eb15a94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-bd925e6c-b52c-48c4-96f9-b2360f246909,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-26f2dc26-ff2b-4ee2-bf79-7d062d4cde97,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-cf387750-5139-4953-9f47-13957232c610,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-f6b8b185-ae07-4d4b-9832-ee153427c016,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-14b70bf3-9023-4d26-a08e-65c1d0c66698,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-5331c752-48ca-4c0b-9b18-1d421a1b5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-8c3b2705-38a9-4105-87d3-b587d7b2aab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551758080-172.17.0.16-1596898994890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40640,DS-ff1b8066-d9e1-4310-aa13-22d12ea0d342,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-5709b608-165b-4af7-91b3-967b21d0ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-a40978bf-539d-4c72-874f-1161cbfd3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-261c2c62-aa96-4841-a00f-4e9cbe6bf20e,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-18a04818-bdd4-4beb-b5f1-2ab249d73fad,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-8e72fa6d-f929-4fb8-a307-0c71a11d2836,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-030e3fb2-9dfe-46d2-bbc0-cb3a5f591feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-68af647a-5ce5-459a-961a-3498872317b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551758080-172.17.0.16-1596898994890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40640,DS-ff1b8066-d9e1-4310-aa13-22d12ea0d342,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-5709b608-165b-4af7-91b3-967b21d0ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-a40978bf-539d-4c72-874f-1161cbfd3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-261c2c62-aa96-4841-a00f-4e9cbe6bf20e,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-18a04818-bdd4-4beb-b5f1-2ab249d73fad,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-8e72fa6d-f929-4fb8-a307-0c71a11d2836,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-030e3fb2-9dfe-46d2-bbc0-cb3a5f591feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-68af647a-5ce5-459a-961a-3498872317b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513696132-172.17.0.16-1596899096070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-ca14c831-6147-437f-b867-8499b2afacd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-2c086cbc-743d-4e6b-9d74-46297cd2c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-767ef5e4-6cef-4e67-863b-5b4176e9d921,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-0837a101-a69e-4132-93c6-b5fc2e773e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-f171bbd4-a98a-4be5-983b-bc027dd9d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-43f8c979-5ede-4910-96d6-374d51ded7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-a505e942-1442-4b66-b998-390414d8908b,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-dfd9f516-4c70-4c99-a49a-eb0f68b127bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513696132-172.17.0.16-1596899096070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-ca14c831-6147-437f-b867-8499b2afacd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-2c086cbc-743d-4e6b-9d74-46297cd2c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-767ef5e4-6cef-4e67-863b-5b4176e9d921,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-0837a101-a69e-4132-93c6-b5fc2e773e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-f171bbd4-a98a-4be5-983b-bc027dd9d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-43f8c979-5ede-4910-96d6-374d51ded7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-a505e942-1442-4b66-b998-390414d8908b,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-dfd9f516-4c70-4c99-a49a-eb0f68b127bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877362468-172.17.0.16-1596899206026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-06ca5c47-f892-4222-b952-5c6f82ac0e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-455bfd21-a64f-4f0b-8730-eef41527714a,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d7e12eb4-a16b-4c89-9b0c-a2be0cdcc473,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-434d9ee5-16db-4162-8e9d-f92f3e3d9b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-fa5cae1f-1db4-43de-86cf-eb07236667a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-a6b4b776-e62d-45e4-a14e-081cc5f28ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-38e39338-98f4-4f42-b580-a6ebb86b1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-2c45818a-130e-425a-890e-1310bc864015,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877362468-172.17.0.16-1596899206026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-06ca5c47-f892-4222-b952-5c6f82ac0e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-455bfd21-a64f-4f0b-8730-eef41527714a,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d7e12eb4-a16b-4c89-9b0c-a2be0cdcc473,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-434d9ee5-16db-4162-8e9d-f92f3e3d9b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-fa5cae1f-1db4-43de-86cf-eb07236667a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-a6b4b776-e62d-45e4-a14e-081cc5f28ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-38e39338-98f4-4f42-b580-a6ebb86b1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-2c45818a-130e-425a-890e-1310bc864015,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12226596-172.17.0.16-1596899475958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33075,DS-b1491163-778b-4f65-bac3-99fbef399a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-33df17e5-133b-4959-bb46-bdafbca0d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-004acf89-f41d-492f-bd27-96a2ce953e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-b3108952-ac1e-4553-a296-6adafdbc1c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-130d0c5f-a8dc-408b-ae36-5184d232fc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-2bf89342-b4b7-40c8-86ff-09d4ff7782aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-72b6e609-9fae-4a00-ac10-e9bf3b535a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-3eab32cf-247e-415a-81a7-d1bde927fe83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12226596-172.17.0.16-1596899475958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33075,DS-b1491163-778b-4f65-bac3-99fbef399a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-33df17e5-133b-4959-bb46-bdafbca0d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-004acf89-f41d-492f-bd27-96a2ce953e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-b3108952-ac1e-4553-a296-6adafdbc1c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-130d0c5f-a8dc-408b-ae36-5184d232fc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-2bf89342-b4b7-40c8-86ff-09d4ff7782aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-72b6e609-9fae-4a00-ac10-e9bf3b535a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-3eab32cf-247e-415a-81a7-d1bde927fe83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399625418-172.17.0.16-1596899546498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-3d9ea5d4-4976-4cbe-bf7b-40feae5cd6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-26c246ca-dcd0-49d7-9347-16188b61ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-fd91cd23-498a-4758-abad-11a6fcd094a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-221e321f-c8e0-4b11-9e5f-0ca858713c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-a73087d2-f5d5-41bb-90b2-e2357c80dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-f68c6313-03e9-462f-9e0d-9ca96c11429b,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-3aad2378-9e08-4e96-b5a6-c31f316af57c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-0e39bdca-0af9-44fc-95e2-65d38853c462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399625418-172.17.0.16-1596899546498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-3d9ea5d4-4976-4cbe-bf7b-40feae5cd6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-26c246ca-dcd0-49d7-9347-16188b61ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-fd91cd23-498a-4758-abad-11a6fcd094a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-221e321f-c8e0-4b11-9e5f-0ca858713c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-a73087d2-f5d5-41bb-90b2-e2357c80dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-f68c6313-03e9-462f-9e0d-9ca96c11429b,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-3aad2378-9e08-4e96-b5a6-c31f316af57c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-0e39bdca-0af9-44fc-95e2-65d38853c462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071529625-172.17.0.16-1596899745287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35638,DS-844aa60a-2f60-4751-bf81-369558099997,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-75e8bb0d-bacf-4d6a-a367-6e4a4bc7d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-6bf3b0c8-a081-45ac-986c-4ac505cc80bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-a7d5b7fd-8649-4261-b13a-fda5cc79e060,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-b96feeaa-4c9f-476a-a96b-6be10e9f9c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-f78818a2-a61a-47ab-8997-bb4b3d15a204,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-38dba0f6-d9b0-4d2e-b797-123488dd7eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-3151ed19-3f13-4061-af1c-8497e0fcebee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071529625-172.17.0.16-1596899745287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35638,DS-844aa60a-2f60-4751-bf81-369558099997,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-75e8bb0d-bacf-4d6a-a367-6e4a4bc7d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-6bf3b0c8-a081-45ac-986c-4ac505cc80bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-a7d5b7fd-8649-4261-b13a-fda5cc79e060,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-b96feeaa-4c9f-476a-a96b-6be10e9f9c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-f78818a2-a61a-47ab-8997-bb4b3d15a204,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-38dba0f6-d9b0-4d2e-b797-123488dd7eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-3151ed19-3f13-4061-af1c-8497e0fcebee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89082554-172.17.0.16-1596899850618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-1ecec72c-04c9-40cc-bcb9-9d3b21626e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-810c2f22-d0b2-4aef-8de7-bca84ac5644c,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-34d5ae0f-9ba7-4b76-9ada-5a534d4afadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-ddab9863-7fb4-4925-b7a3-71a20eabd26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-cfb90828-e797-4e9d-aad7-320dafe2758c,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-06d9f947-4276-4b8a-823a-f44161b41cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-6b481e72-7fdd-427e-8a15-f7608f02e851,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-fbd5d824-a02c-4875-a197-683791ae0005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89082554-172.17.0.16-1596899850618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-1ecec72c-04c9-40cc-bcb9-9d3b21626e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-810c2f22-d0b2-4aef-8de7-bca84ac5644c,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-34d5ae0f-9ba7-4b76-9ada-5a534d4afadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-ddab9863-7fb4-4925-b7a3-71a20eabd26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-cfb90828-e797-4e9d-aad7-320dafe2758c,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-06d9f947-4276-4b8a-823a-f44161b41cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-6b481e72-7fdd-427e-8a15-f7608f02e851,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-fbd5d824-a02c-4875-a197-683791ae0005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167488018-172.17.0.16-1596900291753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41115,DS-fd3ca9a5-a4db-4d72-9870-3e505eef1393,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-adb447e6-8334-467d-8f14-d6540c78e171,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-fcecc7f5-2de2-4448-ad55-d695a13e8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-f8f6e9ff-0111-4418-bf63-b9428c13b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-38f43100-1d2a-4281-b3dd-3c569416fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-60703ca6-aa7a-4ba2-bbd2-bebff8e6ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-43a2604a-8490-4e7e-a6bf-80955f7dc942,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-16fc8c9c-0bd3-4d1b-bfab-dc2ebfa35efc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167488018-172.17.0.16-1596900291753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41115,DS-fd3ca9a5-a4db-4d72-9870-3e505eef1393,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-adb447e6-8334-467d-8f14-d6540c78e171,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-fcecc7f5-2de2-4448-ad55-d695a13e8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-f8f6e9ff-0111-4418-bf63-b9428c13b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-38f43100-1d2a-4281-b3dd-3c569416fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-60703ca6-aa7a-4ba2-bbd2-bebff8e6ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-43a2604a-8490-4e7e-a6bf-80955f7dc942,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-16fc8c9c-0bd3-4d1b-bfab-dc2ebfa35efc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112152243-172.17.0.16-1596900425487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-ee83e9a2-fadf-4b0d-8ee3-ccf114a6e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-bcf084d0-196b-43ca-869e-f2297f8b82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-38294e69-f77d-4853-8106-7b2ec6773095,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-54376794-5e26-4430-9613-f40107477b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-e5701a89-2667-44c3-98ac-284501e6469d,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f4b9c350-39a4-43eb-a2ab-ce4028416d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-257ff52a-becc-437b-b7ba-306b4e0f428c,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-80be6ca5-7ff5-403a-b925-aba378d50380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112152243-172.17.0.16-1596900425487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-ee83e9a2-fadf-4b0d-8ee3-ccf114a6e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-bcf084d0-196b-43ca-869e-f2297f8b82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-38294e69-f77d-4853-8106-7b2ec6773095,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-54376794-5e26-4430-9613-f40107477b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-e5701a89-2667-44c3-98ac-284501e6469d,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f4b9c350-39a4-43eb-a2ab-ce4028416d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-257ff52a-becc-437b-b7ba-306b4e0f428c,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-80be6ca5-7ff5-403a-b925-aba378d50380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686108877-172.17.0.16-1596900501903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44681,DS-be392913-1ed7-454d-a276-1f9ead851b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-8df76a5b-2ec5-4130-a20a-a44e4a6d8c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-9e3adfc6-0afb-404a-925e-c85870ed3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-ec72eeca-5beb-4ae2-bede-85fd1b48e9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-956c7cef-fd1c-487d-b9e4-f24b2d57d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-57b821b0-05a0-4ef8-bf31-bef53d486544,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-80e53128-08e8-4c72-878d-13b82aa60f03,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-184d431c-55fa-4356-82ba-da97fbb1fb8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686108877-172.17.0.16-1596900501903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44681,DS-be392913-1ed7-454d-a276-1f9ead851b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-8df76a5b-2ec5-4130-a20a-a44e4a6d8c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-9e3adfc6-0afb-404a-925e-c85870ed3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-ec72eeca-5beb-4ae2-bede-85fd1b48e9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-956c7cef-fd1c-487d-b9e4-f24b2d57d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-57b821b0-05a0-4ef8-bf31-bef53d486544,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-80e53128-08e8-4c72-878d-13b82aa60f03,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-184d431c-55fa-4356-82ba-da97fbb1fb8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939113549-172.17.0.16-1596900535019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-20ed7e1a-8519-466b-8bab-33860b0c038f,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-6d3f371a-36ef-4558-ad91-b0e75cbda6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-44cc3a77-6b2c-4658-a810-838f3ab2aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-fd78b715-2b74-4e2b-a497-92b067d36595,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-19cb4214-a17d-474a-965e-65dccdbc2272,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-2dd0c788-4909-45f9-ae89-b8ab5aef40ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-12e4b29e-69fe-4b86-b478-2fd328fde9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-edce0849-9b5d-4dc2-baae-d15fd0dcd6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939113549-172.17.0.16-1596900535019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-20ed7e1a-8519-466b-8bab-33860b0c038f,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-6d3f371a-36ef-4558-ad91-b0e75cbda6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-44cc3a77-6b2c-4658-a810-838f3ab2aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-fd78b715-2b74-4e2b-a497-92b067d36595,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-19cb4214-a17d-474a-965e-65dccdbc2272,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-2dd0c788-4909-45f9-ae89-b8ab5aef40ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-12e4b29e-69fe-4b86-b478-2fd328fde9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-edce0849-9b5d-4dc2-baae-d15fd0dcd6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044287530-172.17.0.16-1596900723712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38068,DS-815720b8-d588-4c77-a6ff-ddbe5fd103b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-5b0d9c99-3603-4a21-b4c7-6d053be89847,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-c5d9dc8d-a0f4-4491-acfc-cc08c15f4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-a727356a-63fa-4d99-ba4f-02d5e74679fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-445757bc-4660-44fc-b3c4-0c10c511f330,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-4d6db3c2-4d11-4c82-9d30-a883902d3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-5503d8db-6c54-4721-97f3-27d8186e34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-3f868951-b3ec-4fb7-82af-98b13303ab3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044287530-172.17.0.16-1596900723712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38068,DS-815720b8-d588-4c77-a6ff-ddbe5fd103b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-5b0d9c99-3603-4a21-b4c7-6d053be89847,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-c5d9dc8d-a0f4-4491-acfc-cc08c15f4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-a727356a-63fa-4d99-ba4f-02d5e74679fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-445757bc-4660-44fc-b3c4-0c10c511f330,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-4d6db3c2-4d11-4c82-9d30-a883902d3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-5503d8db-6c54-4721-97f3-27d8186e34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-3f868951-b3ec-4fb7-82af-98b13303ab3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5459
