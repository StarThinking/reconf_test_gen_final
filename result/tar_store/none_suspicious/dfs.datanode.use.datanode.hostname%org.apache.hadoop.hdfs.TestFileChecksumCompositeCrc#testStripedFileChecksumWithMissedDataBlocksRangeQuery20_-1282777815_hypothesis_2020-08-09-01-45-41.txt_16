reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762047606-172.17.0.19-1596937743731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36981,DS-ac6214e7-1d3e-435f-a8bf-a9308e4e97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-b0f924d4-ce5b-4df5-8737-968f838fba83,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-b7fa0ff9-56dc-432d-b394-0651328a9834,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-0389b4aa-4e58-4fc4-872c-0bd1b2fa9a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-12136bfa-c4e0-48bd-aa82-391c3fb814b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-7fb6c4a7-1f40-4a7c-842f-129fb7ea0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-1f94035a-9611-49a3-a857-7b96b1d2e3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-12cadc44-54a5-4fc9-a0d2-9372538ef586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762047606-172.17.0.19-1596937743731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36981,DS-ac6214e7-1d3e-435f-a8bf-a9308e4e97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-b0f924d4-ce5b-4df5-8737-968f838fba83,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-b7fa0ff9-56dc-432d-b394-0651328a9834,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-0389b4aa-4e58-4fc4-872c-0bd1b2fa9a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-12136bfa-c4e0-48bd-aa82-391c3fb814b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-7fb6c4a7-1f40-4a7c-842f-129fb7ea0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-1f94035a-9611-49a3-a857-7b96b1d2e3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-12cadc44-54a5-4fc9-a0d2-9372538ef586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972576498-172.17.0.19-1596937781257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-34b333bb-1c69-42fb-a556-90cc26509711,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-b4acb706-9729-4c69-b1d0-3d12d7611662,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-35dcba7d-af66-4e4c-90d5-04cc6849c074,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-1417fbd0-8af5-4990-8de8-566054fe1752,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-bff81d8f-039d-4410-a166-b1193af5454f,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-40e7cbf0-5972-4dc3-a792-e3311ef74b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-d93b6a82-5bce-401b-9622-fc8806976b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-5b6d0fc9-ac70-4b64-b9b6-110c187616c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972576498-172.17.0.19-1596937781257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-34b333bb-1c69-42fb-a556-90cc26509711,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-b4acb706-9729-4c69-b1d0-3d12d7611662,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-35dcba7d-af66-4e4c-90d5-04cc6849c074,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-1417fbd0-8af5-4990-8de8-566054fe1752,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-bff81d8f-039d-4410-a166-b1193af5454f,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-40e7cbf0-5972-4dc3-a792-e3311ef74b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-d93b6a82-5bce-401b-9622-fc8806976b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-5b6d0fc9-ac70-4b64-b9b6-110c187616c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774094907-172.17.0.19-1596937874280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-b277e216-3aca-45b1-bbab-7b3934807a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3a0164ca-3048-48dd-b788-ced5528ae67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-e969cadc-707d-4153-b591-494924ca11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-a6bf5622-e859-4d59-b845-f41e2e3d4c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a8d8b42e-6f23-4e79-86e7-2c29bbdd0e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-bd940d4d-92b2-46a4-919e-076e93c00f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-8636fad8-452a-4be3-8cd2-935d6d598a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-bf52ce65-0c2b-4b99-b9f2-4a57405b2977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774094907-172.17.0.19-1596937874280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-b277e216-3aca-45b1-bbab-7b3934807a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3a0164ca-3048-48dd-b788-ced5528ae67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-e969cadc-707d-4153-b591-494924ca11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-a6bf5622-e859-4d59-b845-f41e2e3d4c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a8d8b42e-6f23-4e79-86e7-2c29bbdd0e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-bd940d4d-92b2-46a4-919e-076e93c00f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-8636fad8-452a-4be3-8cd2-935d6d598a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-bf52ce65-0c2b-4b99-b9f2-4a57405b2977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430496405-172.17.0.19-1596938181680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41075,DS-358b27da-0374-4cbe-9bee-6341f1a7e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-0f17c084-35d1-416d-a251-2209fe1b0299,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-b34d05de-4b94-4eaa-b222-2cc27b88c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-6415ee03-7bc6-4d23-8b43-9270e61f0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-e3db05ad-ae5e-459c-837d-f8b3c2d3995a,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-9b01921e-f198-4dec-b3a7-9f23e4309e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-5f068418-613b-4cd5-ad5f-67e52cdb96d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-2765c420-6ab1-484a-8418-8735eef14fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430496405-172.17.0.19-1596938181680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41075,DS-358b27da-0374-4cbe-9bee-6341f1a7e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-0f17c084-35d1-416d-a251-2209fe1b0299,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-b34d05de-4b94-4eaa-b222-2cc27b88c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-6415ee03-7bc6-4d23-8b43-9270e61f0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-e3db05ad-ae5e-459c-837d-f8b3c2d3995a,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-9b01921e-f198-4dec-b3a7-9f23e4309e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-5f068418-613b-4cd5-ad5f-67e52cdb96d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-2765c420-6ab1-484a-8418-8735eef14fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155509102-172.17.0.19-1596938221230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-833db8da-7a0a-47ae-ab1f-4c6efb2bd4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-0764a6dd-fa03-46e9-a75a-fb6b648ea824,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-32ba79b2-f435-47c2-8895-dc6dffe0c1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-4d7b8ac6-2335-4fc4-a07d-fa95be8fe3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-48746f2b-4bb3-439f-93ba-f09de6607f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-ceb9874d-9ef8-44b0-9c87-1824dc3e24d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-21dea2e2-54d4-4bed-84a6-09ad198716ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6b6df76a-a81d-433d-936a-2d4008366432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155509102-172.17.0.19-1596938221230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-833db8da-7a0a-47ae-ab1f-4c6efb2bd4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-0764a6dd-fa03-46e9-a75a-fb6b648ea824,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-32ba79b2-f435-47c2-8895-dc6dffe0c1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-4d7b8ac6-2335-4fc4-a07d-fa95be8fe3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-48746f2b-4bb3-439f-93ba-f09de6607f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-ceb9874d-9ef8-44b0-9c87-1824dc3e24d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-21dea2e2-54d4-4bed-84a6-09ad198716ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6b6df76a-a81d-433d-936a-2d4008366432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851311524-172.17.0.19-1596939723217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-e9856eb3-0ca3-4510-9c29-ed383fa984a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-2ecd1d1d-fae9-4feb-9ab8-b953ba34bec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-e10ebb4c-09ec-4aa5-90a3-633209c55134,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-fdb19092-b848-4edb-b720-f8154faf6591,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-ea6eb02b-1381-4785-b486-73f82baf5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-05cf2794-2f96-4cae-83c6-144fe480a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-7e12eea6-ad96-4390-8fed-9a678a67acea,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-b4cb6ced-6790-4cf7-852d-107cecb1821f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851311524-172.17.0.19-1596939723217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-e9856eb3-0ca3-4510-9c29-ed383fa984a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-2ecd1d1d-fae9-4feb-9ab8-b953ba34bec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-e10ebb4c-09ec-4aa5-90a3-633209c55134,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-fdb19092-b848-4edb-b720-f8154faf6591,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-ea6eb02b-1381-4785-b486-73f82baf5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-05cf2794-2f96-4cae-83c6-144fe480a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-7e12eea6-ad96-4390-8fed-9a678a67acea,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-b4cb6ced-6790-4cf7-852d-107cecb1821f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644028819-172.17.0.19-1596939902756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41928,DS-1e06a488-7718-458f-b858-34891d370029,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-a1c1b497-a4e3-4a04-abd5-5bfe04261cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-31228f16-770f-4de0-ae82-28383f584154,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-efc95ee3-6a17-4bf2-b4c2-50fdef22bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-a7d89898-9b49-4301-b32b-f6101847c921,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-a3cc46bb-6e34-43a4-85fc-a38826454c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-1368f711-5576-426b-a017-9a61bffb6067,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-b18df50b-258a-49c8-82de-f8531e59837f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644028819-172.17.0.19-1596939902756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41928,DS-1e06a488-7718-458f-b858-34891d370029,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-a1c1b497-a4e3-4a04-abd5-5bfe04261cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-31228f16-770f-4de0-ae82-28383f584154,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-efc95ee3-6a17-4bf2-b4c2-50fdef22bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-a7d89898-9b49-4301-b32b-f6101847c921,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-a3cc46bb-6e34-43a4-85fc-a38826454c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-1368f711-5576-426b-a017-9a61bffb6067,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-b18df50b-258a-49c8-82de-f8531e59837f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115716134-172.17.0.19-1596940523229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-18c49c5a-88af-4392-9343-eb5c99fa5508,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-ed1e4d59-4929-44b5-a25e-2eb0aa65c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-8fbdbcdd-17f1-4313-a977-df21bb7c684e,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-cbde86df-e29b-4248-b2e5-6edd2ee8533b,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-c63b07af-63e2-4e25-bc4d-c1f4e9dbfada,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-57b6abc3-20ec-4646-9092-661cad350687,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-3a48a8e9-8249-4468-873e-398c70b165c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-fdd89e93-bf8d-48e9-b087-1947f6fbd996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115716134-172.17.0.19-1596940523229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-18c49c5a-88af-4392-9343-eb5c99fa5508,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-ed1e4d59-4929-44b5-a25e-2eb0aa65c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-8fbdbcdd-17f1-4313-a977-df21bb7c684e,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-cbde86df-e29b-4248-b2e5-6edd2ee8533b,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-c63b07af-63e2-4e25-bc4d-c1f4e9dbfada,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-57b6abc3-20ec-4646-9092-661cad350687,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-3a48a8e9-8249-4468-873e-398c70b165c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-fdd89e93-bf8d-48e9-b087-1947f6fbd996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121649949-172.17.0.19-1596940568151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40089,DS-463d6d5a-789d-4138-9ca4-6d866ce80b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-dd166acf-2ee0-4a75-99bb-a66f55cc941c,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-f8f0b611-744d-4532-98bc-501864f7f935,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-1eb738cd-be31-477d-9f58-db4994052cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-bd53af3b-ca28-4388-974a-674227c8583c,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-013d3bd1-3a27-4581-bf49-feae12e42333,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-f2a0a052-7665-4a52-8b77-61f00af5630a,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-f96076cd-ca1c-48aa-b283-5c134c1ef484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121649949-172.17.0.19-1596940568151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40089,DS-463d6d5a-789d-4138-9ca4-6d866ce80b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-dd166acf-2ee0-4a75-99bb-a66f55cc941c,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-f8f0b611-744d-4532-98bc-501864f7f935,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-1eb738cd-be31-477d-9f58-db4994052cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-bd53af3b-ca28-4388-974a-674227c8583c,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-013d3bd1-3a27-4581-bf49-feae12e42333,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-f2a0a052-7665-4a52-8b77-61f00af5630a,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-f96076cd-ca1c-48aa-b283-5c134c1ef484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370534307-172.17.0.19-1596941100202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44169,DS-0b4f0bf1-4a2f-40f0-b3be-05d22aa67396,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-85fc71d1-88b9-405d-94ba-5f3b05870172,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-4439c867-0b7b-4589-af1a-e19a5c7cb7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-fdd455f7-a206-45b3-b368-dc1427691473,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-7c39d93b-6ac1-4c41-bffc-f8c34e7039d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-a2f327d1-653a-41c1-8f35-ab5a5684c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-3a5e10aa-f526-49cf-a3f1-5bafeb97b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-5bdd625e-8f06-42ff-a51a-c7e8bf8bdaa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370534307-172.17.0.19-1596941100202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44169,DS-0b4f0bf1-4a2f-40f0-b3be-05d22aa67396,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-85fc71d1-88b9-405d-94ba-5f3b05870172,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-4439c867-0b7b-4589-af1a-e19a5c7cb7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-fdd455f7-a206-45b3-b368-dc1427691473,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-7c39d93b-6ac1-4c41-bffc-f8c34e7039d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-a2f327d1-653a-41c1-8f35-ab5a5684c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-3a5e10aa-f526-49cf-a3f1-5bafeb97b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-5bdd625e-8f06-42ff-a51a-c7e8bf8bdaa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415935222-172.17.0.19-1596941143621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-75cafe22-9a0e-4fc5-86c7-71c70bb9023a,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-1ddcc3ca-6c8d-4ad0-a38d-ef1539ac2848,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-b62c433e-3dce-46d1-8674-97e6cd1492d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-17cbd534-eab2-4a88-8203-bf353892579a,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-1c3012d9-f7fd-4252-aabc-854d041162bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-b9deeae2-91c1-4158-a059-1b3a353ac483,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-c843ed17-87ea-48b1-81fa-4755c6eadaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-cbc0f188-b527-436e-a077-0f158fd5cfac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415935222-172.17.0.19-1596941143621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-75cafe22-9a0e-4fc5-86c7-71c70bb9023a,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-1ddcc3ca-6c8d-4ad0-a38d-ef1539ac2848,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-b62c433e-3dce-46d1-8674-97e6cd1492d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-17cbd534-eab2-4a88-8203-bf353892579a,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-1c3012d9-f7fd-4252-aabc-854d041162bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-b9deeae2-91c1-4158-a059-1b3a353ac483,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-c843ed17-87ea-48b1-81fa-4755c6eadaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-cbc0f188-b527-436e-a077-0f158fd5cfac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763820448-172.17.0.19-1596941837297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40291,DS-8abd8e70-d184-4c1a-b124-a33e9ed0cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-81cd4f41-ed3f-4d15-a3f1-27dc009a6242,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-96673d83-9cd7-4c7e-83a8-914bd72ffa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a9499fa5-b6e0-41c6-a675-9c8e8b7384d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-70941e7c-7f5f-4eab-8340-c662c330c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-2a47d52e-3647-4bfb-8bdb-5119507d69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-d9b020c9-b882-47a2-bb47-75e2a01ea005,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-21ebe268-ed01-45fc-8cf3-1a9e4adf496d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763820448-172.17.0.19-1596941837297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40291,DS-8abd8e70-d184-4c1a-b124-a33e9ed0cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-81cd4f41-ed3f-4d15-a3f1-27dc009a6242,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-96673d83-9cd7-4c7e-83a8-914bd72ffa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a9499fa5-b6e0-41c6-a675-9c8e8b7384d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-70941e7c-7f5f-4eab-8340-c662c330c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-2a47d52e-3647-4bfb-8bdb-5119507d69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-d9b020c9-b882-47a2-bb47-75e2a01ea005,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-21ebe268-ed01-45fc-8cf3-1a9e4adf496d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842983681-172.17.0.19-1596942256093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-77e7831a-0b85-400c-b8e3-c92006fff872,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-4229e270-0b49-45d1-bb2f-c4549f65d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-9186fedb-ccda-444f-94e1-7fcf87048a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-66c6b449-f389-4f54-a0eb-4be38792bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-a4e6a45e-6b40-4fd1-bfaf-b4a6f47ae207,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-0f04c442-d76a-4e66-a482-135d72b19c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-ba04a217-df0b-4bdc-ab25-619124396306,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-5f1dcea4-a893-4c81-8ce2-d93832171351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842983681-172.17.0.19-1596942256093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-77e7831a-0b85-400c-b8e3-c92006fff872,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-4229e270-0b49-45d1-bb2f-c4549f65d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-9186fedb-ccda-444f-94e1-7fcf87048a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-66c6b449-f389-4f54-a0eb-4be38792bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-a4e6a45e-6b40-4fd1-bfaf-b4a6f47ae207,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-0f04c442-d76a-4e66-a482-135d72b19c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-ba04a217-df0b-4bdc-ab25-619124396306,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-5f1dcea4-a893-4c81-8ce2-d93832171351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962740479-172.17.0.19-1596942532927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46026,DS-0bdedb7b-144c-4ccf-9360-0cef2e87ce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-1f1b36cc-e3ad-4479-b6a1-2b6b83efe65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-42573ef1-ab96-4ff5-af33-860ceeb5938f,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-e1ad3364-eac1-4f7b-9215-7d1ab5a4401a,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-764064ac-160a-40ee-9c1f-fcfabe2ab2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-6535d647-22f0-4f10-b165-9eb8b1b99706,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-ff0faeea-516f-4df9-b419-db45d66c57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-8274a4af-f1d2-4c09-8a26-5b9decaf559f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962740479-172.17.0.19-1596942532927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46026,DS-0bdedb7b-144c-4ccf-9360-0cef2e87ce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-1f1b36cc-e3ad-4479-b6a1-2b6b83efe65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-42573ef1-ab96-4ff5-af33-860ceeb5938f,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-e1ad3364-eac1-4f7b-9215-7d1ab5a4401a,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-764064ac-160a-40ee-9c1f-fcfabe2ab2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-6535d647-22f0-4f10-b165-9eb8b1b99706,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-ff0faeea-516f-4df9-b419-db45d66c57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-8274a4af-f1d2-4c09-8a26-5b9decaf559f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860288342-172.17.0.19-1596943061833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-075116a1-fce3-43d3-b7ee-f55c68b7fa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-392d2532-b81d-4a06-acaa-a889ec1c7979,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-6c34b257-5629-4294-9a6b-3eb9f3aadf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-5e9245fd-40b8-43e0-9b6b-64fc842c5bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-0a985436-2c9c-4f6a-8a35-fe6cb8f07ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-ff50dbce-afeb-4175-8f3d-1e1700a06f60,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-afed21a4-17f0-4949-9aa5-5b82b1215db1,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-abaad965-264d-46a0-a0bb-b172d32e5f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860288342-172.17.0.19-1596943061833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-075116a1-fce3-43d3-b7ee-f55c68b7fa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-392d2532-b81d-4a06-acaa-a889ec1c7979,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-6c34b257-5629-4294-9a6b-3eb9f3aadf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-5e9245fd-40b8-43e0-9b6b-64fc842c5bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-0a985436-2c9c-4f6a-8a35-fe6cb8f07ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-ff50dbce-afeb-4175-8f3d-1e1700a06f60,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-afed21a4-17f0-4949-9aa5-5b82b1215db1,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-abaad965-264d-46a0-a0bb-b172d32e5f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478646724-172.17.0.19-1596943545594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-0545a417-ce28-4711-9a53-83e02482dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-a323daed-aeba-4030-ae25-7ac6b6230a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-b9eeedcc-1473-471f-b362-5af796a30b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-bbbed9ed-e200-4299-9bd3-a352f170096c,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-56582fae-c815-46b9-9673-03c881311e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-0c99e146-0b0b-4668-b436-e8c9d7698fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-66d27eb8-d76e-4894-9018-3ce4f93fb7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-f19ebdba-e924-4f01-a508-455de3ec1564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478646724-172.17.0.19-1596943545594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-0545a417-ce28-4711-9a53-83e02482dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-a323daed-aeba-4030-ae25-7ac6b6230a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-b9eeedcc-1473-471f-b362-5af796a30b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-bbbed9ed-e200-4299-9bd3-a352f170096c,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-56582fae-c815-46b9-9673-03c881311e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-0c99e146-0b0b-4668-b436-e8c9d7698fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-66d27eb8-d76e-4894-9018-3ce4f93fb7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-f19ebdba-e924-4f01-a508-455de3ec1564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77063198-172.17.0.19-1596943961976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37322,DS-5347d1e8-d2c7-419c-ba3e-115fc0b02a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-0f6e85a7-e9b3-4642-8b94-d5bcd16d7662,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-3cf23bcb-9394-4ea9-bd89-7871066f06d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-35ef84a2-bd7e-4811-98e8-c80acddb3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-6f3f929a-99e8-4c39-92ad-f51c5d92466d,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-5e142e19-1a4a-4913-9261-4b915e321656,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-14aeaf4d-5887-462e-a3fe-5c39e68dc4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-068dd7ac-9034-425e-a3a6-07929f5b0d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77063198-172.17.0.19-1596943961976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37322,DS-5347d1e8-d2c7-419c-ba3e-115fc0b02a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-0f6e85a7-e9b3-4642-8b94-d5bcd16d7662,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-3cf23bcb-9394-4ea9-bd89-7871066f06d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-35ef84a2-bd7e-4811-98e8-c80acddb3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-6f3f929a-99e8-4c39-92ad-f51c5d92466d,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-5e142e19-1a4a-4913-9261-4b915e321656,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-14aeaf4d-5887-462e-a3fe-5c39e68dc4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-068dd7ac-9034-425e-a3a6-07929f5b0d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238709578-172.17.0.19-1596944087853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-4fea5c9a-ae6c-474f-bc33-0ecfe50d6d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-0fda3dce-279a-4d24-baae-d8abba904807,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-98eac786-2796-421c-a4dd-99de6c7ba2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-e5ed719f-c127-45f9-b2e4-bdd8f38dbb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-01445e3d-81dd-4d8e-a892-abde5870d700,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-a50de949-2532-481e-b251-e081b2c7bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-788903bb-9bbf-4777-8323-3ca0ddc82f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-8ab0bce4-46e7-420c-b07b-0133b8787893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238709578-172.17.0.19-1596944087853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-4fea5c9a-ae6c-474f-bc33-0ecfe50d6d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-0fda3dce-279a-4d24-baae-d8abba904807,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-98eac786-2796-421c-a4dd-99de6c7ba2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-e5ed719f-c127-45f9-b2e4-bdd8f38dbb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-01445e3d-81dd-4d8e-a892-abde5870d700,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-a50de949-2532-481e-b251-e081b2c7bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-788903bb-9bbf-4777-8323-3ca0ddc82f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-8ab0bce4-46e7-420c-b07b-0133b8787893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143045877-172.17.0.19-1596944134482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34041,DS-e0231890-b15d-4d54-9df3-22262d5fab15,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-c1d74ee6-200e-4df2-9e76-2465c1240e89,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-8db78c43-37c9-4626-9845-dd7073cf8428,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-5c2fcbee-cbc1-45c8-9f22-6a98f2db1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-1e29dd8c-d34a-43b9-8e62-15edc2a9315f,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-df84d42a-9a3a-4d27-bac5-6af48edb46ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a4a7e178-08af-4ee9-ae3e-38fdfe748216,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-fc373ca4-b534-432c-965c-79eb6666d970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143045877-172.17.0.19-1596944134482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34041,DS-e0231890-b15d-4d54-9df3-22262d5fab15,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-c1d74ee6-200e-4df2-9e76-2465c1240e89,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-8db78c43-37c9-4626-9845-dd7073cf8428,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-5c2fcbee-cbc1-45c8-9f22-6a98f2db1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-1e29dd8c-d34a-43b9-8e62-15edc2a9315f,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-df84d42a-9a3a-4d27-bac5-6af48edb46ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a4a7e178-08af-4ee9-ae3e-38fdfe748216,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-fc373ca4-b534-432c-965c-79eb6666d970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6756
