reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471221271-172.17.0.2-1596926361867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-721b8708-9cdc-494b-8719-7e6affcc870d,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-3e364043-275d-4830-a5b1-2d3f8bd5dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c66a5fdf-d35c-4e24-baf6-47fd9475042c,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-3eb5ac1f-6f3b-4064-86c5-5795d0ae91bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-337c505f-91e0-46eb-b669-7f0d879c6ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-8e198c1c-c787-495d-9e43-53b2e415ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-ba73f1e6-0c36-468e-bc17-c7bdb6a97a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-6bb30441-70e4-4b50-ab0e-c18fb54bf569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471221271-172.17.0.2-1596926361867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-721b8708-9cdc-494b-8719-7e6affcc870d,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-3e364043-275d-4830-a5b1-2d3f8bd5dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c66a5fdf-d35c-4e24-baf6-47fd9475042c,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-3eb5ac1f-6f3b-4064-86c5-5795d0ae91bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-337c505f-91e0-46eb-b669-7f0d879c6ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-8e198c1c-c787-495d-9e43-53b2e415ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-ba73f1e6-0c36-468e-bc17-c7bdb6a97a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-6bb30441-70e4-4b50-ab0e-c18fb54bf569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596198463-172.17.0.2-1596926730263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46256,DS-e44f026e-6483-4fe1-bdb5-03cb2c4b1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-702222d4-5752-4996-ba38-be4d34e6ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-51470a99-dfc8-4306-a6a2-b048bd0069e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c3516295-741c-4300-8899-7b1cdc44d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-5373e4cc-1a28-478f-99cd-ebf19e44a714,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-5228a87e-3dc8-4fc3-beaf-d601bdedc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-3a6edb67-3a25-41ea-8d10-73071bbf303b,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-f7a35260-738a-4d66-94f6-47a22835034f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596198463-172.17.0.2-1596926730263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46256,DS-e44f026e-6483-4fe1-bdb5-03cb2c4b1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-702222d4-5752-4996-ba38-be4d34e6ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-51470a99-dfc8-4306-a6a2-b048bd0069e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c3516295-741c-4300-8899-7b1cdc44d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-5373e4cc-1a28-478f-99cd-ebf19e44a714,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-5228a87e-3dc8-4fc3-beaf-d601bdedc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-3a6edb67-3a25-41ea-8d10-73071bbf303b,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-f7a35260-738a-4d66-94f6-47a22835034f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573306135-172.17.0.2-1596927026289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-7e138e57-ec4e-4225-a9f2-4a00b9922a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-8b7b0252-47d2-435c-a50c-e7b89aae37c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-dad84957-96f9-4c22-8483-dda12b216c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-81987fae-7252-4ee3-8be2-ee2ccc07daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-ec23c735-edcb-4593-99ad-f32017954c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-f876d73b-c56c-4a46-92c7-5de1b742de3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-d083a56b-6147-4ab9-9da3-2bb1cc9a12a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d4c6ecb4-7b6a-41f7-adfc-1bd389fd9a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573306135-172.17.0.2-1596927026289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-7e138e57-ec4e-4225-a9f2-4a00b9922a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-8b7b0252-47d2-435c-a50c-e7b89aae37c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-dad84957-96f9-4c22-8483-dda12b216c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-81987fae-7252-4ee3-8be2-ee2ccc07daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-ec23c735-edcb-4593-99ad-f32017954c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-f876d73b-c56c-4a46-92c7-5de1b742de3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-d083a56b-6147-4ab9-9da3-2bb1cc9a12a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d4c6ecb4-7b6a-41f7-adfc-1bd389fd9a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682852388-172.17.0.2-1596927695707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-fb0ceb34-da85-4ee6-8c03-64cee2f3cea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-67ac26ca-eecf-457c-96fe-ddd1868bfb04,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-24526e23-07eb-43f6-a208-d1cb1cc4cea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-e4914d22-16d0-40a8-bcb6-d00c56910a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-a070d1e1-e949-4d85-bb9e-48289c7c8b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-849cc5c8-bad2-46c0-a768-72bc3b983d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-8536d867-ab9a-412f-8d87-e257000dac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-ff074b84-8f00-4e63-8f41-f56dc9b672b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682852388-172.17.0.2-1596927695707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-fb0ceb34-da85-4ee6-8c03-64cee2f3cea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-67ac26ca-eecf-457c-96fe-ddd1868bfb04,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-24526e23-07eb-43f6-a208-d1cb1cc4cea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-e4914d22-16d0-40a8-bcb6-d00c56910a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-a070d1e1-e949-4d85-bb9e-48289c7c8b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-849cc5c8-bad2-46c0-a768-72bc3b983d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-8536d867-ab9a-412f-8d87-e257000dac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-ff074b84-8f00-4e63-8f41-f56dc9b672b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715918686-172.17.0.2-1596927804414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-facc85c6-5c19-449f-8f81-5a24de99ea53,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-22dfa637-6489-40a6-b815-aba21ef91b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-0632f70c-d9fb-4e47-906e-5571c997557d,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-cfddfe2a-3aee-422a-be10-48770903927b,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-af6cf25e-2dda-4e34-9faa-ebcececb217f,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-e90e07b6-3e1f-42b8-883f-e4a840fcb412,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-a3b4e404-c452-4230-8326-c9b046c14093,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-466d4729-89af-4e92-acff-c9c9afdd3e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715918686-172.17.0.2-1596927804414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-facc85c6-5c19-449f-8f81-5a24de99ea53,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-22dfa637-6489-40a6-b815-aba21ef91b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-0632f70c-d9fb-4e47-906e-5571c997557d,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-cfddfe2a-3aee-422a-be10-48770903927b,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-af6cf25e-2dda-4e34-9faa-ebcececb217f,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-e90e07b6-3e1f-42b8-883f-e4a840fcb412,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-a3b4e404-c452-4230-8326-c9b046c14093,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-466d4729-89af-4e92-acff-c9c9afdd3e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083980460-172.17.0.2-1596927837768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-41e49ce7-dcaa-468f-8b6e-746bd1510139,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-9e9902c4-7ec1-420c-9333-d06b9b3d3d68,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-458d4f61-bca5-4b6c-97a6-7017c1249484,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-2daa8ead-36e7-4deb-8a9d-2d5b6ec50e18,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-f2db30c4-02f0-4a41-a930-aab7f144b4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-cb6466b7-aea0-4da5-895e-d15eb864b311,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-24bf8f2c-7b9d-4dd9-acfa-ca6528c2a926,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-2b97393e-f426-4ea2-8bcc-6a0bb387ce2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083980460-172.17.0.2-1596927837768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-41e49ce7-dcaa-468f-8b6e-746bd1510139,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-9e9902c4-7ec1-420c-9333-d06b9b3d3d68,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-458d4f61-bca5-4b6c-97a6-7017c1249484,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-2daa8ead-36e7-4deb-8a9d-2d5b6ec50e18,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-f2db30c4-02f0-4a41-a930-aab7f144b4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-cb6466b7-aea0-4da5-895e-d15eb864b311,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-24bf8f2c-7b9d-4dd9-acfa-ca6528c2a926,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-2b97393e-f426-4ea2-8bcc-6a0bb387ce2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708435602-172.17.0.2-1596927862645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34971,DS-a303af66-9ecb-4e7f-89ad-4e18d69609f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-425a3620-99bb-4762-8618-deca33abc1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-98632d27-e1e8-4d35-b190-015ec9cc1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-7bb459e7-7413-4e88-a8ae-e34a700abd17,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-aa490cff-54b5-410c-af0a-386b662d70a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-26580059-3bcd-48d3-9c80-8e095b4a7229,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-23f9c506-5fbd-4b62-a023-6c71222d25a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-5521b09d-48c2-402e-aeff-62efbfc1ec79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708435602-172.17.0.2-1596927862645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34971,DS-a303af66-9ecb-4e7f-89ad-4e18d69609f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-425a3620-99bb-4762-8618-deca33abc1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-98632d27-e1e8-4d35-b190-015ec9cc1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-7bb459e7-7413-4e88-a8ae-e34a700abd17,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-aa490cff-54b5-410c-af0a-386b662d70a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-26580059-3bcd-48d3-9c80-8e095b4a7229,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-23f9c506-5fbd-4b62-a023-6c71222d25a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-5521b09d-48c2-402e-aeff-62efbfc1ec79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039674237-172.17.0.2-1596927966378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41655,DS-33656ee1-5fa5-43c1-9bc6-63d8a0d36fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-589642f2-ffb1-4979-877f-47a95dbcc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-d5fb53e6-a654-45bb-82c4-07c3fe603556,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-4c34ed7d-3078-467d-822a-5968104e2a81,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-9f28c3b5-8fc1-4d21-9eaf-76ddf603bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-ba629abe-c82a-48fb-a4e3-c3e2b1746f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-0d6d4157-00d4-4d19-94e2-8346d01f8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-b631e964-a298-4886-a042-9ebc2d1390d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039674237-172.17.0.2-1596927966378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41655,DS-33656ee1-5fa5-43c1-9bc6-63d8a0d36fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-589642f2-ffb1-4979-877f-47a95dbcc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-d5fb53e6-a654-45bb-82c4-07c3fe603556,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-4c34ed7d-3078-467d-822a-5968104e2a81,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-9f28c3b5-8fc1-4d21-9eaf-76ddf603bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-ba629abe-c82a-48fb-a4e3-c3e2b1746f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-0d6d4157-00d4-4d19-94e2-8346d01f8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-b631e964-a298-4886-a042-9ebc2d1390d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855962739-172.17.0.2-1596928122231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-2ece44b1-2a6f-4734-a2ff-8be989044186,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-7a4564a6-d95f-4cbb-9480-ae35f346950b,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-058f2f45-dc29-4c76-bed3-c117263adf93,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-818cbc84-1816-4e92-bd8b-2e11a650f101,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-0194a929-ec9a-413d-86c9-4321e0b7bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-db9891cf-0380-47e8-a0f7-7b223b24137e,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-05435815-9d2d-41e1-ba7d-b24c3f732055,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-1cb7e818-bb1a-4a6a-b2cc-9b9714130b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855962739-172.17.0.2-1596928122231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-2ece44b1-2a6f-4734-a2ff-8be989044186,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-7a4564a6-d95f-4cbb-9480-ae35f346950b,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-058f2f45-dc29-4c76-bed3-c117263adf93,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-818cbc84-1816-4e92-bd8b-2e11a650f101,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-0194a929-ec9a-413d-86c9-4321e0b7bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-db9891cf-0380-47e8-a0f7-7b223b24137e,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-05435815-9d2d-41e1-ba7d-b24c3f732055,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-1cb7e818-bb1a-4a6a-b2cc-9b9714130b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865580840-172.17.0.2-1596928152280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37984,DS-a2dd3e90-a1c3-4115-aaa8-3bbf00f47829,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-cfffc174-168f-4af8-a46c-d7663d948e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-2be00334-e989-498d-9189-ba97cb46dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-c69ace1c-1f6a-4f83-bbf0-0abf6e71c399,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-bcb621df-e465-43bb-9185-1b5f73e4751a,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-bc8f84db-e506-4c6b-8ab0-3e2e77282bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-7d16c69b-c858-4345-a432-6cdab84442f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-2628bf25-d746-4692-a368-ef37c4cc033c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865580840-172.17.0.2-1596928152280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37984,DS-a2dd3e90-a1c3-4115-aaa8-3bbf00f47829,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-cfffc174-168f-4af8-a46c-d7663d948e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-2be00334-e989-498d-9189-ba97cb46dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-c69ace1c-1f6a-4f83-bbf0-0abf6e71c399,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-bcb621df-e465-43bb-9185-1b5f73e4751a,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-bc8f84db-e506-4c6b-8ab0-3e2e77282bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-7d16c69b-c858-4345-a432-6cdab84442f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-2628bf25-d746-4692-a368-ef37c4cc033c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286768804-172.17.0.2-1596928595396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-db9fda44-c763-4dd2-bb60-442d6bc55c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-fdc43a81-a01b-4979-a29d-24dd00c481d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-4f4f496e-77f5-4c44-9852-0ad216e6aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-d3936a64-8754-44da-a5ec-d26d0a8259e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-a4fd00fa-b77d-4b75-9991-b508e1360649,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-f4ace2cc-5db1-4726-ac25-237a24d6f081,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-a7a2ba0e-40d9-4116-ab3f-bae86a1dfe85,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-a403480d-d13e-41c0-b9b9-167dc4e7a778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286768804-172.17.0.2-1596928595396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-db9fda44-c763-4dd2-bb60-442d6bc55c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-fdc43a81-a01b-4979-a29d-24dd00c481d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-4f4f496e-77f5-4c44-9852-0ad216e6aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-d3936a64-8754-44da-a5ec-d26d0a8259e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-a4fd00fa-b77d-4b75-9991-b508e1360649,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-f4ace2cc-5db1-4726-ac25-237a24d6f081,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-a7a2ba0e-40d9-4116-ab3f-bae86a1dfe85,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-a403480d-d13e-41c0-b9b9-167dc4e7a778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712244434-172.17.0.2-1596928965476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40128,DS-9395ebca-0cc7-4c63-95eb-b6b840e00cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-6d5645c4-a5f9-4483-9e1f-db45299d11dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-dd0941fd-18df-4e12-a97a-4b6b17dff86c,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-70a77578-4ce9-4598-9551-0ef84bf78b85,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-bbbe1189-0d3d-4396-a88e-7bb636827556,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-0117ce2e-a8dc-483b-99ae-689895902cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-a659a25a-295b-4335-b103-c096b61a02d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-468d0537-7cfa-4b84-a90b-4bbbaa1d9cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712244434-172.17.0.2-1596928965476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40128,DS-9395ebca-0cc7-4c63-95eb-b6b840e00cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-6d5645c4-a5f9-4483-9e1f-db45299d11dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-dd0941fd-18df-4e12-a97a-4b6b17dff86c,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-70a77578-4ce9-4598-9551-0ef84bf78b85,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-bbbe1189-0d3d-4396-a88e-7bb636827556,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-0117ce2e-a8dc-483b-99ae-689895902cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-a659a25a-295b-4335-b103-c096b61a02d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-468d0537-7cfa-4b84-a90b-4bbbaa1d9cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779102210-172.17.0.2-1596929024413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-5a8446fb-4374-4a60-ab63-b5cb06ade090,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-1b45ba91-740f-44bc-90e9-61310da9c899,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-12c16ecd-1c4c-4d66-be3d-a69392b0e778,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-3fac2fce-e5c9-4c05-97d9-de04a86cc151,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-906a2ab9-4178-449e-9243-346ae5ba6c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-0c7ff56f-5941-4370-b3c8-abfca7c4e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-8e059aad-587a-4882-8281-2789d313a005,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-15bdd48e-29b7-4ba7-86ab-178e85a13dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779102210-172.17.0.2-1596929024413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-5a8446fb-4374-4a60-ab63-b5cb06ade090,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-1b45ba91-740f-44bc-90e9-61310da9c899,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-12c16ecd-1c4c-4d66-be3d-a69392b0e778,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-3fac2fce-e5c9-4c05-97d9-de04a86cc151,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-906a2ab9-4178-449e-9243-346ae5ba6c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-0c7ff56f-5941-4370-b3c8-abfca7c4e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-8e059aad-587a-4882-8281-2789d313a005,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-15bdd48e-29b7-4ba7-86ab-178e85a13dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409879015-172.17.0.2-1596929564904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34289,DS-15fd56b4-173f-444f-b74f-97973a7b856a,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-5524cc92-9524-48f7-a571-507ff380d678,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-892804dc-fed2-4e76-8db5-2b8efe65cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-abf5f75d-8931-4b62-a353-4e209a98fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-fe6df460-0597-4385-9328-56a62a17d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-59d7555c-de5a-4f2b-a8db-df78a0d381f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-a4882195-e6cf-4ef8-a4ae-578652ab5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9be90b75-fbb3-4935-a9e4-b534d0ff3ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409879015-172.17.0.2-1596929564904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34289,DS-15fd56b4-173f-444f-b74f-97973a7b856a,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-5524cc92-9524-48f7-a571-507ff380d678,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-892804dc-fed2-4e76-8db5-2b8efe65cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-abf5f75d-8931-4b62-a353-4e209a98fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-fe6df460-0597-4385-9328-56a62a17d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-59d7555c-de5a-4f2b-a8db-df78a0d381f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-a4882195-e6cf-4ef8-a4ae-578652ab5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9be90b75-fbb3-4935-a9e4-b534d0ff3ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466063014-172.17.0.2-1596929812208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39008,DS-0c393b42-bda9-4006-b849-2ab3d23f677b,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-df5dd13d-9064-4fc8-8f6f-c6d2d43b3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-02cb44aa-1866-4556-9613-faf1bf836e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-9cac4f8b-ea7b-429f-acbd-eb68028a2627,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-49d461ac-f184-46a4-aa8b-d536615b26f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-5177b794-1013-4262-8764-f617a5bb5c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b71d738a-b6b6-41a8-b28d-6254b4bf4904,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-52af9169-f030-46ba-a750-a8a3d39c3e75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466063014-172.17.0.2-1596929812208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39008,DS-0c393b42-bda9-4006-b849-2ab3d23f677b,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-df5dd13d-9064-4fc8-8f6f-c6d2d43b3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-02cb44aa-1866-4556-9613-faf1bf836e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-9cac4f8b-ea7b-429f-acbd-eb68028a2627,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-49d461ac-f184-46a4-aa8b-d536615b26f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-5177b794-1013-4262-8764-f617a5bb5c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b71d738a-b6b6-41a8-b28d-6254b4bf4904,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-52af9169-f030-46ba-a750-a8a3d39c3e75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213502619-172.17.0.2-1596929881523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39325,DS-80990b64-b5e1-443b-b48c-30270cd2c201,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-4207fd4e-b55f-4a33-8464-7e44f80b3e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-6829f921-ed28-4475-82fd-43148eeb1558,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-26f7af00-81bc-4f25-9f03-1a2cfc47981a,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-3db89847-dfde-44e8-8be2-45bf799e6827,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-3e4defb1-da19-48df-9d91-f7fee138feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-ad5c3866-ed0c-4727-bef7-731ae629d21f,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-0f705330-9882-4e73-b4ac-6afa457d791e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213502619-172.17.0.2-1596929881523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39325,DS-80990b64-b5e1-443b-b48c-30270cd2c201,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-4207fd4e-b55f-4a33-8464-7e44f80b3e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-6829f921-ed28-4475-82fd-43148eeb1558,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-26f7af00-81bc-4f25-9f03-1a2cfc47981a,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-3db89847-dfde-44e8-8be2-45bf799e6827,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-3e4defb1-da19-48df-9d91-f7fee138feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-ad5c3866-ed0c-4727-bef7-731ae629d21f,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-0f705330-9882-4e73-b4ac-6afa457d791e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879794164-172.17.0.2-1596930160849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-25003698-d4fa-4a18-a47a-0791a009013d,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-06ca6ca8-61e5-4dcd-bab4-9641f0afae5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-713c4e55-38a4-4e9d-888d-39d3a1fb7a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4fa38db4-313c-47cb-a037-aa7f3be8b495,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-aa5f86f8-6527-4548-8d33-2438658797a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-0e83dfcb-c912-4a81-b23e-d1c4511e6209,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-9a8a11ff-447a-4565-9c97-2a6163bc736d,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-377d1df8-4620-4f65-9a59-e5c969dfe375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879794164-172.17.0.2-1596930160849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-25003698-d4fa-4a18-a47a-0791a009013d,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-06ca6ca8-61e5-4dcd-bab4-9641f0afae5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-713c4e55-38a4-4e9d-888d-39d3a1fb7a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4fa38db4-313c-47cb-a037-aa7f3be8b495,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-aa5f86f8-6527-4548-8d33-2438658797a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-0e83dfcb-c912-4a81-b23e-d1c4511e6209,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-9a8a11ff-447a-4565-9c97-2a6163bc736d,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-377d1df8-4620-4f65-9a59-e5c969dfe375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144817677-172.17.0.2-1596930779638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-619b7454-ad1c-46b3-aeec-cc27055e2b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-bb472533-91e8-4126-ac4e-57b4d0e3941c,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-67dbf32b-5dc3-4c74-b50a-2441192e6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-e7c45266-bce2-446e-a7f3-30d732b313db,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-5c27bd02-380b-4d1e-b57f-7d9c7e048909,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-ad7b6a61-b546-46ba-bb0e-e21a7e205f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-ee34f00b-005f-43fc-ac8a-383e6ab1d136,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-f59b1fc1-e663-4d97-b2e1-e06052f9b768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144817677-172.17.0.2-1596930779638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-619b7454-ad1c-46b3-aeec-cc27055e2b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-bb472533-91e8-4126-ac4e-57b4d0e3941c,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-67dbf32b-5dc3-4c74-b50a-2441192e6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-e7c45266-bce2-446e-a7f3-30d732b313db,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-5c27bd02-380b-4d1e-b57f-7d9c7e048909,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-ad7b6a61-b546-46ba-bb0e-e21a7e205f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-ee34f00b-005f-43fc-ac8a-383e6ab1d136,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-f59b1fc1-e663-4d97-b2e1-e06052f9b768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4875
