reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919368150-172.17.0.9-1596966390886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-b5b7dbec-452c-4817-9941-59b62c59bea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-d2913641-cff4-4d1b-ab71-ee9037b009dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-51128cab-cc66-419f-93f0-7b03cbcdb100,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-3e5c7903-9dc8-4d8b-87d9-3e0ff649bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-9cbf177e-ef6d-421c-b0e4-00c2ca2ac0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-6584f6af-6cbc-4c5d-b022-1b8ce6ee64a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-908a5976-f818-42e4-bc58-9f69a687e695,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-9342c32b-f52d-45bb-9d95-e3a3c84c283a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919368150-172.17.0.9-1596966390886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-b5b7dbec-452c-4817-9941-59b62c59bea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-d2913641-cff4-4d1b-ab71-ee9037b009dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-51128cab-cc66-419f-93f0-7b03cbcdb100,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-3e5c7903-9dc8-4d8b-87d9-3e0ff649bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-9cbf177e-ef6d-421c-b0e4-00c2ca2ac0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-6584f6af-6cbc-4c5d-b022-1b8ce6ee64a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-908a5976-f818-42e4-bc58-9f69a687e695,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-9342c32b-f52d-45bb-9d95-e3a3c84c283a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861634489-172.17.0.9-1596967043772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-cea9fd4c-7f2e-4682-ab67-9da59270ccae,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-11bb2a59-7c66-478e-9dca-4a09400d3ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-e6127c3c-5b8b-4492-b05b-7414d7ed7bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-3e045453-8856-41d4-b78c-cf47fac5a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-f9a79445-132e-497f-ba54-38b7eb631e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-123c5a68-4af1-4b16-b54b-ef10a8ddadc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-66e5eac2-8e7c-4957-ad2e-1d7d435c3a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-2d987adb-e377-4d14-a956-3f53f7b38cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861634489-172.17.0.9-1596967043772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-cea9fd4c-7f2e-4682-ab67-9da59270ccae,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-11bb2a59-7c66-478e-9dca-4a09400d3ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-e6127c3c-5b8b-4492-b05b-7414d7ed7bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-3e045453-8856-41d4-b78c-cf47fac5a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-f9a79445-132e-497f-ba54-38b7eb631e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-123c5a68-4af1-4b16-b54b-ef10a8ddadc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-66e5eac2-8e7c-4957-ad2e-1d7d435c3a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-2d987adb-e377-4d14-a956-3f53f7b38cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552906103-172.17.0.9-1596967237419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39234,DS-12bb05cd-b657-4f9b-bc7e-0a5c5085f401,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-cb9dfc9c-8a61-4b5a-a413-668752a48d67,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-e9ae3e08-7d6c-44c3-a259-e15f0d790ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-ac17b860-1a9f-4650-ae78-fb41b70fb6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-85743f53-f202-4e62-bcaf-9456e4c40af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-752e9723-f8f7-45c5-9b14-093e63206f76,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-32877733-a9fe-47ec-8ac6-8749b76d711b,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-7d022ad8-e506-4616-8bb5-99b437719708,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552906103-172.17.0.9-1596967237419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39234,DS-12bb05cd-b657-4f9b-bc7e-0a5c5085f401,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-cb9dfc9c-8a61-4b5a-a413-668752a48d67,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-e9ae3e08-7d6c-44c3-a259-e15f0d790ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-ac17b860-1a9f-4650-ae78-fb41b70fb6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-85743f53-f202-4e62-bcaf-9456e4c40af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-752e9723-f8f7-45c5-9b14-093e63206f76,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-32877733-a9fe-47ec-8ac6-8749b76d711b,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-7d022ad8-e506-4616-8bb5-99b437719708,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291257445-172.17.0.9-1596968274380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-4e4b77f9-8232-49fa-b7c9-4b0e96addfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-1bbfdb3c-e7e1-44fb-810d-170e2f7f746d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-5032a52e-2220-4a49-8323-3db33f31b738,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-b1a6a7cd-5662-4b56-b9e1-8b83cd583a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-331bf7a7-9765-4014-9e28-a43d7931e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-12f11350-7c3c-4b72-997e-c5fa7c5f2959,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-8e786df7-cd9e-4580-9717-e5ae90f610b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-13eae89d-e4b8-49de-885b-c2c07d3014ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291257445-172.17.0.9-1596968274380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-4e4b77f9-8232-49fa-b7c9-4b0e96addfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-1bbfdb3c-e7e1-44fb-810d-170e2f7f746d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-5032a52e-2220-4a49-8323-3db33f31b738,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-b1a6a7cd-5662-4b56-b9e1-8b83cd583a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-331bf7a7-9765-4014-9e28-a43d7931e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-12f11350-7c3c-4b72-997e-c5fa7c5f2959,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-8e786df7-cd9e-4580-9717-e5ae90f610b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-13eae89d-e4b8-49de-885b-c2c07d3014ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569859083-172.17.0.9-1596968762813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42987,DS-8824e856-d505-4623-a58b-8dff5bef2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-66b8e40a-56ee-47dc-8bb7-95f0cd1e4716,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-346b5ad9-2814-405a-ab41-4562a98fa2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-1df11afb-da60-46f4-b1bd-d8ae8e523dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-76a4bad6-c6ef-4009-8893-8d92a7fc1504,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-cedd345e-3097-4275-8871-73f4440120a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-0219fd5d-2473-4cf0-b460-097be0adc757,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-ece988da-f72c-469a-adbf-62e9841ce1b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569859083-172.17.0.9-1596968762813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42987,DS-8824e856-d505-4623-a58b-8dff5bef2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-66b8e40a-56ee-47dc-8bb7-95f0cd1e4716,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-346b5ad9-2814-405a-ab41-4562a98fa2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-1df11afb-da60-46f4-b1bd-d8ae8e523dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-76a4bad6-c6ef-4009-8893-8d92a7fc1504,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-cedd345e-3097-4275-8871-73f4440120a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-0219fd5d-2473-4cf0-b460-097be0adc757,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-ece988da-f72c-469a-adbf-62e9841ce1b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621153600-172.17.0.9-1596968797903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-24d11ea5-d431-4fed-95e1-8796ec325416,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-9c9dd18d-9229-4993-82a3-bc3b9da63d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-05bff11b-ad0b-4e19-8f7b-b0c74008a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-30d3e32e-f74d-4280-9a34-98bf22c88524,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e4a4707e-f2f1-42b2-b0d2-9c3fa5aeae56,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-dc05b0b9-0664-48c7-b95c-36f1dcc11408,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-40af7fd4-9729-4701-b57e-d5452b3f7b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-3cd3b814-09ba-47cf-9236-abbe93651edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621153600-172.17.0.9-1596968797903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-24d11ea5-d431-4fed-95e1-8796ec325416,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-9c9dd18d-9229-4993-82a3-bc3b9da63d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-05bff11b-ad0b-4e19-8f7b-b0c74008a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-30d3e32e-f74d-4280-9a34-98bf22c88524,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e4a4707e-f2f1-42b2-b0d2-9c3fa5aeae56,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-dc05b0b9-0664-48c7-b95c-36f1dcc11408,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-40af7fd4-9729-4701-b57e-d5452b3f7b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-3cd3b814-09ba-47cf-9236-abbe93651edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797588684-172.17.0.9-1596968877590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-e78828b8-7fb3-493e-85a3-020892cf1a11,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-6ddf1735-fd42-4e1c-a6ea-3598de642738,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-0f63d157-e03c-4590-9af9-37893d49a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-fadba9be-0f26-48ac-a7af-46b965b624fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-a9dd15c7-3929-49dc-b51f-caf7e7cb1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-1a73e1fe-8777-40d2-a252-453327c84147,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-5f1c85f0-ab16-46be-b93e-c5a43a242027,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-3c8eaadc-7f24-49f6-b2e1-40001eb986f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797588684-172.17.0.9-1596968877590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-e78828b8-7fb3-493e-85a3-020892cf1a11,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-6ddf1735-fd42-4e1c-a6ea-3598de642738,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-0f63d157-e03c-4590-9af9-37893d49a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-fadba9be-0f26-48ac-a7af-46b965b624fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-a9dd15c7-3929-49dc-b51f-caf7e7cb1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-1a73e1fe-8777-40d2-a252-453327c84147,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-5f1c85f0-ab16-46be-b93e-c5a43a242027,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-3c8eaadc-7f24-49f6-b2e1-40001eb986f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877181625-172.17.0.9-1596970087578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-9b2bb3ed-a24d-4458-bc5d-019ef6d1de81,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-b6ded3a1-0d5b-49ac-81d1-69c4683e4925,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-eac2f4a8-af90-408a-bd1b-dff926309c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-4468d883-1bd7-491e-8df3-90c4855db3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-a227b7ff-bb2d-4b66-8b00-659b5245407a,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-0804cafc-f966-48d1-bbe7-32ebabf8086d,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-4ad54cae-8355-4f8a-b284-1e8154633cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-9eda7302-281d-48c2-8a10-73eb1cb07f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877181625-172.17.0.9-1596970087578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-9b2bb3ed-a24d-4458-bc5d-019ef6d1de81,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-b6ded3a1-0d5b-49ac-81d1-69c4683e4925,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-eac2f4a8-af90-408a-bd1b-dff926309c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-4468d883-1bd7-491e-8df3-90c4855db3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-a227b7ff-bb2d-4b66-8b00-659b5245407a,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-0804cafc-f966-48d1-bbe7-32ebabf8086d,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-4ad54cae-8355-4f8a-b284-1e8154633cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-9eda7302-281d-48c2-8a10-73eb1cb07f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010996932-172.17.0.9-1596970165413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-94898b14-94e6-4ad4-9746-445e948e68ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-dfd1f809-a16a-4f0c-90a7-7f37c91813ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-5177244c-4788-4a72-8e16-e27a0351411b,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-d768ec88-c32b-40dd-99a7-e5be4341b4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-da396a07-93ce-4933-a09a-57cc8c682fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1301e2ae-e3a5-4a3a-8133-b41d08f9e394,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-9add61fe-e26b-481f-925e-1657f982dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-9877e80b-a928-4ce4-b1e9-3a1a2b211786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010996932-172.17.0.9-1596970165413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-94898b14-94e6-4ad4-9746-445e948e68ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-dfd1f809-a16a-4f0c-90a7-7f37c91813ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-5177244c-4788-4a72-8e16-e27a0351411b,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-d768ec88-c32b-40dd-99a7-e5be4341b4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-da396a07-93ce-4933-a09a-57cc8c682fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1301e2ae-e3a5-4a3a-8133-b41d08f9e394,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-9add61fe-e26b-481f-925e-1657f982dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-9877e80b-a928-4ce4-b1e9-3a1a2b211786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829357022-172.17.0.9-1596970210136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-3070fe33-72b9-42cd-b24c-5865adfa132a,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-9cec38f4-2d5d-47cf-90e0-1e34edf3d6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-1aa99ef8-1e23-466c-a88f-ef4d86938aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-9f18e8e8-41e1-4f1d-b78a-774f65c9c10e,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-8b94dab7-5162-4434-ba5d-053477980428,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-45d39ef6-7da7-466a-84e0-867155fb99c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-7a42355c-3095-4cfa-94e9-3045309c8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-09ac3b83-d94a-4524-9c2c-2f3cb0ecdbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829357022-172.17.0.9-1596970210136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-3070fe33-72b9-42cd-b24c-5865adfa132a,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-9cec38f4-2d5d-47cf-90e0-1e34edf3d6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-1aa99ef8-1e23-466c-a88f-ef4d86938aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-9f18e8e8-41e1-4f1d-b78a-774f65c9c10e,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-8b94dab7-5162-4434-ba5d-053477980428,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-45d39ef6-7da7-466a-84e0-867155fb99c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-7a42355c-3095-4cfa-94e9-3045309c8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-09ac3b83-d94a-4524-9c2c-2f3cb0ecdbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014149654-172.17.0.9-1596970343569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45624,DS-c1a86c8a-1233-4331-b686-8e06771fb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-e7aba68f-ab2c-4a3b-a398-15640f95b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-818b1f33-f94e-4be7-b759-3552e6e5ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-a9436d04-26d6-4214-85d6-aa3f6a527101,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-81b9a8c9-ca38-47c7-beea-90093151f422,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-72336641-568d-41ee-bd66-e533d5a72195,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-2e7c45c6-01f5-4ee6-9515-40c3322a7ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-373429c6-f020-4f18-9642-c17deba636ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014149654-172.17.0.9-1596970343569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45624,DS-c1a86c8a-1233-4331-b686-8e06771fb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-e7aba68f-ab2c-4a3b-a398-15640f95b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-818b1f33-f94e-4be7-b759-3552e6e5ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-a9436d04-26d6-4214-85d6-aa3f6a527101,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-81b9a8c9-ca38-47c7-beea-90093151f422,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-72336641-568d-41ee-bd66-e533d5a72195,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-2e7c45c6-01f5-4ee6-9515-40c3322a7ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-373429c6-f020-4f18-9642-c17deba636ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916932264-172.17.0.9-1596970878982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-b981bc78-68dc-4f8a-a31e-53457456f122,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-5a404003-e4df-431b-8508-248cccf4c233,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-3fbf7b3e-757a-497e-8699-ed460e9b8e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-e701b1c1-48cd-4b76-9993-e0f990fa453c,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-53bd13ef-ee06-4ddb-be41-b09eca50bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-8bdd4263-36f5-4fe4-b6ac-7fd9d1400fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-551da8c6-2a8f-4016-acaa-beaeffdc731c,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-70c347c2-b097-4d48-a002-cdb7bac1c9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916932264-172.17.0.9-1596970878982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-b981bc78-68dc-4f8a-a31e-53457456f122,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-5a404003-e4df-431b-8508-248cccf4c233,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-3fbf7b3e-757a-497e-8699-ed460e9b8e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-e701b1c1-48cd-4b76-9993-e0f990fa453c,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-53bd13ef-ee06-4ddb-be41-b09eca50bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-8bdd4263-36f5-4fe4-b6ac-7fd9d1400fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-551da8c6-2a8f-4016-acaa-beaeffdc731c,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-70c347c2-b097-4d48-a002-cdb7bac1c9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365736421-172.17.0.9-1596971098002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-5ba7017a-a32b-4f8a-87b0-8b0f5814d0be,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-db48a4ca-1f54-4f14-a95c-e0ff967c1931,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-6881e670-d6a8-406e-9017-c839ef020f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-08e5ccd3-e2f1-451c-a88b-7adc8255f545,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-5a440753-6707-4204-882d-e93567448bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-07476980-5376-4f4f-bab5-36aba7db8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-fad133ee-aa14-45c0-88a1-0222458e6471,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-c7ec89a9-267c-4942-a03f-e8ae07b14b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365736421-172.17.0.9-1596971098002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-5ba7017a-a32b-4f8a-87b0-8b0f5814d0be,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-db48a4ca-1f54-4f14-a95c-e0ff967c1931,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-6881e670-d6a8-406e-9017-c839ef020f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-08e5ccd3-e2f1-451c-a88b-7adc8255f545,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-5a440753-6707-4204-882d-e93567448bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-07476980-5376-4f4f-bab5-36aba7db8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-fad133ee-aa14-45c0-88a1-0222458e6471,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-c7ec89a9-267c-4942-a03f-e8ae07b14b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5480
