reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274988863-172.17.0.5-1596964316176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34494,DS-fd2ca575-0243-445a-9ebb-c3ba8016e753,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-e76d6f02-34ae-41f1-b9f0-5877bce00c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-6465fff3-9931-4eda-bf92-484798bdb691,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-48f45efa-9a1d-4ecc-b50c-0dc9dacc151a,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-7e697472-e72f-47f1-80ba-e3eaf566c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-ee19cd73-74dd-4c8e-8532-01b3482ac6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-1cb83842-7ebe-42c8-a9a8-4b20b3e3e3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-c2b5ff7f-de0d-4b1f-8a1c-08768a4b8acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274988863-172.17.0.5-1596964316176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34494,DS-fd2ca575-0243-445a-9ebb-c3ba8016e753,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-e76d6f02-34ae-41f1-b9f0-5877bce00c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-6465fff3-9931-4eda-bf92-484798bdb691,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-48f45efa-9a1d-4ecc-b50c-0dc9dacc151a,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-7e697472-e72f-47f1-80ba-e3eaf566c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-ee19cd73-74dd-4c8e-8532-01b3482ac6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-1cb83842-7ebe-42c8-a9a8-4b20b3e3e3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-c2b5ff7f-de0d-4b1f-8a1c-08768a4b8acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767884000-172.17.0.5-1596964391312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32869,DS-56064c74-dadb-4453-8e01-e6cd54b08a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-a80c2405-6815-4778-a069-2c1eb07341b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-49886c1b-3eb4-4269-8507-0a729649d8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-41e72960-4989-41c9-abeb-af7a9eb3cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-cb721aab-b5b3-4593-882b-089052afe67e,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-5148e056-554d-4683-b583-77120b0a3d72,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-4099051e-85b0-4398-a9e2-a3312faf77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-8efb4fa4-d935-4106-bab7-04f315e6a291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767884000-172.17.0.5-1596964391312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32869,DS-56064c74-dadb-4453-8e01-e6cd54b08a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-a80c2405-6815-4778-a069-2c1eb07341b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-49886c1b-3eb4-4269-8507-0a729649d8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-41e72960-4989-41c9-abeb-af7a9eb3cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-cb721aab-b5b3-4593-882b-089052afe67e,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-5148e056-554d-4683-b583-77120b0a3d72,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-4099051e-85b0-4398-a9e2-a3312faf77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-8efb4fa4-d935-4106-bab7-04f315e6a291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063055234-172.17.0.5-1596965259040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-0fa6eb56-261f-4f77-9bf1-fa7b3b0a0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-33db616d-7d32-455e-bb70-d56831c8931e,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-cd985924-469c-4cec-a4b0-f0af0b5a2ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-03af682b-5fbb-4fb3-9146-c46cbbbac144,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-e8941d09-6453-4985-8412-59b978cc7369,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-8a543509-22bb-484b-85f7-8e72b7ab9041,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-a0ae5023-908a-4158-a666-3e2446ca5be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-c2c90113-3013-4ec8-a8b0-57ca6f5c4921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063055234-172.17.0.5-1596965259040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-0fa6eb56-261f-4f77-9bf1-fa7b3b0a0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-33db616d-7d32-455e-bb70-d56831c8931e,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-cd985924-469c-4cec-a4b0-f0af0b5a2ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-03af682b-5fbb-4fb3-9146-c46cbbbac144,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-e8941d09-6453-4985-8412-59b978cc7369,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-8a543509-22bb-484b-85f7-8e72b7ab9041,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-a0ae5023-908a-4158-a666-3e2446ca5be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-c2c90113-3013-4ec8-a8b0-57ca6f5c4921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393357630-172.17.0.5-1596965609720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-f70b2238-8ae6-40cf-95bc-cb6eb6e6ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-da8f35ef-6ef6-4cc6-bbb9-0ea3e661124c,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-2cba675d-f401-44cc-9c1f-757f422d7859,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-e8a0910f-3181-41d3-86ae-2025b438a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-7402fa31-5e77-4318-b722-b827db1be7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-41168c79-01ae-4078-bb03-ceaeaf717304,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-ebf8d7bf-63a7-43a9-b79a-d32ab0fa1d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-242daba7-4e65-4b66-b6b7-3bf004f9c014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393357630-172.17.0.5-1596965609720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-f70b2238-8ae6-40cf-95bc-cb6eb6e6ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-da8f35ef-6ef6-4cc6-bbb9-0ea3e661124c,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-2cba675d-f401-44cc-9c1f-757f422d7859,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-e8a0910f-3181-41d3-86ae-2025b438a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-7402fa31-5e77-4318-b722-b827db1be7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-41168c79-01ae-4078-bb03-ceaeaf717304,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-ebf8d7bf-63a7-43a9-b79a-d32ab0fa1d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-242daba7-4e65-4b66-b6b7-3bf004f9c014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201978470-172.17.0.5-1596965843567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-69446ed1-190c-4055-811a-d5603d5dbb89,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-945fe5f5-f84d-4319-8830-8a891b0615ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-3e48011e-7999-4ca7-9ae6-eb6a0dc172b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-db14be1f-9969-4e1a-8808-6ea23ba5031f,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-74b1266b-f4eb-416c-9b27-91a929ea966c,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-c6e7a682-a71a-4ba5-8715-acbab9099318,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-e564e73b-8291-4009-a42b-f6592fa300b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-a25b18ba-ea62-4254-a1c9-df25bf3f8a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201978470-172.17.0.5-1596965843567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-69446ed1-190c-4055-811a-d5603d5dbb89,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-945fe5f5-f84d-4319-8830-8a891b0615ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-3e48011e-7999-4ca7-9ae6-eb6a0dc172b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-db14be1f-9969-4e1a-8808-6ea23ba5031f,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-74b1266b-f4eb-416c-9b27-91a929ea966c,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-c6e7a682-a71a-4ba5-8715-acbab9099318,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-e564e73b-8291-4009-a42b-f6592fa300b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-a25b18ba-ea62-4254-a1c9-df25bf3f8a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476453637-172.17.0.5-1596965943187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-f5795d43-b8f5-4070-82dd-2c03faeb564a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-9503044c-ad57-4c29-bbe6-a3644c8954ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-0664b47c-1adc-4ba7-b536-28cf93649b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-eea5ff6b-2bbe-4b07-8cae-367fc3381f29,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-8cc6df2d-c269-4889-82e0-ca3c8776818f,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a0efbf65-6bdf-472a-80fb-aed7cd85353d,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3438def2-4afc-41f8-8768-a776f4745eed,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-a332c6b6-f018-4d8a-a7b2-b7c01d8ec6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476453637-172.17.0.5-1596965943187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-f5795d43-b8f5-4070-82dd-2c03faeb564a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-9503044c-ad57-4c29-bbe6-a3644c8954ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-0664b47c-1adc-4ba7-b536-28cf93649b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-eea5ff6b-2bbe-4b07-8cae-367fc3381f29,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-8cc6df2d-c269-4889-82e0-ca3c8776818f,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a0efbf65-6bdf-472a-80fb-aed7cd85353d,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3438def2-4afc-41f8-8768-a776f4745eed,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-a332c6b6-f018-4d8a-a7b2-b7c01d8ec6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635975050-172.17.0.5-1596967002007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-ffa62e82-e474-4f7c-aff1-ec1e4a1a910b,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-df727e46-4c7b-4235-8cf4-2f5b7035b4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-76bea01e-3ca2-4b97-8230-c8203ed45fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8dc7b973-f97a-4c7a-bbc6-1e06160ceb67,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-d59ee6f8-7de9-42f9-89d7-3c04bae8f645,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-4eb37854-939b-4aef-86f5-daef518f837b,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-08cf0fe9-d2e7-4d5d-b111-2b5fc65fc010,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-702a23dc-6c95-4788-a41e-1c82d124b102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635975050-172.17.0.5-1596967002007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-ffa62e82-e474-4f7c-aff1-ec1e4a1a910b,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-df727e46-4c7b-4235-8cf4-2f5b7035b4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-76bea01e-3ca2-4b97-8230-c8203ed45fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8dc7b973-f97a-4c7a-bbc6-1e06160ceb67,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-d59ee6f8-7de9-42f9-89d7-3c04bae8f645,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-4eb37854-939b-4aef-86f5-daef518f837b,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-08cf0fe9-d2e7-4d5d-b111-2b5fc65fc010,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-702a23dc-6c95-4788-a41e-1c82d124b102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566863716-172.17.0.5-1596967474259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-7bf03ea6-0710-4eff-8dd8-7b0f05d367fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-6e8e172f-69b3-4f5f-b370-c91ec08b95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-3c5f26f9-ba01-46c3-98ec-bfdba43232d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-8363bbfc-e649-4ec5-a9ab-193b10a65016,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-97f2c72f-0b97-477c-8b16-97a099caf674,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-b3cb55a7-f76c-46aa-b793-1299e224f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-74ccc643-bc68-4f9a-929b-bf69c469d100,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-f31b235b-1595-4d6b-beb7-ae6a9afe3b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566863716-172.17.0.5-1596967474259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-7bf03ea6-0710-4eff-8dd8-7b0f05d367fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-6e8e172f-69b3-4f5f-b370-c91ec08b95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-3c5f26f9-ba01-46c3-98ec-bfdba43232d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-8363bbfc-e649-4ec5-a9ab-193b10a65016,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-97f2c72f-0b97-477c-8b16-97a099caf674,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-b3cb55a7-f76c-46aa-b793-1299e224f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-74ccc643-bc68-4f9a-929b-bf69c469d100,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-f31b235b-1595-4d6b-beb7-ae6a9afe3b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452220797-172.17.0.5-1596967604977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-eec2a8c6-e672-448c-92a2-f3faaa57d584,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-a044ed31-2640-4d28-b0ef-3c3700602dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-71aaa91b-c139-4194-96df-adc4dc2713ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-6fe4ac3e-6fac-418b-821f-1ee985a9ae27,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-a53d3eff-fbb0-4111-9edb-8ecd5dec8054,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-dab229db-fa24-4d5f-8376-1009ad6d89b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b355114d-8162-4534-8708-3f37682e8230,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-e25e2fb0-2606-4b4e-9134-597438ece238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452220797-172.17.0.5-1596967604977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-eec2a8c6-e672-448c-92a2-f3faaa57d584,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-a044ed31-2640-4d28-b0ef-3c3700602dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-71aaa91b-c139-4194-96df-adc4dc2713ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-6fe4ac3e-6fac-418b-821f-1ee985a9ae27,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-a53d3eff-fbb0-4111-9edb-8ecd5dec8054,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-dab229db-fa24-4d5f-8376-1009ad6d89b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b355114d-8162-4534-8708-3f37682e8230,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-e25e2fb0-2606-4b4e-9134-597438ece238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86341236-172.17.0.5-1596967692901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-0f5d66e8-aa7b-4cc4-bd7d-2783418519fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-cfa4a1b2-9db6-4507-894b-ee15b95d32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-47c7a1bd-4806-4385-b28e-989c4e57d240,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-91f9fa7e-03d9-48e6-af56-8bdb7810bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-0bb67c0f-2202-4537-b362-22c8a528b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-6898cb6b-5281-4199-8375-713c778c99ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c3abdd29-5f0a-4394-8c08-03313b79a588,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-8022e633-1920-485c-81e1-52ff0dece1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86341236-172.17.0.5-1596967692901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-0f5d66e8-aa7b-4cc4-bd7d-2783418519fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-cfa4a1b2-9db6-4507-894b-ee15b95d32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-47c7a1bd-4806-4385-b28e-989c4e57d240,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-91f9fa7e-03d9-48e6-af56-8bdb7810bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-0bb67c0f-2202-4537-b362-22c8a528b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-6898cb6b-5281-4199-8375-713c778c99ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c3abdd29-5f0a-4394-8c08-03313b79a588,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-8022e633-1920-485c-81e1-52ff0dece1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998463436-172.17.0.5-1596967734667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-4a095fc2-5ccc-4d80-9acf-d7f655a3271b,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-a89a6a01-1d73-4cbb-baa6-5336f12a843b,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-18e1b674-5185-429b-9068-758083fd5543,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-41693b91-1cc9-475d-a4ef-562ac6bd083f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-4ad181d0-94f7-4f90-b168-3f33cdfc1966,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-0fd46e46-bc62-469f-a549-5cac6c5c1221,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-68d54838-ccca-461a-9de4-3dac7a5c209c,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-d0d6e8ee-7ed3-49ee-8efe-f6092717adf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998463436-172.17.0.5-1596967734667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-4a095fc2-5ccc-4d80-9acf-d7f655a3271b,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-a89a6a01-1d73-4cbb-baa6-5336f12a843b,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-18e1b674-5185-429b-9068-758083fd5543,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-41693b91-1cc9-475d-a4ef-562ac6bd083f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-4ad181d0-94f7-4f90-b168-3f33cdfc1966,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-0fd46e46-bc62-469f-a549-5cac6c5c1221,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-68d54838-ccca-461a-9de4-3dac7a5c209c,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-d0d6e8ee-7ed3-49ee-8efe-f6092717adf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972605386-172.17.0.5-1596967773191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-11d79c18-d666-4868-91a5-2e2ba12e7784,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-add2175d-776b-4e36-a5b3-4b6ab9f20dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-12f1761d-32a6-430d-b125-0f4c9c4513fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-de0b0e62-e007-4fe1-9658-e6e2e6c09c08,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-fd8b9ebe-cc9e-4c46-837b-ec754d7913d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-180f6434-e643-4d10-95f2-8856d50da18f,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-1a73ff7b-0c36-4249-a9a7-deb3944de426,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d32ed07d-71dc-4dd7-b5fb-bba8a3a5e8c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972605386-172.17.0.5-1596967773191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-11d79c18-d666-4868-91a5-2e2ba12e7784,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-add2175d-776b-4e36-a5b3-4b6ab9f20dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-12f1761d-32a6-430d-b125-0f4c9c4513fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-de0b0e62-e007-4fe1-9658-e6e2e6c09c08,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-fd8b9ebe-cc9e-4c46-837b-ec754d7913d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-180f6434-e643-4d10-95f2-8856d50da18f,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-1a73ff7b-0c36-4249-a9a7-deb3944de426,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d32ed07d-71dc-4dd7-b5fb-bba8a3a5e8c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823224166-172.17.0.5-1596968275585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-9667872d-02fe-44fb-86d1-c3edc50ca3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-1ab8c215-715d-4a2c-aa76-bcf785d660e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-c26cf680-5538-4728-a75c-e89f73e9915c,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-b04bf69e-0a72-4c7b-8168-0e9febc6adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-03962428-d290-4997-8bee-e00e1684f023,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-694fb1fa-b516-491d-9ae8-40f24051702a,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-55cdd3eb-64a9-4c16-9810-5578769c99d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-870a343f-9a7b-4ed8-be1d-389dc60063ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823224166-172.17.0.5-1596968275585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-9667872d-02fe-44fb-86d1-c3edc50ca3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-1ab8c215-715d-4a2c-aa76-bcf785d660e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-c26cf680-5538-4728-a75c-e89f73e9915c,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-b04bf69e-0a72-4c7b-8168-0e9febc6adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-03962428-d290-4997-8bee-e00e1684f023,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-694fb1fa-b516-491d-9ae8-40f24051702a,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-55cdd3eb-64a9-4c16-9810-5578769c99d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-870a343f-9a7b-4ed8-be1d-389dc60063ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035176091-172.17.0.5-1596968489557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41530,DS-0e6e0642-f7cf-497b-94c3-46adbd1657c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-91f28484-0feb-4b1e-b6e6-e4abad799057,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-c01d6503-9a73-4d02-8920-990971201373,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-80c4143e-f48b-49ad-8857-b62b66f8be85,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-6892238a-ed57-4e80-9132-e4c445f00c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-07ad90ba-7a36-4bdf-99b5-798a1700ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-7431365d-eab3-4d15-80c6-0df8e8f9c98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-e6c8199a-d7b1-48e1-a664-f7e3ac5e0b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035176091-172.17.0.5-1596968489557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41530,DS-0e6e0642-f7cf-497b-94c3-46adbd1657c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-91f28484-0feb-4b1e-b6e6-e4abad799057,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-c01d6503-9a73-4d02-8920-990971201373,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-80c4143e-f48b-49ad-8857-b62b66f8be85,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-6892238a-ed57-4e80-9132-e4c445f00c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-07ad90ba-7a36-4bdf-99b5-798a1700ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-7431365d-eab3-4d15-80c6-0df8e8f9c98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-e6c8199a-d7b1-48e1-a664-f7e3ac5e0b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212400737-172.17.0.5-1596968811794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-9ae1319b-c1cc-4f33-92d5-f403d8516372,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-fc133ef1-b6fd-44a7-b3b5-9cf36962a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f43cde0b-a669-44e2-a54b-9d91873bb83c,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-7727a6a1-0228-49f9-b74e-b9d664f6a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-9ec763f8-4f2e-4231-b6c2-78f9df1b9356,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-1ce92c93-7340-40ec-a674-e3b59ff01395,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-11b996c5-d52e-4d18-a96c-14f22ac247fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-073953dd-bb06-4522-a9ee-e9a240fb92af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212400737-172.17.0.5-1596968811794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-9ae1319b-c1cc-4f33-92d5-f403d8516372,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-fc133ef1-b6fd-44a7-b3b5-9cf36962a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f43cde0b-a669-44e2-a54b-9d91873bb83c,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-7727a6a1-0228-49f9-b74e-b9d664f6a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-9ec763f8-4f2e-4231-b6c2-78f9df1b9356,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-1ce92c93-7340-40ec-a674-e3b59ff01395,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-11b996c5-d52e-4d18-a96c-14f22ac247fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-073953dd-bb06-4522-a9ee-e9a240fb92af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995703572-172.17.0.5-1596969008343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-8fb4026a-4829-4ead-9378-2c9135a2c11e,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-ef128ffe-2fcb-4b9a-a800-e70124cc1220,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-f1952b88-238d-4167-b77e-0e92ebf213b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-812906b5-40c8-46fd-b7fd-6d9e3738d7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-84a09665-722b-417a-ae2d-f1b26d4e28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-7f3da54a-8061-4780-88c7-8991930197a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1d7b7635-4b26-4cc3-a253-b45f9fdc5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-872822cf-5de4-468d-a9c1-4ebe10d19711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995703572-172.17.0.5-1596969008343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-8fb4026a-4829-4ead-9378-2c9135a2c11e,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-ef128ffe-2fcb-4b9a-a800-e70124cc1220,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-f1952b88-238d-4167-b77e-0e92ebf213b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-812906b5-40c8-46fd-b7fd-6d9e3738d7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-84a09665-722b-417a-ae2d-f1b26d4e28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-7f3da54a-8061-4780-88c7-8991930197a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1d7b7635-4b26-4cc3-a253-b45f9fdc5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-872822cf-5de4-468d-a9c1-4ebe10d19711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723652822-172.17.0.5-1596969043004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-0588f69c-9a6c-485b-a181-249c132e0322,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-ff3bbbae-fbea-4454-b498-52d5091cba05,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-4396a372-8cd7-491c-b802-96b402baafd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-dd1d3360-ee0d-42a1-9e9a-c6c43f89bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-62e4a815-869d-4479-92fe-756317ced076,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-b7f786cd-4913-4b65-9f46-aca35b63c898,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-4798ca4d-688c-496a-a1f1-6216eb6cbef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-cbc0b2f0-1893-4a7a-be5a-21628233be2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723652822-172.17.0.5-1596969043004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-0588f69c-9a6c-485b-a181-249c132e0322,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-ff3bbbae-fbea-4454-b498-52d5091cba05,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-4396a372-8cd7-491c-b802-96b402baafd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-dd1d3360-ee0d-42a1-9e9a-c6c43f89bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-62e4a815-869d-4479-92fe-756317ced076,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-b7f786cd-4913-4b65-9f46-aca35b63c898,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-4798ca4d-688c-496a-a1f1-6216eb6cbef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-cbc0b2f0-1893-4a7a-be5a-21628233be2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135589989-172.17.0.5-1596969379841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-81ec1fd5-f9ac-42fc-881e-f92b270242f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-970fa306-0f26-4b36-8fa8-b2168a40aa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-2aba0406-4a0b-44e1-85d3-4879de161b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-3dec174d-9fd7-4c31-9309-a1f3b1ac2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-aef53a73-36ee-477e-9d82-a54c684fb961,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5dc87d07-b722-467d-9f3d-6e24dfb23e38,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-b6521012-b40f-4bb5-8f67-9cee26454bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-070e278e-89e2-4978-a0ea-ba90869787d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135589989-172.17.0.5-1596969379841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-81ec1fd5-f9ac-42fc-881e-f92b270242f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-970fa306-0f26-4b36-8fa8-b2168a40aa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-2aba0406-4a0b-44e1-85d3-4879de161b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-3dec174d-9fd7-4c31-9309-a1f3b1ac2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-aef53a73-36ee-477e-9d82-a54c684fb961,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5dc87d07-b722-467d-9f3d-6e24dfb23e38,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-b6521012-b40f-4bb5-8f67-9cee26454bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-070e278e-89e2-4978-a0ea-ba90869787d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5100
