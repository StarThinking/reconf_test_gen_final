reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344824025-172.17.0.7-1596943436019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-38ce5cdc-a23d-425a-a277-aabf5fd6a78e,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-cf04da6f-1f79-40c1-accd-24cd899d9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-9d84bcfe-f093-4dc3-86f4-68ad2e47fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-db5564c4-9f90-4859-bd3e-934fd7016211,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-6fd6b6b9-6343-450b-853b-22e51cbd4eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-5b0cbb49-f121-484d-90e8-8d7376065032,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-ef102546-7b0b-4aa3-86cb-1a6050b7f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-5c04505f-3d17-4933-9dab-62a80d202972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344824025-172.17.0.7-1596943436019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-38ce5cdc-a23d-425a-a277-aabf5fd6a78e,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-cf04da6f-1f79-40c1-accd-24cd899d9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-9d84bcfe-f093-4dc3-86f4-68ad2e47fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-db5564c4-9f90-4859-bd3e-934fd7016211,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-6fd6b6b9-6343-450b-853b-22e51cbd4eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-5b0cbb49-f121-484d-90e8-8d7376065032,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-ef102546-7b0b-4aa3-86cb-1a6050b7f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-5c04505f-3d17-4933-9dab-62a80d202972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593841022-172.17.0.7-1596943732265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33325,DS-95632594-6777-44e5-a18c-28e94276c21e,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-42b27181-7ad1-4da0-a17a-7fd47ed40dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-5c91166c-a4e4-4f0f-8b27-6f83e2c4588b,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-aaa90cb5-f98d-4fe3-b21a-7d0305e87f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-6e9067f5-b5f7-4acf-a9a4-9f0d448a9772,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-2defdec5-0945-4cda-8ebd-d1e56bfacc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-a1e2af6f-8555-4d38-875e-5919ec7e80e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-2bc7d6cc-f44b-4363-9fad-3d68b05bfa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593841022-172.17.0.7-1596943732265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33325,DS-95632594-6777-44e5-a18c-28e94276c21e,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-42b27181-7ad1-4da0-a17a-7fd47ed40dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-5c91166c-a4e4-4f0f-8b27-6f83e2c4588b,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-aaa90cb5-f98d-4fe3-b21a-7d0305e87f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-6e9067f5-b5f7-4acf-a9a4-9f0d448a9772,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-2defdec5-0945-4cda-8ebd-d1e56bfacc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-a1e2af6f-8555-4d38-875e-5919ec7e80e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-2bc7d6cc-f44b-4363-9fad-3d68b05bfa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805516005-172.17.0.7-1596943841167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46774,DS-1edbd9fb-901a-4483-a0f9-2875ae5814b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-8925fd3d-fb1b-4bcc-8576-2666048a6388,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ab0e2480-c3cd-4ce1-be9e-84008402f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-03c9db87-0e4d-4751-8130-b8b381056c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-3ecafd60-cd14-49ee-8fc4-2801637eb423,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-33484d96-b15c-4596-b79d-f6fc41d2422a,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-43da9c3b-27e7-4b48-803b-979f76e8edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-dcd58642-901c-4f44-ae1f-d0741852a8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805516005-172.17.0.7-1596943841167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46774,DS-1edbd9fb-901a-4483-a0f9-2875ae5814b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-8925fd3d-fb1b-4bcc-8576-2666048a6388,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ab0e2480-c3cd-4ce1-be9e-84008402f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-03c9db87-0e4d-4751-8130-b8b381056c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-3ecafd60-cd14-49ee-8fc4-2801637eb423,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-33484d96-b15c-4596-b79d-f6fc41d2422a,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-43da9c3b-27e7-4b48-803b-979f76e8edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-dcd58642-901c-4f44-ae1f-d0741852a8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424306416-172.17.0.7-1596944159876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38947,DS-ef087329-188d-4a57-b02a-ee4a6808e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-5e7e472e-4500-452d-932d-b6db7a30bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-0957a6b4-e704-4085-bab4-5f4f427ba63f,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-bf663aec-783f-4388-8ea5-3602648db616,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-904a1809-8847-4eca-a517-de00d4930fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-410f0eef-c770-4ff6-a993-19a28a41a315,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-ec71ecb8-4a80-44ba-b580-be6fb608f867,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-700f490c-6d01-4292-a4e8-ca8c0cbbb872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424306416-172.17.0.7-1596944159876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38947,DS-ef087329-188d-4a57-b02a-ee4a6808e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-5e7e472e-4500-452d-932d-b6db7a30bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-0957a6b4-e704-4085-bab4-5f4f427ba63f,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-bf663aec-783f-4388-8ea5-3602648db616,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-904a1809-8847-4eca-a517-de00d4930fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-410f0eef-c770-4ff6-a993-19a28a41a315,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-ec71ecb8-4a80-44ba-b580-be6fb608f867,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-700f490c-6d01-4292-a4e8-ca8c0cbbb872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990271290-172.17.0.7-1596944403042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46635,DS-5b2dc012-a44c-40c3-80bd-b2bb593865c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-db956e54-867a-4b3d-a090-cc6930cde1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-c345001f-213b-4c18-9c93-12e951cb80c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-3d731172-e6d0-415c-9d2b-e48fdf9b6a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-ff3c9335-7fa8-4aab-adbd-343fbea0b6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-1daf238f-2595-49dc-842c-097ef266567e,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-3d6c13fb-d751-40ec-b7b9-6111bfb3df18,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-b758088d-4267-4b2c-ba49-85ab513ee047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990271290-172.17.0.7-1596944403042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46635,DS-5b2dc012-a44c-40c3-80bd-b2bb593865c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-db956e54-867a-4b3d-a090-cc6930cde1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-c345001f-213b-4c18-9c93-12e951cb80c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-3d731172-e6d0-415c-9d2b-e48fdf9b6a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-ff3c9335-7fa8-4aab-adbd-343fbea0b6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-1daf238f-2595-49dc-842c-097ef266567e,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-3d6c13fb-d751-40ec-b7b9-6111bfb3df18,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-b758088d-4267-4b2c-ba49-85ab513ee047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670780033-172.17.0.7-1596944692885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-531092d7-3192-48af-ad8e-90663bad2182,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d7e3e8aa-5cd7-4f04-9a65-efd4f3c2a685,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-7dbc8609-d65f-4493-813d-45b5070c565a,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-3754a051-7717-4582-96e5-9945d9d213b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-59b33ee5-e00e-40ea-a485-edcdcffd9554,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-4662ed32-dc12-4ee7-9124-b88aab8171c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-189287a9-205d-4339-96cc-ed0a1e3182ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-eab878a5-1830-42dd-8ad2-30fe5561f0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670780033-172.17.0.7-1596944692885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-531092d7-3192-48af-ad8e-90663bad2182,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d7e3e8aa-5cd7-4f04-9a65-efd4f3c2a685,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-7dbc8609-d65f-4493-813d-45b5070c565a,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-3754a051-7717-4582-96e5-9945d9d213b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-59b33ee5-e00e-40ea-a485-edcdcffd9554,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-4662ed32-dc12-4ee7-9124-b88aab8171c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-189287a9-205d-4339-96cc-ed0a1e3182ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-eab878a5-1830-42dd-8ad2-30fe5561f0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519107196-172.17.0.7-1596944978225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-c0ec4dd8-53dd-40a9-a669-3c4ab56cea88,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-93266496-9682-4d33-af69-13918e2e27cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-4a62bdfa-3b47-4d84-8634-58d135aefa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-7243ddf9-4e17-4e7c-a4f0-b6b27e5f9608,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-eadf9e12-8b30-49ca-9cb8-c06161cc4a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-da639163-d93a-48d5-bdbf-5a43d0d0cd56,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-65bffbd5-a13b-4e83-98b6-8a914997e37e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-92f22c76-ac93-4083-89be-eef3769ae18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519107196-172.17.0.7-1596944978225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-c0ec4dd8-53dd-40a9-a669-3c4ab56cea88,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-93266496-9682-4d33-af69-13918e2e27cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-4a62bdfa-3b47-4d84-8634-58d135aefa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-7243ddf9-4e17-4e7c-a4f0-b6b27e5f9608,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-eadf9e12-8b30-49ca-9cb8-c06161cc4a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-da639163-d93a-48d5-bdbf-5a43d0d0cd56,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-65bffbd5-a13b-4e83-98b6-8a914997e37e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-92f22c76-ac93-4083-89be-eef3769ae18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917826897-172.17.0.7-1596945250834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-f69823bb-cad1-497c-9451-f47e28a7cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-e2525a83-38b1-4568-b48c-08051e6d89df,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-3aceffba-8809-4304-bc8b-f2c6df6e3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3dfd3ade-d51f-464a-979a-de49de624168,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-bec978d3-5783-4996-b308-65dc923f10f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-08fb91a9-5423-4a5d-bd95-ad4ae34ac56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e34990a8-d1af-4c4f-94eb-5b9fd6fccf60,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7207f1ed-13d2-4c17-99f6-87df70b30fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917826897-172.17.0.7-1596945250834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-f69823bb-cad1-497c-9451-f47e28a7cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-e2525a83-38b1-4568-b48c-08051e6d89df,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-3aceffba-8809-4304-bc8b-f2c6df6e3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3dfd3ade-d51f-464a-979a-de49de624168,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-bec978d3-5783-4996-b308-65dc923f10f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-08fb91a9-5423-4a5d-bd95-ad4ae34ac56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e34990a8-d1af-4c4f-94eb-5b9fd6fccf60,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7207f1ed-13d2-4c17-99f6-87df70b30fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945895807-172.17.0.7-1596945689968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-60af46ac-aa28-4a16-a0f5-9a9027b9021d,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-12e8961f-8f34-4047-a798-e0d569baa218,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-f78c43c6-6194-421e-9521-a78355a74829,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-35ef493f-49ff-4021-91ad-d2ddb9c006d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-f2ac8b5d-e5e9-43fa-a14a-a27acdc179dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-ba22f9a3-2a8f-4538-8f42-316c244da08d,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f6c60023-db89-49de-920b-2ff29bb7e7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-0ae8fb3c-5dfd-4354-ab74-c78000a79117,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945895807-172.17.0.7-1596945689968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-60af46ac-aa28-4a16-a0f5-9a9027b9021d,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-12e8961f-8f34-4047-a798-e0d569baa218,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-f78c43c6-6194-421e-9521-a78355a74829,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-35ef493f-49ff-4021-91ad-d2ddb9c006d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-f2ac8b5d-e5e9-43fa-a14a-a27acdc179dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-ba22f9a3-2a8f-4538-8f42-316c244da08d,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f6c60023-db89-49de-920b-2ff29bb7e7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-0ae8fb3c-5dfd-4354-ab74-c78000a79117,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042710852-172.17.0.7-1596946778185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39434,DS-959a49f5-95f6-484d-bf38-7d6b9e41aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-1bbcfb66-09cb-49e9-8a42-a11ddaa33450,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-9e431fb6-07ca-453a-bf85-21d1036bdd20,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-a6d3d3c3-f70b-49da-83aa-67464c84eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-3158f2db-862b-4ae7-ab64-4346654b1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-66534b5e-fbd2-4594-b461-10430114b86e,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-c38085c2-12b1-4e30-8aff-3387737dad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-a67b8cd2-f78a-4d04-8fc6-129b54003cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042710852-172.17.0.7-1596946778185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39434,DS-959a49f5-95f6-484d-bf38-7d6b9e41aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-1bbcfb66-09cb-49e9-8a42-a11ddaa33450,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-9e431fb6-07ca-453a-bf85-21d1036bdd20,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-a6d3d3c3-f70b-49da-83aa-67464c84eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-3158f2db-862b-4ae7-ab64-4346654b1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-66534b5e-fbd2-4594-b461-10430114b86e,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-c38085c2-12b1-4e30-8aff-3387737dad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-a67b8cd2-f78a-4d04-8fc6-129b54003cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429061772-172.17.0.7-1596947090146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41593,DS-0166e439-4f9c-4122-bf30-d3b4d4dc8c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-08399c7f-9b0e-4bca-a9bc-80db271d62b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-e9fa090a-8f93-42bb-bf1f-1bf43eabf54c,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-14448d56-822d-4dad-9d65-9d18197ae3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-c5632025-1ddf-4c1c-adf8-bd1349212fef,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-9fd8df94-0f7b-427f-baaa-44c01bc6491e,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-10530a1f-e93a-4244-ae41-3b10d145c624,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-95d3b039-c9e3-4c4a-bbe0-192ed2a955ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429061772-172.17.0.7-1596947090146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41593,DS-0166e439-4f9c-4122-bf30-d3b4d4dc8c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-08399c7f-9b0e-4bca-a9bc-80db271d62b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-e9fa090a-8f93-42bb-bf1f-1bf43eabf54c,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-14448d56-822d-4dad-9d65-9d18197ae3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-c5632025-1ddf-4c1c-adf8-bd1349212fef,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-9fd8df94-0f7b-427f-baaa-44c01bc6491e,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-10530a1f-e93a-4244-ae41-3b10d145c624,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-95d3b039-c9e3-4c4a-bbe0-192ed2a955ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305615722-172.17.0.7-1596947713492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45425,DS-b8233638-c327-49b8-aa59-bb4b1aec0828,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-1c2a27fe-e0dd-41e8-beb2-9703c2d0c402,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-4db10e21-2889-47a4-b3d5-3674393a7920,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-44787ba9-865e-4c75-aad1-1f3a93da88c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-c6f07bc5-d7ea-49c2-933a-0efcf5028139,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-090a35c8-50a6-4348-9ad6-1736a2623ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-7d4d33fb-0d0a-4bf7-a99d-b2fe7da6c528,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-8ef95329-6495-4def-a37a-f38d4a9ea727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305615722-172.17.0.7-1596947713492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45425,DS-b8233638-c327-49b8-aa59-bb4b1aec0828,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-1c2a27fe-e0dd-41e8-beb2-9703c2d0c402,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-4db10e21-2889-47a4-b3d5-3674393a7920,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-44787ba9-865e-4c75-aad1-1f3a93da88c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-c6f07bc5-d7ea-49c2-933a-0efcf5028139,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-090a35c8-50a6-4348-9ad6-1736a2623ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-7d4d33fb-0d0a-4bf7-a99d-b2fe7da6c528,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-8ef95329-6495-4def-a37a-f38d4a9ea727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484603717-172.17.0.7-1596947752528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-ddab7e02-b08a-4e83-8e2b-90d5a3f44d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-4e78bf70-0d10-4d62-b808-6a771ceb1b01,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ceea496f-d584-46da-a61b-10863927c098,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-df2b3b66-d8d3-496a-b44f-6ab276f20cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-f6d9f663-17ef-4357-a6c3-0f2d0c22b90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-3931352a-7537-43ab-bfb4-2793dc64b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-826e4de0-507f-4c52-a8cc-69e176040de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-f167deee-87a3-4d3e-b3d8-ab6ade84ba51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484603717-172.17.0.7-1596947752528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-ddab7e02-b08a-4e83-8e2b-90d5a3f44d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-4e78bf70-0d10-4d62-b808-6a771ceb1b01,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ceea496f-d584-46da-a61b-10863927c098,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-df2b3b66-d8d3-496a-b44f-6ab276f20cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-f6d9f663-17ef-4357-a6c3-0f2d0c22b90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-3931352a-7537-43ab-bfb4-2793dc64b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-826e4de0-507f-4c52-a8cc-69e176040de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-f167deee-87a3-4d3e-b3d8-ab6ade84ba51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300529531-172.17.0.7-1596947826158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-65ddcfa0-7eba-4c1e-854f-8eb03cbddfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-f8abd897-be72-40e4-ba9d-37c4e0827a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-fea9fe12-3a6b-4142-be94-75adf5278b44,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-9a9d5dd1-03b9-441c-b930-d4f0ae9f1461,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-9e55e55d-bb6b-4b63-9345-4afd887f2865,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-34ad4804-fc24-4f9e-9826-4a17a323459a,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-e2e5444a-89f7-427c-8495-c70466909b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-6505ad43-086c-4263-a64a-60a231edcc68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300529531-172.17.0.7-1596947826158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-65ddcfa0-7eba-4c1e-854f-8eb03cbddfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-f8abd897-be72-40e4-ba9d-37c4e0827a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-fea9fe12-3a6b-4142-be94-75adf5278b44,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-9a9d5dd1-03b9-441c-b930-d4f0ae9f1461,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-9e55e55d-bb6b-4b63-9345-4afd887f2865,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-34ad4804-fc24-4f9e-9826-4a17a323459a,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-e2e5444a-89f7-427c-8495-c70466909b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-6505ad43-086c-4263-a64a-60a231edcc68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094805223-172.17.0.7-1596948306490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-446e67b4-0f8c-4888-ae93-0bb038a0ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-2e7a4a1a-4e9c-4a8b-8ae5-978076696f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-f436ed58-89ec-40a9-b5f2-d23d16bd7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-007889b8-17a9-482b-bdb6-2c4df94e15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-f5345eba-1985-44fe-b480-35bba54e2104,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-6915736e-6d1e-4d7c-97c2-5681f02a9ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-569f842b-b0f6-4677-9491-9e6465674406,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1ea31106-ca79-4191-b2bc-f45212919dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094805223-172.17.0.7-1596948306490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-446e67b4-0f8c-4888-ae93-0bb038a0ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-2e7a4a1a-4e9c-4a8b-8ae5-978076696f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-f436ed58-89ec-40a9-b5f2-d23d16bd7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-007889b8-17a9-482b-bdb6-2c4df94e15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-f5345eba-1985-44fe-b480-35bba54e2104,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-6915736e-6d1e-4d7c-97c2-5681f02a9ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-569f842b-b0f6-4677-9491-9e6465674406,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1ea31106-ca79-4191-b2bc-f45212919dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889460094-172.17.0.7-1596948563160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42470,DS-6d79aeb0-39bb-49c8-92de-a9227a5b76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-82b5537f-f784-4ae8-895a-a5378adb2072,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-fe55fadf-43d1-4998-bb8c-cb3f360c553e,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-70440f18-26a3-4918-bdcb-e6c1c479f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-d8a7ffd2-c740-4e76-820e-c794055a54e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-a311b764-a70e-416d-93a9-7d572147089e,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-0bbf1493-9299-4118-8913-c90005d993a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-f7597464-3d09-4c8b-af82-3420a8c29350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889460094-172.17.0.7-1596948563160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42470,DS-6d79aeb0-39bb-49c8-92de-a9227a5b76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-82b5537f-f784-4ae8-895a-a5378adb2072,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-fe55fadf-43d1-4998-bb8c-cb3f360c553e,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-70440f18-26a3-4918-bdcb-e6c1c479f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-d8a7ffd2-c740-4e76-820e-c794055a54e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-a311b764-a70e-416d-93a9-7d572147089e,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-0bbf1493-9299-4118-8913-c90005d993a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-f7597464-3d09-4c8b-af82-3420a8c29350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5479
