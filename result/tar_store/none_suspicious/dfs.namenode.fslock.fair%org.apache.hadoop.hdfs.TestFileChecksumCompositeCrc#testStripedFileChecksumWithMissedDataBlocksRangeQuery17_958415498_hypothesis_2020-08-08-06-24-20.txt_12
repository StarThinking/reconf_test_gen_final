reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638656668-172.17.0.17-1596868173416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40455,DS-2723b449-e6c4-496c-9312-cc0f63dcf22b,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-cb4aedd5-a1fb-465b-89a1-aca77196ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-51686199-191e-42b4-b75a-bee50420c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-d9442962-2192-4fcb-b932-64e3cdb156f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-c177bb4f-58a2-4ab4-83a9-9da52fa88356,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-35d565b9-b852-4c42-a10f-9c8ea56c5364,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-9d806520-8d3f-4da4-94cc-a1eeadfe4ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0b06b030-5a34-4cbc-919e-3475e0bb7ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638656668-172.17.0.17-1596868173416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40455,DS-2723b449-e6c4-496c-9312-cc0f63dcf22b,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-cb4aedd5-a1fb-465b-89a1-aca77196ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-51686199-191e-42b4-b75a-bee50420c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-d9442962-2192-4fcb-b932-64e3cdb156f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-c177bb4f-58a2-4ab4-83a9-9da52fa88356,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-35d565b9-b852-4c42-a10f-9c8ea56c5364,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-9d806520-8d3f-4da4-94cc-a1eeadfe4ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0b06b030-5a34-4cbc-919e-3475e0bb7ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078923596-172.17.0.17-1596868448471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35130,DS-09c2ec3b-2326-45d6-b4b2-11757fdacef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-9e2dd4c9-63c1-4314-8ddc-354a63581e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-78fc1c08-a4a5-481e-9cfd-7ada5837a651,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-c628cf16-2cc3-45c3-abe9-dbd7ccbabb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-3fa10da4-64f4-4878-b774-3a3bfce7c415,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-dcf8e599-ce3e-4194-b25e-e10369d775a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-7ffd7859-c597-4387-bb79-7c176614a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-c1eb9fbc-ad05-4a9b-bcca-4c655a54668b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078923596-172.17.0.17-1596868448471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35130,DS-09c2ec3b-2326-45d6-b4b2-11757fdacef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-9e2dd4c9-63c1-4314-8ddc-354a63581e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-78fc1c08-a4a5-481e-9cfd-7ada5837a651,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-c628cf16-2cc3-45c3-abe9-dbd7ccbabb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-3fa10da4-64f4-4878-b774-3a3bfce7c415,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-dcf8e599-ce3e-4194-b25e-e10369d775a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-7ffd7859-c597-4387-bb79-7c176614a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-c1eb9fbc-ad05-4a9b-bcca-4c655a54668b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991578783-172.17.0.17-1596868854046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-362eecfe-bd3e-463f-8ace-67b89b2fd26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-d3c971e2-8600-4b5b-97c9-fe849a2220cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-7509a8d4-1322-4ad4-a267-0ccdfeeeac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-fd4bc688-bff8-4b97-9f23-b49d1852dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-c9e816f1-1e76-4650-899c-8171c91af36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-30cda821-a853-4dad-bd84-0ce6b7c7eee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-e0cddf23-525a-47c7-82cd-5ba3adbf631b,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-756d13ba-958c-49eb-a881-65ac733eacd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991578783-172.17.0.17-1596868854046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-362eecfe-bd3e-463f-8ace-67b89b2fd26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-d3c971e2-8600-4b5b-97c9-fe849a2220cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-7509a8d4-1322-4ad4-a267-0ccdfeeeac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-fd4bc688-bff8-4b97-9f23-b49d1852dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-c9e816f1-1e76-4650-899c-8171c91af36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-30cda821-a853-4dad-bd84-0ce6b7c7eee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-e0cddf23-525a-47c7-82cd-5ba3adbf631b,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-756d13ba-958c-49eb-a881-65ac733eacd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510725750-172.17.0.17-1596869181733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-cf962112-1c23-4a46-bf91-ec621f8ecfec,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-032583e2-3438-4243-81c4-206bf1834535,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-c6f5e0c6-0ae2-42e2-acd8-08440b67df64,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-40f75a3a-677e-4951-877b-73e92108cd09,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-99bbdc07-c481-4638-bf87-67acd7fdfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-7426923d-9951-4e1b-b591-9dfde9f85d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-e633ba48-a839-4749-acea-f8d2cf2d9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-ff037806-f3ef-4c03-94e1-1d113951ac65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510725750-172.17.0.17-1596869181733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-cf962112-1c23-4a46-bf91-ec621f8ecfec,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-032583e2-3438-4243-81c4-206bf1834535,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-c6f5e0c6-0ae2-42e2-acd8-08440b67df64,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-40f75a3a-677e-4951-877b-73e92108cd09,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-99bbdc07-c481-4638-bf87-67acd7fdfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-7426923d-9951-4e1b-b591-9dfde9f85d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-e633ba48-a839-4749-acea-f8d2cf2d9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-ff037806-f3ef-4c03-94e1-1d113951ac65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696223826-172.17.0.17-1596869324391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-61ceefc1-e5ec-4e92-a17a-631a6c99f9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-ad750d47-0753-4d85-a767-e9a4a718eb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-d96a96ab-0002-44c0-9124-beda6b566c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-32c4bc1f-090e-46ee-a04c-75fcb7039d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-a56301ae-91d1-44b4-8c08-ed70d080f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-f6dff072-cfc2-459f-b4c9-278f75294e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-a2eca3d2-1102-4900-9c66-41bc731272e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-809c7aab-e662-4f55-a5c6-6fd540d7d65f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696223826-172.17.0.17-1596869324391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-61ceefc1-e5ec-4e92-a17a-631a6c99f9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-ad750d47-0753-4d85-a767-e9a4a718eb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-d96a96ab-0002-44c0-9124-beda6b566c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-32c4bc1f-090e-46ee-a04c-75fcb7039d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-a56301ae-91d1-44b4-8c08-ed70d080f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-f6dff072-cfc2-459f-b4c9-278f75294e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-a2eca3d2-1102-4900-9c66-41bc731272e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-809c7aab-e662-4f55-a5c6-6fd540d7d65f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926169764-172.17.0.17-1596869366736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-8835acb8-f082-41ad-9928-99c1fc75575e,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-ae745b53-f437-42c6-a0dc-e7f68b5e0879,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a8f0f223-aed1-4a30-acea-31db289cc148,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-1d209288-c3b4-4cbe-8774-ac2685c510e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-1abcc46e-9d55-4252-910a-98feb519dcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-418ed4c0-dc79-424e-a2e4-8ab664dd6f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-e1354230-9505-4468-bb23-bed51db799aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-b75007e7-720a-4178-90bc-a9a1c2d1a531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926169764-172.17.0.17-1596869366736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-8835acb8-f082-41ad-9928-99c1fc75575e,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-ae745b53-f437-42c6-a0dc-e7f68b5e0879,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a8f0f223-aed1-4a30-acea-31db289cc148,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-1d209288-c3b4-4cbe-8774-ac2685c510e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-1abcc46e-9d55-4252-910a-98feb519dcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-418ed4c0-dc79-424e-a2e4-8ab664dd6f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-e1354230-9505-4468-bb23-bed51db799aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-b75007e7-720a-4178-90bc-a9a1c2d1a531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757735877-172.17.0.17-1596869408642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39632,DS-ba88aff7-8f34-49f6-a496-2f8b436e5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-5bff12a6-1ad2-4e12-9c83-bd1f7e579d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-78894d53-ed29-4763-b06e-6cc44d87794e,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-a1981f76-4819-4e61-b390-95bc97dc5152,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-7d59c80f-e884-4940-998e-7b28557575fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-7a898216-7e3b-4b69-a279-f34726248c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-2e662a1f-821e-41f8-9716-821b690e7897,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-abfed69c-ee6a-4d74-8876-b7478ba91526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757735877-172.17.0.17-1596869408642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39632,DS-ba88aff7-8f34-49f6-a496-2f8b436e5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-5bff12a6-1ad2-4e12-9c83-bd1f7e579d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-78894d53-ed29-4763-b06e-6cc44d87794e,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-a1981f76-4819-4e61-b390-95bc97dc5152,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-7d59c80f-e884-4940-998e-7b28557575fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-7a898216-7e3b-4b69-a279-f34726248c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-2e662a1f-821e-41f8-9716-821b690e7897,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-abfed69c-ee6a-4d74-8876-b7478ba91526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030450459-172.17.0.17-1596869480819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-e1bf021f-755f-4b7a-b8c6-c2aacfefaae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-9a17ee4e-44a9-4f48-a5b3-55c206243634,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-4d8c3ab7-ba19-4bd8-9a5c-82b102d71089,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-e17bbcef-f762-45e3-92e1-b9a06fdd388c,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-f0927bf6-80e4-4db7-8219-d7cd82301a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-f982dd99-604f-420a-8c80-ab66fc784afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-323cbb8e-6155-49f6-912b-1cfee8bbf94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-c20dde9e-eb14-4d90-8e80-806dc226cbda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030450459-172.17.0.17-1596869480819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-e1bf021f-755f-4b7a-b8c6-c2aacfefaae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-9a17ee4e-44a9-4f48-a5b3-55c206243634,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-4d8c3ab7-ba19-4bd8-9a5c-82b102d71089,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-e17bbcef-f762-45e3-92e1-b9a06fdd388c,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-f0927bf6-80e4-4db7-8219-d7cd82301a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-f982dd99-604f-420a-8c80-ab66fc784afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-323cbb8e-6155-49f6-912b-1cfee8bbf94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-c20dde9e-eb14-4d90-8e80-806dc226cbda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192922131-172.17.0.17-1596869913646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-8e3b9293-fdbd-4ede-934c-571bee5015b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-eec51031-f040-45ec-b445-8edb11b5ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-8ce267b9-c72e-4168-8f76-ed7c3137d816,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-623e2f81-3011-47b7-a872-8c16fd07f062,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-04937469-67c6-45a5-a7b4-f740b925b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-f464e2a8-62b9-46b3-a320-b754960979a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-4b8ed6f0-8bd1-4bd8-85b0-e5f53acd17b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-a6f54933-8740-4c98-b2e1-f9786dec2287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192922131-172.17.0.17-1596869913646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-8e3b9293-fdbd-4ede-934c-571bee5015b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-eec51031-f040-45ec-b445-8edb11b5ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-8ce267b9-c72e-4168-8f76-ed7c3137d816,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-623e2f81-3011-47b7-a872-8c16fd07f062,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-04937469-67c6-45a5-a7b4-f740b925b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-f464e2a8-62b9-46b3-a320-b754960979a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-4b8ed6f0-8bd1-4bd8-85b0-e5f53acd17b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-a6f54933-8740-4c98-b2e1-f9786dec2287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555797629-172.17.0.17-1596869946145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44998,DS-ab2b1ec8-6203-41e3-bf56-00fcbbe93dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-8fc346a3-edac-4563-a9a9-0085b466b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-9f5eae57-ec12-42ba-ac9d-8a3c8e09d298,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-e580fc97-f59f-467b-b5fb-6e4dd105c547,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-380f5977-6ee5-41e2-96da-2a5dc1805d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-319b7fe8-f795-4bef-bd4e-21818a59f973,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-64eebc42-da54-4e9e-9820-9ac17a2de452,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-3c3142cf-a5db-46b0-9c96-6e39d87ae9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555797629-172.17.0.17-1596869946145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44998,DS-ab2b1ec8-6203-41e3-bf56-00fcbbe93dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-8fc346a3-edac-4563-a9a9-0085b466b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-9f5eae57-ec12-42ba-ac9d-8a3c8e09d298,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-e580fc97-f59f-467b-b5fb-6e4dd105c547,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-380f5977-6ee5-41e2-96da-2a5dc1805d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-319b7fe8-f795-4bef-bd4e-21818a59f973,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-64eebc42-da54-4e9e-9820-9ac17a2de452,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-3c3142cf-a5db-46b0-9c96-6e39d87ae9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831174662-172.17.0.17-1596870092411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-4edaf2ff-44aa-434f-a758-3f99b94984f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-73555192-4262-41fb-9489-cc5da449e06b,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-2e7300bf-b008-47e5-9e23-eabddbcd8ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-9c17c2b0-7143-4838-a0e8-c79078910dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-196f7339-6b78-451b-b677-ad467f79f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-5f9f34cd-c77d-4a5c-9778-26a787327f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-32830be2-d386-4835-bd30-4d48f5f9e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-bd940abd-0a83-427b-928d-918bd45762ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831174662-172.17.0.17-1596870092411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-4edaf2ff-44aa-434f-a758-3f99b94984f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-73555192-4262-41fb-9489-cc5da449e06b,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-2e7300bf-b008-47e5-9e23-eabddbcd8ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-9c17c2b0-7143-4838-a0e8-c79078910dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-196f7339-6b78-451b-b677-ad467f79f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-5f9f34cd-c77d-4a5c-9778-26a787327f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-32830be2-d386-4835-bd30-4d48f5f9e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-bd940abd-0a83-427b-928d-918bd45762ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964343876-172.17.0.17-1596870207444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45336,DS-5d3ac0f5-416d-4177-99b9-68a20ead50ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-1298b03e-b855-44cc-b112-de9c746a7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-3e9b153a-1952-41b9-b5d8-c631ea37acbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-b5b03a5f-b0d4-40aa-b552-fd3b59e051e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-58410366-e53d-4c76-a873-3c4f710ad599,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-88ce7672-119e-4047-be7b-b5ad50087583,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-62124f0a-c3d0-42b8-adfa-060ab775475b,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-c77f350f-98c8-43ae-915e-b662846899f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964343876-172.17.0.17-1596870207444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45336,DS-5d3ac0f5-416d-4177-99b9-68a20ead50ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-1298b03e-b855-44cc-b112-de9c746a7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-3e9b153a-1952-41b9-b5d8-c631ea37acbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-b5b03a5f-b0d4-40aa-b552-fd3b59e051e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-58410366-e53d-4c76-a873-3c4f710ad599,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-88ce7672-119e-4047-be7b-b5ad50087583,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-62124f0a-c3d0-42b8-adfa-060ab775475b,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-c77f350f-98c8-43ae-915e-b662846899f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726434527-172.17.0.17-1596870441195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-0af040af-1712-4c20-9123-29e2c2145e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-c0164549-56bd-47a5-a97b-c2de3cb66b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-4ee4650c-e3f5-4ed0-8c4d-83292b34634d,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-cf6a6ff0-d517-4a3e-8ccd-f102525b1483,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-acc2d1e0-edfa-4ac7-a9dd-ededfa223af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-78882067-593a-4d63-8ebe-8e67b64cf061,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-1dd32028-cc9a-4c7e-9cf9-731b208b50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-ce4183f5-23af-4cf0-991f-a31fd258fd42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726434527-172.17.0.17-1596870441195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-0af040af-1712-4c20-9123-29e2c2145e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-c0164549-56bd-47a5-a97b-c2de3cb66b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-4ee4650c-e3f5-4ed0-8c4d-83292b34634d,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-cf6a6ff0-d517-4a3e-8ccd-f102525b1483,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-acc2d1e0-edfa-4ac7-a9dd-ededfa223af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-78882067-593a-4d63-8ebe-8e67b64cf061,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-1dd32028-cc9a-4c7e-9cf9-731b208b50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-ce4183f5-23af-4cf0-991f-a31fd258fd42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091924844-172.17.0.17-1596870650745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-28c9b22c-881d-4fbb-8933-c831f933bec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-64b8f61c-df44-42e6-97c3-6ded1ec02e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-e0c43c4d-6bf5-4276-95c0-b3fbf679b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-8c162cd4-6117-4b0a-be9f-3dcf6ca3fdac,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-7cc38b08-508c-4b2c-899f-186c10f89e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-7072264b-315c-4b33-bcf5-ed6b801d819a,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-c45d5980-74f3-493b-8c89-9755623b4e27,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-d265689e-b09e-437c-b468-c2b45a49ed08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091924844-172.17.0.17-1596870650745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-28c9b22c-881d-4fbb-8933-c831f933bec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-64b8f61c-df44-42e6-97c3-6ded1ec02e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-e0c43c4d-6bf5-4276-95c0-b3fbf679b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-8c162cd4-6117-4b0a-be9f-3dcf6ca3fdac,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-7cc38b08-508c-4b2c-899f-186c10f89e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-7072264b-315c-4b33-bcf5-ed6b801d819a,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-c45d5980-74f3-493b-8c89-9755623b4e27,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-d265689e-b09e-437c-b468-c2b45a49ed08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75209087-172.17.0.17-1596870692318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45144,DS-0bb42cbd-4aa9-45f0-96e7-c691dba1475e,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-03903092-6255-4d9a-a102-59ac3a04b945,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-c0a9f4e9-b268-4912-b428-1b2207620a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-ab381bb7-b7a9-41b0-b5f0-cfd774162017,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-112a4047-0fcd-4cf3-8e42-b0e621804d33,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-2e79aba6-e66e-4836-8731-e35354dbd0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-8bb322ac-0cf2-48a8-bda1-6b38a5e36e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-69f69462-9c91-4847-a39c-71082f28956b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75209087-172.17.0.17-1596870692318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45144,DS-0bb42cbd-4aa9-45f0-96e7-c691dba1475e,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-03903092-6255-4d9a-a102-59ac3a04b945,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-c0a9f4e9-b268-4912-b428-1b2207620a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-ab381bb7-b7a9-41b0-b5f0-cfd774162017,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-112a4047-0fcd-4cf3-8e42-b0e621804d33,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-2e79aba6-e66e-4836-8731-e35354dbd0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-8bb322ac-0cf2-48a8-bda1-6b38a5e36e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-69f69462-9c91-4847-a39c-71082f28956b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986796752-172.17.0.17-1596871421142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35937,DS-3ad0250e-1a9a-425c-bf5d-a63c5aef48b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-19a1edf4-26c5-4c1c-b677-71519a1f9120,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-0d1bac01-b427-4383-ad05-b3987eea1475,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-50b53d47-b78d-43a5-982c-4e090d757a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-e791d6b3-b7a3-4b32-9a56-0872ae767ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-157e77f1-8605-4ca3-bb88-05034776a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-a99a3633-e837-4456-ae07-5db0ba6c5c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-665a5c41-2d90-4ff0-9b32-c6a0114811b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986796752-172.17.0.17-1596871421142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35937,DS-3ad0250e-1a9a-425c-bf5d-a63c5aef48b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-19a1edf4-26c5-4c1c-b677-71519a1f9120,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-0d1bac01-b427-4383-ad05-b3987eea1475,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-50b53d47-b78d-43a5-982c-4e090d757a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-e791d6b3-b7a3-4b32-9a56-0872ae767ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-157e77f1-8605-4ca3-bb88-05034776a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-a99a3633-e837-4456-ae07-5db0ba6c5c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-665a5c41-2d90-4ff0-9b32-c6a0114811b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128463023-172.17.0.17-1596871694213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42159,DS-bef0ae57-2748-491a-b65b-db55052fd123,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-43b47131-8e4d-4d5c-8ef3-40f83a229e09,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-de85e015-461d-4961-a808-7084dbf6d415,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-7bc01a6d-f7d8-44aa-b371-90cbf72dc28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-d241a05a-3ebf-4954-8aa5-c79c9223170a,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-ffe6f58b-77c4-4699-b3c6-67767e26319b,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-c0042976-30af-4b0b-816f-a5af8343fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-aaa1fd2b-3530-4286-a78c-0f9b13387398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128463023-172.17.0.17-1596871694213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42159,DS-bef0ae57-2748-491a-b65b-db55052fd123,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-43b47131-8e4d-4d5c-8ef3-40f83a229e09,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-de85e015-461d-4961-a808-7084dbf6d415,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-7bc01a6d-f7d8-44aa-b371-90cbf72dc28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-d241a05a-3ebf-4954-8aa5-c79c9223170a,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-ffe6f58b-77c4-4699-b3c6-67767e26319b,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-c0042976-30af-4b0b-816f-a5af8343fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-aaa1fd2b-3530-4286-a78c-0f9b13387398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318821577-172.17.0.17-1596872077037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46476,DS-dd9c94ee-4536-4321-8469-649dad1ab44d,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-9f4ffd65-0bee-4517-af35-ac3ed0c5ffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-924dffaf-8ffc-4176-9f03-138d78c44ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-064d8419-36b7-4845-8c12-d663f6dab44f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-b318f324-9041-41f4-a5a4-1f58866e1571,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-1ef8006d-438b-4fce-a87e-0e1025b4f755,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-350219a3-0938-4c32-8dd6-289368ce7270,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-1045ea6e-0ea5-4d1f-9db7-0dd696603124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318821577-172.17.0.17-1596872077037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46476,DS-dd9c94ee-4536-4321-8469-649dad1ab44d,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-9f4ffd65-0bee-4517-af35-ac3ed0c5ffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-924dffaf-8ffc-4176-9f03-138d78c44ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-064d8419-36b7-4845-8c12-d663f6dab44f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-b318f324-9041-41f4-a5a4-1f58866e1571,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-1ef8006d-438b-4fce-a87e-0e1025b4f755,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-350219a3-0938-4c32-8dd6-289368ce7270,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-1045ea6e-0ea5-4d1f-9db7-0dd696603124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011762348-172.17.0.17-1596872329303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35650,DS-04c8fa77-a1d2-45d2-b817-249e9829531a,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-26674d87-482c-4658-8ff4-ae75058d30fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-2343bf83-251d-4749-8807-a961bff2e37f,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-165f81d9-5813-405a-a90a-ebc56d9a2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-8b747448-5edd-4d02-878a-315f0358ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-1a834f5e-ccf7-4fc9-9702-3f319aaaae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-177aed9c-d448-4d24-a262-9c678ab7bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-a9feed54-9f7c-4d62-ab2e-9c6810da7023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011762348-172.17.0.17-1596872329303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35650,DS-04c8fa77-a1d2-45d2-b817-249e9829531a,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-26674d87-482c-4658-8ff4-ae75058d30fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-2343bf83-251d-4749-8807-a961bff2e37f,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-165f81d9-5813-405a-a90a-ebc56d9a2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-8b747448-5edd-4d02-878a-315f0358ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-1a834f5e-ccf7-4fc9-9702-3f319aaaae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-177aed9c-d448-4d24-a262-9c678ab7bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-a9feed54-9f7c-4d62-ab2e-9c6810da7023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117159821-172.17.0.17-1596872999228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34456,DS-c90ee136-f619-4192-bd64-d0990ab23248,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-f5308b72-3afc-44c1-9912-2ff1524155cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-a4dc7375-e433-4636-9556-4df47eccea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-4bf3c5e4-c7fb-46ea-8a66-21d74785ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-b89689c5-2bee-4f81-aca5-b7a0f16df046,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-4559f15a-b8f6-47b0-b6c2-d95cf516564b,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-5cf3b565-f146-4b5a-841f-4422908f2954,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-816a3a2b-ed9a-46bd-8076-20f7b4369b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117159821-172.17.0.17-1596872999228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34456,DS-c90ee136-f619-4192-bd64-d0990ab23248,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-f5308b72-3afc-44c1-9912-2ff1524155cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-a4dc7375-e433-4636-9556-4df47eccea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-4bf3c5e4-c7fb-46ea-8a66-21d74785ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-b89689c5-2bee-4f81-aca5-b7a0f16df046,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-4559f15a-b8f6-47b0-b6c2-d95cf516564b,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-5cf3b565-f146-4b5a-841f-4422908f2954,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-816a3a2b-ed9a-46bd-8076-20f7b4369b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5487
