reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066426536-172.17.0.2-1596960061759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-76696cae-5191-44d7-98d6-20147f737011,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-2cc30a19-02c2-4be5-b9fd-9470c53954de,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-43271af8-1e01-4414-ae5f-fcffffad47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-4c729d5f-47b6-44e8-a2f1-14a388f6cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-52d49b49-b133-42c3-b9bf-8393f34a7008,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-9c53f676-1558-46cb-b645-fb2bf1fd2966,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-994dce9d-9b78-4a6f-8244-b1620c5eb822,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-42dd4958-b9c1-4862-857f-7508c806c4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066426536-172.17.0.2-1596960061759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-76696cae-5191-44d7-98d6-20147f737011,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-2cc30a19-02c2-4be5-b9fd-9470c53954de,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-43271af8-1e01-4414-ae5f-fcffffad47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-4c729d5f-47b6-44e8-a2f1-14a388f6cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-52d49b49-b133-42c3-b9bf-8393f34a7008,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-9c53f676-1558-46cb-b645-fb2bf1fd2966,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-994dce9d-9b78-4a6f-8244-b1620c5eb822,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-42dd4958-b9c1-4862-857f-7508c806c4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743859775-172.17.0.2-1596960214453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-4f4d8cf8-ddf1-46ce-b9ab-15f158c2c107,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-f00a1f73-6cfd-467d-a187-e916f2d1e628,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-9039c96d-8291-4646-93fc-10cebce72f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-e4f5c78a-646e-4e2e-a723-1f8bf35a9248,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-f299f692-8f8e-44d4-b2b5-9dec35f8150f,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-ad2d1b01-e09c-4b50-b3c2-56ece9c309e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-7a94dad0-d77e-44c9-9d15-2e2d4dfaa51a,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-3273237a-719f-4bb3-a116-191105ab4609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743859775-172.17.0.2-1596960214453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-4f4d8cf8-ddf1-46ce-b9ab-15f158c2c107,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-f00a1f73-6cfd-467d-a187-e916f2d1e628,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-9039c96d-8291-4646-93fc-10cebce72f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-e4f5c78a-646e-4e2e-a723-1f8bf35a9248,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-f299f692-8f8e-44d4-b2b5-9dec35f8150f,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-ad2d1b01-e09c-4b50-b3c2-56ece9c309e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-7a94dad0-d77e-44c9-9d15-2e2d4dfaa51a,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-3273237a-719f-4bb3-a116-191105ab4609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056151365-172.17.0.2-1596960281615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-9d5ce41d-c560-46d7-bcaf-e79b1a5c8ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-d0b107a6-8826-43df-aac3-dcc68e380bba,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-87064c8b-e0b9-4006-aa0a-d248277788ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-73250b83-c811-43fe-bc49-705718c81036,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-fb8bf66f-4ec4-4986-b8d4-8f914a56f542,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-00ecb8db-0025-4afb-be44-b98c35d4cba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-131c4801-d336-4c83-aaa3-6766b05eb881,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-719a8957-35bd-4cbc-8311-0893cc80bba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056151365-172.17.0.2-1596960281615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-9d5ce41d-c560-46d7-bcaf-e79b1a5c8ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-d0b107a6-8826-43df-aac3-dcc68e380bba,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-87064c8b-e0b9-4006-aa0a-d248277788ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-73250b83-c811-43fe-bc49-705718c81036,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-fb8bf66f-4ec4-4986-b8d4-8f914a56f542,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-00ecb8db-0025-4afb-be44-b98c35d4cba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-131c4801-d336-4c83-aaa3-6766b05eb881,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-719a8957-35bd-4cbc-8311-0893cc80bba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466730884-172.17.0.2-1596960383920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-a61be3e1-505d-4fc4-bcd8-69e1797b0831,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-c394294d-5620-451c-b811-61e38b9da7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-2088dbb0-dd1b-492c-b375-7338e1fb3baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-c18db37b-6608-4cc3-a081-a68c2f7cf13b,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-2328ed2f-e998-4a1e-a1ce-31d201ae090a,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-69675ce3-9643-4cdd-875b-7658406a5a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-c4466de0-278d-4dc2-8f5d-fb5793e49753,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-9ff1f03b-7c6b-4b41-aef6-2aeb443642b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466730884-172.17.0.2-1596960383920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-a61be3e1-505d-4fc4-bcd8-69e1797b0831,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-c394294d-5620-451c-b811-61e38b9da7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-2088dbb0-dd1b-492c-b375-7338e1fb3baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-c18db37b-6608-4cc3-a081-a68c2f7cf13b,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-2328ed2f-e998-4a1e-a1ce-31d201ae090a,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-69675ce3-9643-4cdd-875b-7658406a5a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-c4466de0-278d-4dc2-8f5d-fb5793e49753,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-9ff1f03b-7c6b-4b41-aef6-2aeb443642b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833708799-172.17.0.2-1596960889524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40365,DS-c0c66afe-0cd1-4eea-bf25-fd1cf224be12,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-62f5444c-c988-4aa2-a68c-936ff31418bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-b021e47a-8a16-4061-bd95-b9271e05a245,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-07162c41-a065-4e3c-829c-80c5932b6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-a79d7bdf-3c3f-42fc-a5f2-373c60a30a31,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-f1c90f11-28b8-459a-b390-6fed7227a91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-3545eb85-78e8-41df-ab30-36c6d7f4db2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-9ae7e469-2395-4e5a-b13d-110b412fc28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833708799-172.17.0.2-1596960889524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40365,DS-c0c66afe-0cd1-4eea-bf25-fd1cf224be12,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-62f5444c-c988-4aa2-a68c-936ff31418bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-b021e47a-8a16-4061-bd95-b9271e05a245,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-07162c41-a065-4e3c-829c-80c5932b6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-a79d7bdf-3c3f-42fc-a5f2-373c60a30a31,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-f1c90f11-28b8-459a-b390-6fed7227a91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-3545eb85-78e8-41df-ab30-36c6d7f4db2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-9ae7e469-2395-4e5a-b13d-110b412fc28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286505412-172.17.0.2-1596961042445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-30d60abf-8e6c-4574-8b2f-74e551adcde3,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-5bd1f400-5265-4fae-be90-68a06bd73565,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-fbb8f075-b789-4755-a74f-2f7c01982666,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-9406b632-3d43-445c-943a-9f7b65344c66,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-931d8ea2-7034-4292-b6f3-e5e0a4ea04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-ba2ae1bf-748f-46dd-9e78-3d0c97861816,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-343de142-fe45-4da2-9f6b-afbd6c1bc40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-afef9e92-13b0-4b92-a97b-7f8635da4f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286505412-172.17.0.2-1596961042445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-30d60abf-8e6c-4574-8b2f-74e551adcde3,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-5bd1f400-5265-4fae-be90-68a06bd73565,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-fbb8f075-b789-4755-a74f-2f7c01982666,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-9406b632-3d43-445c-943a-9f7b65344c66,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-931d8ea2-7034-4292-b6f3-e5e0a4ea04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-ba2ae1bf-748f-46dd-9e78-3d0c97861816,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-343de142-fe45-4da2-9f6b-afbd6c1bc40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-afef9e92-13b0-4b92-a97b-7f8635da4f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337644577-172.17.0.2-1596961128699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41393,DS-ce0417aa-0731-450d-af3c-fef5d0681621,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-9433381e-44f5-42d0-97ad-db8c7e99f156,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-b51114d0-4113-459f-8a3f-c01787dcd4be,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-45cf0567-a2e3-4fd4-ba86-c59dd1a15e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-b9da7eeb-dc7a-48b6-86b2-2c2d12421edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-b62852e7-f9a5-4074-995d-eb759376823e,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-96cdb575-312e-4b96-9852-82208d76bc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-0338dec1-9e91-4d11-8d6e-a09bbd86abe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337644577-172.17.0.2-1596961128699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41393,DS-ce0417aa-0731-450d-af3c-fef5d0681621,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-9433381e-44f5-42d0-97ad-db8c7e99f156,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-b51114d0-4113-459f-8a3f-c01787dcd4be,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-45cf0567-a2e3-4fd4-ba86-c59dd1a15e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-b9da7eeb-dc7a-48b6-86b2-2c2d12421edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-b62852e7-f9a5-4074-995d-eb759376823e,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-96cdb575-312e-4b96-9852-82208d76bc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-0338dec1-9e91-4d11-8d6e-a09bbd86abe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557677115-172.17.0.2-1596961263073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-f4cdfb2d-116a-4bc6-a264-c2f9373114b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-33769398-ca5c-407d-8811-7112eea422de,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-af502c1c-6ef6-4b88-8327-854f5184e2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-5e26302f-fcfe-41fa-861a-c6404ca6c1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-34bd2d3e-b6d4-4645-9d07-e7015c86fbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-a740fe3f-f37f-464f-a787-b5d164c9cf89,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-2baccbf5-83cb-47ea-9cd8-7efb4e835b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-2eed9099-0f6f-40ee-a2fe-6cd92cdbef37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557677115-172.17.0.2-1596961263073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-f4cdfb2d-116a-4bc6-a264-c2f9373114b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-33769398-ca5c-407d-8811-7112eea422de,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-af502c1c-6ef6-4b88-8327-854f5184e2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-5e26302f-fcfe-41fa-861a-c6404ca6c1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-34bd2d3e-b6d4-4645-9d07-e7015c86fbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-a740fe3f-f37f-464f-a787-b5d164c9cf89,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-2baccbf5-83cb-47ea-9cd8-7efb4e835b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-2eed9099-0f6f-40ee-a2fe-6cd92cdbef37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776410893-172.17.0.2-1596961296165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-2fea26d5-a238-4d8e-ad86-5874e0f5c595,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-31b256af-1c70-4247-bb90-ca6b38ea3023,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-d898e58f-4474-48ab-a9c7-a8c92dd7f046,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-e21ac9cc-2ddb-4a89-a3a9-aa14417565f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-7f96b475-35a4-4bf5-b297-f477bfda3555,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-722b786d-71a3-4107-9e87-74d6fee7413f,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-d382ff2a-a308-4f1e-aba0-dbe83aee1d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-5fcb6964-fb4d-40e4-9604-368191f84b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776410893-172.17.0.2-1596961296165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-2fea26d5-a238-4d8e-ad86-5874e0f5c595,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-31b256af-1c70-4247-bb90-ca6b38ea3023,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-d898e58f-4474-48ab-a9c7-a8c92dd7f046,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-e21ac9cc-2ddb-4a89-a3a9-aa14417565f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-7f96b475-35a4-4bf5-b297-f477bfda3555,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-722b786d-71a3-4107-9e87-74d6fee7413f,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-d382ff2a-a308-4f1e-aba0-dbe83aee1d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-5fcb6964-fb4d-40e4-9604-368191f84b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027406110-172.17.0.2-1596961389019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35544,DS-37413b40-ce99-4b0e-8201-6cb38ee3c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-0aec0e3c-995a-45b8-b866-57a58f468d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-60ced52d-b6fc-4d4f-b70f-6040f27b8a20,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-e1ef9a46-9554-4f03-b539-335467707798,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-e8643316-0fcb-48d5-a889-82eca7d1dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-78135af3-0f0a-4c39-99e2-10b39bf063bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b8fe3fb6-8203-4f7a-8898-d4d50a8a244d,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-2cb1429d-3e59-4de4-b8da-a57abe29ce9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027406110-172.17.0.2-1596961389019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35544,DS-37413b40-ce99-4b0e-8201-6cb38ee3c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-0aec0e3c-995a-45b8-b866-57a58f468d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-60ced52d-b6fc-4d4f-b70f-6040f27b8a20,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-e1ef9a46-9554-4f03-b539-335467707798,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-e8643316-0fcb-48d5-a889-82eca7d1dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-78135af3-0f0a-4c39-99e2-10b39bf063bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b8fe3fb6-8203-4f7a-8898-d4d50a8a244d,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-2cb1429d-3e59-4de4-b8da-a57abe29ce9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752652237-172.17.0.2-1596961578853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-c6b3c389-3e10-4057-9b16-99f39e4aadda,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-5e11de05-fa53-44a4-9acd-daf6ab47f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-01939241-332d-4254-b568-ca6072e69f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-a8f0874b-08c0-47aa-a8f6-d8477cfd0c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-9598cf51-a106-4087-a06b-a07966af2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-bae4e4e4-0bd0-4255-a3c2-63a8bbbc2fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-3e3b2c87-7a5c-4b65-a22c-cfc0414d44fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-8eab5214-0621-4850-b186-7015d609fb17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752652237-172.17.0.2-1596961578853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-c6b3c389-3e10-4057-9b16-99f39e4aadda,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-5e11de05-fa53-44a4-9acd-daf6ab47f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-01939241-332d-4254-b568-ca6072e69f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-a8f0874b-08c0-47aa-a8f6-d8477cfd0c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-9598cf51-a106-4087-a06b-a07966af2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-bae4e4e4-0bd0-4255-a3c2-63a8bbbc2fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-3e3b2c87-7a5c-4b65-a22c-cfc0414d44fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-8eab5214-0621-4850-b186-7015d609fb17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252148131-172.17.0.2-1596962542243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34760,DS-6c2447ba-9c4c-42e1-88a3-da4b0edeeb18,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-7630608c-400b-4103-857e-f4e09079c898,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-73da2e13-64eb-4383-9b38-fc2aee2972b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-fab40016-c18e-4b14-8ec8-dfa1b57790fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-76cba2fb-7747-4759-87af-6e05f9f6b626,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-13b84bfa-b3fc-49a9-ac10-5cf2867c6fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-2e617ea2-9153-4192-9e64-e589e04a875b,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-9878ee10-bf1a-41ee-97c7-50403abda887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252148131-172.17.0.2-1596962542243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34760,DS-6c2447ba-9c4c-42e1-88a3-da4b0edeeb18,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-7630608c-400b-4103-857e-f4e09079c898,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-73da2e13-64eb-4383-9b38-fc2aee2972b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-fab40016-c18e-4b14-8ec8-dfa1b57790fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-76cba2fb-7747-4759-87af-6e05f9f6b626,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-13b84bfa-b3fc-49a9-ac10-5cf2867c6fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-2e617ea2-9153-4192-9e64-e589e04a875b,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-9878ee10-bf1a-41ee-97c7-50403abda887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757296548-172.17.0.2-1596962791770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-da1cc576-ed64-4966-bc87-7da1e75cd81e,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-b23615a0-a713-4980-ad80-2cb98b9742d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-d9f72bbd-d5d9-47c1-8b96-75141a844d55,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-fc89b5c1-bcd8-4704-bb8c-47ba2b70bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-922c3f7d-ee08-4a46-a1d8-609846d91cda,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-946daa2c-64d6-4355-9eb9-592a3cba074a,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-f74b1236-c5d4-4a24-a5d8-5691917887a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-790de301-b40a-4b73-b8df-b12010bf9320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757296548-172.17.0.2-1596962791770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-da1cc576-ed64-4966-bc87-7da1e75cd81e,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-b23615a0-a713-4980-ad80-2cb98b9742d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-d9f72bbd-d5d9-47c1-8b96-75141a844d55,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-fc89b5c1-bcd8-4704-bb8c-47ba2b70bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-922c3f7d-ee08-4a46-a1d8-609846d91cda,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-946daa2c-64d6-4355-9eb9-592a3cba074a,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-f74b1236-c5d4-4a24-a5d8-5691917887a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-790de301-b40a-4b73-b8df-b12010bf9320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4931
