reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142022533-172.17.0.16-1596879007185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-3662730c-fc09-434e-b6a9-f48d9180a167,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-1b9353a8-caff-463a-a996-2d109ec37158,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b42bcd4d-1ddc-4718-ab49-6a109a10231f,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-de5c040d-b16a-4750-8a48-4d24533f03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-21c3f26a-2476-465e-857f-5c43ba861be8,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-633ed529-318d-424b-963a-3073a385f0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-bdc2159d-f023-4e2e-863e-c723ca810010,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-0f9e9534-01e8-4521-983b-6e7e57d8b7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142022533-172.17.0.16-1596879007185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-3662730c-fc09-434e-b6a9-f48d9180a167,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-1b9353a8-caff-463a-a996-2d109ec37158,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b42bcd4d-1ddc-4718-ab49-6a109a10231f,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-de5c040d-b16a-4750-8a48-4d24533f03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-21c3f26a-2476-465e-857f-5c43ba861be8,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-633ed529-318d-424b-963a-3073a385f0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-bdc2159d-f023-4e2e-863e-c723ca810010,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-0f9e9534-01e8-4521-983b-6e7e57d8b7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259910235-172.17.0.16-1596879456761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-dff8a111-1410-4f4d-a5d5-d422b7c3e84a,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-95f952ed-9dbf-4a8c-a7a3-cbc5fd097f01,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-1ff2b5aa-b0dd-4949-b990-ba308c761b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-b3b125cd-5c76-4411-bc52-03152d9c994c,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5229f560-063d-4356-abcc-590de33cc26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-e245722f-b13a-4571-87c8-00bfaae0cc89,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-b84bdad2-c945-485d-8c20-89d743a5017b,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-3fc36125-1a33-4408-a756-058c4cd79671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259910235-172.17.0.16-1596879456761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-dff8a111-1410-4f4d-a5d5-d422b7c3e84a,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-95f952ed-9dbf-4a8c-a7a3-cbc5fd097f01,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-1ff2b5aa-b0dd-4949-b990-ba308c761b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-b3b125cd-5c76-4411-bc52-03152d9c994c,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5229f560-063d-4356-abcc-590de33cc26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-e245722f-b13a-4571-87c8-00bfaae0cc89,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-b84bdad2-c945-485d-8c20-89d743a5017b,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-3fc36125-1a33-4408-a756-058c4cd79671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971633434-172.17.0.16-1596879872071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-d418e109-ef28-4dcb-bcc1-011048333606,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-cdae0c51-d5c9-45b8-8197-32304f489300,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-c9ffde7d-7a33-454a-ae11-2b529a9b3a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-928af2ca-bbed-41cf-b654-1df42c98aa24,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-acde4e3a-7f3c-4c87-880c-311b1387726c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-35fedee7-20ce-46de-b4f5-e07281d9f596,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-af130177-0027-4a3d-b4a4-e60ae99045e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-f74f7e19-c852-408c-b3f6-db300ecea95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971633434-172.17.0.16-1596879872071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-d418e109-ef28-4dcb-bcc1-011048333606,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-cdae0c51-d5c9-45b8-8197-32304f489300,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-c9ffde7d-7a33-454a-ae11-2b529a9b3a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-928af2ca-bbed-41cf-b654-1df42c98aa24,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-acde4e3a-7f3c-4c87-880c-311b1387726c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-35fedee7-20ce-46de-b4f5-e07281d9f596,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-af130177-0027-4a3d-b4a4-e60ae99045e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-f74f7e19-c852-408c-b3f6-db300ecea95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584761096-172.17.0.16-1596880524307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-36623714-26b9-4acf-91d1-053853dc60e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-8fd01856-743f-42e4-bfd3-acc7b9c275de,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-bff16092-784d-4924-9eda-08712b805a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-39e7f00e-e0c1-416c-a3d2-e8c275de881f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-01c02b81-9a57-4e04-aa5f-a15f728fb5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f9dd253b-642c-471f-9238-4801e39aabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-ee3bf6ea-d7e1-4e20-9216-60d406e0aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-afc2c610-3637-4111-a9ba-96b7f48f0283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584761096-172.17.0.16-1596880524307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-36623714-26b9-4acf-91d1-053853dc60e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-8fd01856-743f-42e4-bfd3-acc7b9c275de,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-bff16092-784d-4924-9eda-08712b805a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-39e7f00e-e0c1-416c-a3d2-e8c275de881f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-01c02b81-9a57-4e04-aa5f-a15f728fb5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f9dd253b-642c-471f-9238-4801e39aabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-ee3bf6ea-d7e1-4e20-9216-60d406e0aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-afc2c610-3637-4111-a9ba-96b7f48f0283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624734065-172.17.0.16-1596880655517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-f181e8d9-f09d-42ed-987c-a210edca532a,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-59f28c29-69ad-4626-9f85-1c0422d69edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-45011785-3e3d-4914-a286-e16a2cc8e964,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-a0e55391-4810-45ee-9780-f099e11ee094,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-68b73a78-82c8-4ec1-ad5e-e1ad16e78b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-37a2ae9a-558d-48f0-97a1-158c942fd54b,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-d32f8644-cd80-4b3a-a1ab-811cb7b62c81,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-c7192dcf-f0fa-4656-a84e-c043ac1d38e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624734065-172.17.0.16-1596880655517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-f181e8d9-f09d-42ed-987c-a210edca532a,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-59f28c29-69ad-4626-9f85-1c0422d69edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-45011785-3e3d-4914-a286-e16a2cc8e964,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-a0e55391-4810-45ee-9780-f099e11ee094,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-68b73a78-82c8-4ec1-ad5e-e1ad16e78b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-37a2ae9a-558d-48f0-97a1-158c942fd54b,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-d32f8644-cd80-4b3a-a1ab-811cb7b62c81,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-c7192dcf-f0fa-4656-a84e-c043ac1d38e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633459105-172.17.0.16-1596880826625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-6cfe9fbf-f1b4-4941-88ad-832fd40ac082,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-ce87944f-a2c5-4905-8ad7-9dce0b43f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-58ac0a2d-2454-4b49-8dd9-440b8bbf040d,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-39bee9ba-f266-4ebe-a3b4-eec3d9c0d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-85fb8db9-c063-483a-a369-3f3e52305689,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-2cad9dce-6029-451f-abdf-46b98156e475,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-6cc8cdeb-784b-480a-bd07-95d4205a772c,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-1128537f-5e90-433c-bdf0-9b9950cc891e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633459105-172.17.0.16-1596880826625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-6cfe9fbf-f1b4-4941-88ad-832fd40ac082,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-ce87944f-a2c5-4905-8ad7-9dce0b43f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-58ac0a2d-2454-4b49-8dd9-440b8bbf040d,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-39bee9ba-f266-4ebe-a3b4-eec3d9c0d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-85fb8db9-c063-483a-a369-3f3e52305689,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-2cad9dce-6029-451f-abdf-46b98156e475,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-6cc8cdeb-784b-480a-bd07-95d4205a772c,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-1128537f-5e90-433c-bdf0-9b9950cc891e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351846550-172.17.0.16-1596881138114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-853d5a5f-6fd9-4e4d-96a6-334578fee998,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-05c55105-5af7-4515-8e13-e16bcc59d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-d0635afb-98e4-4781-90cc-aa0467aec63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-8799ebd2-1c0d-4953-bd13-e7466f69a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-5640908d-45b3-48f9-bed5-54bbc96942aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-9e5fee6b-0763-4443-9ef0-bca4dedec2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-5cdb20c1-eadb-4a30-928d-ed64991f6787,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-ec56e059-548c-4eeb-8254-09e05c67d8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351846550-172.17.0.16-1596881138114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-853d5a5f-6fd9-4e4d-96a6-334578fee998,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-05c55105-5af7-4515-8e13-e16bcc59d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-d0635afb-98e4-4781-90cc-aa0467aec63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-8799ebd2-1c0d-4953-bd13-e7466f69a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-5640908d-45b3-48f9-bed5-54bbc96942aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-9e5fee6b-0763-4443-9ef0-bca4dedec2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-5cdb20c1-eadb-4a30-928d-ed64991f6787,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-ec56e059-548c-4eeb-8254-09e05c67d8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801640595-172.17.0.16-1596881731347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-82cbc6fc-848e-4aa5-97eb-a11cafe31063,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-bcc7b33d-6181-4fa0-bfe6-0a50bb23c798,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-8bc2195f-1492-4cf1-9195-0ceb265e5311,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-693fff5a-c776-4f94-ad01-f5b6a237752f,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-d72ae229-320a-44a2-a192-87ca89b9b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-6b4d8c8e-e709-4d4d-9f45-8e3d6b1e6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-d8d986c6-af77-4bb6-b074-ac9faa7dd239,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-8c1d94db-fa01-4427-8154-9295018ec67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801640595-172.17.0.16-1596881731347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-82cbc6fc-848e-4aa5-97eb-a11cafe31063,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-bcc7b33d-6181-4fa0-bfe6-0a50bb23c798,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-8bc2195f-1492-4cf1-9195-0ceb265e5311,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-693fff5a-c776-4f94-ad01-f5b6a237752f,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-d72ae229-320a-44a2-a192-87ca89b9b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-6b4d8c8e-e709-4d4d-9f45-8e3d6b1e6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-d8d986c6-af77-4bb6-b074-ac9faa7dd239,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-8c1d94db-fa01-4427-8154-9295018ec67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367669409-172.17.0.16-1596882052652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41956,DS-bf334186-7118-481c-9f5d-34e3343c6a09,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-6955a75e-fa58-47a8-b9f9-f8664bd5dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-cb6daae2-4db3-43ad-ba64-a315d8e823bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-66083b6c-2237-440c-af4b-1671025929f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-11064edc-87c5-4425-89ff-927b943ec2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-cd3e3552-c464-4607-98cb-9b99b8ec3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-b132968d-43f2-44c5-aecd-341162c39b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-18355343-eaf8-4316-a6a5-667ffdbe273f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367669409-172.17.0.16-1596882052652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41956,DS-bf334186-7118-481c-9f5d-34e3343c6a09,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-6955a75e-fa58-47a8-b9f9-f8664bd5dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-cb6daae2-4db3-43ad-ba64-a315d8e823bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-66083b6c-2237-440c-af4b-1671025929f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-11064edc-87c5-4425-89ff-927b943ec2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-cd3e3552-c464-4607-98cb-9b99b8ec3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-b132968d-43f2-44c5-aecd-341162c39b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-18355343-eaf8-4316-a6a5-667ffdbe273f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996550842-172.17.0.16-1596882198403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-9744502c-8926-4b74-9674-739670478209,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-295aedb6-4e69-4b4a-995e-a05624cdb21d,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-9c0331fc-335c-4fdc-8d22-fe1301920cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-86f8adaf-a849-41cd-bf70-1965e8a0d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-753b8f26-793a-4144-86d1-89f7d52316c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-0888861b-c8f7-4f78-b054-ba3806ae06e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-d2d27ef4-21d3-4c45-a101-e72d249566a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-5f9dccf8-aa02-4476-a32f-8d0ae8e19a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996550842-172.17.0.16-1596882198403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-9744502c-8926-4b74-9674-739670478209,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-295aedb6-4e69-4b4a-995e-a05624cdb21d,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-9c0331fc-335c-4fdc-8d22-fe1301920cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-86f8adaf-a849-41cd-bf70-1965e8a0d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-753b8f26-793a-4144-86d1-89f7d52316c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-0888861b-c8f7-4f78-b054-ba3806ae06e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-d2d27ef4-21d3-4c45-a101-e72d249566a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-5f9dccf8-aa02-4476-a32f-8d0ae8e19a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189543818-172.17.0.16-1596882507820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-d6beaf9f-44a6-449c-ab4f-da7582e2ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-a3a974b0-89b7-49d0-8b4c-31ac314be14b,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-cfa59b38-bcc2-4c43-a93d-e7449d6b3485,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-04e43095-de7a-4391-bdd3-93f209586fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-144adce2-c75a-436d-bf21-9c69ac608d76,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-ef1adb48-9718-4ad0-8805-9092ff1b2a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-e79b3cca-80b7-40a7-927b-b9ec39accad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-daca4373-47a8-4b0d-81b5-1fd6bcca0527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189543818-172.17.0.16-1596882507820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-d6beaf9f-44a6-449c-ab4f-da7582e2ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-a3a974b0-89b7-49d0-8b4c-31ac314be14b,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-cfa59b38-bcc2-4c43-a93d-e7449d6b3485,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-04e43095-de7a-4391-bdd3-93f209586fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-144adce2-c75a-436d-bf21-9c69ac608d76,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-ef1adb48-9718-4ad0-8805-9092ff1b2a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-e79b3cca-80b7-40a7-927b-b9ec39accad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-daca4373-47a8-4b0d-81b5-1fd6bcca0527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5210
