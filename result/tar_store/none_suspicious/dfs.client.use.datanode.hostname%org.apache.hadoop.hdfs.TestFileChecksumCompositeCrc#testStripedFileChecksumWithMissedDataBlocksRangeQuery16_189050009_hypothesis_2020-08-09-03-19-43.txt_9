reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511472527-172.17.0.7-1596943198366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-f10f025b-6641-4698-9d27-43f9dbae7552,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-7637d571-14c1-4b56-a4d7-5f4c2cd9e19a,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-98307037-32cf-47b3-9b38-b8afb2bb96e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-6b3b6f09-a750-45ff-a11b-6dbe8456c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-3f309cc0-7a2d-4885-93d3-9bd02a6066e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-ff0775b4-8a71-45cf-9cad-6b48fc53cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-799b0f89-bfc7-4f40-9abc-b133112b9e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-ae728fad-1b1d-4a13-bbf8-214b510128bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511472527-172.17.0.7-1596943198366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-f10f025b-6641-4698-9d27-43f9dbae7552,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-7637d571-14c1-4b56-a4d7-5f4c2cd9e19a,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-98307037-32cf-47b3-9b38-b8afb2bb96e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-6b3b6f09-a750-45ff-a11b-6dbe8456c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-3f309cc0-7a2d-4885-93d3-9bd02a6066e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-ff0775b4-8a71-45cf-9cad-6b48fc53cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-799b0f89-bfc7-4f40-9abc-b133112b9e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-ae728fad-1b1d-4a13-bbf8-214b510128bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912321256-172.17.0.7-1596943382682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-f8c2f138-66d2-4ca0-a3bd-0cf19969889a,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-69dda343-c301-4f97-8abd-8009618e6349,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-774f7395-fca1-4625-92ef-36738dce3533,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-0ecbc177-3687-4234-87a4-8b28b6d14fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-098ef487-f943-4253-88c8-36c9e13e27bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-02df41cc-fefa-4b3e-bc77-4493b7b6c4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-1badfc18-aaad-47a9-9835-50efe59483d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-b15b72ae-1fdf-4db5-a92e-46c41aa473ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912321256-172.17.0.7-1596943382682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-f8c2f138-66d2-4ca0-a3bd-0cf19969889a,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-69dda343-c301-4f97-8abd-8009618e6349,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-774f7395-fca1-4625-92ef-36738dce3533,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-0ecbc177-3687-4234-87a4-8b28b6d14fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-098ef487-f943-4253-88c8-36c9e13e27bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-02df41cc-fefa-4b3e-bc77-4493b7b6c4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-1badfc18-aaad-47a9-9835-50efe59483d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-b15b72ae-1fdf-4db5-a92e-46c41aa473ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474359955-172.17.0.7-1596944042555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-c8f8fbf9-ff2b-41fe-a0c0-74db18cac909,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-ca7d7d93-1faa-4c79-b808-206c79d15195,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-aa2eccf4-693d-4ac2-9c3c-839b1725f908,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-ea8ed73d-3884-45ae-83f9-2e9d3ed41cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-168a0a0e-b0f4-41ca-8e85-f419585e7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-48ca478b-9482-414c-b58d-36d9b9ab1084,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-a393cb42-29b6-4a61-a822-c2ae9ce587a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-7d5bfcbe-5eb3-4891-a0cd-68770423ecfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474359955-172.17.0.7-1596944042555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-c8f8fbf9-ff2b-41fe-a0c0-74db18cac909,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-ca7d7d93-1faa-4c79-b808-206c79d15195,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-aa2eccf4-693d-4ac2-9c3c-839b1725f908,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-ea8ed73d-3884-45ae-83f9-2e9d3ed41cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-168a0a0e-b0f4-41ca-8e85-f419585e7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-48ca478b-9482-414c-b58d-36d9b9ab1084,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-a393cb42-29b6-4a61-a822-c2ae9ce587a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-7d5bfcbe-5eb3-4891-a0cd-68770423ecfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784626525-172.17.0.7-1596944252145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-dc913f28-ffec-46a7-b2b7-af9fea115fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-f75fe9a9-d5ef-4cd4-8373-61546d1ded9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-d22414b5-e7bb-4ac3-811d-1fe6ad0cc4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-a81011ff-e4d5-4459-a3d0-4e14c399eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-4ec11d3d-2e9a-49c0-ba50-69e442d165b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-70e57b0f-ee92-49ba-adf7-164159a9ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-9fae3a43-6ab9-4f83-b94a-8d17d245378a,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-59051976-b4f4-4200-8ee5-91c6e613b4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784626525-172.17.0.7-1596944252145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-dc913f28-ffec-46a7-b2b7-af9fea115fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-f75fe9a9-d5ef-4cd4-8373-61546d1ded9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-d22414b5-e7bb-4ac3-811d-1fe6ad0cc4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-a81011ff-e4d5-4459-a3d0-4e14c399eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-4ec11d3d-2e9a-49c0-ba50-69e442d165b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-70e57b0f-ee92-49ba-adf7-164159a9ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-9fae3a43-6ab9-4f83-b94a-8d17d245378a,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-59051976-b4f4-4200-8ee5-91c6e613b4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080517284-172.17.0.7-1596944568588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41173,DS-1f027d53-8aaf-4b04-8cee-6d4dd8d746bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-22dadd20-1c65-44e1-bf91-982e6dc0f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-3fccfd7c-fce0-4994-8670-7e1c549b8e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-43e65945-4ab5-4032-a80f-e70b8a416c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-f648b5c0-96db-4c96-9950-a9d37fedb6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-d5c9babb-4050-4d04-9fbf-d3c9120c7214,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-70fe9b8b-1e36-4a48-8660-ab6ddec3dc27,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-d0fc92c2-5bcc-4fdd-bfac-b0a22deca0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080517284-172.17.0.7-1596944568588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41173,DS-1f027d53-8aaf-4b04-8cee-6d4dd8d746bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-22dadd20-1c65-44e1-bf91-982e6dc0f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-3fccfd7c-fce0-4994-8670-7e1c549b8e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-43e65945-4ab5-4032-a80f-e70b8a416c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-f648b5c0-96db-4c96-9950-a9d37fedb6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-d5c9babb-4050-4d04-9fbf-d3c9120c7214,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-70fe9b8b-1e36-4a48-8660-ab6ddec3dc27,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-d0fc92c2-5bcc-4fdd-bfac-b0a22deca0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846835331-172.17.0.7-1596944940680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-0ec39406-5d78-42e6-8240-a3b96e588ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-fc4d320a-da99-44a4-be17-daab63d3a421,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-3ffd8da9-c164-4cd7-93ae-f3cec6c4272d,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-22c99e7e-65cc-40d1-9add-48b72ed2299b,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-e6dd2ed7-ddd4-48c5-bac9-1eacb2f99db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-e57c6d7b-4425-4f04-9dbd-30fd9ec2b57f,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-802859d2-0529-487d-8395-60f3df7912f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-c53d01b1-c4ad-41b5-a27d-d6720d35c6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846835331-172.17.0.7-1596944940680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-0ec39406-5d78-42e6-8240-a3b96e588ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-fc4d320a-da99-44a4-be17-daab63d3a421,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-3ffd8da9-c164-4cd7-93ae-f3cec6c4272d,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-22c99e7e-65cc-40d1-9add-48b72ed2299b,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-e6dd2ed7-ddd4-48c5-bac9-1eacb2f99db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-e57c6d7b-4425-4f04-9dbd-30fd9ec2b57f,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-802859d2-0529-487d-8395-60f3df7912f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-c53d01b1-c4ad-41b5-a27d-d6720d35c6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746215901-172.17.0.7-1596945624251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36472,DS-f6e7dff9-4b76-4202-a4c4-e6af2c12e581,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-5389f0e4-637b-4180-988d-c769709825b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-368d9c7f-b6b5-4795-98c2-80a83439ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-2b5ce3f9-a6d3-4ab6-a13a-a666e4ec321c,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-97cd17c6-aa62-4c77-906e-8e3f5298ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-d56f7c6c-5956-468c-9295-9d5b7749494a,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-52234519-eb6c-4080-9f59-5c4de290695a,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-e2207abe-049f-43cf-acd0-14f602c923a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746215901-172.17.0.7-1596945624251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36472,DS-f6e7dff9-4b76-4202-a4c4-e6af2c12e581,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-5389f0e4-637b-4180-988d-c769709825b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-368d9c7f-b6b5-4795-98c2-80a83439ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-2b5ce3f9-a6d3-4ab6-a13a-a666e4ec321c,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-97cd17c6-aa62-4c77-906e-8e3f5298ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-d56f7c6c-5956-468c-9295-9d5b7749494a,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-52234519-eb6c-4080-9f59-5c4de290695a,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-e2207abe-049f-43cf-acd0-14f602c923a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821281328-172.17.0.7-1596945789765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41712,DS-09e08103-c0af-471d-9eac-0824fa9f06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ce6777eb-3230-4183-aef9-e716494fe251,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-4941df1e-20df-4a71-94f1-9acc088252ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-478b3b0a-9089-488e-8cca-46058449a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-b8273fa8-5e07-4a39-86ab-6dda81531325,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-4fe1bc7c-3802-493c-8841-b36b233dcf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-f586fe84-72d2-49c2-bb55-375a7497340b,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-dffd55ca-6122-4182-ada4-2e03ddb0cc43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821281328-172.17.0.7-1596945789765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41712,DS-09e08103-c0af-471d-9eac-0824fa9f06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ce6777eb-3230-4183-aef9-e716494fe251,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-4941df1e-20df-4a71-94f1-9acc088252ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-478b3b0a-9089-488e-8cca-46058449a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-b8273fa8-5e07-4a39-86ab-6dda81531325,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-4fe1bc7c-3802-493c-8841-b36b233dcf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-f586fe84-72d2-49c2-bb55-375a7497340b,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-dffd55ca-6122-4182-ada4-2e03ddb0cc43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983477886-172.17.0.7-1596945826811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46244,DS-0925baa9-850f-45c6-9132-9188547790a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-7bdad97a-d5e0-4507-87d4-89f51acad006,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-e03e42f1-a268-4da7-983e-2fc10a878a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-39f5e405-b5ad-450b-b797-698b9d0b0e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-176f7f5c-fec2-4417-acd9-ce6f5f2fb875,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-14a3a6a1-8be1-4876-aaa5-03c7f5fa016f,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-6a135274-556f-4fa6-b67f-910952c2cf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-5f9381cd-c038-4994-8d50-d1ef9e26a27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983477886-172.17.0.7-1596945826811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46244,DS-0925baa9-850f-45c6-9132-9188547790a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-7bdad97a-d5e0-4507-87d4-89f51acad006,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-e03e42f1-a268-4da7-983e-2fc10a878a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-39f5e405-b5ad-450b-b797-698b9d0b0e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-176f7f5c-fec2-4417-acd9-ce6f5f2fb875,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-14a3a6a1-8be1-4876-aaa5-03c7f5fa016f,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-6a135274-556f-4fa6-b67f-910952c2cf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-5f9381cd-c038-4994-8d50-d1ef9e26a27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493908819-172.17.0.7-1596945892673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-994ab6f9-4266-4050-b437-15a69c162fad,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-c0292c17-ec19-4f1c-8c46-8b8c4e755476,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-459955c2-24ee-4704-bc4f-a24798e36b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-f187bbac-8518-433d-b04a-e1c928b8e146,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-ccf6b606-389a-4b6b-80a4-726fc1154f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-8b1f065b-b352-47cd-a9e0-e45aebcbcdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-fbdb83e3-6566-41f4-9668-af4f974425d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-e5518493-56a8-412d-8d5f-78fd95ad7c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493908819-172.17.0.7-1596945892673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-994ab6f9-4266-4050-b437-15a69c162fad,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-c0292c17-ec19-4f1c-8c46-8b8c4e755476,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-459955c2-24ee-4704-bc4f-a24798e36b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-f187bbac-8518-433d-b04a-e1c928b8e146,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-ccf6b606-389a-4b6b-80a4-726fc1154f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-8b1f065b-b352-47cd-a9e0-e45aebcbcdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-fbdb83e3-6566-41f4-9668-af4f974425d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-e5518493-56a8-412d-8d5f-78fd95ad7c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439229637-172.17.0.7-1596946236527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-31314510-40f5-4e4f-b443-fa51233cdda4,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-02b3a189-7aff-452c-80e2-8ae1333a4914,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-fe4afff6-810c-40d8-8007-e4f4bcc6ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-10f58ec1-a855-43d1-8586-6b75dd7c1085,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-051b5880-9fde-49bf-b361-fefef5323439,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-cf5e2eb9-8eac-41cc-8248-ecf84e995c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-8c07ddbc-90e5-441c-96fd-eec15654ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-4eab9914-4ebb-4bad-80ab-805086c8a487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439229637-172.17.0.7-1596946236527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-31314510-40f5-4e4f-b443-fa51233cdda4,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-02b3a189-7aff-452c-80e2-8ae1333a4914,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-fe4afff6-810c-40d8-8007-e4f4bcc6ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-10f58ec1-a855-43d1-8586-6b75dd7c1085,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-051b5880-9fde-49bf-b361-fefef5323439,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-cf5e2eb9-8eac-41cc-8248-ecf84e995c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-8c07ddbc-90e5-441c-96fd-eec15654ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-4eab9914-4ebb-4bad-80ab-805086c8a487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368925906-172.17.0.7-1596946374491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-a0133919-ef6d-463e-bee5-670bcf0ecdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-7f7e8379-c27b-447a-a6de-5686b80fd4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-764f28fb-79b7-4bab-be98-1e86e6832e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-a13754b2-497c-469b-af4f-ddc7954f6c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-e84ebbbf-e31a-414b-9ea4-38bafedea96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-8777918a-b462-492a-a267-25ccde44f262,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-c6ad581e-ff1a-451c-abbc-3148388573bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-424fdbc5-d56d-4f40-959d-650969353b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368925906-172.17.0.7-1596946374491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-a0133919-ef6d-463e-bee5-670bcf0ecdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-7f7e8379-c27b-447a-a6de-5686b80fd4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-764f28fb-79b7-4bab-be98-1e86e6832e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-a13754b2-497c-469b-af4f-ddc7954f6c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-e84ebbbf-e31a-414b-9ea4-38bafedea96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-8777918a-b462-492a-a267-25ccde44f262,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-c6ad581e-ff1a-451c-abbc-3148388573bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-424fdbc5-d56d-4f40-959d-650969353b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636603858-172.17.0.7-1596947392459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-c27d7e09-ace1-4e3a-8d30-7e0e4c441fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-6898ec3f-32f1-4088-adcc-032b4bba3e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-d174f47f-e8bc-4ef4-a39c-37e51dac1700,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-c16072cc-545f-42c5-92e6-234a79fe0256,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-042678fa-fd61-4946-968c-73c064b1f88a,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-15efd81f-1214-4b14-a01a-199ff47a6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-c7a3266a-6960-438f-afd3-47ac22e1cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-ab0784d4-9bdd-4d21-afde-79ce7cefe37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636603858-172.17.0.7-1596947392459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-c27d7e09-ace1-4e3a-8d30-7e0e4c441fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-6898ec3f-32f1-4088-adcc-032b4bba3e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-d174f47f-e8bc-4ef4-a39c-37e51dac1700,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-c16072cc-545f-42c5-92e6-234a79fe0256,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-042678fa-fd61-4946-968c-73c064b1f88a,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-15efd81f-1214-4b14-a01a-199ff47a6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-c7a3266a-6960-438f-afd3-47ac22e1cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-ab0784d4-9bdd-4d21-afde-79ce7cefe37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777532162-172.17.0.7-1596947493227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39408,DS-ff1962fd-c0a3-478b-84f1-e2ffc848ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-e057a4f8-c570-41b4-b113-9d7607bc306d,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-a83111c6-45d7-44f9-a195-18bd4f23f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-b07b10fc-1a21-484c-8911-ed4e4ef871b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-5d199852-fd51-449d-8bc5-1adb04356c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-372de334-820d-4a6f-9504-2fe5ac5508ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-e38aeeee-78bf-45f8-a75f-f90ff734c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-322afb0f-dee6-44e7-a1e4-ad3202b89237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777532162-172.17.0.7-1596947493227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39408,DS-ff1962fd-c0a3-478b-84f1-e2ffc848ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-e057a4f8-c570-41b4-b113-9d7607bc306d,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-a83111c6-45d7-44f9-a195-18bd4f23f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-b07b10fc-1a21-484c-8911-ed4e4ef871b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-5d199852-fd51-449d-8bc5-1adb04356c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-372de334-820d-4a6f-9504-2fe5ac5508ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-e38aeeee-78bf-45f8-a75f-f90ff734c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-322afb0f-dee6-44e7-a1e4-ad3202b89237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217561314-172.17.0.7-1596947701657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-2a0a1f22-6129-451b-950c-03b13f7b0046,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-d3aa01cd-77de-41fa-a7fe-ba35e34dc579,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-d2e8bbfa-f7da-4dd5-bf0d-c5c530a8f223,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-5b45ac57-194a-4651-8c8f-b1dd2c6356aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-f9a4b1f7-6514-4375-add3-018aa13c108e,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-50c74fbe-6901-4471-9a1e-f0f6a41e5204,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-3787d4af-ff7f-4fdb-a1a1-d996abfde880,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-04e43c76-c224-4584-bac4-95599d4948b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217561314-172.17.0.7-1596947701657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-2a0a1f22-6129-451b-950c-03b13f7b0046,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-d3aa01cd-77de-41fa-a7fe-ba35e34dc579,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-d2e8bbfa-f7da-4dd5-bf0d-c5c530a8f223,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-5b45ac57-194a-4651-8c8f-b1dd2c6356aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-f9a4b1f7-6514-4375-add3-018aa13c108e,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-50c74fbe-6901-4471-9a1e-f0f6a41e5204,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-3787d4af-ff7f-4fdb-a1a1-d996abfde880,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-04e43c76-c224-4584-bac4-95599d4948b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606707870-172.17.0.7-1596948338763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-37020053-d1bd-4082-8420-a3aeaa856c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-264962b1-462d-4f08-b9d9-c60546a8fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-74f12b38-4257-455c-a64f-fd304ea112ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-bcee916a-1858-4be7-a19e-99ce63374ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d0f75275-b6ec-40c1-84af-2380d4ebe561,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-6dff5f9d-990e-4a84-9346-ec73c16e643b,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-1a7336ba-00f0-4bbe-bd57-9848cc4dd169,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-00ec4399-32cf-46b9-b7d9-7500124c6727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606707870-172.17.0.7-1596948338763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-37020053-d1bd-4082-8420-a3aeaa856c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-264962b1-462d-4f08-b9d9-c60546a8fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-74f12b38-4257-455c-a64f-fd304ea112ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-bcee916a-1858-4be7-a19e-99ce63374ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d0f75275-b6ec-40c1-84af-2380d4ebe561,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-6dff5f9d-990e-4a84-9346-ec73c16e643b,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-1a7336ba-00f0-4bbe-bd57-9848cc4dd169,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-00ec4399-32cf-46b9-b7d9-7500124c6727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5170
