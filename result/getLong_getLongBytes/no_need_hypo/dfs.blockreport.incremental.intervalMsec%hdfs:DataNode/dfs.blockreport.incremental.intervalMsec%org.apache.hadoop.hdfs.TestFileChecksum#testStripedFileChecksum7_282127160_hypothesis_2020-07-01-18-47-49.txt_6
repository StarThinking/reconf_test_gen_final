reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1510479700-172.17.0.14-1593629284516:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-9be27a59-2ec3-46e0-938a-2e1b7bb21a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-b995afd2-7b1c-4598-8002-a1579da8e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-954149ca-ace0-4e18-af14-eecf9c2043e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-d4bd6966-98e3-4b43-8b1b-7d119e2040a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-51f1e961-3226-4288-b30d-a5fa12144d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-bea37787-c1d1-4be2-9270-96b04c8f967d,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-7e782e4e-658d-47c7-931c-9ed65504d0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1510479700-172.17.0.14-1593629284516:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-9be27a59-2ec3-46e0-938a-2e1b7bb21a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-b995afd2-7b1c-4598-8002-a1579da8e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-954149ca-ace0-4e18-af14-eecf9c2043e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-d4bd6966-98e3-4b43-8b1b-7d119e2040a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-51f1e961-3226-4288-b30d-a5fa12144d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-bea37787-c1d1-4be2-9270-96b04c8f967d,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-7e782e4e-658d-47c7-931c-9ed65504d0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-61401532-172.17.0.14-1593629444466:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-a4990fbf-1f53-4f82-925c-723e36a3d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-583a90e2-447e-4ede-b997-f4edb9f4aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-a92690ca-721d-4d5e-a037-c698ecb0eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-6e586eb1-9997-45b3-9eb3-534586a10d87,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-92c9e7be-dca5-418b-bb2a-fe8742d8c868,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-e8c8e1ec-fe71-4c95-ade8-c8c6810b98f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-0f7acd7f-bb27-465a-a098-f80589fe87fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c6a7f7fe-fa2f-449e-b13f-fb2628f29d5a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-61401532-172.17.0.14-1593629444466:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-a4990fbf-1f53-4f82-925c-723e36a3d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-583a90e2-447e-4ede-b997-f4edb9f4aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-a92690ca-721d-4d5e-a037-c698ecb0eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-6e586eb1-9997-45b3-9eb3-534586a10d87,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-92c9e7be-dca5-418b-bb2a-fe8742d8c868,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-e8c8e1ec-fe71-4c95-ade8-c8c6810b98f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-0f7acd7f-bb27-465a-a098-f80589fe87fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c6a7f7fe-fa2f-449e-b13f-fb2628f29d5a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-312703644-172.17.0.14-1593629600799:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-4880173a-1e05-45d7-8af5-416e5838cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-cb7f4119-7dff-42a3-a0d7-da26c78ba15c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-36593eed-47f4-4953-8d08-5f3cc6078477,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-f5c59c3b-9b7e-481f-9b88-86bb4963326a,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-6bd82898-b76e-48c9-9aed-cc76ae87ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-7e1de959-51d2-43b6-99a9-b2af9ce7e34e,DISK]]; indices=[1, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-312703644-172.17.0.14-1593629600799:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-4880173a-1e05-45d7-8af5-416e5838cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-cb7f4119-7dff-42a3-a0d7-da26c78ba15c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-36593eed-47f4-4953-8d08-5f3cc6078477,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-f5c59c3b-9b7e-481f-9b88-86bb4963326a,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-6bd82898-b76e-48c9-9aed-cc76ae87ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-7e1de959-51d2-43b6-99a9-b2af9ce7e34e,DISK]]; indices=[1, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1694937224-172.17.0.14-1593629754129:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-7ea5ce18-4a1b-4f3c-826d-606b4306616c,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-8e17d2bd-7e87-4357-bcae-098b93524367,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-ae4de6c9-3ff6-4d53-8823-0e52a74ecb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-c23e48cb-0234-4d64-b13f-aa8aa08a20e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3e2e2cd4-b711-4373-92e5-1b4ddc758371,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-3a205c64-e5dd-4730-832d-00ef672bfd20,DISK]]; indices=[0, 1, 3, 4, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1694937224-172.17.0.14-1593629754129:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-7ea5ce18-4a1b-4f3c-826d-606b4306616c,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-8e17d2bd-7e87-4357-bcae-098b93524367,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-ae4de6c9-3ff6-4d53-8823-0e52a74ecb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-c23e48cb-0234-4d64-b13f-aa8aa08a20e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3e2e2cd4-b711-4373-92e5-1b4ddc758371,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-3a205c64-e5dd-4730-832d-00ef672bfd20,DISK]]; indices=[0, 1, 3, 4, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-909206857-172.17.0.14-1593630209391:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-fcb4182b-b6b9-4568-bf0f-32874efa878e,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-42c1e981-c202-411b-b180-2100dbf6420e,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-f708edc2-f3f7-46ee-9c33-aae1fd832f08,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-dcb1c6ae-44db-481c-87a8-c6fefc3db546,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-46965a9d-ec47-4735-9eb9-d987de4748d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-cd9f50a2-50ba-46c9-a15b-e5f5388c528b,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-25a33047-26e8-4bc6-a00f-e4bffc4dcbcf,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-909206857-172.17.0.14-1593630209391:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-fcb4182b-b6b9-4568-bf0f-32874efa878e,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-42c1e981-c202-411b-b180-2100dbf6420e,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-f708edc2-f3f7-46ee-9c33-aae1fd832f08,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-dcb1c6ae-44db-481c-87a8-c6fefc3db546,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-46965a9d-ec47-4735-9eb9-d987de4748d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-cd9f50a2-50ba-46c9-a15b-e5f5388c528b,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-25a33047-26e8-4bc6-a00f-e4bffc4dcbcf,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-200363882-172.17.0.14-1593630276942:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-b191d19e-c871-497a-94c2-17163b4c0c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-65d48541-1694-4d36-94c0-b9cdfcd86090,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-4ead6f9f-59cc-4add-bfd7-f1a70f2581bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-c83c9be8-3141-4780-a4a8-f01269ebf396,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-fb34e1a6-89c0-4ef9-8421-01766fc70121,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-fa05516d-8c7b-40d5-9424-9bdbafe6a4f1,DISK]]; indices=[0, 2, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-200363882-172.17.0.14-1593630276942:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-b191d19e-c871-497a-94c2-17163b4c0c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-65d48541-1694-4d36-94c0-b9cdfcd86090,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-4ead6f9f-59cc-4add-bfd7-f1a70f2581bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-c83c9be8-3141-4780-a4a8-f01269ebf396,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-fb34e1a6-89c0-4ef9-8421-01766fc70121,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-fa05516d-8c7b-40d5-9424-9bdbafe6a4f1,DISK]]; indices=[0, 2, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-238824461-172.17.0.14-1593631666497:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-e970e846-c475-4656-a689-e1dd8d940880,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2787f6d1-f41b-4127-bc0d-96006991131e,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c6603fd1-62e4-43da-b8d9-a403b4f7cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-a631f021-e562-4113-985a-a9f7b29f0190,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e6d5dc8c-79d6-4c5c-bc82-ce871f361f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-d2c4f8f5-8dcc-42fe-86b0-d22d4157cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-2593b0a6-00db-4ce9-8c39-2fca1ab220ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-106e1806-5c7b-4fc5-8d22-621512403c1a,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-238824461-172.17.0.14-1593631666497:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-e970e846-c475-4656-a689-e1dd8d940880,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2787f6d1-f41b-4127-bc0d-96006991131e,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c6603fd1-62e4-43da-b8d9-a403b4f7cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-a631f021-e562-4113-985a-a9f7b29f0190,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e6d5dc8c-79d6-4c5c-bc82-ce871f361f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-d2c4f8f5-8dcc-42fe-86b0-d22d4157cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-2593b0a6-00db-4ce9-8c39-2fca1ab220ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-106e1806-5c7b-4fc5-8d22-621512403c1a,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1561790208-172.17.0.14-1593632001491:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-a03bddf1-d57c-49a8-a64e-995a49e2d9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-b393a701-4de2-4aec-a4d4-010d053e18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-94712fd2-4c87-4006-9628-f649ce5c668c,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-01afa3c8-775d-429f-ab5d-73407168f7db,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-c7dfb56b-fd0c-40fd-87be-63d670e84402,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-5f3deb19-8816-45bd-8e43-1aca2743fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-b93f8a4f-446b-4b16-81ed-5df577640b58,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-102349bd-b64d-4aeb-ab06-7c6534f4fd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1561790208-172.17.0.14-1593632001491:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-a03bddf1-d57c-49a8-a64e-995a49e2d9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-b393a701-4de2-4aec-a4d4-010d053e18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-94712fd2-4c87-4006-9628-f649ce5c668c,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-01afa3c8-775d-429f-ab5d-73407168f7db,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-c7dfb56b-fd0c-40fd-87be-63d670e84402,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-5f3deb19-8816-45bd-8e43-1aca2743fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-b93f8a4f-446b-4b16-81ed-5df577640b58,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-102349bd-b64d-4aeb-ab06-7c6534f4fd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-26327829-172.17.0.14-1593632101037:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-84d3e62f-d130-482f-a957-34bd9a1e57a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-64ed666c-7eca-4a2d-883d-d69d87e8beed,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-fb0fcdb0-e0ab-4257-91ba-43ba5a256719,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-748fc81c-5707-4c84-9c2b-53ed5d38b8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-51ff1dbd-7a13-4f7a-a990-3c6d4377ac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-7c7c9636-d6f4-4532-ad59-f49bfe96120f,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-a6862b46-2b72-4a1b-8d48-6756c8039f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-d9422f4c-785b-4de8-83b6-11548043f581,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-26327829-172.17.0.14-1593632101037:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-84d3e62f-d130-482f-a957-34bd9a1e57a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-64ed666c-7eca-4a2d-883d-d69d87e8beed,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-fb0fcdb0-e0ab-4257-91ba-43ba5a256719,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-748fc81c-5707-4c84-9c2b-53ed5d38b8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-51ff1dbd-7a13-4f7a-a990-3c6d4377ac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-7c7c9636-d6f4-4532-ad59-f49bfe96120f,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-a6862b46-2b72-4a1b-8d48-6756c8039f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-d9422f4c-785b-4de8-83b6-11548043f581,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-540691540-172.17.0.14-1593633000889:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-f83e2390-32ff-4bf3-9fcc-31fd92dd3c86,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0b5d8e55-7f19-47b8-8ebd-bb1dd4056cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-bb96f0be-a0ea-4e06-90d4-2017fec91578,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-8625e30f-d45b-4cb9-b463-60b36b88f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-7c3f021c-76ed-4332-b61d-0c3cf3e9558d,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-a26f0a49-67a1-4c8d-aa0f-126bf16c9b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-069e6f5f-0c8d-4371-8a9d-0427a774274a,DISK]]; indices=[1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-540691540-172.17.0.14-1593633000889:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-f83e2390-32ff-4bf3-9fcc-31fd92dd3c86,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0b5d8e55-7f19-47b8-8ebd-bb1dd4056cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-bb96f0be-a0ea-4e06-90d4-2017fec91578,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-8625e30f-d45b-4cb9-b463-60b36b88f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-7c3f021c-76ed-4332-b61d-0c3cf3e9558d,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-a26f0a49-67a1-4c8d-aa0f-126bf16c9b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-069e6f5f-0c8d-4371-8a9d-0427a774274a,DISK]]; indices=[1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-236985954-172.17.0.14-1593633490515:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-1a1c1ccf-7ffc-43ea-b48d-0bc9439bbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-fda5e6d1-8e36-458a-a11a-94718c63d523,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-e5ee61d0-18ab-4f46-a99e-f03c08e4dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-d872a51e-daa7-4f3f-9243-75a73c2aec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-ad93b950-30bb-416f-afc5-ae320a5bdd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-2a6e56a7-07d8-43e4-9931-b990c2574115,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-a28f1a27-9d97-46cf-8760-2051681a14c4,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-236985954-172.17.0.14-1593633490515:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-1a1c1ccf-7ffc-43ea-b48d-0bc9439bbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-fda5e6d1-8e36-458a-a11a-94718c63d523,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-e5ee61d0-18ab-4f46-a99e-f03c08e4dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-d872a51e-daa7-4f3f-9243-75a73c2aec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-ad93b950-30bb-416f-afc5-ae320a5bdd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-2a6e56a7-07d8-43e4-9931-b990c2574115,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-a28f1a27-9d97-46cf-8760-2051681a14c4,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1337165378-172.17.0.14-1593634149403:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-e0a2e62b-78f7-49ec-a1cd-71fbce078312,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-2779cc41-ba28-4b2b-85c6-b606fdfd6f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-f3c58bae-731a-43ff-a4c9-bcedc86898db,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-f114e717-ff28-4178-b484-a3f81ac0b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-e3210601-8c83-4e53-be95-f83dc2102938,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-aa28568f-5391-492d-8c86-ac9076426ce5,DISK]]; indices=[0, 1, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1337165378-172.17.0.14-1593634149403:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-e0a2e62b-78f7-49ec-a1cd-71fbce078312,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-2779cc41-ba28-4b2b-85c6-b606fdfd6f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-f3c58bae-731a-43ff-a4c9-bcedc86898db,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-f114e717-ff28-4178-b484-a3f81ac0b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-e3210601-8c83-4e53-be95-f83dc2102938,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-aa28568f-5391-492d-8c86-ac9076426ce5,DISK]]; indices=[0, 1, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1337978127-172.17.0.14-1593635296828:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-642ad28e-2a53-45ae-836f-1245baac20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-c769ac7b-cb3e-4abb-8718-762665b7268f,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-3d4be0e6-311e-4ca3-be1a-2897067f7c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-243362b6-ec12-47b0-bb87-eb49c9b5460d,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-545f00be-d5f2-4584-9e97-6e3a6c9209ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-3712f7bd-c694-4043-94d6-699391d5035f,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-8f8b1af1-bf02-4ec4-bf7f-30f26820e5f6,DISK]]; indices=[0, 1, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1337978127-172.17.0.14-1593635296828:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-642ad28e-2a53-45ae-836f-1245baac20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-c769ac7b-cb3e-4abb-8718-762665b7268f,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-3d4be0e6-311e-4ca3-be1a-2897067f7c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-243362b6-ec12-47b0-bb87-eb49c9b5460d,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-545f00be-d5f2-4584-9e97-6e3a6c9209ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-3712f7bd-c694-4043-94d6-699391d5035f,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-8f8b1af1-bf02-4ec4-bf7f-30f26820e5f6,DISK]]; indices=[0, 1, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1270054222-172.17.0.14-1593636105712:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36308,DS-3ca89563-2e70-403a-a932-49341f2deffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-3949fe37-8c90-4547-b2bc-6c93ded13124,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-c121d69c-bdbc-40c9-9179-c0ecdc9edee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b28375d0-ffeb-4876-a4c8-0894fa22af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-1bd4c6e7-21dd-4dbe-9d5e-c409b301447b,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-0be39abc-2415-48aa-9696-bd6ac1963d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-d5e9dc94-5252-4179-84b4-77a1fd42f06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-11085a3b-589f-4148-8fd8-5ca5eec2618e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1270054222-172.17.0.14-1593636105712:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36308,DS-3ca89563-2e70-403a-a932-49341f2deffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-3949fe37-8c90-4547-b2bc-6c93ded13124,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-c121d69c-bdbc-40c9-9179-c0ecdc9edee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b28375d0-ffeb-4876-a4c8-0894fa22af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-1bd4c6e7-21dd-4dbe-9d5e-c409b301447b,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-0be39abc-2415-48aa-9696-bd6ac1963d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-d5e9dc94-5252-4179-84b4-77a1fd42f06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-11085a3b-589f-4148-8fd8-5ca5eec2618e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-409975951-172.17.0.14-1593636420636:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42175,DS-da0a353d-c2db-47ff-866a-ffbfcf162427,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-a9886f47-9736-4fd1-a435-96628f946c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-45432664-43bd-4212-83b5-3adeebe5d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1eba61d8-b35f-49d0-9d82-d2f9f49c3368,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-ebda11b3-7520-4896-bfd0-07390384a17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-66d943ab-20c4-4d06-b864-64d46bc4c980,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-254f9695-8ea3-4436-b31a-a84de9802325,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-409975951-172.17.0.14-1593636420636:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42175,DS-da0a353d-c2db-47ff-866a-ffbfcf162427,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-a9886f47-9736-4fd1-a435-96628f946c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-45432664-43bd-4212-83b5-3adeebe5d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1eba61d8-b35f-49d0-9d82-d2f9f49c3368,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-ebda11b3-7520-4896-bfd0-07390384a17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-66d943ab-20c4-4d06-b864-64d46bc4c980,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-254f9695-8ea3-4436-b31a-a84de9802325,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1818924454-172.17.0.14-1593636577525:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-afcdc295-65bc-4992-8006-e1816c6606e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-ae3089e9-729c-409e-9869-9061ece6ae16,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-121207b0-f981-46cb-b926-12826ec9a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-0246e62d-79ec-43c2-8fe5-0a6a20b9ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-02f77adc-11a2-4c28-b56c-0a2cf7bbb5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-ae624799-d763-4e96-b9d3-b3cc2b28a052,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-262c569a-3b04-48d7-8eca-fd0d4aeea1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-5547cf17-fbed-46de-844c-7c4e6f921779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1818924454-172.17.0.14-1593636577525:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-afcdc295-65bc-4992-8006-e1816c6606e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-ae3089e9-729c-409e-9869-9061ece6ae16,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-121207b0-f981-46cb-b926-12826ec9a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-0246e62d-79ec-43c2-8fe5-0a6a20b9ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-02f77adc-11a2-4c28-b56c-0a2cf7bbb5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-ae624799-d763-4e96-b9d3-b3cc2b28a052,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-262c569a-3b04-48d7-8eca-fd0d4aeea1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-5547cf17-fbed-46de-844c-7c4e6f921779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-477458923-172.17.0.14-1593636732639:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-5527163d-c4a8-430d-a232-32e3d10166c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-9389bebb-55ac-44e6-aeb8-f3aa9eade92c,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-ebfe3147-9be7-45f6-8b78-4eb457e25986,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-164d3340-55b0-472e-ab1e-63d2d52eb7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-2c3f51f0-15a5-4895-9783-ead5cf4bfde8,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-2ed96fcc-222e-4aa1-88c0-713d7d4242d3,DISK]]; indices=[0, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-477458923-172.17.0.14-1593636732639:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-5527163d-c4a8-430d-a232-32e3d10166c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-9389bebb-55ac-44e6-aeb8-f3aa9eade92c,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-ebfe3147-9be7-45f6-8b78-4eb457e25986,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-164d3340-55b0-472e-ab1e-63d2d52eb7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-2c3f51f0-15a5-4895-9783-ead5cf4bfde8,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-2ed96fcc-222e-4aa1-88c0-713d7d4242d3,DISK]]; indices=[0, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1987921052-172.17.0.14-1593636890186:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-3e2113c1-3770-4bc5-aa7d-a219bda40384,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-14b694de-9b31-4023-adbf-9482ff9caa36,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-fa79aab0-710c-45a9-88de-a59ccef2c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-333a72f6-e52e-4598-85a8-dc9540739ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-907b5e66-38fd-4617-8bc1-9324e4827e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-2baccf29-b794-41fd-8f4d-f4390052e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-04c2e3cb-52bb-4a2c-a585-4c72597682f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-81a4e41c-cd6e-4c6c-badb-9fbcac5ca59b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1987921052-172.17.0.14-1593636890186:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-3e2113c1-3770-4bc5-aa7d-a219bda40384,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-14b694de-9b31-4023-adbf-9482ff9caa36,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-fa79aab0-710c-45a9-88de-a59ccef2c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-333a72f6-e52e-4598-85a8-dc9540739ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-907b5e66-38fd-4617-8bc1-9324e4827e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-2baccf29-b794-41fd-8f4d-f4390052e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-04c2e3cb-52bb-4a2c-a585-4c72597682f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-81a4e41c-cd6e-4c6c-badb-9fbcac5ca59b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-311801586-172.17.0.14-1593637393318:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46763,DS-be4d3b65-9f88-4da3-9768-b2faa11e20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-c5bb603c-3ef4-49cd-80ca-ed1e66bb1352,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-0e6a568d-9060-4281-8985-e661c80d3cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-15c90db7-c7fe-4e42-94b9-64207f87a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-fa0c1dcd-bc05-4a7d-a179-f38fcd1c7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-3d829de3-4b55-4bb3-a310-117f26d156b1,DISK]]; indices=[0, 2, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-311801586-172.17.0.14-1593637393318:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46763,DS-be4d3b65-9f88-4da3-9768-b2faa11e20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-c5bb603c-3ef4-49cd-80ca-ed1e66bb1352,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-0e6a568d-9060-4281-8985-e661c80d3cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-15c90db7-c7fe-4e42-94b9-64207f87a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-fa0c1dcd-bc05-4a7d-a179-f38fcd1c7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-3d829de3-4b55-4bb3-a310-117f26d156b1,DISK]]; indices=[0, 2, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 17 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 8269
