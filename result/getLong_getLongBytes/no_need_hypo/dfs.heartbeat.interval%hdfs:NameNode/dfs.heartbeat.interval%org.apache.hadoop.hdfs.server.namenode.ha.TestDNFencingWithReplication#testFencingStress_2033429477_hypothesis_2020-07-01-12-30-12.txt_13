reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: Deferred
stackTrace: java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.stop(MultithreadedTestUtil.java:166)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication.testFencingStress(TestDNFencingWithReplication.java:141)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: Timed out waiting for 2 replicas on path /test-7
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication$ReplicationToggler.waitForReplicas(TestDNFencingWithReplication.java:97)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication$ReplicationToggler.doAnAction(TestDNFencingWithReplication.java:78)
	at org.apache.hadoop.test.MultithreadedTestUtil$RepeatingTestThread.doWork(MultithreadedTestUtil.java:222)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: File /test-0 could only be written to 0 of the 1 minReplication nodes. There are 2 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2219)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

stackTrace: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /test-0 could only be written to 0 of the 1 minReplication nodes. There are 2 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2219)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy23.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy26.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1866)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: Deferred
stackTrace: java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.stop(MultithreadedTestUtil.java:166)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication.testFencingStress(TestDNFencingWithReplication.java:141)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: Timed out waiting for 1 replicas on path /test-2
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication$ReplicationToggler.waitForReplicas(TestDNFencingWithReplication.java:97)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication$ReplicationToggler.doAnAction(TestDNFencingWithReplication.java:76)
	at org.apache.hadoop.test.MultithreadedTestUtil$RepeatingTestThread.doWork(MultithreadedTestUtil.java:222)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: Deferred
stackTrace: java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.stop(MultithreadedTestUtil.java:166)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication.testFencingStress(TestDNFencingWithReplication.java:141)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category WRITE is not supported in state standby. Visit https://s.apache.org/sbnn-error
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:98)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:2041)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1449)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setReplication(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setReplication(NameNodeRpcServer.java:843)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setReplication(ClientNamenodeProtocolServerSideTranslatorPB.java:521)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy23.setReplication(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setReplication(ClientNamenodeProtocolTranslatorPB.java:419)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy26.setReplication(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setReplication(DFSClient.java:1436)
	at org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setReplication(DistributedFileSystem.java:698)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication$ReplicationToggler.doAnAction(TestDNFencingWithReplication.java:75)
	at org.apache.hadoop.test.MultithreadedTestUtil$RepeatingTestThread.doWork(MultithreadedTestUtil.java:222)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:NameNode
v1: 1
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication#testFencingStress
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: might be true error
Total execution time in seconds : 88238
