reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42528,DS-2b528db0-3cd7-4078-80f7-d025d30dc93a,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42528,DS-2b528db0-3cd7-4078-80f7-d025d30dc93a,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:44175,DS-49276e00-7ce9-41cc-b357-2223d0ce8574,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:44175,DS-49276e00-7ce9-41cc-b357-2223d0ce8574,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36299,DS-f42172df-9e3c-486a-af42-d456eb12caac,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36299,DS-f42172df-9e3c-486a-af42-d456eb12caac,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:37464,DS-03973eed-4611-4129-bad8-75b626ac1edb,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:37464,DS-03973eed-4611-4129-bad8-75b626ac1edb,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41223,DS-0cd4b9cd-f750-4257-9c39-ab0fa1964bd0,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41223,DS-0cd4b9cd-f750-4257-9c39-ab0fa1964bd0,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36339,DS-70423d6f-2334-4532-90e4-8f285b6a3b6f,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36339,DS-70423d6f-2334-4532-90e4-8f285b6a3b6f,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:32928,DS-73432e03-1fe3-400f-9acf-c6334d3fa55c,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:32928,DS-73432e03-1fe3-400f-9acf-c6334d3fa55c,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42256,DS-ea8566a5-6d8f-4e49-a464-74488aa4f992,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:42256,DS-ea8566a5-6d8f-4e49-a464-74488aa4f992,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:35554,DS-ea98f276-8504-4b92-b7ed-eec580518fe3,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:35554,DS-ea98f276-8504-4b92-b7ed-eec580518fe3,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery#testPipelineRecoveryOnRestartFailure
reconfPoint: -1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:44991,DS-558b8da2-df73-4021-8a1a-d1cc18b0a797,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:44991,DS-558b8da2-df73-4021-8a1a-d1cc18b0a797,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 0 out of 50
result: might be true error
Total execution time in seconds : 1790
