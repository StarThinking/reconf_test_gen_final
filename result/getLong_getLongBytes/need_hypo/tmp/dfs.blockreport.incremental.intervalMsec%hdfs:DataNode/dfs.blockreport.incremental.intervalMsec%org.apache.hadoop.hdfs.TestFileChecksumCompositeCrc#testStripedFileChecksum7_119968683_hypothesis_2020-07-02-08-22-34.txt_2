reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-41545787-172.17.0.12-1593678334731:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35495,DS-431500ac-d411-4386-a58f-a2bccd424a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-161c059a-cac8-4ea5-b72e-f8c20eff6a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-d9538a7a-000f-4b8f-a94f-6232f5860901,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-c6e2dfd0-9b42-4119-b02f-0f72d3d43c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-b99913b6-3ba4-4fe5-8579-a8019a26b597,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-f902d97c-e577-430a-970a-bacf41e3f555,DISK]]; indices=[0, 2, 3, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-41545787-172.17.0.12-1593678334731:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35495,DS-431500ac-d411-4386-a58f-a2bccd424a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-161c059a-cac8-4ea5-b72e-f8c20eff6a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-d9538a7a-000f-4b8f-a94f-6232f5860901,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-c6e2dfd0-9b42-4119-b02f-0f72d3d43c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-b99913b6-3ba4-4fe5-8579-a8019a26b597,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-f902d97c-e577-430a-970a-bacf41e3f555,DISK]]; indices=[0, 2, 3, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1309222026-172.17.0.12-1593680229127:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-5c258556-0b28-489d-a315-878238617351,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-e4ca6058-aed5-4c44-8463-179af6041a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-437d82e5-99b3-47ac-bc5b-ce2cf30c8854,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-f5b795df-1646-41a0-b25b-bb50e7eb1804,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-6e30e984-d3dd-4c97-856f-e8fa33e03ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-566a1271-9f69-4a47-915a-5e63f013d016,DISK]]; indices=[1, 2, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1309222026-172.17.0.12-1593680229127:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-5c258556-0b28-489d-a315-878238617351,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-e4ca6058-aed5-4c44-8463-179af6041a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-437d82e5-99b3-47ac-bc5b-ce2cf30c8854,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-f5b795df-1646-41a0-b25b-bb50e7eb1804,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-6e30e984-d3dd-4c97-856f-e8fa33e03ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-566a1271-9f69-4a47-915a-5e63f013d016,DISK]]; indices=[1, 2, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-888424543-172.17.0.12-1593680574752:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43023,DS-6cfbb7f0-89e5-4a03-90bc-2ba395d1179f,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-39516eca-17cb-4071-b36d-c2c6fcc2fb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-9ce94067-f30a-42e7-8459-422c0725abda,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-53edf327-7944-4384-acba-c6ab34b5b9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-4f99aa7b-2342-41e0-b041-9b6f73ebf3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-7ff6ad23-84ff-417a-b5fc-e91e52dbd0c9,DISK]]; indices=[0, 1, 2, 3, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-888424543-172.17.0.12-1593680574752:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43023,DS-6cfbb7f0-89e5-4a03-90bc-2ba395d1179f,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-39516eca-17cb-4071-b36d-c2c6fcc2fb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-9ce94067-f30a-42e7-8459-422c0725abda,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-53edf327-7944-4384-acba-c6ab34b5b9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-4f99aa7b-2342-41e0-b041-9b6f73ebf3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-7ff6ad23-84ff-417a-b5fc-e91e52dbd0c9,DISK]]; indices=[0, 1, 2, 3, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-543916055-172.17.0.12-1593680749397:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-48777eef-1459-4d35-b292-dc68c10a419b,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-3d733217-3957-4ccf-beb5-814c84d601ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-bb722c22-708d-4885-b5bb-a5949a2b2cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-3b7eda35-606f-4615-b7b3-449e7dbbfd69,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-de275219-b72c-4ca3-80e9-cd0f3b1a7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-03b0e920-5836-4fec-889f-8e28124e8bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-a59653e1-070c-4d9f-ba5e-2953535e3a35,DISK]]; indices=[0, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-543916055-172.17.0.12-1593680749397:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-48777eef-1459-4d35-b292-dc68c10a419b,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-3d733217-3957-4ccf-beb5-814c84d601ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-bb722c22-708d-4885-b5bb-a5949a2b2cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-3b7eda35-606f-4615-b7b3-449e7dbbfd69,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-de275219-b72c-4ca3-80e9-cd0f3b1a7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-03b0e920-5836-4fec-889f-8e28124e8bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-a59653e1-070c-4d9f-ba5e-2953535e3a35,DISK]]; indices=[0, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-462723224-172.17.0.12-1593681406123:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-4aac3eb6-8e63-47d1-b381-96779ff97566,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-f898e1b7-f715-445e-b1c3-de0f883d048b,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-30257d5b-6590-4a59-89b1-f48474a9da92,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-c693d70b-8ff4-4112-857d-a71c4f2153e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-2b78f833-3465-47df-be57-64d6fb01d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-2204893e-6c62-4fcd-a62b-b3d485523c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-4ea4deaf-bdda-43f6-aed4-bff40b1df059,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-7fd360b7-0daa-46a5-8bf2-4167f02e1c5d,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-462723224-172.17.0.12-1593681406123:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-4aac3eb6-8e63-47d1-b381-96779ff97566,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-f898e1b7-f715-445e-b1c3-de0f883d048b,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-30257d5b-6590-4a59-89b1-f48474a9da92,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-c693d70b-8ff4-4112-857d-a71c4f2153e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-2b78f833-3465-47df-be57-64d6fb01d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-2204893e-6c62-4fcd-a62b-b3d485523c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-4ea4deaf-bdda-43f6-aed4-bff40b1df059,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-7fd360b7-0daa-46a5-8bf2-4167f02e1c5d,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-307743535-172.17.0.12-1593681567910:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38278,DS-57a99b04-d3e1-45da-ae52-674a9d5ea714,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-b4efcae4-1e2f-4d63-ba2c-f9d53833cbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-0324999a-aa10-44cb-b32d-1748cf7f5f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-d82a58f9-fae8-4a76-81c6-abc10b07bfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-62fd69a8-336e-4ddd-8322-f16e794f6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-8c083c1d-55f8-4313-904a-8890dc66afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-15ef907d-9134-4331-be9d-070712aed4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-23678537-8ba6-410d-83e0-4d4ff7e4624c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-307743535-172.17.0.12-1593681567910:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38278,DS-57a99b04-d3e1-45da-ae52-674a9d5ea714,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-b4efcae4-1e2f-4d63-ba2c-f9d53833cbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-0324999a-aa10-44cb-b32d-1748cf7f5f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-d82a58f9-fae8-4a76-81c6-abc10b07bfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-62fd69a8-336e-4ddd-8322-f16e794f6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-8c083c1d-55f8-4313-904a-8890dc66afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-15ef907d-9134-4331-be9d-070712aed4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-23678537-8ba6-410d-83e0-4d4ff7e4624c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-209939687-172.17.0.12-1593681738727:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-9489a8b1-3397-4956-8933-3a2e10e38d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-02af2f13-b683-4d9f-9a6c-01090f8fdd15,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-77470e0f-f5fc-463b-a4c5-8ad38a3e1332,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-a7579e4b-3f4f-41e9-a756-c08f19267db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-2dc299a7-f925-486f-a6c4-8015dba71e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b59b2b6f-bbaa-4e92-9976-7f745efa3562,DISK]]; indices=[0, 1, 2, 3, 5, 6]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-209939687-172.17.0.12-1593681738727:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-9489a8b1-3397-4956-8933-3a2e10e38d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-02af2f13-b683-4d9f-9a6c-01090f8fdd15,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-77470e0f-f5fc-463b-a4c5-8ad38a3e1332,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-a7579e4b-3f4f-41e9-a756-c08f19267db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-2dc299a7-f925-486f-a6c4-8015dba71e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b59b2b6f-bbaa-4e92-9976-7f745efa3562,DISK]]; indices=[0, 1, 2, 3, 5, 6]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-653657805-172.17.0.12-1593683455978:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-4b972747-285d-4545-81dd-962da639a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-8b555c1c-be1c-41dc-8fc4-c0eadb718a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-3194db04-a3c5-4db7-86c5-364d2ccefdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-9070432c-42cf-4786-a105-f34586a4e0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-f81114e6-7009-4379-9193-62c82937129f,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-4654eb48-b136-461c-a38f-321682eee015,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-19aa4a9c-051c-4d00-9462-8777ec4b25e5,DISK]]; indices=[0, 2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-653657805-172.17.0.12-1593683455978:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-4b972747-285d-4545-81dd-962da639a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-8b555c1c-be1c-41dc-8fc4-c0eadb718a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-3194db04-a3c5-4db7-86c5-364d2ccefdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-9070432c-42cf-4786-a105-f34586a4e0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-f81114e6-7009-4379-9193-62c82937129f,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-4654eb48-b136-461c-a38f-321682eee015,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-19aa4a9c-051c-4d00-9462-8777ec4b25e5,DISK]]; indices=[0, 2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-879160979-172.17.0.12-1593684133374:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-d0635ef5-9736-4100-8571-4ac4f2230117,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-62f1e053-7ecd-4e59-9d3d-78899a0fc7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-8f6a8fec-db9f-4334-b8a3-cf594f6e2f05,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-742f8c0a-587b-4380-9785-768ba5544b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-61531e7c-18a6-4a29-93a1-d7ddea9c3c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-157af9b9-9e5b-49b9-b386-bf1e77a2b8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-29aa3678-5846-405c-81c9-1b7af6adb9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-879160979-172.17.0.12-1593684133374:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-d0635ef5-9736-4100-8571-4ac4f2230117,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-62f1e053-7ecd-4e59-9d3d-78899a0fc7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-8f6a8fec-db9f-4334-b8a3-cf594f6e2f05,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-742f8c0a-587b-4380-9785-768ba5544b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-61531e7c-18a6-4a29-93a1-d7ddea9c3c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-157af9b9-9e5b-49b9-b386-bf1e77a2b8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-29aa3678-5846-405c-81c9-1b7af6adb9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-488264382-172.17.0.12-1593684487140:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-3f94ad8f-d472-49fa-95d6-b3758b8bee05,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-a6f2026d-9611-4f14-9f76-ffe0fa52a435,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-f3f68a9d-c43e-4963-bc0b-a6464187bbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-a3b4963a-2fb5-4d55-8203-b858ddad71f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b244ac59-5bd5-4616-8d27-e767e6c1e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-322dc71b-b628-4a9d-b69e-c6d3cc0d1b27,DISK]]; indices=[0, 2, 3, 4, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-488264382-172.17.0.12-1593684487140:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-3f94ad8f-d472-49fa-95d6-b3758b8bee05,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-a6f2026d-9611-4f14-9f76-ffe0fa52a435,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-f3f68a9d-c43e-4963-bc0b-a6464187bbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-a3b4963a-2fb5-4d55-8203-b858ddad71f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b244ac59-5bd5-4616-8d27-e767e6c1e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-322dc71b-b628-4a9d-b69e-c6d3cc0d1b27,DISK]]; indices=[0, 2, 3, 4, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 0 out of 50
result: might be true error
Total execution time in seconds : 6479
