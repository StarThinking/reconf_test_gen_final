reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2061158716-172.17.0.9-1593346531427:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-bf3c12dc-7d9e-4ded-9ee2-812b1b4ae13f,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-d0532798-dddc-4767-8924-c9e38f394802,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-bafc5123-8560-4a19-b290-08da957c7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-11fc4842-fa95-4a35-b4af-822a6b753125,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-1da2749d-3e77-47b8-8974-2bfa60af8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-7b8ad89b-fbf7-4813-8396-c7c8bc7e6966,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2061158716-172.17.0.9-1593346531427:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-bf3c12dc-7d9e-4ded-9ee2-812b1b4ae13f,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-d0532798-dddc-4767-8924-c9e38f394802,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-bafc5123-8560-4a19-b290-08da957c7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-11fc4842-fa95-4a35-b4af-822a6b753125,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-1da2749d-3e77-47b8-8974-2bfa60af8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-7b8ad89b-fbf7-4813-8396-c7c8bc7e6966,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1322207310-172.17.0.9-1593347431376:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-b36dc634-f8d7-4c0c-8d25-bfcb3fa6499d,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-20917c45-5de4-412f-9cf9-b4ce39fbc072,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-02f968df-5b7f-4bec-bd7f-8876cd6d706b,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-146cfb48-a05b-470a-bda6-df7d0217d566,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-67980081-6a98-4fd5-86cf-331fba7a99e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-c19f16c7-c0af-4003-b038-c2102a35f57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-96b51dc9-5b00-40fe-b538-fff3d0084944,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1322207310-172.17.0.9-1593347431376:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-b36dc634-f8d7-4c0c-8d25-bfcb3fa6499d,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-20917c45-5de4-412f-9cf9-b4ce39fbc072,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-02f968df-5b7f-4bec-bd7f-8876cd6d706b,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-146cfb48-a05b-470a-bda6-df7d0217d566,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-67980081-6a98-4fd5-86cf-331fba7a99e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-c19f16c7-c0af-4003-b038-c2102a35f57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-96b51dc9-5b00-40fe-b538-fff3d0084944,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-960712479-172.17.0.9-1593347706754:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33943,DS-e9f4beaf-5a97-46d6-be33-073cce379955,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-02db74d3-50f8-44af-bf67-b6ab07ab5f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-5faff4a3-f3a1-46d1-b715-e3ced8296abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-e0e5b8a2-37fa-407e-8384-9dee1e43b695,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-4adf73c6-35de-48ca-a7fa-06f97bcf2219,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-6f0cc5bc-1022-4f2c-ab1c-e00809fbae35,DISK]]; indices=[0, 1, 2, 3, 5, 6]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-960712479-172.17.0.9-1593347706754:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33943,DS-e9f4beaf-5a97-46d6-be33-073cce379955,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-02db74d3-50f8-44af-bf67-b6ab07ab5f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-5faff4a3-f3a1-46d1-b715-e3ced8296abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-e0e5b8a2-37fa-407e-8384-9dee1e43b695,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-4adf73c6-35de-48ca-a7fa-06f97bcf2219,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-6f0cc5bc-1022-4f2c-ab1c-e00809fbae35,DISK]]; indices=[0, 1, 2, 3, 5, 6]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1678777891-172.17.0.9-1593347948441:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-d89ac715-be35-48c0-a833-e435aae11639,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-2dae815c-4996-411a-8fe4-1fad6e794a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-685cf0be-dce7-4eb4-ac46-a1a261568af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-36aa6a81-5e3c-4c68-97bb-358d4ef59c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-1cb4a33f-8207-4d25-b72c-4e49dc1b4e06,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-cea80114-fb51-46e2-82f7-a5bbfe2eb10f,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-665b3f00-e456-45fa-a7f4-0b44b2b3bba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-2d96db17-da10-49c3-8ec2-9c15eb0f85a1,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1678777891-172.17.0.9-1593347948441:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-d89ac715-be35-48c0-a833-e435aae11639,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-2dae815c-4996-411a-8fe4-1fad6e794a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-685cf0be-dce7-4eb4-ac46-a1a261568af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-36aa6a81-5e3c-4c68-97bb-358d4ef59c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-1cb4a33f-8207-4d25-b72c-4e49dc1b4e06,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-cea80114-fb51-46e2-82f7-a5bbfe2eb10f,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-665b3f00-e456-45fa-a7f4-0b44b2b3bba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-2d96db17-da10-49c3-8ec2-9c15eb0f85a1,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1624208843-172.17.0.9-1593348053551:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-f7f5aaa1-d8b5-4d5e-a142-6f491f8cfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-98e8a5fc-f98a-410b-8e67-ff477f0c67bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-2e95a072-0934-4bd1-9d11-c6854a7ab4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-8b8d8ded-8498-4eb5-8dfd-31157410abc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-fd926d40-d1e3-49de-9b24-e09d357a26c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-6004b442-2225-4f66-be7e-c95e014aa2f7,DISK]]; indices=[0, 2, 3, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1624208843-172.17.0.9-1593348053551:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-f7f5aaa1-d8b5-4d5e-a142-6f491f8cfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-98e8a5fc-f98a-410b-8e67-ff477f0c67bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-2e95a072-0934-4bd1-9d11-c6854a7ab4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-8b8d8ded-8498-4eb5-8dfd-31157410abc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-fd926d40-d1e3-49de-9b24-e09d357a26c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-6004b442-2225-4f66-be7e-c95e014aa2f7,DISK]]; indices=[0, 2, 3, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-553851955-172.17.0.9-1593348382761:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35718,DS-5740970c-1244-4297-a8f0-aba14f5f54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-2c547347-549f-4adb-a9e1-9f7d071c284e,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-adc1ed01-0673-48ce-ab38-c72c74fa872f,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-8969c380-8e54-4909-8628-b37986d6f460,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-c8076c23-bc9e-4d17-8c71-46073b3d928d,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-8d937b22-5cfc-45cb-a2bb-5799350cc942,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-8b908c1d-03f9-4da2-80da-ce75d3c304ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-553851955-172.17.0.9-1593348382761:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35718,DS-5740970c-1244-4297-a8f0-aba14f5f54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-2c547347-549f-4adb-a9e1-9f7d071c284e,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-adc1ed01-0673-48ce-ab38-c72c74fa872f,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-8969c380-8e54-4909-8628-b37986d6f460,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-c8076c23-bc9e-4d17-8c71-46073b3d928d,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-8d937b22-5cfc-45cb-a2bb-5799350cc942,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-8b908c1d-03f9-4da2-80da-ce75d3c304ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-549425469-172.17.0.9-1593348552479:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-ce67786b-8ae7-4a4d-8a88-305b4eadf0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-df8d514a-673f-4bd9-b110-b1849598f5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-a24c7b0e-28ad-4a26-84fc-b4e4c75ac35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-4c2285ed-04c5-4894-b020-44aad43f7ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-995560dd-fccd-452b-a328-f0dd9c98812d,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-fc87dc83-c8a5-416d-9131-abd07dcab422,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a2d2093c-4cdc-4e6a-ad37-a5d242e6faa9,DISK]]; indices=[0, 1, 2, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-549425469-172.17.0.9-1593348552479:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-ce67786b-8ae7-4a4d-8a88-305b4eadf0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-df8d514a-673f-4bd9-b110-b1849598f5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-a24c7b0e-28ad-4a26-84fc-b4e4c75ac35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-4c2285ed-04c5-4894-b020-44aad43f7ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-995560dd-fccd-452b-a328-f0dd9c98812d,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-fc87dc83-c8a5-416d-9131-abd07dcab422,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a2d2093c-4cdc-4e6a-ad37-a5d242e6faa9,DISK]]; indices=[0, 1, 2, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-991330859-172.17.0.9-1593349226873:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-f825290f-2fba-4f3d-b3d5-3ae951e5c165,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-0f462b6f-e825-47d0-9bd2-3a079284af92,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-8d197ce0-02f9-48dc-9d02-10238d552d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-1a82923f-c02b-469f-a98c-80f01e2bb3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-55a09212-47b2-4644-9c17-c79c2688749a,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-b6fcdcab-c7b8-4358-be50-49d3c25492df,DISK]]; indices=[0, 1, 2, 3, 4, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-991330859-172.17.0.9-1593349226873:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-f825290f-2fba-4f3d-b3d5-3ae951e5c165,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-0f462b6f-e825-47d0-9bd2-3a079284af92,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-8d197ce0-02f9-48dc-9d02-10238d552d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-1a82923f-c02b-469f-a98c-80f01e2bb3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-55a09212-47b2-4644-9c17-c79c2688749a,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-b6fcdcab-c7b8-4358-be50-49d3c25492df,DISK]]; indices=[0, 1, 2, 3, 4, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-471085467-172.17.0.9-1593349716760:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35232,DS-a981628e-29f6-4013-a04c-db092eacd6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-53d3952f-d7e0-4bca-9a51-73d7b81d8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-fe8cf621-9be3-4680-b81b-03d66cc9caae,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-32b50922-bc33-4250-abc3-a2f09d610a15,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-8173de47-bdf0-46de-9827-24ac9b93099a,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-bb0d0d17-d312-4072-b409-8ace91e66153,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-5412e369-4bbf-477c-b8be-e8260ef47cc8,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-471085467-172.17.0.9-1593349716760:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35232,DS-a981628e-29f6-4013-a04c-db092eacd6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-53d3952f-d7e0-4bca-9a51-73d7b81d8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-fe8cf621-9be3-4680-b81b-03d66cc9caae,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-32b50922-bc33-4250-abc3-a2f09d610a15,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-8173de47-bdf0-46de-9827-24ac9b93099a,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-bb0d0d17-d312-4072-b409-8ace91e66153,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-5412e369-4bbf-477c-b8be-e8260ef47cc8,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-873974363-172.17.0.9-1593350054343:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-0e5a9726-88e8-4370-ab6b-995be0c0756b,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-ac8c051b-4eb9-46bf-baef-024cb903d4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-5f7d040f-c8ab-4441-87e2-1c0e1f47a2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-43ff63d2-b33d-4980-9dd0-b4127ccc04d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-7b776032-4e94-4a9d-a1c8-a5ba513fac16,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-7c73fb23-fc79-4ae0-b435-1b371ed8c562,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-591bdb15-8e7c-4b3e-bccd-b56fa5771ea2,DISK]]; indices=[0, 1, 2, 3, 4, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-873974363-172.17.0.9-1593350054343:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-0e5a9726-88e8-4370-ab6b-995be0c0756b,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-ac8c051b-4eb9-46bf-baef-024cb903d4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-5f7d040f-c8ab-4441-87e2-1c0e1f47a2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-43ff63d2-b33d-4980-9dd0-b4127ccc04d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-7b776032-4e94-4a9d-a1c8-a5ba513fac16,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-7c73fb23-fc79-4ae0-b435-1b371ed8c562,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-591bdb15-8e7c-4b3e-bccd-b56fa5771ea2,DISK]]; indices=[0, 1, 2, 3, 4, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1085872008-172.17.0.9-1593350282561:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-1ded9552-d13b-4855-9c65-66c977e9eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-827498d6-e5e7-4191-98e9-8611f01096dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-94c1a863-6b52-406c-a30b-3249ea26e937,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-3d643bb4-662d-43b0-afbc-deb10a6615c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-61031ced-d622-4277-bde6-05d0e10afceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-ff741195-ea4d-4e89-9042-8f3c010e17af,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-2124ce81-e51e-4997-a220-1fca31a0ba64,DISK]]; indices=[0, 1, 2, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1085872008-172.17.0.9-1593350282561:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-1ded9552-d13b-4855-9c65-66c977e9eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-827498d6-e5e7-4191-98e9-8611f01096dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-94c1a863-6b52-406c-a30b-3249ea26e937,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-3d643bb4-662d-43b0-afbc-deb10a6615c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-61031ced-d622-4277-bde6-05d0e10afceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-ff741195-ea4d-4e89-9042-8f3c010e17af,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-2124ce81-e51e-4997-a220-1fca31a0ba64,DISK]]; indices=[0, 1, 2, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1213280013-172.17.0.9-1593351834480:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-f279c976-5864-4471-90d8-1b0260559d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5d7772de-ffba-4bfa-8539-fe002e8acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e69378e8-6cd0-4abc-abbc-2cd6c3627df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-56b038e3-3550-438e-a1f6-7160691059e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-87e3ef40-c245-49bc-b714-9b4cfed85084,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-ae04bf96-307d-44e1-8e71-da4c183d2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-865bd1d3-c538-41a1-bcfa-a8843fe7bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-8b7cdcf6-7ead-41c8-9e7a-f5976684f9d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1213280013-172.17.0.9-1593351834480:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-f279c976-5864-4471-90d8-1b0260559d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5d7772de-ffba-4bfa-8539-fe002e8acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e69378e8-6cd0-4abc-abbc-2cd6c3627df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-56b038e3-3550-438e-a1f6-7160691059e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-87e3ef40-c245-49bc-b714-9b4cfed85084,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-ae04bf96-307d-44e1-8e71-da4c183d2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-865bd1d3-c538-41a1-bcfa-a8843fe7bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-8b7cdcf6-7ead-41c8-9e7a-f5976684f9d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1293671666-172.17.0.9-1593352282193:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41214,DS-4ee2edc0-b920-4a91-b2fc-0a6e6026a96a,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-ca84a468-fe11-4c59-8375-25cf4fafd3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b089ba45-e35f-4ee7-934e-2e2bac37e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-19c4f66c-5bd0-4c10-ab1e-7fd6221664f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-5533be0c-129d-4a20-8e18-b16bba4e2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-481109d4-4af6-41ad-9a43-0e8f52761e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-552d448e-9f10-4f14-a55c-c3ab272cdcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1293671666-172.17.0.9-1593352282193:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41214,DS-4ee2edc0-b920-4a91-b2fc-0a6e6026a96a,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-ca84a468-fe11-4c59-8375-25cf4fafd3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b089ba45-e35f-4ee7-934e-2e2bac37e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-19c4f66c-5bd0-4c10-ab1e-7fd6221664f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-5533be0c-129d-4a20-8e18-b16bba4e2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-481109d4-4af6-41ad-9a43-0e8f52761e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-552d448e-9f10-4f14-a55c-c3ab272cdcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-365620250-172.17.0.9-1593352437484:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:36279,DS-79bfded6-4054-4d81-bc9d-b119580f4161,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-46b2838f-f54e-48c0-b190-ef5c751d9f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-6942d32b-380b-4615-899e-d4e072d1094a,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-06c75753-1fad-481b-95af-7bc0df99aade,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-69506ca6-cfcb-4d12-8487-1866fb858afb,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-50766b78-54ae-4a97-9f63-8ae170761fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-a46828a5-b195-4c9c-9bb6-facd0cbedc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-42fc2a64-7f86-42e1-9c95-cf50d2cec915,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-365620250-172.17.0.9-1593352437484:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:36279,DS-79bfded6-4054-4d81-bc9d-b119580f4161,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-46b2838f-f54e-48c0-b190-ef5c751d9f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-6942d32b-380b-4615-899e-d4e072d1094a,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-06c75753-1fad-481b-95af-7bc0df99aade,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-69506ca6-cfcb-4d12-8487-1866fb858afb,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-50766b78-54ae-4a97-9f63-8ae170761fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-a46828a5-b195-4c9c-9bb6-facd0cbedc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-42fc2a64-7f86-42e1-9c95-cf50d2cec915,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1958583742-172.17.0.9-1593352765962:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-4510bf9d-6797-4688-9778-a5dfcb1ce1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-add96cfd-32f2-4d1c-b925-580e678bee46,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-1764ba0f-a03f-4703-9316-ef0f589f36f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-b9dc9dbb-40c5-4eb5-bf4d-7174db69ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-81d3ad68-16ff-4e8b-b7e4-c13acdffe66d,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-ae2515c5-8e56-4243-a8b7-f729ad0d6e19,DISK]]; indices=[2, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1958583742-172.17.0.9-1593352765962:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-4510bf9d-6797-4688-9778-a5dfcb1ce1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-add96cfd-32f2-4d1c-b925-580e678bee46,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-1764ba0f-a03f-4703-9316-ef0f589f36f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-b9dc9dbb-40c5-4eb5-bf4d-7174db69ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-81d3ad68-16ff-4e8b-b7e4-c13acdffe66d,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-ae2515c5-8e56-4243-a8b7-f729ad0d6e19,DISK]]; indices=[2, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-259270893-172.17.0.9-1593352927295:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41074,DS-dfba6329-8bf4-4564-bda4-c43367b496cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-7e2ab8ff-cf8c-4a95-b4e8-8871f4d7b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-e48da3f6-9543-4cb8-9e36-62274f79aadc,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-911ebda9-31a6-4992-bc54-9dddb421194f,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-8692c481-8989-45a1-8f7e-70a3ed0cb9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-13f173c7-9f25-4039-a4a6-90b3935f5eca,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-259270893-172.17.0.9-1593352927295:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41074,DS-dfba6329-8bf4-4564-bda4-c43367b496cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-7e2ab8ff-cf8c-4a95-b4e8-8871f4d7b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-e48da3f6-9543-4cb8-9e36-62274f79aadc,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-911ebda9-31a6-4992-bc54-9dddb421194f,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-8692c481-8989-45a1-8f7e-70a3ed0cb9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-13f173c7-9f25-4039-a4a6-90b3935f5eca,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1471609684-172.17.0.9-1593353264762:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-94bce723-868b-4a89-84b2-a171be7fcf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-e43f399a-16e9-4323-aeb3-c846eeadd31e,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-b520c4d8-0299-46b8-8341-608f3db676d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-dac1da77-b1b0-4c19-be5b-06c2e0ffe63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-1cf29ac4-4c1a-4689-92ea-8f4372e513a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-cf46e301-9b5b-4a7c-8f75-9b29cf6acd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-498181e0-0e0b-4b9e-ba5b-3dd4ac219680,DISK]]; indices=[0, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1471609684-172.17.0.9-1593353264762:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-94bce723-868b-4a89-84b2-a171be7fcf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-e43f399a-16e9-4323-aeb3-c846eeadd31e,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-b520c4d8-0299-46b8-8341-608f3db676d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-dac1da77-b1b0-4c19-be5b-06c2e0ffe63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-1cf29ac4-4c1a-4689-92ea-8f4372e513a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-cf46e301-9b5b-4a7c-8f75-9b29cf6acd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-498181e0-0e0b-4b9e-ba5b-3dd4ac219680,DISK]]; indices=[0, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1570769394-172.17.0.9-1593353579584:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-7ebc20da-6d94-4a2d-ae67-0114f0a2093b,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-b8b165f9-15a7-4866-a603-3186379eae55,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-db0b2ff5-cc21-4aec-8f61-60e5d96da4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-9c84fa51-7687-4273-ae8b-54a49c079284,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-cc93edf9-c251-4b8d-8ef0-3493ebe8da39,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-4ca41af7-acd7-47ca-82bc-2b667daf245d,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-92452661-b236-4d86-ba01-6f1d11419788,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-d16344cc-52c1-419a-9d8b-4f6f115667df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1570769394-172.17.0.9-1593353579584:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-7ebc20da-6d94-4a2d-ae67-0114f0a2093b,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-b8b165f9-15a7-4866-a603-3186379eae55,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-db0b2ff5-cc21-4aec-8f61-60e5d96da4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-9c84fa51-7687-4273-ae8b-54a49c079284,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-cc93edf9-c251-4b8d-8ef0-3493ebe8da39,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-4ca41af7-acd7-47ca-82bc-2b667daf245d,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-92452661-b236-4d86-ba01-6f1d11419788,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-d16344cc-52c1-419a-9d8b-4f6f115667df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1266611290-172.17.0.9-1593353743594:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-73da5d06-ab04-4f1c-b800-b61903e1004e,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-954632f1-8672-4912-8a42-89b2da682562,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-6853d707-cd06-43b6-bf04-594a9a68dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-3d799c0d-c1cf-4bc5-9f22-cc34dcd4ed10,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-46410350-043f-4844-8a49-8ceacaf1d367,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-5eb95b37-c453-4e8d-a2a9-90b8c6320b5e,DISK]]; indices=[1, 2, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1266611290-172.17.0.9-1593353743594:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-73da5d06-ab04-4f1c-b800-b61903e1004e,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-954632f1-8672-4912-8a42-89b2da682562,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-6853d707-cd06-43b6-bf04-594a9a68dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-3d799c0d-c1cf-4bc5-9f22-cc34dcd4ed10,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-46410350-043f-4844-8a49-8ceacaf1d367,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-5eb95b37-c453-4e8d-a2a9-90b8c6320b5e,DISK]]; indices=[1, 2, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1283997413-172.17.0.9-1593354581988:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-0696ce12-7cac-47eb-9292-bca43e5cb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-00868f25-9f61-4313-8f17-05a7fef8c304,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-94ffcf59-e997-43f6-bd0f-ee74feef20e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-08e62ab8-5714-45d3-b7da-fa382b4e5594,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-d25d8ad3-0323-4af2-8a7c-8258a35312fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-f7db366f-bed5-4195-865e-24428c93a155,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-cd813a63-513f-4fe2-88cb-ead34c182f18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1283997413-172.17.0.9-1593354581988:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-0696ce12-7cac-47eb-9292-bca43e5cb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-00868f25-9f61-4313-8f17-05a7fef8c304,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-94ffcf59-e997-43f6-bd0f-ee74feef20e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-08e62ab8-5714-45d3-b7da-fa382b4e5594,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-d25d8ad3-0323-4af2-8a7c-8258a35312fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-f7db366f-bed5-4195-865e-24428c93a155,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-cd813a63-513f-4fe2-88cb-ead34c182f18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 8396
