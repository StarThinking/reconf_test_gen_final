reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-639689832-172.17.0.19-1593485990967:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:42515,DS-d5b16253-d73f-446c-9b24-81e38e3f6294,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-b3e42ceb-190a-48ad-b570-a1d701c280e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-2b20bd72-8912-4d66-b416-c737193cb389,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-0d931913-2599-4caa-b8bb-8cd02d1a39da,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-d8b739cd-1fe9-4f18-84d9-b7675afd27df,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-551e7a9c-d9bb-4edd-86cd-333f37a093f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-83f4e20f-8a67-4113-878f-515a70aa5fb3,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-639689832-172.17.0.19-1593485990967:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:42515,DS-d5b16253-d73f-446c-9b24-81e38e3f6294,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-b3e42ceb-190a-48ad-b570-a1d701c280e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-2b20bd72-8912-4d66-b416-c737193cb389,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-0d931913-2599-4caa-b8bb-8cd02d1a39da,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-d8b739cd-1fe9-4f18-84d9-b7675afd27df,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-551e7a9c-d9bb-4edd-86cd-333f37a093f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-83f4e20f-8a67-4113-878f-515a70aa5fb3,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1951514643-172.17.0.19-1593486283938:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-b31d8cb8-ec42-45af-9fd9-b89dd2b90d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-6a7f514a-9db8-4c1f-8137-4b80bbf89196,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-76d04d91-ecbc-43d2-8548-146faffda7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-ea383e4f-9f32-49e3-be48-8ff2343a6801,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-4955b9a0-32e7-431b-9e24-2120a47d04cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-5e7b24e7-4548-4d4c-b1b7-2c60b1348c6a,DISK]]; indices=[2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1951514643-172.17.0.19-1593486283938:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-b31d8cb8-ec42-45af-9fd9-b89dd2b90d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-6a7f514a-9db8-4c1f-8137-4b80bbf89196,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-76d04d91-ecbc-43d2-8548-146faffda7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-ea383e4f-9f32-49e3-be48-8ff2343a6801,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-4955b9a0-32e7-431b-9e24-2120a47d04cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-5e7b24e7-4548-4d4c-b1b7-2c60b1348c6a,DISK]]; indices=[2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-213636533-172.17.0.19-1593486626247:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33914,DS-52c73e3e-3604-4b3a-9114-924c4c455f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-9bf4a176-a9cf-40c4-92d8-0a1a23773ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-78dc0865-195e-4f93-89c4-1a36866e9966,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-aa1b6df5-1bca-4d7b-8eb1-21c16ef0bead,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-0ee7478f-3c5b-4736-885b-30b4a891ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-4e092dcd-a6c6-4f86-8c6c-4b12e4c0d415,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-6c4b0788-a091-433f-979c-0df12501be90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-213636533-172.17.0.19-1593486626247:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33914,DS-52c73e3e-3604-4b3a-9114-924c4c455f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-9bf4a176-a9cf-40c4-92d8-0a1a23773ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-78dc0865-195e-4f93-89c4-1a36866e9966,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-aa1b6df5-1bca-4d7b-8eb1-21c16ef0bead,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-0ee7478f-3c5b-4736-885b-30b4a891ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-4e092dcd-a6c6-4f86-8c6c-4b12e4c0d415,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-6c4b0788-a091-433f-979c-0df12501be90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1054837522-172.17.0.19-1593486902628:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-fd3c5f17-e3ea-4e08-9eb6-5bf13e2eb1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-7e0371a2-ff7c-413f-aa14-6235b853a077,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-ea1e8e5c-36ed-4356-91d3-7335296691d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-d6f87dd8-ad4b-4824-be04-c81318cfdbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-d17a2157-4fe5-4a16-a566-004959825a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-72ef29ff-fd98-430d-94f5-328491d68919,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-e4995fc7-0ad3-4c04-bd3b-9cd44782a252,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1054837522-172.17.0.19-1593486902628:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-fd3c5f17-e3ea-4e08-9eb6-5bf13e2eb1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-7e0371a2-ff7c-413f-aa14-6235b853a077,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-ea1e8e5c-36ed-4356-91d3-7335296691d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-d6f87dd8-ad4b-4824-be04-c81318cfdbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-d17a2157-4fe5-4a16-a566-004959825a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-72ef29ff-fd98-430d-94f5-328491d68919,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-e4995fc7-0ad3-4c04-bd3b-9cd44782a252,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1142425027-172.17.0.19-1593487128324:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-4fd5b5b6-ae3a-4149-a109-68d85c4f0f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-6c762f9e-ad78-470f-8470-735b1578f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-6ae830b1-71ca-47be-9d25-af1ec2577fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-dee36a1e-99a2-4453-9e32-1dfda5f02d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-8ebbce7d-afcb-40c1-b2d6-0c549d5c1a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-6d9c31c8-17f7-4722-ad3a-48ec3371d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-5ce13153-0763-4ef0-816e-bffbc6037900,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1142425027-172.17.0.19-1593487128324:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-4fd5b5b6-ae3a-4149-a109-68d85c4f0f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-6c762f9e-ad78-470f-8470-735b1578f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-6ae830b1-71ca-47be-9d25-af1ec2577fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-dee36a1e-99a2-4453-9e32-1dfda5f02d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-8ebbce7d-afcb-40c1-b2d6-0c549d5c1a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-6d9c31c8-17f7-4722-ad3a-48ec3371d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-5ce13153-0763-4ef0-816e-bffbc6037900,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1838156390-172.17.0.19-1593487228293:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:32843,DS-49d42c65-cbeb-447e-b5ca-f8ebc44d69c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-ab82ce8d-f930-487e-9576-c49e7860e402,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-bf56ea83-e28c-49e4-ba20-ea6d64e3916b,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-05a8a314-bb18-4e44-8b18-1888188e465a,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-2b63b75a-74aa-4e13-bb0e-505af728f926,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-769980d7-ae6d-44d4-8bb5-e897b3c04736,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-77da494e-bdd2-402b-a4cd-eb7dccf7dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-1d57126d-662c-428a-af2e-b4499f80e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1838156390-172.17.0.19-1593487228293:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:32843,DS-49d42c65-cbeb-447e-b5ca-f8ebc44d69c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-ab82ce8d-f930-487e-9576-c49e7860e402,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-bf56ea83-e28c-49e4-ba20-ea6d64e3916b,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-05a8a314-bb18-4e44-8b18-1888188e465a,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-2b63b75a-74aa-4e13-bb0e-505af728f926,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-769980d7-ae6d-44d4-8bb5-e897b3c04736,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-77da494e-bdd2-402b-a4cd-eb7dccf7dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-1d57126d-662c-428a-af2e-b4499f80e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1751984615-172.17.0.19-1593487469926:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-ddc897f5-64f9-4945-a2f1-f5ec32e15934,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-4b27170a-e350-4a63-8371-a7fc60f99d75,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-688d63fc-c6aa-43a0-92c0-8bab64bf43c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-4365068f-4ff5-487d-893c-12511730d2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-b1fa45f8-dda4-45be-b9cb-70ca48112b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-648bfb79-ce21-485e-a539-f15654648d3c,DISK]]; indices=[1, 2, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1751984615-172.17.0.19-1593487469926:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-ddc897f5-64f9-4945-a2f1-f5ec32e15934,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-4b27170a-e350-4a63-8371-a7fc60f99d75,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-688d63fc-c6aa-43a0-92c0-8bab64bf43c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-4365068f-4ff5-487d-893c-12511730d2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-b1fa45f8-dda4-45be-b9cb-70ca48112b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-648bfb79-ce21-485e-a539-f15654648d3c,DISK]]; indices=[1, 2, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1958261795-172.17.0.19-1593488169003:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-729284e1-a7e9-4e3b-83a8-5aa3fd27b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-0f6eb3a9-7973-45f5-ba83-cd8f6e57b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-542d05bc-e247-40c6-89a4-4478b3d5d66c,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-5472eb2c-89f6-4ffe-9e60-2287124f1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-747f38d0-d95f-4a2f-b04d-6a56ae649f17,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-814d3e52-830b-46f1-a437-6342a261ac63,DISK]]; indices=[1, 2, 3, 4, 5, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1958261795-172.17.0.19-1593488169003:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-729284e1-a7e9-4e3b-83a8-5aa3fd27b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-0f6eb3a9-7973-45f5-ba83-cd8f6e57b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-542d05bc-e247-40c6-89a4-4478b3d5d66c,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-5472eb2c-89f6-4ffe-9e60-2287124f1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-747f38d0-d95f-4a2f-b04d-6a56ae649f17,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-814d3e52-830b-46f1-a437-6342a261ac63,DISK]]; indices=[1, 2, 3, 4, 5, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1094530976-172.17.0.19-1593489373961:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-839f380f-a1e3-4d1c-9762-8cc7663f2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-3da21d5d-b584-447d-8fd8-ed924872990f,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-e2ecadda-a7b1-4700-93e5-5d1821ed826e,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-1507350a-393a-4b1e-a101-fe3b045c55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-34bd76bb-932f-4b73-9756-80cb658ed178,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-fa1928eb-5516-4a2d-808b-53ee220d005b,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-e1bfc82f-61b5-48b1-b9b2-c7aaf1738a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-63034e56-60e3-42b4-8055-879aff7442d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1094530976-172.17.0.19-1593489373961:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-839f380f-a1e3-4d1c-9762-8cc7663f2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-3da21d5d-b584-447d-8fd8-ed924872990f,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-e2ecadda-a7b1-4700-93e5-5d1821ed826e,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-1507350a-393a-4b1e-a101-fe3b045c55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-34bd76bb-932f-4b73-9756-80cb658ed178,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-fa1928eb-5516-4a2d-808b-53ee220d005b,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-e1bfc82f-61b5-48b1-b9b2-c7aaf1738a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-63034e56-60e3-42b4-8055-879aff7442d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-85412570-172.17.0.19-1593489631282:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-2e941a46-ced5-46eb-8e03-dff762b9f9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-265d9271-607d-4b07-8b26-8aa609a24517,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-9c991fd0-b6a1-48d7-989c-cf97de8c9780,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-6e4f885d-7b67-4783-bf48-8146508c76bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-397994bb-246e-4ea9-be79-f46050cec374,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-5cb25762-540c-4b09-9a46-f4d62450ac31,DISK]]; indices=[1, 2, 3, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-85412570-172.17.0.19-1593489631282:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-2e941a46-ced5-46eb-8e03-dff762b9f9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-265d9271-607d-4b07-8b26-8aa609a24517,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-9c991fd0-b6a1-48d7-989c-cf97de8c9780,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-6e4f885d-7b67-4783-bf48-8146508c76bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-397994bb-246e-4ea9-be79-f46050cec374,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-5cb25762-540c-4b09-9a46-f4d62450ac31,DISK]]; indices=[1, 2, 3, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1190631750-172.17.0.19-1593489864810:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-45997b1d-c3ae-4d22-a5bb-e414d1f2d660,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-43a00cde-2cd7-4006-8008-b6f481374c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-c1a05d52-77bc-4b7f-a777-87b6fc54465d,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-edadbcd4-2a9c-4249-bf71-6f6fccd3676f,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-794a8951-ef87-417a-806c-d812dbdbb9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-a94e5ba5-3443-4260-a6e4-3095a0003c75,DISK]]; indices=[1, 2, 3, 4, 5, 6]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1190631750-172.17.0.19-1593489864810:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-45997b1d-c3ae-4d22-a5bb-e414d1f2d660,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-43a00cde-2cd7-4006-8008-b6f481374c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-c1a05d52-77bc-4b7f-a777-87b6fc54465d,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-edadbcd4-2a9c-4249-bf71-6f6fccd3676f,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-794a8951-ef87-417a-806c-d812dbdbb9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-a94e5ba5-3443-4260-a6e4-3095a0003c75,DISK]]; indices=[1, 2, 3, 4, 5, 6]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-299651440-172.17.0.19-1593490216264:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-23612aea-ed06-4566-b070-4521a08a71a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-79d36020-3095-4aa7-b2f0-ba0004f8701a,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-577f824a-20cd-414c-b9ef-c18e845dd53c,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-06627017-8326-493a-a0a3-97e9c6b0f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-5643afe6-86f7-4050-a9d0-f383ebadea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-776f1352-e347-4a01-8f91-00560dc9abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-3a8dc5bd-11c8-48b3-9d71-7c1785a86719,DISK]]; indices=[0, 1, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-299651440-172.17.0.19-1593490216264:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-23612aea-ed06-4566-b070-4521a08a71a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-79d36020-3095-4aa7-b2f0-ba0004f8701a,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-577f824a-20cd-414c-b9ef-c18e845dd53c,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-06627017-8326-493a-a0a3-97e9c6b0f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-5643afe6-86f7-4050-a9d0-f383ebadea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-776f1352-e347-4a01-8f91-00560dc9abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-3a8dc5bd-11c8-48b3-9d71-7c1785a86719,DISK]]; indices=[0, 1, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-419330614-172.17.0.19-1593490379984:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-2739db33-93fe-4544-8b4c-0dba1c9a0e30,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-7d3584f2-56a9-4ac0-9df8-2478aa4a9cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-e9b84970-04a6-4e17-9811-79079a493936,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-4763bc3c-eebb-4b68-b945-3bde5edb43f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-b09f1904-7066-4451-91b5-77df2170050c,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-cfc98ac1-83ab-46f5-a2aa-0d4f0f4d59fb,DISK]]; indices=[0, 2, 3, 4, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-419330614-172.17.0.19-1593490379984:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-2739db33-93fe-4544-8b4c-0dba1c9a0e30,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-7d3584f2-56a9-4ac0-9df8-2478aa4a9cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-e9b84970-04a6-4e17-9811-79079a493936,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-4763bc3c-eebb-4b68-b945-3bde5edb43f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-b09f1904-7066-4451-91b5-77df2170050c,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-cfc98ac1-83ab-46f5-a2aa-0d4f0f4d59fb,DISK]]; indices=[0, 2, 3, 4, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1195291953-172.17.0.19-1593491417969:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44262,DS-7475a792-083a-469e-b80c-984ed025a793,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-e712979b-a3e1-43b9-b56d-698a8895a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-7bf89ac9-36b2-4ea6-a604-e961377b863d,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-51118239-22ec-4e3d-81e1-ac949be1ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-6430acf1-3e68-45be-9cf7-d6894379f5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-56ee824e-47b5-42d2-9525-a53f3cdbfe31,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-de6172b2-5b6a-4f67-94fa-b19f2aaf6a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-8aa06e5f-dff0-4d4f-b96d-f9b416df6bd4,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1195291953-172.17.0.19-1593491417969:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44262,DS-7475a792-083a-469e-b80c-984ed025a793,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-e712979b-a3e1-43b9-b56d-698a8895a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-7bf89ac9-36b2-4ea6-a604-e961377b863d,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-51118239-22ec-4e3d-81e1-ac949be1ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-6430acf1-3e68-45be-9cf7-d6894379f5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-56ee824e-47b5-42d2-9525-a53f3cdbfe31,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-de6172b2-5b6a-4f67-94fa-b19f2aaf6a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-8aa06e5f-dff0-4d4f-b96d-f9b416df6bd4,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1388170952-172.17.0.19-1593491750493:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-3141d8d0-8f13-4588-a84b-c564daeaf7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-cd3745a3-dde6-4d26-b27e-2b66542a910e,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-d37023a7-1b85-4e32-a0f4-a97916fca153,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-ef1924b5-61ef-47da-a3c1-ee8894d26d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-5d88b2d7-2611-4a2d-8419-80f8f7ad2786,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-e6c62894-6f21-44fb-9cc1-dbc1b08efe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-822d5862-8108-4c41-83ad-d368088b6e8d,DISK]]; indices=[0, 1, 2, 3, 4, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1388170952-172.17.0.19-1593491750493:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-3141d8d0-8f13-4588-a84b-c564daeaf7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-cd3745a3-dde6-4d26-b27e-2b66542a910e,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-d37023a7-1b85-4e32-a0f4-a97916fca153,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-ef1924b5-61ef-47da-a3c1-ee8894d26d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-5d88b2d7-2611-4a2d-8419-80f8f7ad2786,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-e6c62894-6f21-44fb-9cc1-dbc1b08efe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-822d5862-8108-4c41-83ad-d368088b6e8d,DISK]]; indices=[0, 1, 2, 3, 4, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1089764528-172.17.0.19-1593491914250:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-7604cc85-f646-40f7-b5c5-46430429697d,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-10a8c1ba-7d56-4a3e-ac75-1b42981ba521,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-ad04c0d9-dc24-4c51-ab9a-babb3592828d,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-4f0e3345-21ae-4574-9522-66b7cb29ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-3666c9ef-c7aa-4a72-a9fb-ccc3ed4f028c,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-86e1d8c7-d12c-4307-a98a-e80bd78eae95,DISK]]; indices=[0, 2, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1089764528-172.17.0.19-1593491914250:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-7604cc85-f646-40f7-b5c5-46430429697d,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-10a8c1ba-7d56-4a3e-ac75-1b42981ba521,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-ad04c0d9-dc24-4c51-ab9a-babb3592828d,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-4f0e3345-21ae-4574-9522-66b7cb29ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-3666c9ef-c7aa-4a72-a9fb-ccc3ed4f028c,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-86e1d8c7-d12c-4307-a98a-e80bd78eae95,DISK]]; indices=[0, 2, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-245429467-172.17.0.19-1593492406115:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-8194164d-2dd0-4c87-a2a4-fdf6cfd90870,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-1f22d9b1-0c56-4c6f-aa80-c96442b0a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-5dc2df45-09bd-4f4b-a2ff-e019be35e2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-f7a323fa-755f-415e-93d7-aefebdd13956,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-577f86c4-2b25-4d47-825c-b3960d32ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-0432156c-5f51-4f70-b13c-688415d28416,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-ad4f4747-4e65-4bd1-9179-d3566f7b7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-fb26b574-6a3e-46e3-988c-5794665edade,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-245429467-172.17.0.19-1593492406115:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-8194164d-2dd0-4c87-a2a4-fdf6cfd90870,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-1f22d9b1-0c56-4c6f-aa80-c96442b0a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-5dc2df45-09bd-4f4b-a2ff-e019be35e2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-f7a323fa-755f-415e-93d7-aefebdd13956,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-577f86c4-2b25-4d47-825c-b3960d32ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-0432156c-5f51-4f70-b13c-688415d28416,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-ad4f4747-4e65-4bd1-9179-d3566f7b7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-fb26b574-6a3e-46e3-988c-5794665edade,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1843883025-172.17.0.19-1593493289829:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45086,DS-b2f6e1d9-05ca-4ed2-bba3-442414ab4e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-b6e73787-4820-4e00-a671-8813cb672c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-f567c0ab-9db6-4686-9126-68d949b94653,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-f72b843f-e981-4e32-bf37-4a17f96858b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-48fd266c-8e9f-4e40-bb89-24b51fcaec47,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-59c01229-1f2a-4a8c-94da-5fbbde8f79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-db6e783e-734f-4b9b-bede-7a44768542fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-a3aabaca-beca-4786-836a-e7b0fc971252,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1843883025-172.17.0.19-1593493289829:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45086,DS-b2f6e1d9-05ca-4ed2-bba3-442414ab4e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-b6e73787-4820-4e00-a671-8813cb672c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-f567c0ab-9db6-4686-9126-68d949b94653,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-f72b843f-e981-4e32-bf37-4a17f96858b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-48fd266c-8e9f-4e40-bb89-24b51fcaec47,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-59c01229-1f2a-4a8c-94da-5fbbde8f79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-db6e783e-734f-4b9b-bede-7a44768542fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-a3aabaca-beca-4786-836a-e7b0fc971252,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 8473
