reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913846295-172.17.0.11-1593969954241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-462d654c-f67c-4b22-bbcc-e15e87809335,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-f91d0f2e-1421-4e79-8720-7eae63c85754,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-be40d067-c876-4dff-a412-1cbf6ad4587e,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-a4766d9f-a6cf-4c6b-9ced-aaf520529c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-314cba52-f3f6-41d9-8f02-ee5b6cd16ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-de458a2f-77c6-4f19-a02a-877b56ee8b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-2a90cb5c-6af8-4e15-93a0-7eab2e5828a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-d718cbf1-b382-48ea-8a84-c58258d07226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913846295-172.17.0.11-1593969954241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-462d654c-f67c-4b22-bbcc-e15e87809335,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-f91d0f2e-1421-4e79-8720-7eae63c85754,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-be40d067-c876-4dff-a412-1cbf6ad4587e,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-a4766d9f-a6cf-4c6b-9ced-aaf520529c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-314cba52-f3f6-41d9-8f02-ee5b6cd16ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-de458a2f-77c6-4f19-a02a-877b56ee8b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-2a90cb5c-6af8-4e15-93a0-7eab2e5828a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-d718cbf1-b382-48ea-8a84-c58258d07226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002483688-172.17.0.11-1593970249724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-d4a487ad-4f6e-472e-9964-a6961c4a3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-f6c75495-c737-4d12-91f9-7a69bf9efdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-5791e5e5-b993-44ea-b165-bb55312fd074,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-8728b1b7-68e4-47ee-8416-1c48e46d9d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-4993a9c9-e395-4696-be7c-e0f18199b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-02ddc69c-6737-4104-9d9f-50328e58729e,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-b59e1008-336a-4471-98fe-579c4c4fa407,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-c997f169-fb12-459b-96ae-601c1ad21b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002483688-172.17.0.11-1593970249724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-d4a487ad-4f6e-472e-9964-a6961c4a3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-f6c75495-c737-4d12-91f9-7a69bf9efdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-5791e5e5-b993-44ea-b165-bb55312fd074,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-8728b1b7-68e4-47ee-8416-1c48e46d9d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-4993a9c9-e395-4696-be7c-e0f18199b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-02ddc69c-6737-4104-9d9f-50328e58729e,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-b59e1008-336a-4471-98fe-579c4c4fa407,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-c997f169-fb12-459b-96ae-601c1ad21b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416281394-172.17.0.11-1593970514856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-9072c501-f5cf-4ec2-b4f5-ea35e786a86c,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-51ab1d9b-c8d3-4226-8d91-e1250d54ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-1c784489-82a9-4aa9-9bd7-d2bf5512b670,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-2f81d063-6b20-4b23-8879-2c053d6137f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-85f38c4e-9596-4bb8-a554-a9cb931fa641,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-a4c88c6a-1935-4402-94e2-24e356e38cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-820b5929-e0f0-4072-9271-ebe083368ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-61073823-7aa3-43ac-954e-ee00556cba8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416281394-172.17.0.11-1593970514856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-9072c501-f5cf-4ec2-b4f5-ea35e786a86c,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-51ab1d9b-c8d3-4226-8d91-e1250d54ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-1c784489-82a9-4aa9-9bd7-d2bf5512b670,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-2f81d063-6b20-4b23-8879-2c053d6137f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-85f38c4e-9596-4bb8-a554-a9cb931fa641,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-a4c88c6a-1935-4402-94e2-24e356e38cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-820b5929-e0f0-4072-9271-ebe083368ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-61073823-7aa3-43ac-954e-ee00556cba8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720208641-172.17.0.11-1593970690525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-db7b1157-7e27-4e66-8e4a-4745bcda6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-5022a4f4-8d71-4148-8aa1-d6bda219a39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-2e83f940-e4fb-42e4-bb3f-e02ca365ac54,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-3e6332db-ea3c-433e-a40b-277bc3713f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-165bff57-5923-40be-9606-a742e4c9dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-6ad9f01a-0c6d-4a98-b086-540bc83ef07a,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-74ae4859-7aac-413b-a079-3b012fe3fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-8a23c601-ec6d-4a46-8df5-964948e8affc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720208641-172.17.0.11-1593970690525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-db7b1157-7e27-4e66-8e4a-4745bcda6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-5022a4f4-8d71-4148-8aa1-d6bda219a39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-2e83f940-e4fb-42e4-bb3f-e02ca365ac54,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-3e6332db-ea3c-433e-a40b-277bc3713f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-165bff57-5923-40be-9606-a742e4c9dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-6ad9f01a-0c6d-4a98-b086-540bc83ef07a,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-74ae4859-7aac-413b-a079-3b012fe3fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-8a23c601-ec6d-4a46-8df5-964948e8affc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520028048-172.17.0.11-1593970858295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-b340acd9-2c71-47d6-832c-955dca1357ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-27ca879f-01b9-4cd4-ba83-c241ffad8f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-5682638d-afdd-4611-8940-fa9eb81d14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-8986ac23-9f28-4bca-ae67-13797d31d65a,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-04922c6e-39e5-40c8-a0d5-a0664a3c877d,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-8b477aa6-6637-40cb-a533-41ea4e35e6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-8d15ae90-9268-4598-9c84-cd43e25be529,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-b9aa2c49-5518-48c7-a65f-1faf1f0dada3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520028048-172.17.0.11-1593970858295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-b340acd9-2c71-47d6-832c-955dca1357ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-27ca879f-01b9-4cd4-ba83-c241ffad8f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-5682638d-afdd-4611-8940-fa9eb81d14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-8986ac23-9f28-4bca-ae67-13797d31d65a,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-04922c6e-39e5-40c8-a0d5-a0664a3c877d,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-8b477aa6-6637-40cb-a533-41ea4e35e6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-8d15ae90-9268-4598-9c84-cd43e25be529,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-b9aa2c49-5518-48c7-a65f-1faf1f0dada3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689431250-172.17.0.11-1593971625346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-50f69e35-a570-41a6-824d-dd0098da0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-79682ee4-30c2-4227-898c-859dc3d31641,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-5b28707c-bee0-4514-8e40-9ff9cce8dd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-7f3dca9c-0ed8-4cbf-a478-478f277c704f,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-a926a2df-20f6-4c12-97f4-a0a0f00474af,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-719c0edc-5f34-4ed4-b30f-d0bb6b571d42,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-842d6930-9abd-4aae-9b32-0b7e1d2ba32d,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-b0f4f40f-1f09-48c3-aa74-ab6331748121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689431250-172.17.0.11-1593971625346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-50f69e35-a570-41a6-824d-dd0098da0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-79682ee4-30c2-4227-898c-859dc3d31641,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-5b28707c-bee0-4514-8e40-9ff9cce8dd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-7f3dca9c-0ed8-4cbf-a478-478f277c704f,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-a926a2df-20f6-4c12-97f4-a0a0f00474af,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-719c0edc-5f34-4ed4-b30f-d0bb6b571d42,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-842d6930-9abd-4aae-9b32-0b7e1d2ba32d,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-b0f4f40f-1f09-48c3-aa74-ab6331748121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209564518-172.17.0.11-1593971831138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36278,DS-c7af4a65-5222-4dc7-afac-92dce6bef671,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-43246821-a1d2-4c45-84dd-8661e1f3c657,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-361a4d06-1c5e-4c7c-92b9-6756afe2338b,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-0fd748ff-021e-45f6-81fa-dd8ec85406e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-46d22cb3-91b4-43cd-9dd2-51ef1c52195d,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-01d97b9e-2108-4924-9613-0561d9f62226,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-f40fbdcd-4dbf-464d-bd80-2fb8c38da49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-273072b5-e639-4640-8005-5fb521c2710d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209564518-172.17.0.11-1593971831138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36278,DS-c7af4a65-5222-4dc7-afac-92dce6bef671,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-43246821-a1d2-4c45-84dd-8661e1f3c657,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-361a4d06-1c5e-4c7c-92b9-6756afe2338b,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-0fd748ff-021e-45f6-81fa-dd8ec85406e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-46d22cb3-91b4-43cd-9dd2-51ef1c52195d,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-01d97b9e-2108-4924-9613-0561d9f62226,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-f40fbdcd-4dbf-464d-bd80-2fb8c38da49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-273072b5-e639-4640-8005-5fb521c2710d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956695310-172.17.0.11-1593972002723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33696,DS-907923a0-a393-4437-a7f9-fab8cf62a784,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-2a35c287-8055-4e13-8b13-ed8b9182430b,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-5bbfcfeb-8c77-4fd9-bd8f-43182d763681,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-bcd44190-b1ce-4eec-9618-e0adaa5a5418,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-b6ac7d35-2e27-4541-83f2-489e77b7945e,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-5f42716c-fb9b-4bf3-ab20-de47030e2ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-f58c5360-eac5-40af-80ac-1ac21c9f8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-e7522b1e-0197-4d88-af3c-b7103cdae86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956695310-172.17.0.11-1593972002723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33696,DS-907923a0-a393-4437-a7f9-fab8cf62a784,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-2a35c287-8055-4e13-8b13-ed8b9182430b,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-5bbfcfeb-8c77-4fd9-bd8f-43182d763681,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-bcd44190-b1ce-4eec-9618-e0adaa5a5418,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-b6ac7d35-2e27-4541-83f2-489e77b7945e,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-5f42716c-fb9b-4bf3-ab20-de47030e2ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-f58c5360-eac5-40af-80ac-1ac21c9f8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-e7522b1e-0197-4d88-af3c-b7103cdae86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939510308-172.17.0.11-1593972225169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-ddd54959-d59a-4e3b-965a-0ed54b8e8829,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-898b914f-ca93-4e34-a949-99983431cb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-abefb2a4-9cb8-495e-9da9-b4f54612fa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-39ca6d34-f939-422d-ba90-e0daae145d26,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-e5d8a225-e6ed-4ea4-8d3d-898721447e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-7f107108-3fac-4056-a73e-52d2718c9503,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-135195fa-8ea7-40e2-90e3-ab0cb586cb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-f3241338-702d-4529-928c-ca40e40345e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939510308-172.17.0.11-1593972225169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-ddd54959-d59a-4e3b-965a-0ed54b8e8829,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-898b914f-ca93-4e34-a949-99983431cb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-abefb2a4-9cb8-495e-9da9-b4f54612fa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-39ca6d34-f939-422d-ba90-e0daae145d26,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-e5d8a225-e6ed-4ea4-8d3d-898721447e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-7f107108-3fac-4056-a73e-52d2718c9503,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-135195fa-8ea7-40e2-90e3-ab0cb586cb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-f3241338-702d-4529-928c-ca40e40345e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293528396-172.17.0.11-1593972314596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34176,DS-de9600c6-5b9a-46f8-adde-bdc16a9a12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-55b326d5-5f87-495f-b6f0-4c16d03c20bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-d2b7170c-adf0-47a1-b985-b38cb0de1448,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-cab5070d-1e69-4e20-a888-18bef26ec032,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-406a4743-e19c-48f8-a89e-4bbc5b97e994,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-59907f80-e0af-4d21-94d7-2a6342b32d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-e204e404-d83a-4d61-8c9a-ff7e6723d85f,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-87bf12bc-6e47-445a-9e51-337771ff4fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293528396-172.17.0.11-1593972314596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34176,DS-de9600c6-5b9a-46f8-adde-bdc16a9a12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-55b326d5-5f87-495f-b6f0-4c16d03c20bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-d2b7170c-adf0-47a1-b985-b38cb0de1448,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-cab5070d-1e69-4e20-a888-18bef26ec032,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-406a4743-e19c-48f8-a89e-4bbc5b97e994,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-59907f80-e0af-4d21-94d7-2a6342b32d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-e204e404-d83a-4d61-8c9a-ff7e6723d85f,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-87bf12bc-6e47-445a-9e51-337771ff4fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461593825-172.17.0.11-1593972413987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-6bcbced3-8b65-4cd5-9fbe-71e01c9c855c,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-d5c4c3ee-9b8d-47f7-8d2d-09cdec5cffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-b097b6b5-e936-478e-bd6c-8a6610c0a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-4817c4c7-221e-475e-8d1f-9c8a3e6d8af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-dd080305-d7f1-42e4-b2d3-107a7eaad67f,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-ebd3903e-d550-4b49-a9d4-41332a97915f,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-f893ef81-cb08-48d8-9982-fc925b45eb57,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-b0e19010-76f1-4326-9c30-a7c1aa8a7f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461593825-172.17.0.11-1593972413987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-6bcbced3-8b65-4cd5-9fbe-71e01c9c855c,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-d5c4c3ee-9b8d-47f7-8d2d-09cdec5cffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-b097b6b5-e936-478e-bd6c-8a6610c0a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-4817c4c7-221e-475e-8d1f-9c8a3e6d8af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-dd080305-d7f1-42e4-b2d3-107a7eaad67f,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-ebd3903e-d550-4b49-a9d4-41332a97915f,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-f893ef81-cb08-48d8-9982-fc925b45eb57,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-b0e19010-76f1-4326-9c30-a7c1aa8a7f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385621679-172.17.0.11-1593973056243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33664,DS-15210198-9773-42eb-b88a-edd2f4d9a851,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-aa9264b4-a977-4fbd-84c9-5a86113e1e10,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-66895f89-427c-4590-a135-12b66bdbe332,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-6f71ef41-5348-41dc-9a75-766b64a0ea43,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-545b519f-c30c-46a1-8852-d578086ecb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-7eae6c54-d8b5-42fa-b844-4980aadfa6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-3c2faf79-7927-41ee-9775-250ff47255d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-3a1111cd-3373-4cbb-a5f6-87d620a33494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385621679-172.17.0.11-1593973056243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33664,DS-15210198-9773-42eb-b88a-edd2f4d9a851,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-aa9264b4-a977-4fbd-84c9-5a86113e1e10,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-66895f89-427c-4590-a135-12b66bdbe332,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-6f71ef41-5348-41dc-9a75-766b64a0ea43,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-545b519f-c30c-46a1-8852-d578086ecb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-7eae6c54-d8b5-42fa-b844-4980aadfa6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-3c2faf79-7927-41ee-9775-250ff47255d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-3a1111cd-3373-4cbb-a5f6-87d620a33494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882442976-172.17.0.11-1593974058410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-525e9741-5ea4-444e-b4e4-2748b751db46,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-4810b45f-c1fb-4c0b-900f-5b01fd087fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-15b27f49-2144-4e47-94ef-bd8d330b2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-20f068d2-d77e-4f56-a32b-dd7b34588fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-07158804-1bef-4481-9759-85f2940f8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-5f718303-ea49-4846-ba10-ca7ec104a674,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-a2414ea8-1018-4a44-b5e1-2d90b15ae8be,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-55ab55a0-58a0-4a38-b2d8-e30d88dd2501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882442976-172.17.0.11-1593974058410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-525e9741-5ea4-444e-b4e4-2748b751db46,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-4810b45f-c1fb-4c0b-900f-5b01fd087fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-15b27f49-2144-4e47-94ef-bd8d330b2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-20f068d2-d77e-4f56-a32b-dd7b34588fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-07158804-1bef-4481-9759-85f2940f8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-5f718303-ea49-4846-ba10-ca7ec104a674,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-a2414ea8-1018-4a44-b5e1-2d90b15ae8be,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-55ab55a0-58a0-4a38-b2d8-e30d88dd2501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398083369-172.17.0.11-1593974609849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-b3b02f68-1836-49cf-8fe3-f78335114a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-ce6acd01-9561-477e-b230-993071c36a89,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c2175588-d8a5-407c-bf9c-0d637e641845,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-aa62cda5-ed20-4e76-beef-0f05a7ae0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-b5b099e9-5219-4d84-aa21-af96cc82d348,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-df74d948-dff7-4cf6-b251-007da31613a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-8745f875-895b-425b-93be-14adf4e6e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-fd543d7e-d63a-4756-9658-41b38944280a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398083369-172.17.0.11-1593974609849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-b3b02f68-1836-49cf-8fe3-f78335114a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-ce6acd01-9561-477e-b230-993071c36a89,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c2175588-d8a5-407c-bf9c-0d637e641845,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-aa62cda5-ed20-4e76-beef-0f05a7ae0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-b5b099e9-5219-4d84-aa21-af96cc82d348,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-df74d948-dff7-4cf6-b251-007da31613a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-8745f875-895b-425b-93be-14adf4e6e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-fd543d7e-d63a-4756-9658-41b38944280a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390387201-172.17.0.11-1593975039106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-f2f28e96-9ee8-42cc-9aa1-876def7a6887,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-a955acb5-65b2-4c0e-8eb0-ff9d41eea9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-07a00db9-edf3-4d23-9b8a-1e9ff6e304c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-9300dfe5-2c11-4662-9f8d-05bb153535b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-76dada93-2e35-42db-8235-0b82fa64af25,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-e39f301b-2710-42c2-9caa-f40d901950da,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-6a0e76cc-354b-4365-b984-3735e528bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-d5bb5eef-e6cb-4fed-973f-1cbf95d90e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390387201-172.17.0.11-1593975039106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-f2f28e96-9ee8-42cc-9aa1-876def7a6887,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-a955acb5-65b2-4c0e-8eb0-ff9d41eea9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-07a00db9-edf3-4d23-9b8a-1e9ff6e304c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-9300dfe5-2c11-4662-9f8d-05bb153535b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-76dada93-2e35-42db-8235-0b82fa64af25,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-e39f301b-2710-42c2-9caa-f40d901950da,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-6a0e76cc-354b-4365-b984-3735e528bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-d5bb5eef-e6cb-4fed-973f-1cbf95d90e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5225
