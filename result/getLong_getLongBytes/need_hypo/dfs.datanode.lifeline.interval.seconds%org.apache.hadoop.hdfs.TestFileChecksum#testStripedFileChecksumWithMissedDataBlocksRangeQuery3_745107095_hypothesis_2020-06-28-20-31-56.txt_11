reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979039690-172.17.0.6-1593376751740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42932,DS-1c3ae6a5-7ba0-46c0-8bd9-b4c7608a7ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-df5ac467-6338-4421-9780-1c6859458949,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-8abb0ac9-7051-4944-82d2-09a010a20374,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-3405316a-d910-4b42-9f0a-2e6647e7ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-3576f5c9-55dd-4dde-86db-cf44258fb8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-95cbedbb-a80e-4714-967a-84dec41c25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-c9b855eb-2b77-4627-a245-1bffb34de732,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-662861e5-36c1-4f9b-b30c-8b8d2d194fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979039690-172.17.0.6-1593376751740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42932,DS-1c3ae6a5-7ba0-46c0-8bd9-b4c7608a7ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-df5ac467-6338-4421-9780-1c6859458949,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-8abb0ac9-7051-4944-82d2-09a010a20374,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-3405316a-d910-4b42-9f0a-2e6647e7ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-3576f5c9-55dd-4dde-86db-cf44258fb8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-95cbedbb-a80e-4714-967a-84dec41c25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-c9b855eb-2b77-4627-a245-1bffb34de732,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-662861e5-36c1-4f9b-b30c-8b8d2d194fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956351377-172.17.0.6-1593377145986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-80674bd2-5aa8-4dea-b0b5-1947e68eb26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-117a2dfe-ae6a-4add-b46b-229b8f0dbecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-26109a23-6bbc-4efc-8c9a-99154eecfb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-c18a93bb-9814-4ea5-ad24-5eb9578ff914,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-8f162d51-9e0d-42df-aaf9-8d6d205a315c,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-5872b553-3ca6-42c4-bfee-0ad7828af766,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-8c46b578-fd0d-468f-bab0-946b64d6c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-39334b95-9fa1-4016-b536-5f5482a8c497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956351377-172.17.0.6-1593377145986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-80674bd2-5aa8-4dea-b0b5-1947e68eb26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-117a2dfe-ae6a-4add-b46b-229b8f0dbecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-26109a23-6bbc-4efc-8c9a-99154eecfb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-c18a93bb-9814-4ea5-ad24-5eb9578ff914,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-8f162d51-9e0d-42df-aaf9-8d6d205a315c,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-5872b553-3ca6-42c4-bfee-0ad7828af766,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-8c46b578-fd0d-468f-bab0-946b64d6c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-39334b95-9fa1-4016-b536-5f5482a8c497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367657901-172.17.0.6-1593378346747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43389,DS-b9344f6f-53c5-4853-8432-bd8cbbf12409,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-799058e5-bd3d-420a-bbaa-1ee28e2dfc86,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-b4f0f336-de5c-47cd-9283-a8733c3f4a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-52b6d59f-31f0-49c4-bc7a-4cd1c22d5652,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-018ab966-2bcf-4953-938c-ba3750261440,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-927d3442-5ed4-4738-b133-d08e1b1815d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-0a727d4f-89bb-4449-ad0b-ef30c4657522,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-28ae721f-4a8f-41e5-b40d-23d9b00843e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367657901-172.17.0.6-1593378346747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43389,DS-b9344f6f-53c5-4853-8432-bd8cbbf12409,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-799058e5-bd3d-420a-bbaa-1ee28e2dfc86,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-b4f0f336-de5c-47cd-9283-a8733c3f4a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-52b6d59f-31f0-49c4-bc7a-4cd1c22d5652,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-018ab966-2bcf-4953-938c-ba3750261440,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-927d3442-5ed4-4738-b133-d08e1b1815d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-0a727d4f-89bb-4449-ad0b-ef30c4657522,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-28ae721f-4a8f-41e5-b40d-23d9b00843e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238840789-172.17.0.6-1593378387415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-c53f89bb-59ad-4b76-8241-ab14f3a7df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-a26ea29d-2bae-4283-99ba-a6f2bd180c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-08fd3eb7-a8f7-459d-b6d1-0fa66a56c68b,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-fa8df4c0-d45f-46be-8e74-15d208d136d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-1c0e0612-c819-4ea8-a70b-6939c6db7702,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-8886e643-1075-4b18-92d0-b34ff88c12e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-b8b34798-69fe-41dd-96d5-4a9e4e400597,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-7b1cadc3-cff9-411b-86a2-843299152001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238840789-172.17.0.6-1593378387415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-c53f89bb-59ad-4b76-8241-ab14f3a7df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-a26ea29d-2bae-4283-99ba-a6f2bd180c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-08fd3eb7-a8f7-459d-b6d1-0fa66a56c68b,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-fa8df4c0-d45f-46be-8e74-15d208d136d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-1c0e0612-c819-4ea8-a70b-6939c6db7702,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-8886e643-1075-4b18-92d0-b34ff88c12e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-b8b34798-69fe-41dd-96d5-4a9e4e400597,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-7b1cadc3-cff9-411b-86a2-843299152001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857132838-172.17.0.6-1593378688437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38838,DS-87d1c815-982f-405c-b6ea-4ad34ed636c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-50d35c91-976f-4083-ab5c-a07ba032fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-9c0ef49f-1bda-4d01-a03e-10716773b2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0a06efa0-1a8c-4678-9d1d-e4857b8fc6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-06689d98-88f1-45f2-83c7-28207693bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-72aafbad-437d-4a77-99ae-c50445b28246,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-e774a2e9-f203-43fb-bced-f9ab8bdf3349,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-8d47db3d-007e-4b8f-b1ed-cce0324a87a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857132838-172.17.0.6-1593378688437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38838,DS-87d1c815-982f-405c-b6ea-4ad34ed636c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-50d35c91-976f-4083-ab5c-a07ba032fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-9c0ef49f-1bda-4d01-a03e-10716773b2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0a06efa0-1a8c-4678-9d1d-e4857b8fc6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-06689d98-88f1-45f2-83c7-28207693bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-72aafbad-437d-4a77-99ae-c50445b28246,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-e774a2e9-f203-43fb-bced-f9ab8bdf3349,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-8d47db3d-007e-4b8f-b1ed-cce0324a87a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163101225-172.17.0.6-1593378809189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33657,DS-f23e7e35-4985-462c-94e2-84259b04989d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-abe9830e-3b0f-4cd9-837d-4797a9d417e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-951cc827-3745-4d7f-8f9d-87157184f1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-fc18b524-8463-41ab-a758-1c0f82f50218,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-4f5e89db-c5fe-4c3e-8a2f-35522cfcec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-14cd6b3a-1a80-4d58-a5ad-cc59e1e34d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-a2fda979-d34e-4193-882c-d32230a250fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-37920088-8e2a-4bdb-b5f6-edd22cf7da8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163101225-172.17.0.6-1593378809189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33657,DS-f23e7e35-4985-462c-94e2-84259b04989d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-abe9830e-3b0f-4cd9-837d-4797a9d417e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-951cc827-3745-4d7f-8f9d-87157184f1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-fc18b524-8463-41ab-a758-1c0f82f50218,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-4f5e89db-c5fe-4c3e-8a2f-35522cfcec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-14cd6b3a-1a80-4d58-a5ad-cc59e1e34d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-a2fda979-d34e-4193-882c-d32230a250fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-37920088-8e2a-4bdb-b5f6-edd22cf7da8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793726143-172.17.0.6-1593379530018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-b3d9d5c2-e0a4-45ca-aea4-e937152381b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-e81a9d1b-8d9c-4d89-b015-0a516a9a5492,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-9792826b-5be5-4e42-833f-ad34d505fa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-1927b5dd-331b-4936-80cc-f7573070c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-30ad967e-6829-41bd-87a9-fa6115c8b8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-28256a9a-d936-4b2f-bbff-255ef22abc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-7f452bc5-70b7-494f-a828-fbb08ae3217f,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-7bb4124e-beff-4d75-b6c3-02801b40c0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793726143-172.17.0.6-1593379530018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-b3d9d5c2-e0a4-45ca-aea4-e937152381b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-e81a9d1b-8d9c-4d89-b015-0a516a9a5492,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-9792826b-5be5-4e42-833f-ad34d505fa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-1927b5dd-331b-4936-80cc-f7573070c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-30ad967e-6829-41bd-87a9-fa6115c8b8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-28256a9a-d936-4b2f-bbff-255ef22abc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-7f452bc5-70b7-494f-a828-fbb08ae3217f,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-7bb4124e-beff-4d75-b6c3-02801b40c0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46372491-172.17.0.6-1593379753315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-d96eed06-e8f0-47aa-ae95-272a15bbce14,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-09ddbed5-57cf-44e8-bd00-54f28fcf2663,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-f8cfdf15-a3b6-4ea3-bd22-826b06a73f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-cce6c634-0f0a-43e9-95ff-566ed4cbb9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-55cc1b65-9b0b-4f4e-8a5c-36af814de120,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-d7ddb1e8-f3d4-45ab-803b-aad0243ac16c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-49894e15-3628-45a6-8c36-d64bb11a828a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-8af2657b-e607-42bc-9690-a25893533fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46372491-172.17.0.6-1593379753315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-d96eed06-e8f0-47aa-ae95-272a15bbce14,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-09ddbed5-57cf-44e8-bd00-54f28fcf2663,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-f8cfdf15-a3b6-4ea3-bd22-826b06a73f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-cce6c634-0f0a-43e9-95ff-566ed4cbb9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-55cc1b65-9b0b-4f4e-8a5c-36af814de120,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-d7ddb1e8-f3d4-45ab-803b-aad0243ac16c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-49894e15-3628-45a6-8c36-d64bb11a828a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-8af2657b-e607-42bc-9690-a25893533fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600064315-172.17.0.6-1593379867498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-65e99f0e-5730-48d8-87a7-6058211ecc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-42fa6889-b4f4-42e8-bcb7-ca5c25e13da1,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-0446b4a7-641e-4429-ad3e-c9f228cc02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-09ab257f-d619-4fe9-a8e3-505276eb731c,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-3cf0a3ba-e069-4b9d-b2af-52c384266b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-f41e954f-bc51-47d0-aa18-1f450dc3d5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-c5b71870-c544-481a-b6b9-605e98741f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-12904270-fe8f-4530-a959-1346c544bdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600064315-172.17.0.6-1593379867498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-65e99f0e-5730-48d8-87a7-6058211ecc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-42fa6889-b4f4-42e8-bcb7-ca5c25e13da1,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-0446b4a7-641e-4429-ad3e-c9f228cc02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-09ab257f-d619-4fe9-a8e3-505276eb731c,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-3cf0a3ba-e069-4b9d-b2af-52c384266b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-f41e954f-bc51-47d0-aa18-1f450dc3d5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-c5b71870-c544-481a-b6b9-605e98741f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-12904270-fe8f-4530-a959-1346c544bdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403043253-172.17.0.6-1593380313621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-fb8fb88b-57c4-440a-8076-0dcaaae83a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-ccb5ce67-0d89-4981-857e-2e9e4e146ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-8ac8dd5e-6ca0-4a8d-9587-8d6c7cb8c747,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-bc27b2e8-3d5b-4968-9c71-e207e9c4ecda,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-b4e0b08b-8093-44f4-8189-e1985204ee11,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-f15a780e-7f16-4807-84a0-c887ae288ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6115c5fa-899a-4c0e-b263-2a54be35aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b5177b4b-aa40-437d-ba98-f28335c3103c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403043253-172.17.0.6-1593380313621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-fb8fb88b-57c4-440a-8076-0dcaaae83a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-ccb5ce67-0d89-4981-857e-2e9e4e146ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-8ac8dd5e-6ca0-4a8d-9587-8d6c7cb8c747,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-bc27b2e8-3d5b-4968-9c71-e207e9c4ecda,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-b4e0b08b-8093-44f4-8189-e1985204ee11,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-f15a780e-7f16-4807-84a0-c887ae288ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6115c5fa-899a-4c0e-b263-2a54be35aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b5177b4b-aa40-437d-ba98-f28335c3103c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974236118-172.17.0.6-1593380915266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-72a30ce7-d993-47cd-8822-12f9cae96f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-61d9def5-d61c-49dc-860c-68c7ad096577,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-4ed75869-1233-45a8-83d4-cb0cd53dc4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-906c060a-f766-498c-a703-2868f43c8ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-353a963a-8219-494a-ab5a-eceebae1d4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-e8990bdc-c806-4a6e-b5e8-143e5c6df826,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-a7b6d258-1af8-493e-87ed-04e366d4ce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-98a0ec25-6f79-4faa-ae56-0f011413b885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974236118-172.17.0.6-1593380915266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-72a30ce7-d993-47cd-8822-12f9cae96f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-61d9def5-d61c-49dc-860c-68c7ad096577,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-4ed75869-1233-45a8-83d4-cb0cd53dc4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-906c060a-f766-498c-a703-2868f43c8ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-353a963a-8219-494a-ab5a-eceebae1d4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-e8990bdc-c806-4a6e-b5e8-143e5c6df826,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-a7b6d258-1af8-493e-87ed-04e366d4ce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-98a0ec25-6f79-4faa-ae56-0f011413b885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121037185-172.17.0.6-1593381026075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44223,DS-a23cf9c7-2979-4551-bb5d-62f2141a532f,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-8055527d-861c-460f-8db9-606257e8a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-617d7f62-da3a-473d-b104-ee6a43850720,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-f0ccbdcf-fe73-4895-9451-348b269a40e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-aa222ad1-19d2-45bb-b501-f8baf3fce2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-d5d3b920-a00d-4cee-b7ac-f9e2bed193d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-b0dc6751-bbc4-47c9-ae02-d74d7acd4a80,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-6aac3204-8744-4b62-a225-236e03a62e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121037185-172.17.0.6-1593381026075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44223,DS-a23cf9c7-2979-4551-bb5d-62f2141a532f,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-8055527d-861c-460f-8db9-606257e8a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-617d7f62-da3a-473d-b104-ee6a43850720,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-f0ccbdcf-fe73-4895-9451-348b269a40e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-aa222ad1-19d2-45bb-b501-f8baf3fce2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-d5d3b920-a00d-4cee-b7ac-f9e2bed193d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-b0dc6751-bbc4-47c9-ae02-d74d7acd4a80,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-6aac3204-8744-4b62-a225-236e03a62e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401402933-172.17.0.6-1593381488826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-51faef62-593a-4074-8db1-b9d4e070ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-13c88316-1f99-4c48-a1ee-2fdc4bcad7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-0387c57d-af28-40cb-babd-9294261a1342,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-c28f53f7-a9c3-4e6f-81b3-16c616ef91fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-71a29f8b-372f-475f-acaa-c85dd0023d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-bed88137-0ac8-4f8d-ad36-cc8bca140794,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-c63d1b92-2020-4aa0-9e55-8c65f1db4e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-a21de079-0716-4ec2-afa7-0c9a121b606d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401402933-172.17.0.6-1593381488826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-51faef62-593a-4074-8db1-b9d4e070ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-13c88316-1f99-4c48-a1ee-2fdc4bcad7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-0387c57d-af28-40cb-babd-9294261a1342,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-c28f53f7-a9c3-4e6f-81b3-16c616ef91fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-71a29f8b-372f-475f-acaa-c85dd0023d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-bed88137-0ac8-4f8d-ad36-cc8bca140794,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-c63d1b92-2020-4aa0-9e55-8c65f1db4e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-a21de079-0716-4ec2-afa7-0c9a121b606d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851342146-172.17.0.6-1593381596461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45170,DS-03b241e8-eb8e-44bd-8a13-0d66708e5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-9d155941-920a-473f-b11f-5b4caeb47b59,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-20702bd9-6f10-4db2-95d2-65f4af94ad80,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-93d6cf25-c1aa-45a2-9c1a-1abbdbc8c2de,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-34ee6e4c-8e36-4634-9553-1401b42b79e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-c02d8e3e-ed2d-4f0b-b373-c3027d367b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-8ac72f79-d89f-400c-94e9-95be3cbfbd55,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-2816d368-4b64-4ef8-8a39-9e399b65dfc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851342146-172.17.0.6-1593381596461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45170,DS-03b241e8-eb8e-44bd-8a13-0d66708e5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-9d155941-920a-473f-b11f-5b4caeb47b59,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-20702bd9-6f10-4db2-95d2-65f4af94ad80,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-93d6cf25-c1aa-45a2-9c1a-1abbdbc8c2de,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-34ee6e4c-8e36-4634-9553-1401b42b79e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-c02d8e3e-ed2d-4f0b-b373-c3027d367b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-8ac72f79-d89f-400c-94e9-95be3cbfbd55,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-2816d368-4b64-4ef8-8a39-9e399b65dfc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 100
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999079486-172.17.0.6-1593381706903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-38387c64-f215-454a-88db-831b465ca963,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-51414804-ebd3-4083-8b57-9a5a210ba334,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-d4a4241d-d316-456e-b911-5f7ca4c7a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-04f6c0e0-c986-4b37-a95a-a558d01351b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-112a76ba-e200-410c-9f0b-72984fbdbc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-206457e6-9f37-4f3c-9c58-5932ed68f806,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-b784cf75-ef6f-4134-8efc-3b2239d3b677,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-f02738a5-431f-44f8-92a2-889c13d88633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999079486-172.17.0.6-1593381706903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-38387c64-f215-454a-88db-831b465ca963,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-51414804-ebd3-4083-8b57-9a5a210ba334,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-d4a4241d-d316-456e-b911-5f7ca4c7a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-04f6c0e0-c986-4b37-a95a-a558d01351b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-112a76ba-e200-410c-9f0b-72984fbdbc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-206457e6-9f37-4f3c-9c58-5932ed68f806,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-b784cf75-ef6f-4134-8efc-3b2239d3b677,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-f02738a5-431f-44f8-92a2-889c13d88633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5599
