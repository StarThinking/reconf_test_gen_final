reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-911236224-172.17.0.20-1593447771187:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-9302fecc-9fdf-462f-9f50-3905da2b05ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-50f9a0ff-a036-48f7-b6ad-7661b9b33260,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-7801a3bb-e3b5-46fa-adc5-a1588087b395,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-3cea6f99-6ec3-4a11-a437-6c9c780721c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3e2978fc-cef1-4c9b-897f-ffd2911e60e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-81e6591c-9e43-4bb2-8061-88e920e64502,DISK]]; indices=[0, 1, 2, 3, 4, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-911236224-172.17.0.20-1593447771187:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-9302fecc-9fdf-462f-9f50-3905da2b05ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-50f9a0ff-a036-48f7-b6ad-7661b9b33260,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-7801a3bb-e3b5-46fa-adc5-a1588087b395,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-3cea6f99-6ec3-4a11-a437-6c9c780721c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3e2978fc-cef1-4c9b-897f-ffd2911e60e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-81e6591c-9e43-4bb2-8061-88e920e64502,DISK]]; indices=[0, 1, 2, 3, 4, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1273229767-172.17.0.20-1593449001346:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-1b6d99a1-f6f0-4304-b21e-984275bb731e,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-1898a03d-d531-4e9a-8a5b-ef5056f47356,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-722f484c-63d5-423f-95f2-dab02c57657c,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-a14a0432-48bb-40fa-b3f8-d7a61c836d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9bce48a4-fb51-4ba7-95e6-430359d6fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7d12ac93-b141-4c70-b42f-06182bb94594,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-398cd115-b239-4d12-b837-e39e0944f589,DISK]]; indices=[1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1273229767-172.17.0.20-1593449001346:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-1b6d99a1-f6f0-4304-b21e-984275bb731e,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-1898a03d-d531-4e9a-8a5b-ef5056f47356,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-722f484c-63d5-423f-95f2-dab02c57657c,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-a14a0432-48bb-40fa-b3f8-d7a61c836d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9bce48a4-fb51-4ba7-95e6-430359d6fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7d12ac93-b141-4c70-b42f-06182bb94594,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-398cd115-b239-4d12-b837-e39e0944f589,DISK]]; indices=[1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1881002714-172.17.0.20-1593449173728:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-7504d413-e30c-4afa-9648-418300bb0fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-c75fc8de-b984-4fa3-a3fd-213b167be5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-c86ac27e-a01c-44cd-b789-973a89a469fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-d227e352-caab-4673-bb29-13900b53c816,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-645d6b78-3da4-4f88-a01e-d80c52dcfcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-19bba46f-97ae-47a4-b8e2-66daa02a3ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-0093722b-3e30-4d6c-9f33-ce186fc8dec8,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1881002714-172.17.0.20-1593449173728:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-7504d413-e30c-4afa-9648-418300bb0fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-c75fc8de-b984-4fa3-a3fd-213b167be5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-c86ac27e-a01c-44cd-b789-973a89a469fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-d227e352-caab-4673-bb29-13900b53c816,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-645d6b78-3da4-4f88-a01e-d80c52dcfcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-19bba46f-97ae-47a4-b8e2-66daa02a3ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-0093722b-3e30-4d6c-9f33-ce186fc8dec8,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-548236913-172.17.0.20-1593449224969:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-9af37616-d11c-4e82-81b4-77d09b2b4fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-03ce5221-194f-4c44-9c9f-ea0edd550bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-a9fd0eef-e270-4e18-95e4-5135c9af0737,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-829e6cdb-1328-42ce-aaaa-23a53b2f7f18,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-179ebc8a-5685-4959-8c7e-6c5edb1868ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-2f21cd36-9fae-4e62-9dbc-2ea804748d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-949cfa20-3447-4bd0-ab20-7781744a7a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f58c9e75-6747-45a7-8ce2-97b4b376f111,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-548236913-172.17.0.20-1593449224969:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-9af37616-d11c-4e82-81b4-77d09b2b4fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-03ce5221-194f-4c44-9c9f-ea0edd550bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-a9fd0eef-e270-4e18-95e4-5135c9af0737,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-829e6cdb-1328-42ce-aaaa-23a53b2f7f18,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-179ebc8a-5685-4959-8c7e-6c5edb1868ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-2f21cd36-9fae-4e62-9dbc-2ea804748d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-949cfa20-3447-4bd0-ab20-7781744a7a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f58c9e75-6747-45a7-8ce2-97b4b376f111,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-936907630-172.17.0.20-1593450212363:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43228,DS-7a050db4-97d8-4a29-a665-b01d3a7511ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2fd41670-271f-41f8-b95a-41a36b0a7ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-4f1b6747-0d89-4aac-ad85-da50e2d90128,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-16fcb795-5ab1-4274-88c2-78ec0117b00c,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-ee2753c5-92b9-4151-8699-e194915dd130,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-bde3fc68-a8e4-4ec9-85cc-ccb45470a6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-e93bb1aa-0e94-4c7c-806f-3d9990ed8c26,DISK]]; indices=[0, 1, 2, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-936907630-172.17.0.20-1593450212363:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43228,DS-7a050db4-97d8-4a29-a665-b01d3a7511ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2fd41670-271f-41f8-b95a-41a36b0a7ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-4f1b6747-0d89-4aac-ad85-da50e2d90128,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-16fcb795-5ab1-4274-88c2-78ec0117b00c,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-ee2753c5-92b9-4151-8699-e194915dd130,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-bde3fc68-a8e4-4ec9-85cc-ccb45470a6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-e93bb1aa-0e94-4c7c-806f-3d9990ed8c26,DISK]]; indices=[0, 1, 2, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-92830383-172.17.0.20-1593450881896:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35600,DS-9cc2adee-a121-46f5-87d1-466ed909f1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-1d674d34-c618-4b98-9b26-0449d138c993,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-799a9ab5-45b4-4416-bc57-7c23b588c54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-701e873b-d8e9-46db-a9ff-cdc9b80317ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-eeaf190a-5352-4e11-aa8c-09a119adfe12,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-f18e52dd-b518-4f60-8b48-3adbcf3eec04,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-d1a3913d-2875-43a8-953d-1c4641adb3a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-92830383-172.17.0.20-1593450881896:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35600,DS-9cc2adee-a121-46f5-87d1-466ed909f1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-1d674d34-c618-4b98-9b26-0449d138c993,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-799a9ab5-45b4-4416-bc57-7c23b588c54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-701e873b-d8e9-46db-a9ff-cdc9b80317ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-eeaf190a-5352-4e11-aa8c-09a119adfe12,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-f18e52dd-b518-4f60-8b48-3adbcf3eec04,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-d1a3913d-2875-43a8-953d-1c4641adb3a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1075486536-172.17.0.20-1593451725908:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-645a8baf-08fb-4fb1-ab80-c86ba3ef3469,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-1177f245-45da-4522-9e72-c04afa746ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-1b859948-7ce6-4c12-be82-c8efafae44e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-d0111016-a676-463d-9829-78855273adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-05a490cb-6654-4a24-9848-478e7dbe8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-6be9c0dc-35c8-4cfe-bf3e-bea8fc356639,DISK]]; indices=[1, 2, 3, 4, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1075486536-172.17.0.20-1593451725908:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-645a8baf-08fb-4fb1-ab80-c86ba3ef3469,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-1177f245-45da-4522-9e72-c04afa746ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-1b859948-7ce6-4c12-be82-c8efafae44e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-d0111016-a676-463d-9829-78855273adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-05a490cb-6654-4a24-9848-478e7dbe8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-6be9c0dc-35c8-4cfe-bf3e-bea8fc356639,DISK]]; indices=[1, 2, 3, 4, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-821270711-172.17.0.20-1593452421091:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-bebc9fd9-a14a-45fb-8abf-bb976f8b298b,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-a9bd81e3-a42c-4db6-b69a-4efef94dec80,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-46a23163-541d-4fde-90e8-688b38c0fda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-1199ca62-21c6-4f22-b187-31ed1c7ce74c,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-69f22771-72f2-486b-93b1-3007b996e319,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-80481a7b-027f-4ba7-bd7a-595e7e9a0b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-a290c103-180f-467d-b96c-ac5078249313,DISK]]; indices=[0, 1, 2, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-821270711-172.17.0.20-1593452421091:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-bebc9fd9-a14a-45fb-8abf-bb976f8b298b,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-a9bd81e3-a42c-4db6-b69a-4efef94dec80,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-46a23163-541d-4fde-90e8-688b38c0fda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-1199ca62-21c6-4f22-b187-31ed1c7ce74c,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-69f22771-72f2-486b-93b1-3007b996e319,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-80481a7b-027f-4ba7-bd7a-595e7e9a0b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-a290c103-180f-467d-b96c-ac5078249313,DISK]]; indices=[0, 1, 2, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-319379354-172.17.0.20-1593452937650:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-2ab93584-7726-49f8-83b9-6e9cdef54eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-72dd85f6-25e8-4e87-9d85-727567d5ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-b21352a2-f804-4190-aba5-a7ca53199b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-95f2dc0b-d65a-456f-8093-1096daeb9132,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-f14d477b-0483-4dd3-aa96-72df183a310b,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-768dd8a0-ea90-4c73-813e-9bcda4c7a0ef,DISK]]; indices=[0, 1, 2, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-319379354-172.17.0.20-1593452937650:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-2ab93584-7726-49f8-83b9-6e9cdef54eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-72dd85f6-25e8-4e87-9d85-727567d5ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-b21352a2-f804-4190-aba5-a7ca53199b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-95f2dc0b-d65a-456f-8093-1096daeb9132,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-f14d477b-0483-4dd3-aa96-72df183a310b,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-768dd8a0-ea90-4c73-813e-9bcda4c7a0ef,DISK]]; indices=[0, 1, 2, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-422606417-172.17.0.20-1593453111973:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-0c3f3eaa-81d2-4d30-857d-197596c4380d,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-16fd8dbd-584e-4575-8818-2fd1de94fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-6f970514-3217-4ac3-8af5-f08cbb56c322,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-483a7d22-a7a7-4176-b92c-e33198ec6779,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-ee868d0c-6e62-480c-8521-e84a9ddc16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-07100e71-d00a-4b3b-b9d7-1b46183a6d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-58140fc0-2f83-47e5-890c-020d8f31954e,DISK]]; indices=[0, 1, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-422606417-172.17.0.20-1593453111973:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-0c3f3eaa-81d2-4d30-857d-197596c4380d,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-16fd8dbd-584e-4575-8818-2fd1de94fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-6f970514-3217-4ac3-8af5-f08cbb56c322,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-483a7d22-a7a7-4176-b92c-e33198ec6779,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-ee868d0c-6e62-480c-8521-e84a9ddc16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-07100e71-d00a-4b3b-b9d7-1b46183a6d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-58140fc0-2f83-47e5-890c-020d8f31954e,DISK]]; indices=[0, 1, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1463066773-172.17.0.20-1593453277367:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:38361,DS-3be96f10-a3cc-472e-9c7e-c168b1ebd356,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-e3ee7335-4875-4d61-a5ac-e80d2120284a,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-d9972087-95c4-4353-8e90-7a1d040aa7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-c3f992ad-0d28-4c75-8917-ad53dda85b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-ca654c28-5aa5-4e21-afd7-8ce7ab9c8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-e33357f9-faca-4925-83e3-8818e07a520f,DISK]]; indices=[1, 2, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1463066773-172.17.0.20-1593453277367:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:38361,DS-3be96f10-a3cc-472e-9c7e-c168b1ebd356,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-e3ee7335-4875-4d61-a5ac-e80d2120284a,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-d9972087-95c4-4353-8e90-7a1d040aa7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-c3f992ad-0d28-4c75-8917-ad53dda85b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-ca654c28-5aa5-4e21-afd7-8ce7ab9c8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-e33357f9-faca-4925-83e3-8818e07a520f,DISK]]; indices=[1, 2, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1022216772-172.17.0.20-1593453630961:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-40b0449e-4eb9-46a1-9b2f-13779b9add45,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-329c83be-1f03-4581-b08b-23f1c8b7b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-d0b9c6ce-66d7-4502-bd13-a457a73c1d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-2bf74ac4-5884-4960-ac05-e27d10412d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-f4604d83-2ccf-43fd-9b42-2082f53e3703,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-182a5fbc-4a7a-4a49-9da5-b5ddd811be49,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-8a0cbeee-1a93-4406-9dd7-d261aa7d4f5d,DISK]]; indices=[0, 2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1022216772-172.17.0.20-1593453630961:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-40b0449e-4eb9-46a1-9b2f-13779b9add45,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-329c83be-1f03-4581-b08b-23f1c8b7b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-d0b9c6ce-66d7-4502-bd13-a457a73c1d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-2bf74ac4-5884-4960-ac05-e27d10412d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-f4604d83-2ccf-43fd-9b42-2082f53e3703,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-182a5fbc-4a7a-4a49-9da5-b5ddd811be49,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-8a0cbeee-1a93-4406-9dd7-d261aa7d4f5d,DISK]]; indices=[0, 2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-735911534-172.17.0.20-1593453985340:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-c2fb0fd1-f507-4d9b-ab9d-065299a9ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-5cf7fb79-214f-4ec5-9bf1-3cc5c1e40380,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-b67724fd-1062-4fd0-9f95-10b6180c8466,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-de40f5fe-d112-49b1-adf9-72c2d2bb9d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-c12de288-90f6-42f3-83cf-59987328eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-195162c2-cdcf-4851-a308-8df8b52d4d99,DISK]]; indices=[2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-735911534-172.17.0.20-1593453985340:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-c2fb0fd1-f507-4d9b-ab9d-065299a9ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-5cf7fb79-214f-4ec5-9bf1-3cc5c1e40380,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-b67724fd-1062-4fd0-9f95-10b6180c8466,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-de40f5fe-d112-49b1-adf9-72c2d2bb9d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-c12de288-90f6-42f3-83cf-59987328eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-195162c2-cdcf-4851-a308-8df8b52d4d99,DISK]]; indices=[2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1606434982-172.17.0.20-1593454154097:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-4135db0d-eef3-4677-ba0c-37bf2448a273,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-bc421725-6d72-43be-8f28-252fea22a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-3fd61d50-f58d-4cef-b714-29e1d9f81ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-4989c2b2-4260-4d22-aa4f-da48758b60ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-777c245b-dc0c-4c53-97bd-4d0596208a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-848b52c6-9ebb-4232-b9e6-caca00a7e001,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-ffd069a7-6f63-42ff-bd60-3fb73467841b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1606434982-172.17.0.20-1593454154097:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-4135db0d-eef3-4677-ba0c-37bf2448a273,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-bc421725-6d72-43be-8f28-252fea22a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-3fd61d50-f58d-4cef-b714-29e1d9f81ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-4989c2b2-4260-4d22-aa4f-da48758b60ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-777c245b-dc0c-4c53-97bd-4d0596208a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-848b52c6-9ebb-4232-b9e6-caca00a7e001,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-ffd069a7-6f63-42ff-bd60-3fb73467841b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1953419523-172.17.0.20-1593454862329:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-b16b3994-03e7-4f41-93df-ac586c6cdb71,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-67c723bb-6ddd-4e89-ad5f-b138c0f58414,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-721a12ee-9df6-4b87-ad6d-1b71e057be9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-6c6f31a1-b0b7-4b43-b4ba-e4856dfb5061,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-5a426f09-3adc-42e1-9d12-2defe4955635,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-44a43322-7bc4-44c0-bff9-a9f0548a3c61,DISK]]; indices=[0, 1, 2, 4, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1953419523-172.17.0.20-1593454862329:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-b16b3994-03e7-4f41-93df-ac586c6cdb71,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-67c723bb-6ddd-4e89-ad5f-b138c0f58414,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-721a12ee-9df6-4b87-ad6d-1b71e057be9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-6c6f31a1-b0b7-4b43-b4ba-e4856dfb5061,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-5a426f09-3adc-42e1-9d12-2defe4955635,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-44a43322-7bc4-44c0-bff9-a9f0548a3c61,DISK]]; indices=[0, 1, 2, 4, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 1 out of 50
result: might be true error
Total execution time in seconds : 8629
