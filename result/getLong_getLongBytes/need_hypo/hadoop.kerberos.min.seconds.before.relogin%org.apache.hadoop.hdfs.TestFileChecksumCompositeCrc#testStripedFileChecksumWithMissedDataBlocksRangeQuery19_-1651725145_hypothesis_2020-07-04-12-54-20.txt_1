reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770253401-172.17.0.6-1593867423196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-6b716c53-6170-4bb6-b2ca-8b9f4c8b41aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-b06fddf6-7053-46a0-a0d8-715c889c2a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-7960a179-47b9-4ee5-ab04-c5baf2ed082f,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-5f237250-3c58-437a-855c-b475f92ca3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-44ce3f59-d45b-43b8-8b65-12cac2d6defa,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-80416bfa-1bc0-4078-8618-c00befbb1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-95f7691e-68ee-4c89-847d-119fb3c3006c,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-6ed4d047-8b57-4ac2-aa38-6a615d1af795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770253401-172.17.0.6-1593867423196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-6b716c53-6170-4bb6-b2ca-8b9f4c8b41aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-b06fddf6-7053-46a0-a0d8-715c889c2a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-7960a179-47b9-4ee5-ab04-c5baf2ed082f,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-5f237250-3c58-437a-855c-b475f92ca3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-44ce3f59-d45b-43b8-8b65-12cac2d6defa,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-80416bfa-1bc0-4078-8618-c00befbb1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-95f7691e-68ee-4c89-847d-119fb3c3006c,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-6ed4d047-8b57-4ac2-aa38-6a615d1af795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336612821-172.17.0.6-1593867575638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35476,DS-2bdc1369-9b54-4f45-818c-bb4fb73c0ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-3eabf167-77c4-462a-a623-5ecf07f41564,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-6caae26b-a1f6-47d9-a51d-cfca9dea1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-831a3a76-a6f5-4cc6-a5ab-0140983fd330,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-591cf63c-9933-4b26-9b12-827ff63f82c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-635ac3d3-abd5-4db9-b0f5-4ef65895b11c,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-70e97a30-648b-4d62-a6f3-f551cb5397cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-a86e25c1-ab2b-4827-9a95-3708d18c4b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336612821-172.17.0.6-1593867575638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35476,DS-2bdc1369-9b54-4f45-818c-bb4fb73c0ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-3eabf167-77c4-462a-a623-5ecf07f41564,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-6caae26b-a1f6-47d9-a51d-cfca9dea1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-831a3a76-a6f5-4cc6-a5ab-0140983fd330,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-591cf63c-9933-4b26-9b12-827ff63f82c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-635ac3d3-abd5-4db9-b0f5-4ef65895b11c,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-70e97a30-648b-4d62-a6f3-f551cb5397cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-a86e25c1-ab2b-4827-9a95-3708d18c4b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953034187-172.17.0.6-1593867618423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-453dbac2-2c08-4d0a-8107-f43493170e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3d058ace-9ed2-4da1-b606-83e68a12a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-c3495306-2275-4df2-87d4-8027f8e115b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-c0595911-f484-4820-b9f5-d00a503099cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-417e17cd-594b-44ca-9bf2-cb984575953a,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-2750f1dc-8613-4ffe-a587-6cfa77e21b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-88d3dc68-97d6-4fae-af44-02958f84e78e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a34c059b-72e5-42f4-a30d-461127480877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953034187-172.17.0.6-1593867618423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-453dbac2-2c08-4d0a-8107-f43493170e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3d058ace-9ed2-4da1-b606-83e68a12a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-c3495306-2275-4df2-87d4-8027f8e115b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-c0595911-f484-4820-b9f5-d00a503099cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-417e17cd-594b-44ca-9bf2-cb984575953a,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-2750f1dc-8613-4ffe-a587-6cfa77e21b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-88d3dc68-97d6-4fae-af44-02958f84e78e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a34c059b-72e5-42f4-a30d-461127480877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168181611-172.17.0.6-1593867831993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-da75779c-5486-45c7-8112-594a32532cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-356783ec-1642-481d-91eb-16b0a454bbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-217ba814-7c74-4810-9c73-1c8703251a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-f4f8724a-98aa-4f85-a2aa-45527faf5f38,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-60ce5571-80c7-463d-816b-e5a1b4bcddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-aff5af1f-95e4-49f7-8f78-1b27a4bb627f,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-5134dbed-de94-4a4c-b620-5bd728f423b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-1cde2beb-be27-429e-9375-3f76fa52609c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168181611-172.17.0.6-1593867831993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-da75779c-5486-45c7-8112-594a32532cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-356783ec-1642-481d-91eb-16b0a454bbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-217ba814-7c74-4810-9c73-1c8703251a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-f4f8724a-98aa-4f85-a2aa-45527faf5f38,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-60ce5571-80c7-463d-816b-e5a1b4bcddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-aff5af1f-95e4-49f7-8f78-1b27a4bb627f,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-5134dbed-de94-4a4c-b620-5bd728f423b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-1cde2beb-be27-429e-9375-3f76fa52609c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501875207-172.17.0.6-1593867862156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-76aebf11-f4f7-4fb1-9f3d-e718129ebed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-7340992f-4666-4d2a-9223-15cdfe93988a,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-15d7ee9f-4b32-43b5-bd3a-429561899ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-3bb31bae-a67a-4433-b595-89c543201e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-4a2f206a-37e8-4b56-92b6-18314f97c731,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-a37051c1-3848-4272-8ec8-e59d8616f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-c8969c4b-bfd2-413c-a92c-655fcc4cc2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-451a2ab0-8917-4391-b356-42e1c9dd0915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501875207-172.17.0.6-1593867862156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-76aebf11-f4f7-4fb1-9f3d-e718129ebed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-7340992f-4666-4d2a-9223-15cdfe93988a,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-15d7ee9f-4b32-43b5-bd3a-429561899ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-3bb31bae-a67a-4433-b595-89c543201e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-4a2f206a-37e8-4b56-92b6-18314f97c731,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-a37051c1-3848-4272-8ec8-e59d8616f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-c8969c4b-bfd2-413c-a92c-655fcc4cc2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-451a2ab0-8917-4391-b356-42e1c9dd0915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369303202-172.17.0.6-1593868042824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-73976c29-d53c-4e35-bea4-396037b995b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-efbac115-4232-471e-a778-5e3ec61b28d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-2b633ac3-6c1b-478b-aba2-aaafdb6d939d,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-b0701ba9-b201-4263-bfd1-6489a0eb2d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-904369af-d6ab-439f-9fd7-74b67ebc70b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-891b6153-ae0b-42e6-9c29-22392a6aa09e,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-0c2fe8ee-0a4c-458e-9bed-7a1fc643dbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-b4c671db-652d-4309-bd7d-a3b4289b25f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369303202-172.17.0.6-1593868042824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-73976c29-d53c-4e35-bea4-396037b995b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-efbac115-4232-471e-a778-5e3ec61b28d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-2b633ac3-6c1b-478b-aba2-aaafdb6d939d,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-b0701ba9-b201-4263-bfd1-6489a0eb2d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-904369af-d6ab-439f-9fd7-74b67ebc70b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-891b6153-ae0b-42e6-9c29-22392a6aa09e,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-0c2fe8ee-0a4c-458e-9bed-7a1fc643dbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-b4c671db-652d-4309-bd7d-a3b4289b25f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795777851-172.17.0.6-1593868166244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43905,DS-b91f19b7-8897-4f30-9b79-76286c88657f,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-f8ce7e04-5ab6-4b86-89ae-b89bc2839654,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-8f052cef-5bef-4d37-bea3-8e131434444d,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-e2821c11-c31e-45f5-836b-168938001a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-e5f2c5ec-4613-4427-b19d-d2024f25ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-c4aa93a9-1274-43f7-bfaa-7b7181a34624,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-ffec47b9-2079-49fa-8093-5eaad934ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-e8948267-9477-494c-b8f9-9f1c300b42cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795777851-172.17.0.6-1593868166244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43905,DS-b91f19b7-8897-4f30-9b79-76286c88657f,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-f8ce7e04-5ab6-4b86-89ae-b89bc2839654,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-8f052cef-5bef-4d37-bea3-8e131434444d,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-e2821c11-c31e-45f5-836b-168938001a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-e5f2c5ec-4613-4427-b19d-d2024f25ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-c4aa93a9-1274-43f7-bfaa-7b7181a34624,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-ffec47b9-2079-49fa-8093-5eaad934ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-e8948267-9477-494c-b8f9-9f1c300b42cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341305648-172.17.0.6-1593868350167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-ba65a7e1-8493-4641-bf24-418125ea96c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-bbd4cb3f-dbce-4ff8-be18-74e23d883589,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-4e63ece2-e856-4368-a05b-d9c13c5b8141,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-91b5f905-0894-47c8-b380-828f2b864e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-2ef66b6b-c80c-4b67-9ca3-2661c4d46eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-9a4eb71b-8a14-4989-92db-089048176952,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-72e30a37-6377-419a-9962-d39ad018f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-73d8a350-9fbd-498c-aaa9-928d502331ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341305648-172.17.0.6-1593868350167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-ba65a7e1-8493-4641-bf24-418125ea96c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-bbd4cb3f-dbce-4ff8-be18-74e23d883589,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-4e63ece2-e856-4368-a05b-d9c13c5b8141,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-91b5f905-0894-47c8-b380-828f2b864e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-2ef66b6b-c80c-4b67-9ca3-2661c4d46eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-9a4eb71b-8a14-4989-92db-089048176952,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-72e30a37-6377-419a-9962-d39ad018f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-73d8a350-9fbd-498c-aaa9-928d502331ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471676560-172.17.0.6-1593868888237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38106,DS-0896d59a-2fb8-480d-8dea-368923c27bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-8c1c718c-edf5-421d-9162-748a409964e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-41632755-c9b8-4af3-b61b-f9fd513e8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-d4c44de3-a1ed-4d20-aa61-5ae1ccd20a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-7b9c2183-1444-4d43-a026-f4e254ca7b69,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-dd2cb35e-99c3-4cc5-927d-dff4094ade26,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-90f27758-8d6b-4bfe-b7d2-8bb7cd444e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-a31ff57b-f161-4c21-a175-6f0e0dac2b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471676560-172.17.0.6-1593868888237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38106,DS-0896d59a-2fb8-480d-8dea-368923c27bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-8c1c718c-edf5-421d-9162-748a409964e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-41632755-c9b8-4af3-b61b-f9fd513e8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-d4c44de3-a1ed-4d20-aa61-5ae1ccd20a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-7b9c2183-1444-4d43-a026-f4e254ca7b69,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-dd2cb35e-99c3-4cc5-927d-dff4094ade26,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-90f27758-8d6b-4bfe-b7d2-8bb7cd444e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-a31ff57b-f161-4c21-a175-6f0e0dac2b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950265774-172.17.0.6-1593869222844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-0fa9b378-3eb7-4f45-9da0-8dc71a0b16f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-60bfe5ef-7cf5-4b28-97eb-81a089eb9dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-d46f5f30-4138-4d40-ba65-389312462012,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-d496f048-f2a9-4ee0-999c-66a33a8e55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-32bfd956-2e17-417b-85a4-cfaa9f52027e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-3d7d8326-22c3-4bd1-bf1c-5b5519ee1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-2df52fa3-9443-44e8-b435-8f65fd140737,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-923af575-ed15-4545-8eab-e62137316770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950265774-172.17.0.6-1593869222844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-0fa9b378-3eb7-4f45-9da0-8dc71a0b16f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-60bfe5ef-7cf5-4b28-97eb-81a089eb9dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-d46f5f30-4138-4d40-ba65-389312462012,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-d496f048-f2a9-4ee0-999c-66a33a8e55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-32bfd956-2e17-417b-85a4-cfaa9f52027e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-3d7d8326-22c3-4bd1-bf1c-5b5519ee1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-2df52fa3-9443-44e8-b435-8f65fd140737,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-923af575-ed15-4545-8eab-e62137316770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209585619-172.17.0.6-1593869570329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-6a465e52-3252-49b4-aab9-67ae4b975c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-dc4c742e-9d38-4957-8316-b109b490dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-ddacc980-08d4-4029-9526-f210596cdab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-b5bdbbaa-2063-4ef0-87f9-4b4fa38b29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-7b33e68e-2e41-45cd-aa70-d489e45f6cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-da22853d-938a-42c1-8b03-6ad5d8be50ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-9fe2e8a6-7e40-431b-b8c3-da9cf40e61c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-e865719a-ff09-4141-89b4-171b1fe760e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209585619-172.17.0.6-1593869570329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-6a465e52-3252-49b4-aab9-67ae4b975c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-dc4c742e-9d38-4957-8316-b109b490dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-ddacc980-08d4-4029-9526-f210596cdab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-b5bdbbaa-2063-4ef0-87f9-4b4fa38b29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-7b33e68e-2e41-45cd-aa70-d489e45f6cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-da22853d-938a-42c1-8b03-6ad5d8be50ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-9fe2e8a6-7e40-431b-b8c3-da9cf40e61c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-e865719a-ff09-4141-89b4-171b1fe760e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202655730-172.17.0.6-1593869695488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-d6e09d70-d189-4432-a11a-a6bec362c1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-fc0b67fb-7c0f-487e-b5dd-5536a4431393,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-6d680d51-6321-4c71-b8d8-e8a94bb3228f,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-4e9b4bf7-8232-46a5-947b-2c7fee1f8766,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-af7763b1-3a3f-4cfa-b9bb-b8d965527f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-77e69b82-c2cd-4cf4-bd7c-02f30cfe5c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-8cb5a7ab-b151-4d7c-a5f0-328b46b95275,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-4e67573b-71d2-4195-a5e6-c01849444561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202655730-172.17.0.6-1593869695488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-d6e09d70-d189-4432-a11a-a6bec362c1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-fc0b67fb-7c0f-487e-b5dd-5536a4431393,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-6d680d51-6321-4c71-b8d8-e8a94bb3228f,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-4e9b4bf7-8232-46a5-947b-2c7fee1f8766,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-af7763b1-3a3f-4cfa-b9bb-b8d965527f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-77e69b82-c2cd-4cf4-bd7c-02f30cfe5c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-8cb5a7ab-b151-4d7c-a5f0-328b46b95275,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-4e67573b-71d2-4195-a5e6-c01849444561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867611687-172.17.0.6-1593869809985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37790,DS-e345e83b-45a1-42bd-9295-39e18a5e5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-35152cf8-3dbc-4df4-8875-350933368107,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-8c491430-3317-4bf6-8650-e3c885b54e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-7f65ff66-a2eb-459b-a970-b866fec05464,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-c04026a8-b528-48fd-9c04-dd1d3dc9eb16,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-11723137-6d77-49a5-9e90-221f6d19a004,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a81c3a40-7d21-4d88-99de-b470fbeb11c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-3fc4902a-9919-4dc5-95e6-70d87dde6048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867611687-172.17.0.6-1593869809985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37790,DS-e345e83b-45a1-42bd-9295-39e18a5e5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-35152cf8-3dbc-4df4-8875-350933368107,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-8c491430-3317-4bf6-8650-e3c885b54e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-7f65ff66-a2eb-459b-a970-b866fec05464,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-c04026a8-b528-48fd-9c04-dd1d3dc9eb16,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-11723137-6d77-49a5-9e90-221f6d19a004,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a81c3a40-7d21-4d88-99de-b470fbeb11c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-3fc4902a-9919-4dc5-95e6-70d87dde6048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027247702-172.17.0.6-1593870028326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-963582a0-0c79-465b-b406-bcda22c00823,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-589fb981-91c7-446f-9895-1ecdaa0c029c,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-2e204bb4-a1d8-44a6-8215-03229cf989d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-7ee64119-9821-4c78-b005-cab0cae2e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-e08c79dc-6715-4a86-873e-38b267e5c0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-fd5f8545-6a94-4e91-a4ea-50b7bab6494b,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-7088a880-53ff-41b6-9dbe-b27a089e98bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-a2a97fbf-85a7-48e6-9678-0b444f949c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027247702-172.17.0.6-1593870028326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-963582a0-0c79-465b-b406-bcda22c00823,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-589fb981-91c7-446f-9895-1ecdaa0c029c,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-2e204bb4-a1d8-44a6-8215-03229cf989d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-7ee64119-9821-4c78-b005-cab0cae2e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-e08c79dc-6715-4a86-873e-38b267e5c0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-fd5f8545-6a94-4e91-a4ea-50b7bab6494b,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-7088a880-53ff-41b6-9dbe-b27a089e98bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-a2a97fbf-85a7-48e6-9678-0b444f949c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808304686-172.17.0.6-1593870451491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-d276369c-eb17-4348-a49d-8db34087df97,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-3b7893dc-4c81-4c44-81e5-d11f7a16421c,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c8add47d-8f48-47ee-8fdb-e4cb9eae32a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-659595ff-ecb1-43f6-92cd-5f7c66af6203,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-e7caa5bf-44be-43a9-8763-a6cdca1bbe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-16a4223c-e731-4523-ab92-09d7b50cf674,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-ea1cee13-22ca-4792-8fa0-e6b8be6673b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-7e00380e-2e82-4add-84ad-403f8fea02bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808304686-172.17.0.6-1593870451491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-d276369c-eb17-4348-a49d-8db34087df97,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-3b7893dc-4c81-4c44-81e5-d11f7a16421c,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c8add47d-8f48-47ee-8fdb-e4cb9eae32a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-659595ff-ecb1-43f6-92cd-5f7c66af6203,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-e7caa5bf-44be-43a9-8763-a6cdca1bbe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-16a4223c-e731-4523-ab92-09d7b50cf674,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-ea1cee13-22ca-4792-8fa0-e6b8be6673b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-7e00380e-2e82-4add-84ad-403f8fea02bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988759872-172.17.0.6-1593870571864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-6df2ef94-4386-4642-8621-69b42d5316eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-974acb08-982b-4137-a700-7c5a71bdd6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-b9861228-8986-45fa-974d-d984cae14a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-d6f8b484-723c-4402-9537-93257c3098c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-24ad11d8-6577-4159-a1dc-9b7d9ba69747,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-13f7aba0-b7d4-4279-9a61-66a1f29bfacb,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-16aff02f-341b-43c9-88b8-737e4846ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-7fde2197-d8ad-4d23-9f6d-20dbcc6330ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988759872-172.17.0.6-1593870571864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-6df2ef94-4386-4642-8621-69b42d5316eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-974acb08-982b-4137-a700-7c5a71bdd6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-b9861228-8986-45fa-974d-d984cae14a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-d6f8b484-723c-4402-9537-93257c3098c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-24ad11d8-6577-4159-a1dc-9b7d9ba69747,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-13f7aba0-b7d4-4279-9a61-66a1f29bfacb,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-16aff02f-341b-43c9-88b8-737e4846ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-7fde2197-d8ad-4d23-9f6d-20dbcc6330ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473282195-172.17.0.6-1593871146259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33820,DS-81a56612-c491-4b8b-b461-4729485eb80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-02a31f5a-fa56-4df4-b553-545ce5ec5a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-a4bfc2b8-bfc4-4d38-b2af-4a391b6e04ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-a0dedc57-7634-4d32-863d-49b28febb587,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-fb18217c-bcbf-4346-a9b4-6a1fefbb60fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-42ab68ba-3f1f-4e08-86d6-e5bfd72ed6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-6b8b9d62-4683-44fe-a32a-f03633c19c32,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-581fa510-bcb6-4f3a-a3ae-1e16cbac445a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473282195-172.17.0.6-1593871146259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33820,DS-81a56612-c491-4b8b-b461-4729485eb80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-02a31f5a-fa56-4df4-b553-545ce5ec5a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-a4bfc2b8-bfc4-4d38-b2af-4a391b6e04ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-a0dedc57-7634-4d32-863d-49b28febb587,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-fb18217c-bcbf-4346-a9b4-6a1fefbb60fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-42ab68ba-3f1f-4e08-86d6-e5bfd72ed6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-6b8b9d62-4683-44fe-a32a-f03633c19c32,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-581fa510-bcb6-4f3a-a3ae-1e16cbac445a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983920974-172.17.0.6-1593872394371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-7c17bc23-c034-42dc-9029-9d62f29a116f,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-58acee5d-e057-4b6c-8f89-a38db2c3674f,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-a9f39560-fb4b-498e-aa41-22f3d53c5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-c097e89c-2fe6-4304-9959-9e656a360958,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-8d9444ec-3436-4589-9e7b-26b8f085fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-fa36e1ad-5eed-46cc-9408-204ed5893a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-9c10cf58-72d4-40f7-a3ea-de0ae1806d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-75bb3e85-a6b2-4c95-9072-a7ad4749783f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983920974-172.17.0.6-1593872394371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-7c17bc23-c034-42dc-9029-9d62f29a116f,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-58acee5d-e057-4b6c-8f89-a38db2c3674f,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-a9f39560-fb4b-498e-aa41-22f3d53c5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-c097e89c-2fe6-4304-9959-9e656a360958,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-8d9444ec-3436-4589-9e7b-26b8f085fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-fa36e1ad-5eed-46cc-9408-204ed5893a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-9c10cf58-72d4-40f7-a3ea-de0ae1806d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-75bb3e85-a6b2-4c95-9072-a7ad4749783f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535986324-172.17.0.6-1593872567891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43290,DS-023b2907-253f-4221-80ac-e09a027838ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-f767b608-efa0-454d-bb45-91763ce5da84,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-72591560-5417-45a8-971d-10e70a1f3c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-28b1df6b-662c-433e-b1b1-ea3f15c2ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-c1d1f6f3-ea02-4368-a21a-ec0617033fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-400f4168-27fb-4778-83fd-9cbb66bee5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-5e191410-79fb-4c83-9685-437196c277c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-cc73dbc9-e816-44bc-8b17-65b370d68cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535986324-172.17.0.6-1593872567891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43290,DS-023b2907-253f-4221-80ac-e09a027838ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-f767b608-efa0-454d-bb45-91763ce5da84,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-72591560-5417-45a8-971d-10e70a1f3c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-28b1df6b-662c-433e-b1b1-ea3f15c2ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-c1d1f6f3-ea02-4368-a21a-ec0617033fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-400f4168-27fb-4778-83fd-9cbb66bee5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-5e191410-79fb-4c83-9685-437196c277c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-cc73dbc9-e816-44bc-8b17-65b370d68cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334274232-172.17.0.6-1593872608084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-64fe0e50-85c4-4200-a013-67cb1dd11590,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-cc51d65c-adf6-4038-b5de-d1da43225393,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-1ecf0a65-9661-4bfd-9158-cd6de2f9ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-848f7f6e-0f83-4815-8c65-d49ad548cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-f903e2f2-40a0-4c37-a6c2-edc89ecffdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-850b45cf-a212-4cde-b7cd-aac5b3ca96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-7e492a35-3f4e-40ff-88de-bed8e317fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-b1b9a6ec-0868-4aa7-8362-90d3d0affe46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334274232-172.17.0.6-1593872608084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-64fe0e50-85c4-4200-a013-67cb1dd11590,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-cc51d65c-adf6-4038-b5de-d1da43225393,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-1ecf0a65-9661-4bfd-9158-cd6de2f9ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-848f7f6e-0f83-4815-8c65-d49ad548cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-f903e2f2-40a0-4c37-a6c2-edc89ecffdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-850b45cf-a212-4cde-b7cd-aac5b3ca96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-7e492a35-3f4e-40ff-88de-bed8e317fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-b1b9a6ec-0868-4aa7-8362-90d3d0affe46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5528
