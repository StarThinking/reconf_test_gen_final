reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292595846-172.17.0.4-1593651547045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-92fbd998-5b01-452c-90e9-3109705a2a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-4b3305cd-fb09-4b21-b511-eb149a45e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-1721d103-e452-46e0-9e7f-b1cda362a5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-3bc59954-93e7-4e00-903e-0d964264b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-809f2ceb-f763-4748-be47-b8034653ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-2db1af7d-28e3-4ba5-adc0-961db887b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-8b3e9e60-806d-4847-b458-5b97b466d991,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-44ec260c-8bae-4bf4-962d-1548f03a39e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292595846-172.17.0.4-1593651547045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-92fbd998-5b01-452c-90e9-3109705a2a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-4b3305cd-fb09-4b21-b511-eb149a45e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-1721d103-e452-46e0-9e7f-b1cda362a5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-3bc59954-93e7-4e00-903e-0d964264b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-809f2ceb-f763-4748-be47-b8034653ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-2db1af7d-28e3-4ba5-adc0-961db887b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-8b3e9e60-806d-4847-b458-5b97b466d991,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-44ec260c-8bae-4bf4-962d-1548f03a39e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701820719-172.17.0.4-1593651895063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-b8d7e506-92fc-46b0-8476-5f8efb5c2f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-a0b695fc-fc68-4cb8-9b88-77b6d2e21a42,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-87edd4cd-a947-4410-97b3-82849087eda0,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-19a4762c-8489-4317-a1dc-11a66cce1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-8f9f38e2-e0f9-4060-9be6-242b81977e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-7b9560a0-88d7-4d07-9cbe-499d1422396a,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-f02a371a-094f-4f38-8a9d-db0b2978d59c,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-850c7c21-ef10-448a-8594-66d1e35c754c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701820719-172.17.0.4-1593651895063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-b8d7e506-92fc-46b0-8476-5f8efb5c2f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-a0b695fc-fc68-4cb8-9b88-77b6d2e21a42,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-87edd4cd-a947-4410-97b3-82849087eda0,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-19a4762c-8489-4317-a1dc-11a66cce1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-8f9f38e2-e0f9-4060-9be6-242b81977e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-7b9560a0-88d7-4d07-9cbe-499d1422396a,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-f02a371a-094f-4f38-8a9d-db0b2978d59c,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-850c7c21-ef10-448a-8594-66d1e35c754c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959413463-172.17.0.4-1593654102383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-54dccad8-9d05-4d68-9de1-55d39acae6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-c98198db-69b9-4426-b29d-64376ba731ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-5077bb9b-6191-4808-ad57-0aa598c3c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-9c74fb92-2557-459f-a550-2eebcc01e4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-a0246b70-04da-4f24-90e5-88740d76e295,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ae981584-4237-43a6-884b-929806ba6f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ddb9028a-bfce-42c3-b474-0368e830bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-4a37f3a6-1339-45b7-ab79-61832c731c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959413463-172.17.0.4-1593654102383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-54dccad8-9d05-4d68-9de1-55d39acae6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-c98198db-69b9-4426-b29d-64376ba731ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-5077bb9b-6191-4808-ad57-0aa598c3c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-9c74fb92-2557-459f-a550-2eebcc01e4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-a0246b70-04da-4f24-90e5-88740d76e295,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ae981584-4237-43a6-884b-929806ba6f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ddb9028a-bfce-42c3-b474-0368e830bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-4a37f3a6-1339-45b7-ab79-61832c731c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021549522-172.17.0.4-1593654260261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-a19b1832-6e07-4508-8c8d-268efbff97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-cc9ec9f3-8741-448c-8aa5-32a351bb2e27,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-6cc5eaf5-c87f-4c9d-a324-1073773a3cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-38290efe-bdfb-4d1c-9e48-137bb3616369,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-de2ad728-b43f-4ce9-9361-e7caea017449,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-e20f5d8f-f10a-4a54-b84b-21dddea71f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-deb25e0a-024e-4c8c-a6d7-97b44b440338,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-a5787e8e-e3ef-4a18-a61a-fcb7ce87d40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021549522-172.17.0.4-1593654260261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-a19b1832-6e07-4508-8c8d-268efbff97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-cc9ec9f3-8741-448c-8aa5-32a351bb2e27,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-6cc5eaf5-c87f-4c9d-a324-1073773a3cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-38290efe-bdfb-4d1c-9e48-137bb3616369,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-de2ad728-b43f-4ce9-9361-e7caea017449,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-e20f5d8f-f10a-4a54-b84b-21dddea71f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-deb25e0a-024e-4c8c-a6d7-97b44b440338,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-a5787e8e-e3ef-4a18-a61a-fcb7ce87d40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128380766-172.17.0.4-1593654634271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-762808b0-f6b3-4824-a465-8380ddd5a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-0a99a31d-c735-46d9-8767-67eabdf13cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-c509d67b-28c3-415e-be61-eacaa11b5015,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-dc59de86-ee78-412a-828e-7c232cbc3ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-7052c0ed-27cf-4d1a-9dbc-65992bfa0770,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e52d1185-ee77-4bf3-88bd-7b1eb395f708,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-3cb05f9b-5a81-4028-afa8-36ec7b4842d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-72e308a7-022f-4328-beed-03e72e42e893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128380766-172.17.0.4-1593654634271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-762808b0-f6b3-4824-a465-8380ddd5a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-0a99a31d-c735-46d9-8767-67eabdf13cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-c509d67b-28c3-415e-be61-eacaa11b5015,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-dc59de86-ee78-412a-828e-7c232cbc3ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-7052c0ed-27cf-4d1a-9dbc-65992bfa0770,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e52d1185-ee77-4bf3-88bd-7b1eb395f708,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-3cb05f9b-5a81-4028-afa8-36ec7b4842d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-72e308a7-022f-4328-beed-03e72e42e893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598798798-172.17.0.4-1593654904946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-4d1b9910-e27d-437d-802c-47d7939e1939,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-d0c65d62-adc8-4b64-8a6a-f261ed9da099,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-1ee8218a-9d81-4142-86cb-5c78b867eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-c8bd581a-57ed-4362-943f-d1f72bea1833,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-c1ee6368-c81a-4b78-ade6-9816f4126f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-e4640260-2a00-4795-8189-7571d3a1a6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-b2407bd0-c0aa-4917-9837-3d90189744d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-f5b76f27-a4ee-4d7b-8a25-7c456dd25605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598798798-172.17.0.4-1593654904946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-4d1b9910-e27d-437d-802c-47d7939e1939,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-d0c65d62-adc8-4b64-8a6a-f261ed9da099,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-1ee8218a-9d81-4142-86cb-5c78b867eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-c8bd581a-57ed-4362-943f-d1f72bea1833,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-c1ee6368-c81a-4b78-ade6-9816f4126f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-e4640260-2a00-4795-8189-7571d3a1a6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-b2407bd0-c0aa-4917-9837-3d90189744d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-f5b76f27-a4ee-4d7b-8a25-7c456dd25605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246562627-172.17.0.4-1593655974084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-298e8e08-6d96-456e-9819-08e51dc8ed38,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-2ee3439b-0434-42da-be56-7090fb01d08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ac856b86-e190-4a1a-a1d8-07d756771930,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-e612bc04-7c0f-43fa-bb4b-28468fa61422,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-8dc55070-51ad-4d65-8edf-e373c8f569e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-2d917503-40dc-4e7d-94d9-1cfd17180e53,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-13a2f33b-2a53-433f-914a-fac5a1d78ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-1f5b61f8-5501-4959-94f0-e6a1a215d114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246562627-172.17.0.4-1593655974084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-298e8e08-6d96-456e-9819-08e51dc8ed38,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-2ee3439b-0434-42da-be56-7090fb01d08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ac856b86-e190-4a1a-a1d8-07d756771930,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-e612bc04-7c0f-43fa-bb4b-28468fa61422,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-8dc55070-51ad-4d65-8edf-e373c8f569e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-2d917503-40dc-4e7d-94d9-1cfd17180e53,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-13a2f33b-2a53-433f-914a-fac5a1d78ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-1f5b61f8-5501-4959-94f0-e6a1a215d114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078104793-172.17.0.4-1593656081491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-8410541b-fcb1-4a64-b5d3-46e58d3ce184,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-cd5c4f30-c632-4f49-9143-aea1f83fb953,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-eba7d924-44fe-4c37-85be-17cabcccf9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-cf4f174a-fe49-47e8-8eaf-4ed272cbc74f,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-5d9522aa-aca0-4454-b3bf-954ce849726c,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-1cc18175-2bcf-4f4c-93f8-704fc0ee04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-edb2c515-5d83-4f6b-a484-1f9c0459b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-028da570-5ac2-4f94-ace0-8e019f3e94f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078104793-172.17.0.4-1593656081491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-8410541b-fcb1-4a64-b5d3-46e58d3ce184,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-cd5c4f30-c632-4f49-9143-aea1f83fb953,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-eba7d924-44fe-4c37-85be-17cabcccf9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-cf4f174a-fe49-47e8-8eaf-4ed272cbc74f,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-5d9522aa-aca0-4454-b3bf-954ce849726c,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-1cc18175-2bcf-4f4c-93f8-704fc0ee04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-edb2c515-5d83-4f6b-a484-1f9c0459b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-028da570-5ac2-4f94-ace0-8e019f3e94f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006478599-172.17.0.4-1593656184441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-fb5b100a-aea9-4bf6-84fd-e96d62359597,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-26177e0b-e56e-47b2-821f-97387f97d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-f858b006-e04b-4edb-9cca-2ef18f12500a,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-1bbb08c3-79e5-4f98-8942-5019f834425d,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-92ffba4a-2834-4a9a-a370-dcf6e3b7d522,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-d9532584-5068-473c-8712-83a54e5a2681,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-1ce88887-da11-4d6f-adac-236d132b286c,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-abd53957-9cee-4dae-8d58-52c5f52dd9de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006478599-172.17.0.4-1593656184441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-fb5b100a-aea9-4bf6-84fd-e96d62359597,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-26177e0b-e56e-47b2-821f-97387f97d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-f858b006-e04b-4edb-9cca-2ef18f12500a,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-1bbb08c3-79e5-4f98-8942-5019f834425d,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-92ffba4a-2834-4a9a-a370-dcf6e3b7d522,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-d9532584-5068-473c-8712-83a54e5a2681,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-1ce88887-da11-4d6f-adac-236d132b286c,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-abd53957-9cee-4dae-8d58-52c5f52dd9de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564980576-172.17.0.4-1593656418004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-a22a5f58-c025-4691-9a7a-80ad1677241a,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-83800ac5-b72b-483e-a3c0-2b506935fb87,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-a257fe1b-6326-4ce8-b185-dd9d41f3b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-2338f1cb-21af-4a14-a790-603adfa132c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-a848e67b-7f09-415d-bb6b-72d4417a8f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-57a9b95d-5837-4c6d-9166-6f8c97513ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-4e4b2150-305c-47b3-ab1e-f763e20b556b,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e9ceae04-7995-4fac-85c6-393244d7cb24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564980576-172.17.0.4-1593656418004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-a22a5f58-c025-4691-9a7a-80ad1677241a,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-83800ac5-b72b-483e-a3c0-2b506935fb87,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-a257fe1b-6326-4ce8-b185-dd9d41f3b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-2338f1cb-21af-4a14-a790-603adfa132c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-a848e67b-7f09-415d-bb6b-72d4417a8f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-57a9b95d-5837-4c6d-9166-6f8c97513ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-4e4b2150-305c-47b3-ab1e-f763e20b556b,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e9ceae04-7995-4fac-85c6-393244d7cb24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58548749-172.17.0.4-1593656887147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-7114e25b-a670-4f54-b52e-647d8f3d01f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-b18c12a0-3ede-405b-816c-d4929d40fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-b974b77d-addd-4b9d-a3e9-c861aaa0ee23,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-6b4ea899-f6ba-4247-8f88-76e7fd3eebda,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-08f8c468-158d-43db-8339-48ff2c1d3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-8f55d0ff-4239-4cb2-933a-4f7c6f2a2584,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-5a998ccb-eef4-4ac5-98d7-120f8eb92242,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-6ddd412a-2227-428d-9e09-ffa519d7b19b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58548749-172.17.0.4-1593656887147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-7114e25b-a670-4f54-b52e-647d8f3d01f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-b18c12a0-3ede-405b-816c-d4929d40fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-b974b77d-addd-4b9d-a3e9-c861aaa0ee23,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-6b4ea899-f6ba-4247-8f88-76e7fd3eebda,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-08f8c468-158d-43db-8339-48ff2c1d3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-8f55d0ff-4239-4cb2-933a-4f7c6f2a2584,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-5a998ccb-eef4-4ac5-98d7-120f8eb92242,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-6ddd412a-2227-428d-9e09-ffa519d7b19b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393749242-172.17.0.4-1593656927324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-89c7fadc-fd1b-4507-9a98-f6d38ad844be,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-1b000b67-3aff-4ee3-9f5f-5b97d3be7298,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-90788ab2-b391-46c1-af84-3ab382425e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-c2d48547-f9ba-4cef-ae3d-07f294803c58,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-a50db289-6d86-4939-85ff-8e7ed8d6ce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-a157cb32-85f1-4b26-8dbc-9e3f8def99a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ddc3b08b-bbf4-4089-ab3f-c12503e23988,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-c5640da7-20bb-4dad-aa34-b5fc6d6760d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393749242-172.17.0.4-1593656927324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-89c7fadc-fd1b-4507-9a98-f6d38ad844be,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-1b000b67-3aff-4ee3-9f5f-5b97d3be7298,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-90788ab2-b391-46c1-af84-3ab382425e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-c2d48547-f9ba-4cef-ae3d-07f294803c58,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-a50db289-6d86-4939-85ff-8e7ed8d6ce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-a157cb32-85f1-4b26-8dbc-9e3f8def99a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ddc3b08b-bbf4-4089-ab3f-c12503e23988,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-c5640da7-20bb-4dad-aa34-b5fc6d6760d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5690
