reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869707808-172.17.0.14-1593180899261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-c26f5f09-00d9-473b-b41a-f5ace058e553,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-4a3d0745-cbee-42fa-a27c-3b7ea14dbeef,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-169febee-dba3-4001-8cd6-4c4541f4f243,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-de30ed81-b81d-404b-aa74-d112c2978ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-933108ac-40c8-4eb2-a855-454eb5db3998,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-5bcb0344-26d6-49bc-8667-0218d739caba,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-c7b6a07f-d5c9-42a6-a4ef-2581a1a69a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-a8ddd32e-c5db-4076-ad55-e057d5a21f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869707808-172.17.0.14-1593180899261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-c26f5f09-00d9-473b-b41a-f5ace058e553,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-4a3d0745-cbee-42fa-a27c-3b7ea14dbeef,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-169febee-dba3-4001-8cd6-4c4541f4f243,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-de30ed81-b81d-404b-aa74-d112c2978ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-933108ac-40c8-4eb2-a855-454eb5db3998,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-5bcb0344-26d6-49bc-8667-0218d739caba,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-c7b6a07f-d5c9-42a6-a4ef-2581a1a69a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-a8ddd32e-c5db-4076-ad55-e057d5a21f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353588700-172.17.0.14-1593181025563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-103effbb-b208-481e-ab6f-051ca1a8dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-f182c25c-2292-4bfd-a0c3-166c0d24a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-511a4c34-3109-4f03-95bb-f95d2fe8c504,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-d8d0cfca-9ee7-47b6-92b9-3f9e8448477c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-51d9b63d-a43c-4dc9-8f93-b242e5079317,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-f8ca4730-b333-47be-b3c6-65cb92acda69,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-99297b16-4fc1-4f0c-8520-83eb9d85913c,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-304d7860-85ef-4130-97e7-60ee63cd5ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353588700-172.17.0.14-1593181025563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-103effbb-b208-481e-ab6f-051ca1a8dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-f182c25c-2292-4bfd-a0c3-166c0d24a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-511a4c34-3109-4f03-95bb-f95d2fe8c504,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-d8d0cfca-9ee7-47b6-92b9-3f9e8448477c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-51d9b63d-a43c-4dc9-8f93-b242e5079317,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-f8ca4730-b333-47be-b3c6-65cb92acda69,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-99297b16-4fc1-4f0c-8520-83eb9d85913c,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-304d7860-85ef-4130-97e7-60ee63cd5ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635756302-172.17.0.14-1593181265269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-67bfd648-3366-4f31-886f-8cb0817268b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-7f4692f9-e036-43b0-aca9-cda9995931ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7efb87b0-9300-4027-b7d4-e5fddae8dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-f5c63579-8c9a-4775-994d-c175b0e4b0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-92553535-aa4a-4806-8328-946f5d8d8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-66432655-c36c-4875-886c-53e1d42f975e,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-81d28be5-0a9b-4672-9450-8cf78210237d,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-d6d23c74-9c75-4d73-b4b1-413b72c2b1b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635756302-172.17.0.14-1593181265269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-67bfd648-3366-4f31-886f-8cb0817268b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-7f4692f9-e036-43b0-aca9-cda9995931ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7efb87b0-9300-4027-b7d4-e5fddae8dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-f5c63579-8c9a-4775-994d-c175b0e4b0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-92553535-aa4a-4806-8328-946f5d8d8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-66432655-c36c-4875-886c-53e1d42f975e,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-81d28be5-0a9b-4672-9450-8cf78210237d,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-d6d23c74-9c75-4d73-b4b1-413b72c2b1b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082017920-172.17.0.14-1593182072767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-495b2dd3-02f9-49a7-baa6-85db3d7d35f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-c9ac05fc-f18b-4586-9384-2d76fc865c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-2d922a88-4c8b-440b-bc71-97922f35f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-8c790610-c1d9-4803-86ab-8ae733951a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-3de3c895-f060-45f9-9124-9a5663564a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-7635e590-839f-46b6-acf0-595adea34466,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-106121b5-db69-44c4-97e8-737ed70e5d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-6fd3cba5-3e58-4b3d-8318-8f909e4d4a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082017920-172.17.0.14-1593182072767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-495b2dd3-02f9-49a7-baa6-85db3d7d35f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-c9ac05fc-f18b-4586-9384-2d76fc865c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-2d922a88-4c8b-440b-bc71-97922f35f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-8c790610-c1d9-4803-86ab-8ae733951a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-3de3c895-f060-45f9-9124-9a5663564a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-7635e590-839f-46b6-acf0-595adea34466,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-106121b5-db69-44c4-97e8-737ed70e5d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-6fd3cba5-3e58-4b3d-8318-8f909e4d4a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95956927-172.17.0.14-1593182106459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-ce3d2249-4525-4774-8fe6-8bd10533ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-b93b239f-09a7-49c3-bce5-c48fff0f3a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-e3b1b7fe-83ee-42cf-a484-fe3eb77532b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-75767856-2abc-4feb-942e-34a3131900b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-7b2591d1-79ed-4d77-ae0f-5613c8aac997,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-30fbabfd-308d-489c-afb4-73bbc1b18e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-7b29ae2b-57fc-4b0a-850a-09819d0a509c,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-89768610-4ab4-4b9f-86d7-48d3d34a450a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95956927-172.17.0.14-1593182106459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-ce3d2249-4525-4774-8fe6-8bd10533ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-b93b239f-09a7-49c3-bce5-c48fff0f3a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-e3b1b7fe-83ee-42cf-a484-fe3eb77532b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-75767856-2abc-4feb-942e-34a3131900b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-7b2591d1-79ed-4d77-ae0f-5613c8aac997,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-30fbabfd-308d-489c-afb4-73bbc1b18e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-7b29ae2b-57fc-4b0a-850a-09819d0a509c,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-89768610-4ab4-4b9f-86d7-48d3d34a450a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759418732-172.17.0.14-1593182739679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-e78cbf48-974d-48e8-8bab-b1dc7e1d8440,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-f415a34f-7f67-4241-857f-f95273cc7e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-79dc30b9-2859-49b8-b27f-52bca7c02048,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-8a50988b-e19c-4eb7-8b4d-52fe1ac11e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-dba84024-5ebc-4186-adb8-f2e72ce9261c,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-190e1245-4090-4e0b-84bf-0fefb8cbaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-1a6de7f0-9b64-44c7-8980-67b124c43642,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-0b2e09c4-7adf-4c2e-84ab-6b12b9dd3696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759418732-172.17.0.14-1593182739679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-e78cbf48-974d-48e8-8bab-b1dc7e1d8440,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-f415a34f-7f67-4241-857f-f95273cc7e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-79dc30b9-2859-49b8-b27f-52bca7c02048,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-8a50988b-e19c-4eb7-8b4d-52fe1ac11e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-dba84024-5ebc-4186-adb8-f2e72ce9261c,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-190e1245-4090-4e0b-84bf-0fefb8cbaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-1a6de7f0-9b64-44c7-8980-67b124c43642,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-0b2e09c4-7adf-4c2e-84ab-6b12b9dd3696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326651520-172.17.0.14-1593182778528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-34b7b3e6-4b35-470d-b979-7fa39a7741f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-284a529d-85e4-4821-ae11-b1d4239b8fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-dddbd1b3-ddc7-4c86-b421-70b775dccd94,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-d9bbd39e-b56f-4eb9-b495-5addef3d4c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-02ace421-a1f3-4eaa-a6c6-427c47b2e245,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-48f36fcb-ceb7-4f19-9dde-234301915ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-31818ec3-d2ee-4ffa-8c95-79eedad6e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-6ad1345c-0f82-4015-8d45-ecd0ff8a8f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326651520-172.17.0.14-1593182778528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-34b7b3e6-4b35-470d-b979-7fa39a7741f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-284a529d-85e4-4821-ae11-b1d4239b8fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-dddbd1b3-ddc7-4c86-b421-70b775dccd94,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-d9bbd39e-b56f-4eb9-b495-5addef3d4c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-02ace421-a1f3-4eaa-a6c6-427c47b2e245,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-48f36fcb-ceb7-4f19-9dde-234301915ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-31818ec3-d2ee-4ffa-8c95-79eedad6e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-6ad1345c-0f82-4015-8d45-ecd0ff8a8f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107085055-172.17.0.14-1593183112873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-bdce41bb-831f-4330-88a0-04da5aff9cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-f9222fcd-53d4-40f3-8539-c551fb21bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-93131000-2c98-4b9a-a6a7-d04e9261047d,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-d50e8cf8-19d7-4e9e-a880-22f72f7d00c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-16ab60c6-315e-4345-9775-9405981e20b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-9d40ce2d-a32f-4e42-a07e-bd44bdba86f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-f627830b-06a6-41dc-8d64-3e43b2d01cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-6b2b438a-a4f4-4187-b496-80540b3dfefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107085055-172.17.0.14-1593183112873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-bdce41bb-831f-4330-88a0-04da5aff9cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-f9222fcd-53d4-40f3-8539-c551fb21bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-93131000-2c98-4b9a-a6a7-d04e9261047d,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-d50e8cf8-19d7-4e9e-a880-22f72f7d00c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-16ab60c6-315e-4345-9775-9405981e20b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-9d40ce2d-a32f-4e42-a07e-bd44bdba86f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-f627830b-06a6-41dc-8d64-3e43b2d01cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-6b2b438a-a4f4-4187-b496-80540b3dfefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969380251-172.17.0.14-1593183160780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-eb9ec25f-c7cf-4956-badc-afdb051ab38b,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-9300d023-5851-4a8b-ba57-2fd57b8a377c,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-479e201c-168d-40c6-823d-2e5c8766324c,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-93f0a927-5035-482d-bcf2-3ce30640e6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-bd638441-9377-4fd4-ae1f-b7d4b92ef7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4cce7e19-b16d-4e3d-8fe2-e80eba13e69f,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-9fc62068-c73c-49f2-b0ef-1f8765d29d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-fef15741-69b3-4dca-be62-794e7c32f2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969380251-172.17.0.14-1593183160780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-eb9ec25f-c7cf-4956-badc-afdb051ab38b,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-9300d023-5851-4a8b-ba57-2fd57b8a377c,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-479e201c-168d-40c6-823d-2e5c8766324c,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-93f0a927-5035-482d-bcf2-3ce30640e6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-bd638441-9377-4fd4-ae1f-b7d4b92ef7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4cce7e19-b16d-4e3d-8fe2-e80eba13e69f,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-9fc62068-c73c-49f2-b0ef-1f8765d29d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-fef15741-69b3-4dca-be62-794e7c32f2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111254450-172.17.0.14-1593183989926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39405,DS-eff010ad-8358-45c0-846a-caf00a2fc096,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e6c7cdb6-6751-4c49-836b-09f3f4a0d821,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-24a5d654-23c7-48d1-ae1b-f0d745c7c867,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-978c30c6-6c40-4bd1-b183-218c5d7c2350,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-d092fa8d-06af-45a4-9341-2314c4ede177,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-4e204f2f-dbc7-410f-94b5-0b04e3481741,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-15c07fa1-04b9-4b32-974d-e8cb52facb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-7ce3a7b1-b8ac-458d-b6c1-572d96a9926a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111254450-172.17.0.14-1593183989926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39405,DS-eff010ad-8358-45c0-846a-caf00a2fc096,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e6c7cdb6-6751-4c49-836b-09f3f4a0d821,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-24a5d654-23c7-48d1-ae1b-f0d745c7c867,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-978c30c6-6c40-4bd1-b183-218c5d7c2350,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-d092fa8d-06af-45a4-9341-2314c4ede177,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-4e204f2f-dbc7-410f-94b5-0b04e3481741,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-15c07fa1-04b9-4b32-974d-e8cb52facb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-7ce3a7b1-b8ac-458d-b6c1-572d96a9926a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358239819-172.17.0.14-1593184595702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41108,DS-cdfa38a6-393b-4671-b92e-39adab2d0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-6a48a529-1b02-4db4-8c92-71ddf633346b,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-8a49720e-3342-44c9-8c86-ff4f14358126,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-31ca93fa-740d-4651-b30a-bb424871ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-7d7a6c11-2d39-4c42-ab68-93c1302c165f,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-f5cf2d27-e1de-426f-ba41-b0913adf89cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-5c630ca2-572c-4827-bf63-e46c7e71bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-e0f3c91c-a336-4174-a05e-bc471778577a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358239819-172.17.0.14-1593184595702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41108,DS-cdfa38a6-393b-4671-b92e-39adab2d0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-6a48a529-1b02-4db4-8c92-71ddf633346b,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-8a49720e-3342-44c9-8c86-ff4f14358126,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-31ca93fa-740d-4651-b30a-bb424871ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-7d7a6c11-2d39-4c42-ab68-93c1302c165f,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-f5cf2d27-e1de-426f-ba41-b0913adf89cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-5c630ca2-572c-4827-bf63-e46c7e71bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-e0f3c91c-a336-4174-a05e-bc471778577a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291097171-172.17.0.14-1593184680633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-53c39b00-05e6-442a-842d-20f2078500b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-2d72ba85-1f18-4380-80fb-590c644d1672,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-c4b02929-1a95-472c-8517-70db369d05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-de610621-ffaf-436f-8af3-c062a1af6080,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-c713f20a-ad04-443a-b7a0-e60ce6dac0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-10989bce-2d3b-48aa-8378-adafdaed4255,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-290ab3e3-fe32-4703-b525-8f9cecab51c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e228f968-d69e-4c6b-9415-6e77387d3d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291097171-172.17.0.14-1593184680633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-53c39b00-05e6-442a-842d-20f2078500b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-2d72ba85-1f18-4380-80fb-590c644d1672,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-c4b02929-1a95-472c-8517-70db369d05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-de610621-ffaf-436f-8af3-c062a1af6080,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-c713f20a-ad04-443a-b7a0-e60ce6dac0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-10989bce-2d3b-48aa-8378-adafdaed4255,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-290ab3e3-fe32-4703-b525-8f9cecab51c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e228f968-d69e-4c6b-9415-6e77387d3d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691261236-172.17.0.14-1593185357799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45990,DS-fde049e8-b00a-419f-9a4e-0fb0dab89b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-207dbbcc-0639-4853-bcab-83a7df48b8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-badfff16-b2a1-49be-b651-bee9a29a1fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-3a76f7bb-8578-4296-adec-986833bccf20,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-87fe06dc-3cc7-4091-b953-7e44e6036b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9ebf0b28-ad95-4de7-960d-88f566c1374a,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-b4c43669-99c4-4264-b30a-aa448a26d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-0b91d91c-94ad-4a96-a63e-abb54986ecf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691261236-172.17.0.14-1593185357799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45990,DS-fde049e8-b00a-419f-9a4e-0fb0dab89b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-207dbbcc-0639-4853-bcab-83a7df48b8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-badfff16-b2a1-49be-b651-bee9a29a1fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-3a76f7bb-8578-4296-adec-986833bccf20,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-87fe06dc-3cc7-4091-b953-7e44e6036b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9ebf0b28-ad95-4de7-960d-88f566c1374a,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-b4c43669-99c4-4264-b30a-aa448a26d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-0b91d91c-94ad-4a96-a63e-abb54986ecf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775962117-172.17.0.14-1593185400592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42174,DS-e669ee89-425c-4855-af7e-87fa70a17c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9d1970e3-5079-445c-8d2f-b5469bf842bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-e23af0c7-f1bb-4957-b479-d32c8f9ce269,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-fbe4bcec-6841-40c0-a535-9b33f3c2d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-e30cafcf-ad02-4975-9089-98f3696a5975,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-ff9b4ea5-23f1-411f-95d7-36eb018d674f,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-27445955-571b-4a6b-8329-881b2d2e0f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-1e86e811-bfa0-4e81-b535-bdaae00bfb6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775962117-172.17.0.14-1593185400592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42174,DS-e669ee89-425c-4855-af7e-87fa70a17c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9d1970e3-5079-445c-8d2f-b5469bf842bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-e23af0c7-f1bb-4957-b479-d32c8f9ce269,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-fbe4bcec-6841-40c0-a535-9b33f3c2d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-e30cafcf-ad02-4975-9089-98f3696a5975,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-ff9b4ea5-23f1-411f-95d7-36eb018d674f,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-27445955-571b-4a6b-8329-881b2d2e0f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-1e86e811-bfa0-4e81-b535-bdaae00bfb6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654712635-172.17.0.14-1593185563794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-6e963e79-7701-496d-ac52-4ff75cd28b49,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-f9ff83f1-e503-4f16-a013-d51e21bb9d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-e46f7b48-0d23-4c79-b2fe-7c9f2d774293,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-d3687631-3cf8-4bc4-b3b8-8eebcf61d285,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-a467fc97-392f-4d55-b72c-b4921c023a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-46c94fa6-2d47-4784-be05-764d6c2d8566,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-26e0e306-665a-4ca1-ae0f-da9c6a5ac508,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-77279805-4937-4cfe-8568-80840d34e493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654712635-172.17.0.14-1593185563794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-6e963e79-7701-496d-ac52-4ff75cd28b49,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-f9ff83f1-e503-4f16-a013-d51e21bb9d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-e46f7b48-0d23-4c79-b2fe-7c9f2d774293,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-d3687631-3cf8-4bc4-b3b8-8eebcf61d285,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-a467fc97-392f-4d55-b72c-b4921c023a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-46c94fa6-2d47-4784-be05-764d6c2d8566,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-26e0e306-665a-4ca1-ae0f-da9c6a5ac508,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-77279805-4937-4cfe-8568-80840d34e493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649889034-172.17.0.14-1593185920258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-652ac06a-b3b0-41fd-ac83-6259c1feb624,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-907929e9-de18-4eca-b740-cc83fa4a46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-6c16f98b-176f-48dc-b3d6-3b091fa3ee05,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-b242032f-7e86-40d0-95c5-c62f3983e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-9a706f45-247e-4693-a79e-88d82cdea36c,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-ba095468-62ea-4812-80fd-9325db3ded6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-fbfb2166-5381-4253-9c95-035aae57777d,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-af0f49b2-0c79-425c-9c06-fd324f6e46c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649889034-172.17.0.14-1593185920258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-652ac06a-b3b0-41fd-ac83-6259c1feb624,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-907929e9-de18-4eca-b740-cc83fa4a46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-6c16f98b-176f-48dc-b3d6-3b091fa3ee05,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-b242032f-7e86-40d0-95c5-c62f3983e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-9a706f45-247e-4693-a79e-88d82cdea36c,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-ba095468-62ea-4812-80fd-9325db3ded6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-fbfb2166-5381-4253-9c95-035aae57777d,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-af0f49b2-0c79-425c-9c06-fd324f6e46c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943851417-172.17.0.14-1593186304648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33639,DS-86dd1378-74cc-4abe-b108-11a0b841a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-680e4ed9-076a-4839-8bd7-68916b2a221a,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-18663aa8-d9dc-41d5-9d85-713e6bb2c786,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-80c0efda-88d9-4e5b-a2b3-748587596a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-cb15765a-0155-472d-a90c-5a67d5094360,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-919e3080-92c1-463a-8002-897b4bcc9b46,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-0319c5d7-d74f-4155-9583-cd7db984374b,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-17237a29-51cf-4d06-9cda-fe4ba3a5f262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943851417-172.17.0.14-1593186304648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33639,DS-86dd1378-74cc-4abe-b108-11a0b841a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-680e4ed9-076a-4839-8bd7-68916b2a221a,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-18663aa8-d9dc-41d5-9d85-713e6bb2c786,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-80c0efda-88d9-4e5b-a2b3-748587596a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-cb15765a-0155-472d-a90c-5a67d5094360,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-919e3080-92c1-463a-8002-897b4bcc9b46,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-0319c5d7-d74f-4155-9583-cd7db984374b,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-17237a29-51cf-4d06-9cda-fe4ba3a5f262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046630449-172.17.0.14-1593186548638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-7e48070a-e5b8-46b7-b2aa-88c7a30775bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-1952bbed-3181-4050-83fd-ed9eb2755209,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-ab814cd3-d08e-46a2-9807-4f38a9273446,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-3aa8a6e2-3cc6-4f6c-b149-ec81652ac35d,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-2eeeec8d-1e84-4768-b7ff-27389161ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-537a25b6-f4cf-4bed-9eea-6b8441c671f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-91895224-c334-468b-b233-c54d43a56fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-1ba747af-8eab-49fd-b9f8-9af3c9f7e273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046630449-172.17.0.14-1593186548638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-7e48070a-e5b8-46b7-b2aa-88c7a30775bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-1952bbed-3181-4050-83fd-ed9eb2755209,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-ab814cd3-d08e-46a2-9807-4f38a9273446,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-3aa8a6e2-3cc6-4f6c-b149-ec81652ac35d,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-2eeeec8d-1e84-4768-b7ff-27389161ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-537a25b6-f4cf-4bed-9eea-6b8441c671f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-91895224-c334-468b-b233-c54d43a56fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-1ba747af-8eab-49fd-b9f8-9af3c9f7e273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045925063-172.17.0.14-1593186585671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-2fe14ab4-7f34-4769-a877-2c38bf73c129,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-0c6df9e6-f07b-49f3-b4ef-91ed03e429da,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-bf59dbcf-d4cd-42c5-bedf-6c02d31350f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-f5e0b5a2-0ca0-4ec3-b02f-6d536d6745be,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-93c0f814-cd5e-44bf-a9bd-a7f2e914b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-a7ea1c43-306d-4a18-988f-ae7a78a7b2da,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-2afa7f1f-dcda-48ed-9a56-5dbfbb94f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-107a68cf-ecc8-420b-bd38-d9c3c6c9acd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045925063-172.17.0.14-1593186585671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-2fe14ab4-7f34-4769-a877-2c38bf73c129,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-0c6df9e6-f07b-49f3-b4ef-91ed03e429da,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-bf59dbcf-d4cd-42c5-bedf-6c02d31350f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-f5e0b5a2-0ca0-4ec3-b02f-6d536d6745be,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-93c0f814-cd5e-44bf-a9bd-a7f2e914b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-a7ea1c43-306d-4a18-988f-ae7a78a7b2da,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-2afa7f1f-dcda-48ed-9a56-5dbfbb94f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-107a68cf-ecc8-420b-bd38-d9c3c6c9acd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385431485-172.17.0.14-1593186751961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34516,DS-46402a55-ffc1-4463-ac03-f559e5d7881b,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-32fb7a1d-e17b-4473-81a8-42d6948a7537,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-8f56debe-3b74-4bb7-95e0-31b6007834e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-625b58c0-d2f0-4fb1-a418-742bf0a5a965,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-d7eb6686-61da-4ec5-bc0b-023a9764dc29,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-7cc566a1-dab6-4fcb-945b-291ebd0b85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-5c932bff-7747-479c-8046-250d6af0eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-f56feb32-409b-46da-9ada-059bd35fd0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385431485-172.17.0.14-1593186751961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34516,DS-46402a55-ffc1-4463-ac03-f559e5d7881b,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-32fb7a1d-e17b-4473-81a8-42d6948a7537,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-8f56debe-3b74-4bb7-95e0-31b6007834e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-625b58c0-d2f0-4fb1-a418-742bf0a5a965,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-d7eb6686-61da-4ec5-bc0b-023a9764dc29,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-7cc566a1-dab6-4fcb-945b-291ebd0b85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-5c932bff-7747-479c-8046-250d6af0eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-f56feb32-409b-46da-9ada-059bd35fd0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write.stale.datanode.ratio
component: hdfs:NameNode
v1: 0.5
v2: 0.5f
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664196357-172.17.0.14-1593186872735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38218,DS-644a3633-03c5-47fc-9c93-a7a574d34eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-f20af1bf-0456-4644-ac9c-a691ea328279,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-afd29e3b-9735-4d4c-b970-07689c4e4100,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-7569e4d3-12dc-4b7c-ae18-e976f48254c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-3da7e497-6ff7-4fdc-9b93-54276b8bb155,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-686de4c7-d1dd-479d-aeba-38c00844bbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-e89b7865-3c59-412d-9843-c8f25ed80f25,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-56b1eed8-0261-4abf-a702-efb6daacecae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664196357-172.17.0.14-1593186872735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38218,DS-644a3633-03c5-47fc-9c93-a7a574d34eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-f20af1bf-0456-4644-ac9c-a691ea328279,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-afd29e3b-9735-4d4c-b970-07689c4e4100,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-7569e4d3-12dc-4b7c-ae18-e976f48254c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-3da7e497-6ff7-4fdc-9b93-54276b8bb155,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-686de4c7-d1dd-479d-aeba-38c00844bbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-e89b7865-3c59-412d-9843-c8f25ed80f25,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-56b1eed8-0261-4abf-a702-efb6daacecae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 6126
