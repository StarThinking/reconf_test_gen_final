reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36455,DS-a90c40f2-477f-44f0-aa19-89b0fe5f7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-9e7ea1b4-60bd-4523-a4c7-c1837004ed7e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-9e7ea1b4-60bd-4523-a4c7-c1837004ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-a90c40f2-477f-44f0-aa19-89b0fe5f7da9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36455,DS-a90c40f2-477f-44f0-aa19-89b0fe5f7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-9e7ea1b4-60bd-4523-a4c7-c1837004ed7e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-9e7ea1b4-60bd-4523-a4c7-c1837004ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-a90c40f2-477f-44f0-aa19-89b0fe5f7da9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-4bd55dca-4603-4e31-9a6c-a43f63298b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-714d5990-2721-45b9-8916-26d020179026,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-4bd55dca-4603-4e31-9a6c-a43f63298b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-714d5990-2721-45b9-8916-26d020179026,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-4bd55dca-4603-4e31-9a6c-a43f63298b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-714d5990-2721-45b9-8916-26d020179026,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-4bd55dca-4603-4e31-9a6c-a43f63298b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-714d5990-2721-45b9-8916-26d020179026,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34912,DS-a01eb768-ea90-4747-878f-01d3570306ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-aeb70df3-dd09-4f81-8927-c9905978de70,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34912,DS-a01eb768-ea90-4747-878f-01d3570306ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-aeb70df3-dd09-4f81-8927-c9905978de70,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34912,DS-a01eb768-ea90-4747-878f-01d3570306ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-aeb70df3-dd09-4f81-8927-c9905978de70,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34912,DS-a01eb768-ea90-4747-878f-01d3570306ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-aeb70df3-dd09-4f81-8927-c9905978de70,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-e50cc0ae-01bb-4cd9-b256-912a0075116c,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e43027ad-8eb7-475f-aea4-4436a0953501,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-e43027ad-8eb7-475f-aea4-4436a0953501,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-e50cc0ae-01bb-4cd9-b256-912a0075116c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-e50cc0ae-01bb-4cd9-b256-912a0075116c,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e43027ad-8eb7-475f-aea4-4436a0953501,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-e43027ad-8eb7-475f-aea4-4436a0953501,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-e50cc0ae-01bb-4cd9-b256-912a0075116c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-93b78514-8b25-40f6-ab5f-148d0f8509e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-e4a185f8-57d0-454e-bc64-e31bf07f76cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-93b78514-8b25-40f6-ab5f-148d0f8509e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-e4a185f8-57d0-454e-bc64-e31bf07f76cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-93b78514-8b25-40f6-ab5f-148d0f8509e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-e4a185f8-57d0-454e-bc64-e31bf07f76cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-93b78514-8b25-40f6-ab5f-148d0f8509e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-e4a185f8-57d0-454e-bc64-e31bf07f76cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-b02a61f6-ddf1-4b4e-9cd9-6c3e948fa7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62527079-9629-4d6c-b63a-e989d0e7ffb5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-b02a61f6-ddf1-4b4e-9cd9-6c3e948fa7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62527079-9629-4d6c-b63a-e989d0e7ffb5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-b02a61f6-ddf1-4b4e-9cd9-6c3e948fa7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62527079-9629-4d6c-b63a-e989d0e7ffb5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-b02a61f6-ddf1-4b4e-9cd9-6c3e948fa7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62527079-9629-4d6c-b63a-e989d0e7ffb5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45746,DS-efa1dbea-5319-4faf-a5dd-2c108cec5c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-b0f6b933-7c5f-49bf-a6eb-335ca1a979da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45746,DS-efa1dbea-5319-4faf-a5dd-2c108cec5c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-b0f6b933-7c5f-49bf-a6eb-335ca1a979da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45746,DS-efa1dbea-5319-4faf-a5dd-2c108cec5c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-b0f6b933-7c5f-49bf-a6eb-335ca1a979da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45746,DS-efa1dbea-5319-4faf-a5dd-2c108cec5c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-b0f6b933-7c5f-49bf-a6eb-335ca1a979da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-99b361b6-5210-4bc0-bbdd-f331f8625dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-6d1ec544-4c4e-4fe4-a7bf-11e0dff99647,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-99b361b6-5210-4bc0-bbdd-f331f8625dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-6d1ec544-4c4e-4fe4-a7bf-11e0dff99647,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-99b361b6-5210-4bc0-bbdd-f331f8625dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-6d1ec544-4c4e-4fe4-a7bf-11e0dff99647,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-99b361b6-5210-4bc0-bbdd-f331f8625dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-6d1ec544-4c4e-4fe4-a7bf-11e0dff99647,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-6dffcf90-9554-4645-9a7b-a5038afd8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-a7cf6ad3-2ab8-4d4b-b857-91e44be87450,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-6dffcf90-9554-4645-9a7b-a5038afd8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-a7cf6ad3-2ab8-4d4b-b857-91e44be87450,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-6dffcf90-9554-4645-9a7b-a5038afd8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-a7cf6ad3-2ab8-4d4b-b857-91e44be87450,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-6dffcf90-9554-4645-9a7b-a5038afd8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-a7cf6ad3-2ab8-4d4b-b857-91e44be87450,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-a3a8dc14-02de-4c4c-9929-a768ca52cb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-7ceb3b7b-006e-455d-bfac-80029b321a08,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-a3a8dc14-02de-4c4c-9929-a768ca52cb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-7ceb3b7b-006e-455d-bfac-80029b321a08,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-a3a8dc14-02de-4c4c-9929-a768ca52cb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-7ceb3b7b-006e-455d-bfac-80029b321a08,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-a3a8dc14-02de-4c4c-9929-a768ca52cb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-7ceb3b7b-006e-455d-bfac-80029b321a08,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 779
