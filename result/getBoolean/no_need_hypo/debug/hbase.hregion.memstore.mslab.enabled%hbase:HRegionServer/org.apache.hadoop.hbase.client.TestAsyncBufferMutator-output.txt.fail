msx-reconfagent reconf_vvmode=v1v2, reconf_parameter=hbase.hregion.memstore.mslab.enabled, reconf_component=hbase:HRegionServer, reconf_v1=true, reconf_v2=false, reconf_point=1
2020-06-19 02:12:30,320 DEBUG [main] hbase.HBaseTestingUtility(350): Setting hbase.rootdir to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf
msx-debug TestAsyncBufferMutator:setUp 0
2020-06-19 02:12:30,336 INFO  [Time-limited test] hbase.HBaseTestingUtility(1081): Starting up minicluster with option: StartMiniClusterOption{numMasters=1, masterClass=null, numRegionServers=1, rsPorts=, rsClass=null, numDataNodes=1, dataNodeHosts=null, numZkServers=1, createRootDir=false, createWALDir=false}
2020-06-19 02:12:30,338 INFO  [Time-limited test] hbase.HBaseZKTestingUtility(83): Created new mini-cluster data directory: /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/cluster_41a19304-2004-3bdd-2aa9-a2e65ee31048, deleteOnExit=true
2020-06-19 02:12:30,338 INFO  [Time-limited test] hbase.HBaseTestingUtility(1095): STARTING DFS
2020-06-19 02:12:30,340 INFO  [Time-limited test] hbase.HBaseTestingUtility(770): Setting test.cache.data to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/cache_data in system properties and HBase conf
2020-06-19 02:12:30,341 INFO  [Time-limited test] hbase.HBaseTestingUtility(770): Setting hadoop.tmp.dir to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/hadoop_tmp in system properties and HBase conf
2020-06-19 02:12:30,342 INFO  [Time-limited test] hbase.HBaseTestingUtility(770): Setting hadoop.log.dir to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/hadoop_logs in system properties and HBase conf
2020-06-19 02:12:30,343 INFO  [Time-limited test] hbase.HBaseTestingUtility(770): Setting mapreduce.cluster.local.dir to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/mapred_local in system properties and HBase conf
2020-06-19 02:12:30,343 INFO  [Time-limited test] hbase.HBaseTestingUtility(770): Setting mapreduce.cluster.temp.dir to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/mapred_temp in system properties and HBase conf
2020-06-19 02:12:30,344 INFO  [Time-limited test] hbase.HBaseTestingUtility(761): read short circuit is OFF
2020-06-19 02:12:30,463 WARN  [Time-limited test] util.NativeCodeLoader(62): Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-19 02:12:30,820 DEBUG [Time-limited test] fs.HFileSystem(317): The file system is not a DistributedFileSystem. Skipping on block location reordering
Formatting using clusterid: testClusterID
2020-06-19 02:12:31,773 WARN  [Time-limited test] impl.MetricsConfig(128): Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
msx-reconfagent conf 638114973 itself is unique for hdfs:NameNode 1033400255
msx-reconfagent performReconf for comoponent hdfs:NameNode 1033400255 uniqueConf 638114973 originConf 638114973
msx-reconfagent hdfs:NameNode init 1033400255, irrelevant component. Set value as v1 true
2020-06-19 02:12:31,939 INFO  [Time-limited test] log.Slf4jLog(67): Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-06-19 02:12:31,996 INFO  [Time-limited test] log.Slf4jLog(67): jetty-6.1.26
2020-06-19 02:12:32,018 INFO  [Time-limited test] log.Slf4jLog(67): Extract jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.8.5/hadoop-hdfs-2.8.5-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_44990_hdfs____.uj0gqu/webapp
2020-06-19 02:12:32,194 INFO  [Time-limited test] log.Slf4jLog(67): Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44990
msx-reconfagent conf 949610578 itself is unique for hdfs:DataNode 1100791599
msx-reconfagent performReconf for comoponent hdfs:DataNode 1100791599 uniqueConf 949610578 originConf 949610578
msx-reconfagent hdfs:DataNode init 1100791599, irrelevant component. Set value as v1 true
2020-06-19 02:12:32,802 INFO  [Time-limited test] log.Slf4jLog(67): jetty-6.1.26
2020-06-19 02:12:32,810 INFO  [Time-limited test] log.Slf4jLog(67): Extract jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.8.5/hadoop-hdfs-2.8.5-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_45389_datanode____66vt16/webapp
2020-06-19 02:12:32,929 INFO  [Time-limited test] log.Slf4jLog(67): Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45389
2020-06-19 02:12:33,989 INFO  [Block report processor] blockmanagement.BlockManager(2000): BLOCK* processReport 0xc65c572c3c23bdc2: Processing first storage report for DS-19c80b35-43b2-45db-aa37-f2b21bc9e057 from datanode 01f8a5b1-80f7-432d-af66-81d73551fe58
2020-06-19 02:12:33,994 INFO  [Block report processor] blockmanagement.BlockManager(2026): BLOCK* processReport 0xc65c572c3c23bdc2: from storage DS-19c80b35-43b2-45db-aa37-f2b21bc9e057 node DatanodeRegistration(127.0.0.1:41379, datanodeUuid=01f8a5b1-80f7-432d-af66-81d73551fe58, infoPort=44956, infoSecurePort=0, ipcPort=45123, storageInfo=lv=-57;cid=testClusterID;nsid=1523042151;c=1592532751314), blocks: 0, hasStaleStorage: true, processing time: 5 msecs, invalidatedBlocks: 0
2020-06-19 02:12:33,995 INFO  [Block report processor] blockmanagement.BlockManager(2000): BLOCK* processReport 0xc65c572c3c23bdc2: Processing first storage report for DS-057fad41-d3db-4449-a066-f10f43fd544b from datanode 01f8a5b1-80f7-432d-af66-81d73551fe58
2020-06-19 02:12:33,996 INFO  [Block report processor] blockmanagement.BlockManager(2026): BLOCK* processReport 0xc65c572c3c23bdc2: from storage DS-057fad41-d3db-4449-a066-f10f43fd544b node DatanodeRegistration(127.0.0.1:41379, datanodeUuid=01f8a5b1-80f7-432d-af66-81d73551fe58, infoPort=44956, infoSecurePort=0, ipcPort=45123, storageInfo=lv=-57;cid=testClusterID;nsid=1523042151;c=1592532751314), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-06-19 02:12:34,074 DEBUG [Time-limited test] hbase.HBaseTestingUtility(684): Setting hbase.rootdir to /root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf
2020-06-19 02:12:34,112 ERROR [Time-limited test] server.ZooKeeperServer(472): ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes
2020-06-19 02:12:34,127 INFO  [Time-limited test] zookeeper.MiniZooKeeperCluster(281): Started MiniZooKeeperCluster and ran successful 'stat' on client port=55163
2020-06-19 02:12:34,139 INFO  [Time-limited test] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:34,142 INFO  [Time-limited test] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:34,869 INFO  [Time-limited test] util.FSUtils(518): Created version file at hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3 with version=8
2020-06-19 02:12:34,870 INFO  [Time-limited test] hbase.HBaseTestingUtility(1440): Setting hbase.fs.tmp.dir to hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/hbase-staging
msx-reconfagent conf 922300450 itself is unique for hbase:HMaster 767488409
msx-reconfagent performReconf for comoponent hbase:HMaster 767488409 uniqueConf 922300450 originConf 922300450
msx-reconfagent hbase:HMaster init 767488409, irrelevant component. Set value as v1 true
2020-06-19 02:12:35,079 INFO  [Time-limited test] metrics.MetricRegistriesLoader(66): Loaded MetricRegistries class org.apache.hadoop.hbase.metrics.impl.MetricRegistriesImpl
2020-06-19 02:12:35,358 INFO  [Time-limited test] client.ConnectionUtils(132): master/a83bc24e6e49:0 server-side Connection retries=45
2020-06-19 02:12:35,379 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated default.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=50, handlerCount=5
2020-06-19 02:12:35,381 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated priority.RWQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=2, maxQueueLength=50, handlerCount=6
2020-06-19 02:12:35,381 INFO  [Time-limited test] ipc.RWQueueRpcExecutor(107): priority.RWQ.Fifo writeQueues=1 writeHandlers=1 readQueues=1 readHandlers=5 scanQueues=0 scanHandlers=0
2020-06-19 02:12:35,382 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated replication.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=50, handlerCount=3
2020-06-19 02:12:35,382 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated metaPriority.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=50, handlerCount=1
2020-06-19 02:12:35,501 INFO  [Time-limited test] ipc.RpcServerFactory(65): Creating org.apache.hadoop.hbase.ipc.NettyRpcServer hosting hbase.pb.MasterService, hbase.pb.RegionServerStatusService, hbase.pb.LockService, hbase.pb.HbckService, hbase.pb.ClientService, hbase.pb.AdminService
2020-06-19 02:12:35,542 DEBUG [Time-limited test] util.ClassSize(229): Using Unsafe to estimate memory layout
2020-06-19 02:12:35,612 INFO  [Time-limited test] ipc.NettyRpcServer(110): Bind to /172.17.0.6:44913
2020-06-19 02:12:35,630 INFO  [Time-limited test] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:35,636 INFO  [Time-limited test] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:35,694 INFO  [Time-limited test] zookeeper.RecoverableZooKeeper(106): Process identifier=master:44913 connecting to ZooKeeper ensemble=localhost:55163
2020-06-19 02:12:35,731 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:449130x0, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2020-06-19 02:12:35,732 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(542): master:44913-0x172ca595eb70000 connected
2020-06-19 02:12:35,770 DEBUG [Time-limited test] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2020-06-19 02:12:35,771 DEBUG [Time-limited test] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2020-06-19 02:12:35,782 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=5 with threadPrefix=default.FPBQ.Fifo, numCallQueues=1, port=44913
2020-06-19 02:12:35,783 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=1 with threadPrefix=priority.RWQ.Fifo.write, numCallQueues=1, port=44913
2020-06-19 02:12:35,785 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=6 with threadPrefix=priority.RWQ.Fifo.read, numCallQueues=1, port=44913
2020-06-19 02:12:35,786 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=3 with threadPrefix=replication.FPBQ.Fifo, numCallQueues=1, port=44913
2020-06-19 02:12:35,786 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=1 with threadPrefix=metaPriority.FPBQ.Fifo, numCallQueues=1, port=44913
2020-06-19 02:12:35,798 INFO  [Time-limited test] master.HMaster(510): hbase.rootdir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3, hbase.cluster.distributed=false
msx-reconfagent conf 1058993535 itself is unique for hbase:HRegionServer 1480698702
msx-reconfagent performReconf for comoponent hbase:HRegionServer 1480698702 uniqueConf 1058993535 originConf 1058993535
msx-reconfagent hbase:HRegionServer init 1480698702, PERFORM V1V2 RECONF 1. Set value as v2 false
2020-06-19 02:12:35,934 INFO  [Time-limited test] client.ConnectionUtils(132): regionserver/a83bc24e6e49:0 server-side Connection retries=45
2020-06-19 02:12:35,934 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated default.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=50, handlerCount=5
2020-06-19 02:12:35,934 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated priority.RWQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=2, maxQueueLength=50, handlerCount=6
2020-06-19 02:12:35,935 INFO  [Time-limited test] ipc.RWQueueRpcExecutor(107): priority.RWQ.Fifo writeQueues=1 writeHandlers=1 readQueues=1 readHandlers=5 scanQueues=0 scanHandlers=0
2020-06-19 02:12:35,935 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated replication.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=50, handlerCount=3
2020-06-19 02:12:35,935 INFO  [Time-limited test] ipc.RpcExecutor(162): Instantiated metaPriority.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=50, handlerCount=1
2020-06-19 02:12:35,939 INFO  [Time-limited test] ipc.RpcServerFactory(65): Creating org.apache.hadoop.hbase.ipc.NettyRpcServer hosting hbase.pb.ClientService, hbase.pb.AdminService
2020-06-19 02:12:35,940 INFO  [Time-limited test] io.ByteBufferPool(83): Created with bufferSize=64 KB and maxPoolSize=320 B
2020-06-19 02:12:35,945 INFO  [Time-limited test] ipc.NettyRpcServer(110): Bind to /172.17.0.6:45768
2020-06-19 02:12:35,948 INFO  [Time-limited test] hfile.BlockCacheFactory(134): Allocating onheap LruBlockCache size=995.60 MB, blockSize=64 KB
2020-06-19 02:12:35,959 DEBUG [Time-limited test] mob.MobFileCache(124): MobFileCache enabled with cacheSize=1000, evictPeriods=3600sec, evictRemainRatio=0.5
2020-06-19 02:12:35,962 INFO  [Time-limited test] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:35,967 INFO  [Time-limited test] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:35,972 INFO  [Time-limited test] zookeeper.RecoverableZooKeeper(106): Process identifier=regionserver:45768 connecting to ZooKeeper ensemble=localhost:55163
2020-06-19 02:12:35,976 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): regionserver:457680x0, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2020-06-19 02:12:35,977 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(542): regionserver:45768-0x172ca595eb70001 connected
2020-06-19 02:12:35,977 DEBUG [Time-limited test] zookeeper.ZKUtil(356): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2020-06-19 02:12:35,978 DEBUG [Time-limited test] zookeeper.ZKUtil(356): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2020-06-19 02:12:35,980 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=5 with threadPrefix=default.FPBQ.Fifo, numCallQueues=1, port=45768
2020-06-19 02:12:35,981 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=1 with threadPrefix=priority.RWQ.Fifo.write, numCallQueues=1, port=45768
2020-06-19 02:12:35,982 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=6 with threadPrefix=priority.RWQ.Fifo.read, numCallQueues=1, port=45768
2020-06-19 02:12:35,983 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=3 with threadPrefix=replication.FPBQ.Fifo, numCallQueues=1, port=45768
2020-06-19 02:12:35,984 DEBUG [Time-limited test] ipc.RpcExecutor(277): Started handlerCount=1 with threadPrefix=metaPriority.FPBQ.Fifo, numCallQueues=1, port=45768
2020-06-19 02:12:35,989 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.HMaster(2105): Adding backup master ZNode /hbase/backup-masters/a83bc24e6e49,44913,1592532754956
2020-06-19 02:12:36,003 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(354): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on existing znode=/hbase/backup-masters/a83bc24e6e49,44913,1592532754956
2020-06-19 02:12:36,039 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2020-06-19 02:12:36,039 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2020-06-19 02:12:36,040 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(354): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2020-06-19 02:12:36,041 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.ActiveMasterManager(172): Deleting ZNode for /hbase/backup-masters/a83bc24e6e49,44913,1592532754956 from backup master directory
2020-06-19 02:12:36,044 DEBUG [Time-limited test-EventThread] zookeeper.ZKUtil(354): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2020-06-19 02:12:36,046 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/backup-masters/a83bc24e6e49,44913,1592532754956
2020-06-19 02:12:36,047 WARN  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ZNodeClearer(63): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2020-06-19 02:12:36,047 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.ActiveMasterManager(181): Registered as active master=a83bc24e6e49,44913,1592532754956
2020-06-19 02:12:36,809 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] util.FSUtils(670): Created cluster ID file at hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/hbase.id with ID: e27dd020-6e8a-4212-81ae-3ae4917c0416
2020-06-19 02:12:36,835 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.MasterFileSystem(398): BOOTSTRAP: creating hbase:meta region
2020-06-19 02:12:36,860 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(7106): creating {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}, tableDescriptor='hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}}, {NAME => 'info', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'false', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'false', BLOCKSIZE => '8192'}, {NAME => 'rep_barrier', VERSIONS => '2147483647', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '65536'}, {NAME => 'table', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'}, regionDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3
msx-debug HRegion:<init> this.conf.hashCode() = 240744668
2020-06-19 02:12:36,905 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(855): Instantiated hbase:meta,,1.1588230740; StoreHotnessProtector, parallelPutToStoreThreadLimit=10 ; minColumnNum=100 ; preparePutThreadLimit=20 ; hotProtect now enable
msx-debug HStore:<init> this.conf.hashCode() = 92951296
2020-06-19 02:12:36,970 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/info
msx-reconfagent conf 92951296 itself is unique for hbase:AbstractMemStore 843932188
msx-reconfagent performReconf for comoponent hbase:AbstractMemStore 843932188 uniqueConf 92951296 originConf 92951296
msx-reconfagent hbase:AbstractMemStore init 843932188, irrelevant component. Set value as v1 true
msx-debug MemStoreLAB:newInstance isEnabled(conf) = true
msx-debug MemStoreLABImpl<init> before ChunkCreator.getInstance()
msx-debug this.chunkCreator is null
msx-debug Segment:<init> memStoreLAB = org.apache.hadoop.hbase.regionserver.MemStoreLABImpl@573ed158
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:86)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:84)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> memStoreLAB = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:72)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> segment = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:124)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.<init>(ImmutableSegment.java:68)
	at org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.<init>(CSLMImmutableSegment.java:40)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:79)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:73)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:36,996 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(174): Created cacheConfig: cacheDataOnRead=false, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false for family {NAME => 'info', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'false', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'false', BLOCKSIZE => '8192'} with blockCache=null
2020-06-19 02:12:37,005 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(147): size [128 MB, 8.00 EB, 8.00 EB); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2020-06-19 02:12:37,026 INFO  [StoreOpener-1588230740-1] regionserver.HStore(336): Store=info,  memstore type=DefaultMemStore, storagePolicy=HOT, verifyBulkLoads=false, parallelPutCountPrintThreshold=50, encoding=NONE, compression=NONE
msx-debug HStore:<init> this.conf.hashCode() = 971317217
2020-06-19 02:12:37,031 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/rep_barrier
msx-reconfagent conf 971317217 itself is unique for hbase:AbstractMemStore 389707333
msx-reconfagent performReconf for comoponent hbase:AbstractMemStore 389707333 uniqueConf 971317217 originConf 971317217
msx-reconfagent hbase:AbstractMemStore init 389707333, irrelevant component. Set value as v1 true
msx-debug MemStoreLAB:newInstance isEnabled(conf) = true
msx-debug MemStoreLABImpl<init> before ChunkCreator.getInstance()
msx-debug this.chunkCreator is null
msx-debug Segment:<init> memStoreLAB = org.apache.hadoop.hbase.regionserver.MemStoreLABImpl@48e3c420
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:86)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:84)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> memStoreLAB = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:72)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> segment = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:124)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.<init>(ImmutableSegment.java:68)
	at org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.<init>(CSLMImmutableSegment.java:40)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:79)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:73)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:37,035 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(174): Created cacheConfig: cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false for family {NAME => 'rep_barrier', VERSIONS => '2147483647', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '65536'} with blockCache=null
2020-06-19 02:12:37,037 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(147): size [128 MB, 8.00 EB, 8.00 EB); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2020-06-19 02:12:37,039 INFO  [StoreOpener-1588230740-1] regionserver.HStore(336): Store=rep_barrier,  memstore type=DefaultMemStore, storagePolicy=HOT, verifyBulkLoads=false, parallelPutCountPrintThreshold=50, encoding=NONE, compression=NONE
msx-debug HStore:<init> this.conf.hashCode() = 1508430026
2020-06-19 02:12:37,044 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/table
msx-reconfagent conf 1508430026 itself is unique for hbase:AbstractMemStore 497294828
msx-reconfagent performReconf for comoponent hbase:AbstractMemStore 497294828 uniqueConf 1508430026 originConf 1508430026
msx-reconfagent hbase:AbstractMemStore init 497294828, irrelevant component. Set value as v1 true
msx-debug MemStoreLAB:newInstance isEnabled(conf) = true
msx-debug MemStoreLABImpl<init> before ChunkCreator.getInstance()
msx-debug this.chunkCreator is null
msx-debug Segment:<init> memStoreLAB = org.apache.hadoop.hbase.regionserver.MemStoreLABImpl@e41c396
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:86)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:84)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> memStoreLAB = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:72)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> segment = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:124)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.<init>(ImmutableSegment.java:68)
	at org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.<init>(CSLMImmutableSegment.java:40)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:79)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:73)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:37,048 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(174): Created cacheConfig: cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false for family {NAME => 'table', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'} with blockCache=null
2020-06-19 02:12:37,049 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(147): size [128 MB, 8.00 EB, 8.00 EB); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2020-06-19 02:12:37,051 INFO  [StoreOpener-1588230740-1] regionserver.HStore(336): Store=table,  memstore type=DefaultMemStore, storagePolicy=HOT, verifyBulkLoads=false, parallelPutCountPrintThreshold=50, encoding=NONE, compression=NONE
2020-06-19 02:12:37,059 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(4669): Found 0 recovered edits file(s) under hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740
2020-06-19 02:12:37,062 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(4669): Found 0 recovered edits file(s) under hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740
2020-06-19 02:12:37,085 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.FlushLargeStoresPolicy(61): No hbase.hregion.percolumnfamilyflush.size.lower.bound set in table hbase:meta descriptor;using region.getMemStoreFlushHeapSize/# of families (42.7M)) instead.
2020-06-19 02:12:37,092 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(1029): writing seq id for 1588230740
2020-06-19 02:12:37,100 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] wal.WALSplitUtil(421): Wrote file=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/recovered.edits/1.seqid, newMaxSeqId=1, maxSeqId=-1
2020-06-19 02:12:37,102 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(1046): Opened 1588230740; next sequenceid=2
2020-06-19 02:12:37,102 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(945): Region open journal:
null at 1592532756905
	Writing region info on filesystem at 1592532756906
	Initializing all the Stores at 1592532756910
	Instantiating store for column family {NAME => 'info', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'false', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'false', BLOCKSIZE => '8192'} at 1592532756911
	Instantiating store for column family {NAME => 'rep_barrier', VERSIONS => '2147483647', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '65536'} at 1592532756912
	Instantiating store for column family {NAME => 'table', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'} at 1592532756913
	Cleaning up temporary data from old regions at 1592532757068
	Cleaning up detritus from prior splits at 1592532757077
	Region opened successfully at 1592532757102
2020-06-19 02:12:37,102 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(1597): Closing 1588230740, disabling compactions & flushes
2020-06-19 02:12:37,103 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(1637): Updates disabled for region hbase:meta,,1.1588230740
2020-06-19 02:12:37,104 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(1754): Closed hbase:meta,,1.1588230740
2020-06-19 02:12:37,105 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] regionserver.HRegion(1552): Region close journal:
null at 1592532757102
	Waiting for close lock at 1592532757102
	Disabling compacts and flushes for region at 1592532757102
	Disabling writes for close at 1592532757103
	Writing region close event to WAL at 1592532757104
	Closed at 1592532757104
2020-06-19 02:12:37,548 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] util.FSTableDescriptors(684): Wrote into hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2020-06-19 02:12:37,589 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] fs.HFileSystem(348): Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2020-06-19 02:12:37,606 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] coordination.ZKSplitLogManagerCoordination(494): Found 0 orphan tasks and 0 rescan nodes
2020-06-19 02:12:37,607 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: SplitLogManager Timeout Monitor Period: 1000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:37,667 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ReadOnlyZKClient(142): Connect 0x240781c7 to localhost:55163 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
2020-06-19 02:12:37,704 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] ipc.AbstractRpcClient(202): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@b628065, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=true, bind address=null
msx-reconfagent WARN: conf 922300450 is shared with component hbase:HMaster, let copy and return new conf 749382957
msx-reconfagent performReconf for comoponent hbase:WALProcedureStore 1043639867 uniqueConf 749382957 originConf 922300450
msx-reconfagent hbase:WALProcedureStore init 1043639867, irrelevant component. Set value as v1 true
2020-06-19 02:12:37,741 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.ProcedureExecutor(568): Starting 16 core workers (bigger of cpus/4 or 16) with max (burst) worker count=160
2020-06-19 02:12:37,744 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] wal.WALProcedureStore(405): Starting WAL Procedure Store lease recovery
2020-06-19 02:12:37,751 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] util.CommonFSUtils$DfsBuilderUtility(789): org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder not available, will not use builder API for file creation.
2020-06-19 02:12:37,756 WARN  [master/a83bc24e6e49:0:becomeActiveMaster] util.CommonFSUtils$StreamCapabilities(906): Your Hadoop installation does not include the StreamCapabilities class from HDFS-11644, so we will skip checking if any FSDataOutputStreams actually support hflush/hsync. If you are running on top of HDFS this probably just means you have an older version and this can be ignored. If you are running on top of an alternate FileSystem implementation you should manually verify that hflush and hsync are implemented; otherwise you risk data loss and hard to diagnose errors when our assumptions are violated.
2020-06-19 02:12:37,756 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] util.CommonFSUtils$StreamCapabilities(913): The first request to check for StreamCapabilities came from this stacktrace.
java.lang.ClassNotFoundException: org.apache.hadoop.fs.StreamCapabilities
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:419)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:352)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.hbase.util.CommonFSUtils$StreamCapabilities.<clinit>(CommonFSUtils.java:902)
	at org.apache.hadoop.hbase.util.CommonFSUtils.hasCapability(CommonFSUtils.java:940)
	at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.rollWriter(WALProcedureStore.java:1093)
	at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.recoverLease(WALProcedureStore.java:426)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.init(ProcedureExecutor.java:586)
	at org.apache.hadoop.hbase.master.HMaster.createProcedureExecutor(HMaster.java:1524)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:939)
	at org.apache.hadoop.hbase.master.HMaster.startActiveMasterManager(HMaster.java:2125)
	at org.apache.hadoop.hbase.master.HMaster.lambda$run$0(HMaster.java:581)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:37,763 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] wal.WALProcedureStore(1138): Rolled new Procedure Store WAL, id=1
2020-06-19 02:12:37,765 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] wal.WALProcedureStore(440): Lease acquired for flushLogId=1
2020-06-19 02:12:37,765 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.ProcedureExecutor(588): Recovered WALProcedureStore lease in 20msec
2020-06-19 02:12:37,767 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] wal.WALProcedureStore(458): No state logs to replay.
2020-06-19 02:12:37,767 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.ProcedureExecutor(602): Loaded WALProcedureStore in 1msec
2020-06-19 02:12:37,768 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.RemoteProcedureDispatcher(94): Instantiated, coreThreads=128 (allowCoreThreadTimeOut=true), queueMaxSize=32, operationDelay=150
2020-06-19 02:12:37,814 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(612): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server because node does not exist (not an error)
2020-06-19 02:12:37,826 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.RegionServerTracker(123): Starting RegionServerTracker; 0 have existing ServerCrashProcedures, 0 possibly 'live' servers, and 0 'splitting'.
2020-06-19 02:12:37,870 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] balancer.BaseLoadBalancer(1051): slop=0.001, systemTablesOnMaster=false
2020-06-19 02:12:37,875 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] balancer.StochasticLoadBalancer(213): Loaded config; maxSteps=1000000, stepsPerRegion=800, maxRunningTime=30000, isByTable=false, etc.
2020-06-19 02:12:37,877 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2020-06-19 02:12:37,878 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/normalizer
2020-06-19 02:12:37,882 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/switch/split
2020-06-19 02:12:37,883 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/switch/merge
2020-06-19 02:12:37,896 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2020-06-19 02:12:37,897 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2020-06-19 02:12:37,897 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.HMaster(795): Active/primary master=a83bc24e6e49,44913,1592532754956, sessionid=0x172ca595eb70000, setting cluster-up flag (Was=false)
2020-06-19 02:12:37,916 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure.ZKProcedureUtil(272): Clearing all znodes /hbase/flush-table-proc/acquired, /hbase/flush-table-proc/reached, /hbase/flush-table-proc/abort
2020-06-19 02:12:37,917 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure.ZKProcedureCoordinator(250): Starting controller for procedure member=a83bc24e6e49,44913,1592532754956
2020-06-19 02:12:37,925 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure.ZKProcedureUtil(272): Clearing all znodes /hbase/online-snapshot/acquired, /hbase/online-snapshot/reached, /hbase/online-snapshot/abort
2020-06-19 02:12:37,927 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure.ZKProcedureCoordinator(250): Starting controller for procedure member=a83bc24e6e49,44913,1592532754956
2020-06-19 02:12:37,929 WARN  [master/a83bc24e6e49:0:becomeActiveMaster] snapshot.SnapshotManager(300): Couldn't delete working snapshot directory: hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/.hbase-snapshot/.tmp
msx-reconfagent WARN: conf 922300450 is shared with component hbase:HMaster, let copy and return new conf 290060215
msx-reconfagent performReconf for comoponent hbase:ReplicationPeerConfigUpgrader 1015116611 uniqueConf 290060215 originConf 922300450
msx-reconfagent hbase:ReplicationPeerConfigUpgrader init 1015116611, irrelevant component. Set value as v1 true
2020-06-19 02:12:37,974 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.HMaster(1013): hbase:meta {1588230740 state=OFFLINE, ts=1592532757817, server=null}
2020-06-19 02:12:38,006 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(928): ClusterId : e27dd020-6e8a-4212-81ae-3ae4917c0416
2020-06-19 02:12:38,012 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(45): Procedure flush-table-proc initializing
2020-06-19 02:12:38,018 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(47): Procedure flush-table-proc initialized
2020-06-19 02:12:38,018 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot initializing
2020-06-19 02:12:38,021 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(47): Procedure online-snapshot initialized
2020-06-19 02:12:38,022 DEBUG [RS:0;a83bc24e6e49:45768] zookeeper.ReadOnlyZKClient(142): Connect 0x29e56185 to localhost:55163 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
2020-06-19 02:12:38,028 DEBUG [RS:0;a83bc24e6e49:45768] ipc.AbstractRpcClient(202): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2ddaf061, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=true, bind address=null
2020-06-19 02:12:38,029 DEBUG [RS:0;a83bc24e6e49:45768] ipc.AbstractRpcClient(202): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@68d86bbe, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=true, bind address=a83bc24e6e49/172.17.0.6:0
msx-reconfagent WARN: conf 1058993535 is shared with component hbase:HRegionServer, let copy and return new conf 1527881639
msx-reconfagent performReconf for comoponent hbase:ShutdownHook_install static uniqueConf 1527881639 originConf 1058993535
msx-reconfagent hbase:ShutdownHook_install init static, irrelevant component. Set value as v1 true
2020-06-19 02:12:38,036 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.ShutdownHook(90): Installed shutdown hook thread: Shutdownhook:RS:0;a83bc24e6e49:45768
2020-06-19 02:12:38,041 INFO  [RS:0;a83bc24e6e49:45768] regionserver.RegionServerCoprocessorHost(67): System coprocessor loading is enabled
2020-06-19 02:12:38,041 INFO  [RS:0;a83bc24e6e49:45768] regionserver.RegionServerCoprocessorHost(68): Table coprocessor loading is enabled
2020-06-19 02:12:38,041 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(997): About to register with Master.
2020-06-19 02:12:38,044 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(2693): reportForDuty to master=a83bc24e6e49,44913,1592532754956 with port=45768, startcode=1592532755920
2020-06-19 02:12:38,128 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.ProcedureExecutor(1043): Stored pid=1, state=RUNNABLE:INIT_META_ASSIGN_META; InitMetaProcedure table=hbase:meta
2020-06-19 02:12:38,134 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=0 size=1) to run queue because: the exclusive lock is not held by anyone when adding pid=1, state=RUNNABLE:INIT_META_ASSIGN_META; InitMetaProcedure table=hbase:meta
2020-06-19 02:12:38,142 INFO  [RS-EventLoopGroup-1-2] ipc.ServerRpcConnection(556): Connection from 172.17.0.6:50559, version=2.2.4, sasl=false, ugi=root.hfs.0 (auth:SIMPLE), service=RegionServerStatusService
2020-06-19 02:12:38,149 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=MASTER_OPEN_REGION-master/a83bc24e6e49:0, corePoolSize=5, maxPoolSize=5
2020-06-19 02:12:38,149 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=MASTER_CLOSE_REGION-master/a83bc24e6e49:0, corePoolSize=5, maxPoolSize=5
2020-06-19 02:12:38,149 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=MASTER_SERVER_OPERATIONS-master/a83bc24e6e49:0, corePoolSize=5, maxPoolSize=5
2020-06-19 02:12:38,149 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=MASTER_META_SERVER_OPERATIONS-master/a83bc24e6e49:0, corePoolSize=5, maxPoolSize=5
2020-06-19 02:12:38,150 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=M_LOG_REPLAY_OPS-master/a83bc24e6e49:0, corePoolSize=10, maxPoolSize=10
2020-06-19 02:12:38,150 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=MASTER_SNAPSHOT_OPERATIONS-master/a83bc24e6e49:0, corePoolSize=1, maxPoolSize=1
2020-06-19 02:12:38,150 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] executor.ExecutorService(99): Starting executor service name=MASTER_TABLE_OPERATIONS-master/a83bc24e6e49:0, corePoolSize=1, maxPoolSize=1
2020-06-19 02:12:38,155 DEBUG [PEWorker-1] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=false sharedLock=0 size=0) from run queue because: queue is empty after polling out pid=1, state=RUNNABLE:INIT_META_ASSIGN_META; InitMetaProcedure table=hbase:meta
2020-06-19 02:12:38,157 DEBUG [PEWorker-1] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=true (1) sharedLock=0 size=0) from run queue because: pid=1, state=RUNNABLE:INIT_META_ASSIGN_META; InitMetaProcedure table=hbase:meta held the exclusive lock
2020-06-19 02:12:38,160 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.TimeoutExecutorThread(80): ADDED pid=-1, state=WAITING_TIMEOUT; org.apache.hadoop.hbase.procedure2.CompletedProcedureCleaner; timeout=30000, timestamp=1592532788160
2020-06-19 02:12:38,165 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.DirScanPool(49): Cleaner pool size is 10
2020-06-19 02:12:38,166 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.CleanerChore(157): Initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2020-06-19 02:12:38,168 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] zookeeper.RecoverableZooKeeper(106): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:55163
2020-06-19 02:12:38,170 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.CleanerChore(157): Initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2020-06-19 02:12:38,172 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.CleanerChore(157): Initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner
2020-06-19 02:12:38,173 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.LogCleaner(143): Creating 2 OldWALs cleaner threads
2020-06-19 02:12:38,173 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster-EventThread] zookeeper.ZKWatcher(477): replicationLogCleaner0x0, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2020-06-19 02:12:38,174 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster-EventThread] zookeeper.ZKWatcher(542): replicationLogCleaner-0x172ca595eb70004 connected
2020-06-19 02:12:38,174 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: LogsCleaner Period: 600000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:38,178 INFO  [PEWorker-1] procedure2.ProcedureExecutor(1697): Initialized subprocedures=[{pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN}]
2020-06-19 02:12:38,179 DEBUG [PEWorker-1] procedure2.RootProcedureState(151): Add procedure pid=1, state=WAITING, locked=true; InitMetaProcedure table=hbase:meta as the 0th rollback step
2020-06-19 02:12:38,180 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.CleanerChore(157): Initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2020-06-19 02:12:38,182 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.CleanerChore(157): Initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2020-06-19 02:12:38,184 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.CleanerChore(157): Initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2020-06-19 02:12:38,186 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.HFileCleaner(228): Starting for large file=Thread[master/a83bc24e6e49:0:becomeActiveMaster-HFileCleaner.large.0-1592532758186,5,FailOnTimeoutGroup]
2020-06-19 02:12:38,187 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] cleaner.HFileCleaner(243): Starting for small files=Thread[master/a83bc24e6e49:0:becomeActiveMaster-HFileCleaner.small.0-1592532758186,5,FailOnTimeoutGroup]
2020-06-19 02:12:38,187 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: HFileCleaner Period: 600000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:38,189 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: ReplicationBarrierCleaner Period: 43200000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:38,192 DEBUG [PEWorker-1] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=true (1) sharedLock=0 size=1) to run queue because: pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN has the excusive lock access
2020-06-19 02:12:38,192 DEBUG [PEWorker-2] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=true (1) sharedLock=0 size=0) from run queue because: queue is empty after polling out pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN
2020-06-19 02:12:38,194 INFO  [PEWorker-2] procedure.MasterProcedureScheduler(737): Took xlock for pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN
2020-06-19 02:12:38,196 DEBUG [PEWorker-1] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=1 size=0) to run queue because: pid=1, state=WAITING; InitMetaProcedure table=hbase:meta released the exclusive lock
2020-06-19 02:12:38,225 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(2713): Master is not running yet
2020-06-19 02:12:38,226 WARN  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1005): reportForDuty failed; sleeping 1000 ms and then retrying.
2020-06-19 02:12:38,298 INFO  [PEWorker-2] assignment.TransitRegionStateProcedure(189): Starting pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN; rit=OFFLINE, location=null; forceNewPlan=false, retain=false
2020-06-19 02:12:38,299 DEBUG [PEWorker-2] procedure2.RootProcedureState(151): Add procedure pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_OPEN, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN as the 1th rollback step
2020-06-19 02:12:38,449 WARN  [master/a83bc24e6e49:0] assignment.AssignmentManager(1944): No servers available; cannot place 1 unassigned regions.
2020-06-19 02:12:39,227 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(2693): reportForDuty to master=a83bc24e6e49,44913,1592532754956 with port=45768, startcode=1592532755920
2020-06-19 02:12:39,237 INFO  [RpcServer.default.FPBQ.Fifo.handler=4,queue=0,port=44913] master.ServerManager(403): Registering regionserver=a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,247 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1574): Config from master: hbase.rootdir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3
2020-06-19 02:12:39,247 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1574): Config from master: fs.defaultFS=hdfs://localhost:35543
2020-06-19 02:12:39,247 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1574): Config from master: hbase.master.info.port=-1
2020-06-19 02:12:39,254 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2020-06-19 02:12:39,255 DEBUG [RS:0;a83bc24e6e49:45768] zookeeper.ZKUtil(354): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,255 WARN  [RS:0;a83bc24e6e49:45768] hbase.ZNodeClearer(63): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2020-06-19 02:12:39,258 INFO  [RegionServerTracker-0] master.RegionServerTracker(182): RegionServer ephemeral node created, adding [a83bc24e6e49,45768,1592532755920]
2020-06-19 02:12:39,277 DEBUG [RS:0;a83bc24e6e49:45768] asyncfs.FanOutOneBlockAsyncDFSOutputHelper(252): ClientProtocol::create wrong number of arguments, should be hadoop 2.x
2020-06-19 02:12:39,281 DEBUG [RS:0;a83bc24e6e49:45768] asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper(245): No decryptEncryptedDataEncryptionKey method in DFSClient, should be hadoop version with HDFS-12396
java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(org.apache.hadoop.fs.FileEncryptionInfo)
	at java.lang.Class.getDeclaredMethod(Class.java:2130)
	at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.createTransparentCryptoHelperWithoutHDFS12396(FanOutOneBlockAsyncDFSOutputSaslHelper.java:184)
	at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.createTransparentCryptoHelper(FanOutOneBlockAsyncDFSOutputSaslHelper.java:243)
	at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.<clinit>(FanOutOneBlockAsyncDFSOutputSaslHelper.java:254)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.load(AsyncFSWALProvider.java:137)
	at org.apache.hadoop.hbase.wal.WALFactory.getProviderClass(WALFactory.java:136)
	at org.apache.hadoop.hbase.wal.WALFactory.getProvider(WALFactory.java:175)
	at org.apache.hadoop.hbase.wal.WALFactory.<init>(WALFactory.java:198)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.setupWALAndReplication(HRegionServer.java:1879)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.handleReportForDutyResponse(HRegionServer.java:1596)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.handleReportForDutyResponse(MiniHBaseCluster.java:157)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1008)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.runRegionServer(MiniHBaseCluster.java:184)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.access$000(MiniHBaseCluster.java:130)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer$1.run(MiniHBaseCluster.java:168)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1824)
	at org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:341)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.run(MiniHBaseCluster.java:165)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:39,282 INFO  [RS:0;a83bc24e6e49:45768] wal.WALFactory(158): Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.AsyncFSWALProvider
2020-06-19 02:12:39,287 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1886): logDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/WALs/a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,303 DEBUG [RS:0;a83bc24e6e49:45768] zookeeper.ZKUtil(354): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,310 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.Replication(131): Replication stats-in-log period=300 seconds
2020-06-19 02:12:39,323 INFO  [RS:0;a83bc24e6e49:45768] regionserver.MetricsRegionServerWrapperImpl(150): Computing regionserver metrics every 5000 milliseconds
2020-06-19 02:12:39,353 INFO  [RS:0;a83bc24e6e49:45768] regionserver.MemStoreFlusher(132): globalMemStoreLimit=995.6 M, globalMemStoreLimitLowMark=945.8 M, Offheap=false
2020-06-19 02:12:39,361 INFO  [RS:0;a83bc24e6e49:45768] throttle.PressureAwareCompactionThroughputController(134): Compaction throughput configurations, higher bound: 100.00 MB/second, lower bound 50.00 MB/second, off peak: unlimited, tuning period: 60000 ms
2020-06-19 02:12:39,362 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: CompactionThroughputTuner Period: 60000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:39,365 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer$CompactionChecker(1775): CompactionChecker runs every PT1S
2020-06-19 02:12:39,381 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: CompactedHFilesCleaner Period: 120000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:39,382 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_OPEN_REGION-regionserver/a83bc24e6e49:0, corePoolSize=3, maxPoolSize=3
2020-06-19 02:12:39,383 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_OPEN_META-regionserver/a83bc24e6e49:0, corePoolSize=1, maxPoolSize=1
2020-06-19 02:12:39,383 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_OPEN_PRIORITY_REGION-regionserver/a83bc24e6e49:0, corePoolSize=3, maxPoolSize=3
2020-06-19 02:12:39,383 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_CLOSE_REGION-regionserver/a83bc24e6e49:0, corePoolSize=3, maxPoolSize=3
2020-06-19 02:12:39,384 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_CLOSE_META-regionserver/a83bc24e6e49:0, corePoolSize=1, maxPoolSize=1
2020-06-19 02:12:39,384 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_LOG_REPLAY_OPS-regionserver/a83bc24e6e49:0, corePoolSize=2, maxPoolSize=2
2020-06-19 02:12:39,384 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_COMPACTED_FILES_DISCHARGER-regionserver/a83bc24e6e49:0, corePoolSize=10, maxPoolSize=10
2020-06-19 02:12:39,384 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_REGION_REPLICA_FLUSH_OPS-regionserver/a83bc24e6e49:0, corePoolSize=3, maxPoolSize=3
2020-06-19 02:12:39,385 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_REFRESH_PEER-regionserver/a83bc24e6e49:0, corePoolSize=2, maxPoolSize=2
2020-06-19 02:12:39,385 DEBUG [RS:0;a83bc24e6e49:45768] executor.ExecutorService(99): Starting executor service name=RS_SWITCH_RPC_THROTTLE-regionserver/a83bc24e6e49:0, corePoolSize=1, maxPoolSize=1
2020-06-19 02:12:39,387 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: CompactionChecker Period: 1000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:39,387 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: MemstoreFlusherChore Period: 1000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:39,387 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: nonceCleaner Period: 360000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:39,387 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: MovedRegionsCleaner for region a83bc24e6e49,45768,1592532755920 Period: 120000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:39,419 INFO  [SplitLogWorker-a83bc24e6e49:45768] regionserver.SplitLogWorker(139): SplitLogWorker a83bc24e6e49,45768,1592532755920 starting
2020-06-19 02:12:39,429 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HeapMemoryManager(210): Starting, tuneOn=false
2020-06-19 02:12:39,433 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(157): Chore [ScheduledChore: Name: a83bc24e6e49,45768,1592532755920-HeapMemoryTunerChore Period: 60000 Unit: MILLISECONDS] is enabled.
msx-debug HRegionServer:initializeMemStoreChunkCreator MemStoreLAB.isEnabled = false
2020-06-19 02:12:39,452 DEBUG [master/a83bc24e6e49:0] assignment.AssignmentManager(1965): Processing assignQueue; systemServersCount=1, allServersCount=1
2020-06-19 02:12:39,455 DEBUG [master/a83bc24e6e49:0] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=1 size=1) to run queue because: pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_OPEN, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN has lock
2020-06-19 02:12:39,456 DEBUG [PEWorker-7] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=false sharedLock=1 size=0) from run queue because: queue is empty after polling out pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_OPEN, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN
2020-06-19 02:12:39,456 INFO  [PEWorker-7] zookeeper.MetaTableLocator(237): Setting hbase:meta (replicaId=0) location in ZooKeeper as a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,464 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1616): Serving as a83bc24e6e49,45768,1592532755920, RpcServer on a83bc24e6e49/172.17.0.6:45768, sessionid=0x172ca595eb70001
2020-06-19 02:12:39,465 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(53): Procedure flush-table-proc starting
2020-06-19 02:12:39,465 DEBUG [RS:0;a83bc24e6e49:45768] flush.RegionServerFlushTableProcedureManager(104): Start region server flush procedure manager a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,465 DEBUG [RS:0;a83bc24e6e49:45768] procedure.ZKProcedureMemberRpcs(357): Starting procedure member 'a83bc24e6e49,45768,1592532755920'
2020-06-19 02:12:39,465 DEBUG [RS:0;a83bc24e6e49:45768] procedure.ZKProcedureMemberRpcs(135): Checking for aborted procedures on node: '/hbase/flush-table-proc/abort'
2020-06-19 02:12:39,466 DEBUG [RS:0;a83bc24e6e49:45768] procedure.ZKProcedureMemberRpcs(155): Looking for new procedures under znode:'/hbase/flush-table-proc/acquired'
2020-06-19 02:12:39,467 DEBUG [PEWorker-7] zookeeper.MetaTableLocator(251): META region location doesn't exist, create it
2020-06-19 02:12:39,467 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(55): Procedure flush-table-proc started
2020-06-19 02:12:39,467 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot starting
2020-06-19 02:12:39,468 DEBUG [RS:0;a83bc24e6e49:45768] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,468 DEBUG [RS:0;a83bc24e6e49:45768] procedure.ZKProcedureMemberRpcs(357): Starting procedure member 'a83bc24e6e49,45768,1592532755920'
2020-06-19 02:12:39,468 DEBUG [RS:0;a83bc24e6e49:45768] procedure.ZKProcedureMemberRpcs(135): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2020-06-19 02:12:39,469 DEBUG [RS:0;a83bc24e6e49:45768] procedure.ZKProcedureMemberRpcs(155): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2020-06-19 02:12:39,469 DEBUG [RS:0;a83bc24e6e49:45768] procedure.RegionServerProcedureManagerHost(55): Procedure online-snapshot started
2020-06-19 02:12:39,469 INFO  [RS:0;a83bc24e6e49:45768] quotas.RegionServerRpcQuotaManager(67): Quota support disabled
2020-06-19 02:12:39,469 INFO  [RS:0;a83bc24e6e49:45768] quotas.RegionServerSpaceQuotaManager(84): Quota support disabled, not starting space quota manager.
2020-06-19 02:12:39,475 INFO  [PEWorker-7] procedure2.ProcedureExecutor(1697): Initialized subprocedures=[{pid=3, ppid=2, state=RUNNABLE; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure}]
2020-06-19 02:12:39,476 DEBUG [PEWorker-7] procedure2.RootProcedureState(151): Add procedure pid=2, ppid=1, state=WAITING:REGION_STATE_TRANSITION_CONFIRM_OPENED, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN as the 2th rollback step
2020-06-19 02:12:39,489 DEBUG [PEWorker-7] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=1 size=1) to run queue because: the exclusive lock is not held by anyone when adding pid=3, ppid=2, state=RUNNABLE; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure
2020-06-19 02:12:39,490 DEBUG [PEWorker-3] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=false sharedLock=1 size=0) from run queue because: queue is empty after polling out pid=3, ppid=2, state=RUNNABLE; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure
2020-06-19 02:12:39,494 DEBUG [PEWorker-3] procedure2.RootProcedureState(151): Add procedure pid=3, ppid=2, state=RUNNABLE, locked=true; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure as the 3th rollback step
2020-06-19 02:12:39,686 DEBUG [RSProcedureDispatcher-pool3-t1] master.ServerManager(710): New admin connection to a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:39,697 INFO  [RS-EventLoopGroup-3-4] ipc.ServerRpcConnection(556): Connection from 172.17.0.6:51528, version=2.2.4, sasl=false, ugi=root (auth:SIMPLE), service=AdminService
2020-06-19 02:12:39,707 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] handler.AssignRegionHandler(123): Open hbase:meta,,1.1588230740
2020-06-19 02:12:39,707 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] wal.WALFactory(158): Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.AsyncFSWALProvider
msx-reconfagent WARN: conf 1058993535 is shared with component hbase:HRegionServer, let copy and return new conf 102423252
msx-reconfagent performReconf for comoponent hbase:AbstractFSWAL 1809030156 uniqueConf 102423252 originConf 1058993535
msx-reconfagent hbase:AbstractFSWAL init 1809030156, irrelevant component. Set value as v1 true
2020-06-19 02:12:39,733 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] wal.AbstractFSWAL(423): WAL configuration: blocksize=256 MB, rollsize=128 MB, prefix=a83bc24e6e49%2C45768%2C1592532755920.meta, suffix=.meta, logDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/WALs/a83bc24e6e49,45768,1592532755920, archiveDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/oldWALs
2020-06-19 02:12:39,762 DEBUG [RS-EventLoopGroup-3-5] asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper(737): SASL client skipping handshake in unsecured configuration for addr = 127.0.0.1/127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:41379,DS-19c80b35-43b2-45db-aa37-f2b21bc9e057,DISK]
2020-06-19 02:12:39,793 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] wal.AbstractFSWAL(689): New WAL /user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/WALs/a83bc24e6e49,45768,1592532755920/a83bc24e6e49%2C45768%2C1592532755920.meta.1592532759748.meta
2020-06-19 02:12:39,794 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] wal.AbstractFSWAL(775): Create new AsyncFSWAL writer with pipeline: [DatanodeInfoWithStorage[127.0.0.1:41379,DS-19c80b35-43b2-45db-aa37-f2b21bc9e057,DISK]]
2020-06-19 02:12:39,795 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(7294): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
msx-debug HRegion:<init> this.conf.hashCode() = 1861847835
2020-06-19 02:12:39,825 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] coprocessor.CoprocessorHost(214): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2020-06-19 02:12:39,843 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(8257): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2020-06-19 02:12:39,850 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.RegionCoprocessorHost(393): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2020-06-19 02:12:39,855 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.MetricsRegionSourceImpl(75): Creating new MetricsRegionSourceImpl for table meta 1588230740
2020-06-19 02:12:39,856 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(855): Instantiated hbase:meta,,1.1588230740; StoreHotnessProtector, parallelPutToStoreThreadLimit=10 ; minColumnNum=100 ; preparePutThreadLimit=20 ; hotProtect now enable
msx-debug HStore:<init> this.conf.hashCode() = 769307648
2020-06-19 02:12:39,869 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/info
2020-06-19 02:12:39,869 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/info
msx-reconfagent conf 769307648 itself is unique for hbase:AbstractMemStore 702883171
msx-reconfagent performReconf for comoponent hbase:AbstractMemStore 702883171 uniqueConf 769307648 originConf 769307648
msx-reconfagent hbase:AbstractMemStore init 702883171, irrelevant component. Set value as v1 true
msx-debug MemStoreLAB:newInstance isEnabled(conf) = true
msx-debug MemStoreLABImpl<init> before ChunkCreator.getInstance()
msx-debug this.chunkCreator is null
msx-debug Segment:<init> memStoreLAB = org.apache.hadoop.hbase.regionserver.MemStoreLABImpl@25431862
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:86)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:84)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> memStoreLAB = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:72)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> segment = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:124)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.<init>(ImmutableSegment.java:68)
	at org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.<init>(CSLMImmutableSegment.java:40)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:79)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:73)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:39,874 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(174): Created cacheConfig: cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false for family {NAME => 'info', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'} with blockCache=LruBlockCache{blockCount=0, currentSize=747.70 KB, freeSize=994.87 MB, maxSize=995.60 MB, heapSize=747.70 KB, minSize=945.82 MB, minFactor=0.95, multiSize=472.91 MB, multiFactor=0.5, singleSize=236.46 MB, singleFactor=0.25}
2020-06-19 02:12:39,875 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(147): size [128 MB, 8.00 EB, 8.00 EB); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2020-06-19 02:12:39,877 INFO  [StoreOpener-1588230740-1] regionserver.HStore(336): Store=info,  memstore type=DefaultMemStore, storagePolicy=HOT, verifyBulkLoads=false, parallelPutCountPrintThreshold=50, encoding=NONE, compression=NONE
msx-debug HStore:<init> this.conf.hashCode() = 1660174069
2020-06-19 02:12:39,879 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/rep_barrier
2020-06-19 02:12:39,880 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/rep_barrier
msx-reconfagent conf 1660174069 itself is unique for hbase:AbstractMemStore 1175126857
msx-reconfagent performReconf for comoponent hbase:AbstractMemStore 1175126857 uniqueConf 1660174069 originConf 1660174069
msx-reconfagent hbase:AbstractMemStore init 1175126857, irrelevant component. Set value as v1 true
msx-debug MemStoreLAB:newInstance isEnabled(conf) = true
msx-debug MemStoreLABImpl<init> before ChunkCreator.getInstance()
msx-debug this.chunkCreator is null
msx-debug Segment:<init> memStoreLAB = org.apache.hadoop.hbase.regionserver.MemStoreLABImpl@1728e97a
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:86)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:84)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> memStoreLAB = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:72)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> segment = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:124)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.<init>(ImmutableSegment.java:68)
	at org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.<init>(CSLMImmutableSegment.java:40)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:79)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:73)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:39,883 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(174): Created cacheConfig: cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false for family {NAME => 'rep_barrier', VERSIONS => '2147483647', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '65536'} with blockCache=LruBlockCache{blockCount=0, currentSize=747.70 KB, freeSize=994.87 MB, maxSize=995.60 MB, heapSize=747.70 KB, minSize=945.82 MB, minFactor=0.95, multiSize=472.91 MB, multiFactor=0.5, singleSize=236.46 MB, singleFactor=0.25}
2020-06-19 02:12:39,884 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(147): size [128 MB, 8.00 EB, 8.00 EB); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2020-06-19 02:12:39,885 INFO  [StoreOpener-1588230740-1] regionserver.HStore(336): Store=rep_barrier,  memstore type=DefaultMemStore, storagePolicy=HOT, verifyBulkLoads=false, parallelPutCountPrintThreshold=50, encoding=NONE, compression=NONE
msx-debug HStore:<init> this.conf.hashCode() = 1424523004
2020-06-19 02:12:39,888 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/table
2020-06-19 02:12:39,888 DEBUG [StoreOpener-1588230740-1] util.CommonFSUtils(532): Set storagePolicy=HOT for path=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/table
msx-reconfagent conf 1424523004 itself is unique for hbase:AbstractMemStore 1248280163
msx-reconfagent performReconf for comoponent hbase:AbstractMemStore 1248280163 uniqueConf 1424523004 originConf 1424523004
msx-reconfagent hbase:AbstractMemStore init 1248280163, irrelevant component. Set value as v1 true
msx-debug MemStoreLAB:newInstance isEnabled(conf) = true
msx-debug MemStoreLABImpl<init> before ChunkCreator.getInstance()
msx-debug this.chunkCreator is null
msx-debug Segment:<init> memStoreLAB = org.apache.hadoop.hbase.regionserver.MemStoreLABImpl@23a3ecd2
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:86)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:84)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> memStoreLAB = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:104)
	at org.apache.hadoop.hbase.regionserver.MutableSegment.<init>(MutableSegment.java:52)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.generateMutableSegment(SegmentFactory.java:149)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:72)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
msx-debug Segment:<init> segment = null
Printing stack trace:
	at org.apache.hadoop.hbase.regionserver.Segment.<init>(Segment.java:124)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.<init>(ImmutableSegment.java:68)
	at org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.<init>(CSLMImmutableSegment.java:40)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:79)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:73)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:85)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.<init>(DefaultMemStore.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(NativeConstructorAccessorImpl.java:-2)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:58)
	at org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:72)
	at org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:363)
	at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:282)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5806)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1092)
	at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1089)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:12:39,891 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(174): Created cacheConfig: cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false for family {NAME => 'table', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'} with blockCache=LruBlockCache{blockCount=0, currentSize=747.70 KB, freeSize=994.87 MB, maxSize=995.60 MB, heapSize=747.70 KB, minSize=945.82 MB, minFactor=0.95, multiSize=472.91 MB, multiFactor=0.5, singleSize=236.46 MB, singleFactor=0.25}
2020-06-19 02:12:39,892 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(147): size [128 MB, 8.00 EB, 8.00 EB); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2020-06-19 02:12:39,893 INFO  [StoreOpener-1588230740-1] regionserver.HStore(336): Store=table,  memstore type=DefaultMemStore, storagePolicy=HOT, verifyBulkLoads=false, parallelPutCountPrintThreshold=50, encoding=NONE, compression=NONE
2020-06-19 02:12:39,897 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(4669): Found 0 recovered edits file(s) under hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740
2020-06-19 02:12:39,901 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(4669): Found 0 recovered edits file(s) under hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740
2020-06-19 02:12:39,905 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.FlushLargeStoresPolicy(61): No hbase.hregion.percolumnfamilyflush.size.lower.bound set in table hbase:meta descriptor;using region.getMemStoreFlushHeapSize/# of families (42.7M)) instead.
2020-06-19 02:12:39,909 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(1029): writing seq id for 1588230740
2020-06-19 02:12:39,912 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(1046): Opened 1588230740; next sequenceid=2
2020-06-19 02:12:39,912 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(945): Region open journal:
null at 1592532759858
	Running coprocessor pre-open hook at 1592532759858
	Writing region info on filesystem at 1592532759859
	Initializing all the Stores at 1592532759861
	Instantiating store for column family {NAME => 'info', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'} at 1592532759861
	Instantiating store for column family {NAME => 'rep_barrier', VERSIONS => '2147483647', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '65536'} at 1592532759862
	Instantiating store for column family {NAME => 'table', VERSIONS => '3', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'NONE', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'} at 1592532759862
	Cleaning up temporary data from old regions at 1592532759902
	Cleaning up detritus from prior splits at 1592532759903
	Running coprocessor post-open hooks at 1592532759912
	Region opened successfully at 1592532759912
2020-06-19 02:12:39,953 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegionServer(2267): Post open deploy tasks for hbase:meta,,1.1588230740, openProcId=3, masterSystemTime=1592532759665
2020-06-19 02:12:40,078 DEBUG [RpcServer.metaPriority.FPBQ.Fifo.handler=0,queue=0,port=44913] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=1 size=1) to run queue because: the exclusive lock is not held by anyone when adding pid=3, ppid=2, state=RUNNABLE; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure
2020-06-19 02:12:40,079 DEBUG [PEWorker-8] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=false sharedLock=1 size=0) from run queue because: queue is empty after polling out pid=3, ppid=2, state=RUNNABLE; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure
2020-06-19 02:12:40,083 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegionServer(2292): Finished post open deploy task for hbase:meta,,1.1588230740
2020-06-19 02:12:40,084 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] handler.AssignRegionHandler(141): Opened hbase:meta,,1.1588230740
2020-06-19 02:12:40,085 INFO  [PEWorker-8] zookeeper.MetaTableLocator(237): Setting hbase:meta (replicaId=0) location in ZooKeeper as a83bc24e6e49,45768,1592532755920
2020-06-19 02:12:40,088 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/meta-region-server
2020-06-19 02:12:40,089 DEBUG [PEWorker-8] procedure2.RootProcedureState(151): Add procedure pid=3, ppid=2, state=SUCCESS, locked=true; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure as the 4th rollback step
2020-06-19 02:12:40,097 DEBUG [PEWorker-8] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=1 size=1) to run queue because: pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_CONFIRM_OPENED, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN has lock
2020-06-19 02:12:40,098 INFO  [PEWorker-8] procedure2.ProcedureExecutor(1837): Finished subprocedure pid=3, resume processing parent pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_CONFIRM_OPENED, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN
2020-06-19 02:12:40,098 DEBUG [PEWorker-9] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=false sharedLock=1 size=0) from run queue because: queue is empty after polling out pid=2, ppid=1, state=RUNNABLE:REGION_STATE_TRANSITION_CONFIRM_OPENED, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN
2020-06-19 02:12:40,098 INFO  [PEWorker-8] procedure2.ProcedureExecutor(1427): Finished pid=3, ppid=2, state=SUCCESS; org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure in 614msec
2020-06-19 02:12:40,099 DEBUG [PEWorker-9] procedure2.RootProcedureState(151): Add procedure pid=2, ppid=1, state=SUCCESS, locked=true; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN as the 5th rollback step
2020-06-19 02:12:40,105 DEBUG [PEWorker-9] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=0 size=0) to run queue because: pid=2, ppid=1, state=SUCCESS; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN released the shared lock
2020-06-19 02:12:40,108 DEBUG [PEWorker-9] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=0 size=1) to run queue because: the exclusive lock is not held by anyone when adding pid=1, state=RUNNABLE; InitMetaProcedure table=hbase:meta
2020-06-19 02:12:40,108 INFO  [PEWorker-9] procedure2.ProcedureExecutor(1837): Finished subprocedure pid=2, resume processing parent pid=1, state=RUNNABLE; InitMetaProcedure table=hbase:meta
2020-06-19 02:12:40,108 DEBUG [PEWorker-10] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=false sharedLock=0 size=0) from run queue because: queue is empty after polling out pid=1, state=RUNNABLE; InitMetaProcedure table=hbase:meta
2020-06-19 02:12:40,108 INFO  [PEWorker-9] procedure2.ProcedureExecutor(1427): Finished pid=2, ppid=1, state=SUCCESS; TransitRegionStateProcedure table=hbase:meta, region=1588230740, ASSIGN in 1.9220sec
2020-06-19 02:12:40,109 DEBUG [PEWorker-10] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:meta, xlock=true (1) sharedLock=0 size=0) from run queue because: pid=1, state=RUNNABLE; InitMetaProcedure table=hbase:meta held the exclusive lock
2020-06-19 02:12:40,111 DEBUG [PEWorker-10] procedure2.RootProcedureState(151): Add procedure pid=1, state=SUCCESS, locked=true; InitMetaProcedure table=hbase:meta as the 6th rollback step
2020-06-19 02:12:40,119 DEBUG [PEWorker-10] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:meta, xlock=false sharedLock=0 size=0) to run queue because: pid=1, state=SUCCESS; InitMetaProcedure table=hbase:meta released the exclusive lock
2020-06-19 02:12:40,119 INFO  [PEWorker-10] procedure2.ProcedureExecutor(1427): Finished pid=1, state=SUCCESS; InitMetaProcedure table=hbase:meta in 2.1340sec
2020-06-19 02:12:40,119 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.HMaster(1048): Master startup: status=Wait for region servers to report in, state=RUNNING, startTime=1592532756033, completionTime=-1
2020-06-19 02:12:40,120 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.ServerManager(821): Finished waiting on RegionServer count=1; waited=0ms, expected min=1 server(s), max=1 server(s), master is running
2020-06-19 02:12:40,120 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] assignment.AssignmentManager(1351): Joining cluster...
2020-06-19 02:12:40,216 INFO  [RS-EventLoopGroup-3-7] ipc.ServerRpcConnection(556): Connection from 172.17.0.6:51532, version=2.2.4, sasl=false, ugi=root (auth:SIMPLE), service=ClientService
2020-06-19 02:12:40,260 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] assignment.AssignmentManager(1363): Number of RegionServers=1
2020-06-19 02:12:40,260 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.TimeoutExecutorThread(80): ADDED pid=-1, state=WAITING_TIMEOUT; org.apache.hadoop.hbase.master.assignment.AssignmentManager$RegionInTransitionChore; timeout=60000, timestamp=1592532820260
2020-06-19 02:12:40,260 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.TimeoutExecutorThread(80): ADDED pid=-1, state=WAITING_TIMEOUT; org.apache.hadoop.hbase.master.assignment.AssignmentManager$DeadServerMetricRegionChore; timeout=120000, timestamp=1592532880260
2020-06-19 02:12:40,260 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] assignment.AssignmentManager(1370): Joined the cluster in 140msec
2020-06-19 02:12:40,296 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: a83bc24e6e49,44913,1592532754956-ClusterStatusChore Period: 60000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:40,297 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: a83bc24e6e49,44913,1592532754956-BalancerChore Period: 300000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:40,297 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: a83bc24e6e49,44913,1592532754956-RegionNormalizerChore Period: 300000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:40,299 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: CatalogJanitor-a83bc24e6e49:44913 Period: 300000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:40,299 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] hbase.ChoreService(157): Chore [ScheduledChore: Name: HbckChore- Period: 3600000 Unit: MILLISECONDS] is enabled.
2020-06-19 02:12:40,334 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.TableNamespaceManager(96): Namespace table not found. Creating...
2020-06-19 02:12:40,336 INFO  [master/a83bc24e6e49:0:becomeActiveMaster] master.HMaster(2082): Client=null/null create 'hbase:namespace', {NAME => 'info', VERSIONS => '10', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'ROW', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'}
2020-06-19 02:12:40,450 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure2.ProcedureExecutor(1043): Stored pid=4, state=RUNNABLE:CREATE_TABLE_PRE_OPERATION; CreateTableProcedure table=hbase:namespace
2020-06-19 02:12:40,450 DEBUG [master/a83bc24e6e49:0:becomeActiveMaster] procedure.MasterProcedureScheduler(352): Add TableQueue(hbase:namespace, xlock=false sharedLock=0 size=1) to run queue because: the exclusive lock is not held by anyone when adding pid=4, state=RUNNABLE:CREATE_TABLE_PRE_OPERATION; CreateTableProcedure table=hbase:namespace
2020-06-19 02:12:40,451 DEBUG [PEWorker-4] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:namespace, xlock=false sharedLock=0 size=0) from run queue because: queue is empty after polling out pid=4, state=RUNNABLE:CREATE_TABLE_PRE_OPERATION; CreateTableProcedure table=hbase:namespace
2020-06-19 02:12:40,452 DEBUG [PEWorker-4] procedure.MasterProcedureScheduler(362): Remove TableQueue(hbase:namespace, xlock=true (4) sharedLock=0 size=0) from run queue because: pid=4, state=RUNNABLE:CREATE_TABLE_PRE_OPERATION; CreateTableProcedure table=hbase:namespace held the exclusive lock
2020-06-19 02:12:40,462 DEBUG [PEWorker-4] procedure2.RootProcedureState(151): Add procedure pid=4, state=RUNNABLE:CREATE_TABLE_WRITE_FS_LAYOUT, locked=true; CreateTableProcedure table=hbase:namespace as the 0th rollback step
2020-06-19 02:12:40,478 DEBUG [HFileArchiver-1] backup.HFileArchiver(133): ARCHIVING hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/.tmp/data/hbase/namespace/87d9cd97da3b5fd5acdc3b068e006077
2020-06-19 02:12:40,481 DEBUG [HFileArchiver-1] backup.HFileArchiver(156): Directory hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/.tmp/data/hbase/namespace/87d9cd97da3b5fd5acdc3b068e006077 empty.
2020-06-19 02:12:40,483 DEBUG [HFileArchiver-1] backup.HFileArchiver(569): Failed to delete directory hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/.tmp/data/hbase/namespace/87d9cd97da3b5fd5acdc3b068e006077
2020-06-19 02:12:40,483 DEBUG [PEWorker-4] procedure.DeleteTableProcedure(322): Table 'hbase:namespace' archived!
msx-reconfagent WARN: conf 1058993535 is shared with component hbase:HRegionServer, let copy and return new conf 1422790790
msx-reconfagent performReconf for comoponent hbase:AbstractFSWAL 197359092 uniqueConf 1422790790 originConf 1058993535
msx-reconfagent hbase:AbstractFSWAL init 197359092, irrelevant component. Set value as v1 true
2020-06-19 02:12:40,491 INFO  [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(423): WAL configuration: blocksize=256 MB, rollsize=128 MB, prefix=a83bc24e6e49%2C45768%2C1592532755920, suffix=, logDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/WALs/a83bc24e6e49,45768,1592532755920, archiveDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/oldWALs
2020-06-19 02:12:40,509 DEBUG [RS-EventLoopGroup-3-8] asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper(737): SASL client skipping handshake in unsecured configuration for addr = 127.0.0.1/127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:41379,DS-19c80b35-43b2-45db-aa37-f2b21bc9e057,DISK]
2020-06-19 02:12:40,525 INFO  [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(689): New WAL /user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/WALs/a83bc24e6e49,45768,1592532755920/a83bc24e6e49%2C45768%2C1592532755920.1592532760496
2020-06-19 02:12:40,526 DEBUG [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(775): Create new AsyncFSWAL writer with pipeline: [DatanodeInfoWithStorage[127.0.0.1:41379,DS-19c80b35-43b2-45db-aa37-f2b21bc9e057,DISK]]
2020-06-19 02:12:40,930 DEBUG [PEWorker-4] util.FSTableDescriptors(684): Wrote into hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2020-06-19 02:12:40,935 INFO  [RegionOpenAndInitThread-hbase:namespace-pool7-t1] regionserver.HRegion(7106): creating {ENCODED => 87d9cd97da3b5fd5acdc3b068e006077, NAME => 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.', STARTKEY => '', ENDKEY => ''}, tableDescriptor='hbase:namespace', {NAME => 'info', VERSIONS => '10', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'ROW', CACHE_INDEX_ON_WRITE => 'false', IN_MEMORY => 'true', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '8192'}, regionDir=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/.tmp
msx-debug HRegion:<init> this.conf.hashCode() = 860996384
2020-06-19 02:12:41,357 DEBUG [RegionOpenAndInitThread-hbase:namespace-pool7-t1] regionserver.HRegion(855): Instantiated hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.; StoreHotnessProtector, parallelPutToStoreThreadLimit=10 ; minColumnNum=100 ; preparePutThreadLimit=20 ; hotProtect now enable
2020-06-19 02:12:41,358 DEBUG [RegionOpenAndInitThread-hbase:namespace-pool7-t1] regionserver.HRegion(1597): Closing 87d9cd97da3b5fd5acdc3b068e006077, disabling compactions & flushes
2020-06-19 02:12:41,358 DEBUG [RegionOpenAndInitThread-hbase:namespace-pool7-t1] regionserver.HRegion(1637): Updates disabled for region hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.
2020-06-19 02:12:41,358 INFO  [RegionOpenAndInitThread-hbase:namespace-pool7-t1] regionserver.HRegion(1754): Closed hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.
2020-06-19 02:12:41,358 DEBUG [RegionOpenAndInitThread-hbase:namespace-pool7-t1] regionserver.HRegion(1552): Region close journal:
null at 1592532761358
	Waiting for close lock at 1592532761358
	Disabling compacts and flushes for region at 1592532761358
	Disabling writes for close at 1592532761358
	Writing region close event to WAL at 1592532761358
	Closed at 1592532761358
2020-06-19 02:12:41,364 DEBUG [PEWorker-4] procedure2.RootProcedureState(151): Add procedure pid=4, state=RUNNABLE:CREATE_TABLE_ADD_TO_META, locked=true; CreateTableProcedure table=hbase:namespace as the 1th rollback step
2020-06-19 02:12:41,385 DEBUG [PEWorker-4] hbase.MetaTableAccessor(2178): Put {"totalColumns":2,"row":"hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.","families":{"info":[{"qualifier":"regioninfo","vlen":41,"tag":[],"timestamp":"1592532761372"},{"qualifier":"state","vlen":6,"tag":[],"timestamp":"1592532761372"}]},"ts":"1592532761372"}
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:41,434 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:41,435 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 6 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532821406, exception=java.io.IOException
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:41,548 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:41,549 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 7 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532821544, exception=java.io.IOException
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:41,757 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:41,758 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 8 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532821754, exception=java.io.IOException
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:42,068 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:42,069 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 9 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532822065, exception=java.io.IOException
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:42,581 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:42,582 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 10 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532822578, exception=java.io.IOException
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:43,590 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:43,591 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 11 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532823587, exception=java.io.IOException
2020-06-19 02:12:45,367 WARN  [HBase-Metrics2-1] impl.MetricsConfig(128): Cannot locate configuration: tried hadoop-metrics2-hbase.properties,hadoop-metrics2.properties
2020-06-19 02:12:45,461 DEBUG [HBase-Metrics2-1] impl.GlobalMetricRegistriesAdapter(135): Registering adapter for the MetricRegistry: RegionServer,sub=Coprocessor.Region.CP_org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2020-06-19 02:12:45,463 INFO  [HBase-Metrics2-1] impl.GlobalMetricRegistriesAdapter(139): Registering RegionServer,sub=Coprocessor.Region.CP_org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint Metrics about HBase RegionObservers
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:45,602 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:45,603 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 12 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532825599, exception=java.io.IOException
2020-06-19 02:12:45,606 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=6, retries=46, started=4219 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:49,619 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:49,619 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 13 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532829616, exception=java.io.IOException
2020-06-19 02:12:49,622 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=7, retries=46, started=8235 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:12:53,160 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 12.7080sec
2020-06-19 02:12:58,161 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 17.7090sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:12:59,685 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:12:59,687 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 14 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532839682, exception=java.io.IOException
2020-06-19 02:12:59,690 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=8, retries=46, started=18303 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:13:03,162 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 22.7090sec
2020-06-19 02:13:08,163 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 27.7110sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:13:09,779 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:13:09,789 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 15 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532849776, exception=java.io.IOException
2020-06-19 02:13:09,792 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=9, retries=46, started=28405 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:13:13,163 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 32.7110sec
2020-06-19 02:13:18,164 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 37.7120sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:13:19,844 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:13:19,845 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 16 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532859840, exception=java.io.IOException
2020-06-19 02:13:19,848 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=10, retries=46, started=38461 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:13:23,165 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 42.7120sec
2020-06-19 02:13:28,165 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 47.7130sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:13:29,946 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:13:29,948 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 17 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532869943, exception=java.io.IOException
2020-06-19 02:13:29,950 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=11, retries=46, started=48563 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:13:33,166 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 52.7140sec
2020-06-19 02:13:38,166 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 57.7140sec
2020-06-19 02:13:43,167 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 2.715sec
2020-06-19 02:13:48,167 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 7.715sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:13:50,094 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:13:50,095 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 18 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532890091, exception=java.io.IOException
2020-06-19 02:13:50,099 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=12, retries=46, started=68711 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:13:53,168 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 12.716sec
2020-06-19 02:13:58,168 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 17.716sec
2020-06-19 02:14:03,169 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 22.717sec
2020-06-19 02:14:08,169 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 27.717sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:14:10,185 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:14:10,186 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 19 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532910182, exception=java.io.IOException
2020-06-19 02:14:10,189 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=13, retries=46, started=88802 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:14:13,170 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 32.717sec
2020-06-19 02:14:18,170 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 37.718sec
2020-06-19 02:14:23,170 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 42.718sec
2020-06-19 02:14:28,171 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 47.719sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:14:30,321 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:14:30,322 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 20 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532930318, exception=java.io.IOException
2020-06-19 02:14:30,325 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=14, retries=46, started=108938 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:14:33,171 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 52.719sec
2020-06-19 02:14:38,172 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 1mins, 57.72sec
2020-06-19 02:14:43,172 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 2.72sec
2020-06-19 02:14:48,173 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 7.721sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:14:50,346 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:14:50,349 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 21 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532950340, exception=java.io.IOException
2020-06-19 02:14:50,353 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=15, retries=46, started=128966 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:14:53,173 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 12.721sec
2020-06-19 02:14:58,175 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 17.723sec
2020-06-19 02:15:03,175 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 22.723sec
2020-06-19 02:15:08,176 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 27.724sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:15:10,551 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:15:10,552 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 22 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532970547, exception=java.io.IOException
2020-06-19 02:15:10,554 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=16, retries=46, started=149167 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:15:13,176 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 32.724sec
2020-06-19 02:15:18,176 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 37.724sec
2020-06-19 02:15:23,176 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 42.724sec
2020-06-19 02:15:28,177 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 47.725sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:15:30,632 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:15:30,633 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 23 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592532990629, exception=java.io.IOException
2020-06-19 02:15:30,635 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=17, retries=46, started=169248 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:15:33,177 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 52.725sec
2020-06-19 02:15:38,177 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 2mins, 57.725sec
2020-06-19 02:15:43,178 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 3mins, 2.726sec
2020-06-19 02:15:48,178 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 3mins, 7.726sec
msx-debug Segment:maybeCloneWithAllocator memStoreLAB is not null
msx-debug MemStoreLABImpl:getOrMakeChunk
msx-debug MemStoreLABImpl:getOrMakeChunk this.chunkCreator is null
2020-06-19 02:15:50,666 ERROR [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.RpcServer(471): Unexpected throwable object 
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
2020-06-19 02:15:50,667 DEBUG [RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768] ipc.CallRunner(145): callId: 24 service: ClientService methodName: Mutate size: 217 connection: 172.17.0.6:51532 deadline: 1592533010663, exception=java.io.IOException
2020-06-19 02:15:50,669 DEBUG [PEWorker-4] client.RpcRetryingCallerImpl(132): Call exception, tries=18, retries=46, started=189282 ms ago, cancelled=false, msg=java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more
, details=row 'hbase:namespace,,1592532760335.87d9cd97da3b5fd5acdc3b068e006077.' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=a83bc24e6e49,45768,1592532755920, seqNum=-1, see https://s.apache.org/timeout, exception=java.io.IOException: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:99)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:89)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:282)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:269)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:129)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
	at org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
	at org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:472)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.getOrMakeChunk(MemStoreLABImpl.java:347)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:195)
	at org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.copyCellInto(MemStoreLABImpl.java:117)
	at org.apache.hadoop.hbase.regionserver.Segment.maybeCloneWithAllocator(Segment.java:192)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.maybeCloneWithAllocator(AbstractMemStore.java:336)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAdd(AbstractMemStore.java:159)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.doAddOrUpsert(AbstractMemStore.java:149)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:119)
	at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113)
	at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:775)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemStore(HRegion.java:4496)
	at org.apache.hadoop.hbase.regionserver.HRegion.access$500(HRegion.java:230)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.applyFamilyMapToMemStore(HRegion.java:3551)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.lambda$writeMiniBatchOperationsToMemStore$0(HRegion.java:3242)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.visitBatchOperations(HRegion.java:3175)
	at org.apache.hadoop.hbase.regionserver.HRegion$BatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3234)
	at org.apache.hadoop.hbase.regionserver.HRegion$MutationBatchOperation.writeMiniBatchOperationsToMemStore(HRegion.java:3716)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:4134)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:4063)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3994)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3985)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:3999)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:4330)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3118)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2895)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:42276)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
	... 3 more

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:389)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:97)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:423)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:419)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:117)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:132)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.readResponse(NettyRpcDuplexHandler.java:162)
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.channelRead(NettyRpcDuplexHandler.java:192)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323)
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:337)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:345)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:796)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:427)
	at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:328)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2020-06-19 02:15:53,179 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 3mins, 12.727sec
Process Thread Dump: Thread dump because: Master not initialized after 200000ms
197 active threads
Thread 463 (RS_COMPACTED_FILES_DISCHARGER-regionserver/a83bc24e6e49:0-2):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@28df4cd
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 462 (RS_COMPACTED_FILES_DISCHARGER-regionserver/a83bc24e6e49:0-1):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@28df4cd
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 461 (RS_COMPACTED_FILES_DISCHARGER-regionserver/a83bc24e6e49:0-0):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@28df4cd
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 453 (Timer for 'HBase' metrics system):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 20
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 447 (AsyncFSWAL-0):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@39bd01f7
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 444 (PacketResponder: BP-483853614-172.17.0.6-1592532751314:blk_1073741831_1007, type=LAST_IN_PIPELINE):
  State: WAITING
  Blocked count: 7
  Waited count: 8
  Waiting on java.util.LinkedList@23be592
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.waitForAckHead(BlockReceiver.java:1251)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1323)
    java.lang.Thread.run(Thread.java:748)
Thread 442 (DataXceiver for client DFSClient_NONMAPREDUCE_-82120035_25 at /127.0.0.1:49406 [Receiving block BP-483853614-172.17.0.6-1592532751314:blk_1073741831_1007]):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
    org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
    java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
    java.io.BufferedInputStream.read(BufferedInputStream.java:345)
    java.io.DataInputStream.read(DataInputStream.java:149)
    org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:206)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:521)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:923)
    org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:854)
Thread 441 (RS-EventLoopGroup-3-8):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 435 (RS-EventLoopGroup-3-7):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 434 (RS-EventLoopGroup-3-6):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 431 (AsyncFSWAL-0):
  State: WAITING
  Blocked count: 0
  Waited count: 40
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5c564403
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 430 (PacketResponder: BP-483853614-172.17.0.6-1592532751314:blk_1073741830_1006, type=LAST_IN_PIPELINE):
  State: WAITING
  Blocked count: 21
  Waited count: 22
  Waiting on java.util.LinkedList@d3554c7
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.waitForAckHead(BlockReceiver.java:1251)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1323)
    java.lang.Thread.run(Thread.java:748)
Thread 429 (DataXceiver for client DFSClient_NONMAPREDUCE_-82120035_25 at /127.0.0.1:49402 [Receiving block BP-483853614-172.17.0.6-1592532751314:blk_1073741830_1006]):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
    org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
    java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
    java.io.BufferedInputStream.read(BufferedInputStream.java:345)
    java.io.DataInputStream.read(DataInputStream.java:149)
    org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:206)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:521)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:923)
    org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:854)
Thread 428 (RS-EventLoopGroup-3-5):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 2
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 427 (LeaseRenewer:root.hfs.0@localhost:35543):
  State: TIMED_WAITING
  Blocked count: 6
  Waited count: 211
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
    org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
    org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
    java.lang.Thread.run(Thread.java:748)
Thread 426 (RS_CLOSE_META-regionserver/a83bc24e6e49:0-0):
  State: WAITING
  Blocked count: 23
  Waited count: 48
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@507f3786
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 425 (RS-EventLoopGroup-3-4):
  State: RUNNABLE
  Blocked count: 2
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 424 (RS-EventLoopGroup-3-3):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 421 (a83bc24e6e49:45768Replication Statistics #0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 420 (ReplicationExecutor-0):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@77964770
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 419 (SplitLogWorker-a83bc24e6e49:45768):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 43
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.taskLoop(ZkSplitLogWorkerCoordination.java:444)
    org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:147)
    java.lang.Thread.run(Thread.java:748)
Thread 412 (regionserver/a83bc24e6e49:0.leaseChecker):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 199
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.regionserver.Leases.run(Leases.java:95)
    java.lang.Thread.run(Thread.java:748)
Thread 414 (regionserver/a83bc24e6e49:0.procedureResultReporter):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@34d6713c
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.regionserver.RemoteProcedureResultReporter.run(RemoteProcedureResultReporter.java:77)
Thread 417 (MemStoreFlusher.1):
  State: TIMED_WAITING
  Blocked count: 3
  Waited count: 200
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.DelayQueue.poll(DelayQueue.java:259)
    java.util.concurrent.DelayQueue.poll(DelayQueue.java:70)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:335)
    java.lang.Thread.run(Thread.java:748)
Thread 415 (MemStoreFlusher.0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 202
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.DelayQueue.poll(DelayQueue.java:259)
    java.util.concurrent.DelayQueue.poll(DelayQueue.java:70)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:335)
    java.lang.Thread.run(Thread.java:748)
Thread 413 (regionserver/a83bc24e6e49:0.logRoller):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 199
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:163)
    java.lang.Thread.run(Thread.java:748)
Thread 411 (regionserver/a83bc24e6e49:0.Chore.1):
  State: TIMED_WAITING
  Blocked count: 3
  Waited count: 368
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 410 (RS:0;a83bc24e6e49:45768-longCompactions-0):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@939a55e
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    org.apache.hadoop.hbase.util.StealJobQueue.take(StealJobQueue.java:106)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 409 (JvmPauseMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 398
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:154)
    java.lang.Thread.run(Thread.java:748)
Thread 407 (RegionServerTracker-0):
  State: WAITING
  Blocked count: 1
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@ff39c95
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 406 (master/a83bc24e6e49:0:becomeActiveMaster-HFileCleaner.small.0-1592532758186):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@ac6afd6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:550)
    org.apache.hadoop.hbase.master.cleaner.HFileCleaner.consumerLoop(HFileCleaner.java:253)
    org.apache.hadoop.hbase.master.cleaner.HFileCleaner$2.run(HFileCleaner.java:237)
Thread 405 (master/a83bc24e6e49:0:becomeActiveMaster-HFileCleaner.large.0-1592532758186):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4e91f885
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    org.apache.hadoop.hbase.util.StealJobQueue.take(StealJobQueue.java:106)
    org.apache.hadoop.hbase.master.cleaner.HFileCleaner.consumerLoop(HFileCleaner.java:253)
    org.apache.hadoop.hbase.master.cleaner.HFileCleaner$1.run(HFileCleaner.java:222)
Thread 404 (snapshot-hfile-cleaner-cache-refresher):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 403 (master/a83bc24e6e49:0.Chore.1):
  State: TIMED_WAITING
  Blocked count: 4
  Waited count: 19
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 402 (OldWALsCleaner-1):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@74e48003
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.master.cleaner.LogCleaner.deleteFile(LogCleaner.java:167)
    org.apache.hadoop.hbase.master.cleaner.LogCleaner.lambda$createOldWalsCleaner$0(LogCleaner.java:147)
    org.apache.hadoop.hbase.master.cleaner.LogCleaner$$Lambda$145/1295746159.run(Unknown Source)
    java.lang.Thread.run(Thread.java:748)
Thread 401 (OldWALsCleaner-0):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@74e48003
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.master.cleaner.LogCleaner.deleteFile(LogCleaner.java:167)
    org.apache.hadoop.hbase.master.cleaner.LogCleaner.lambda$createOldWalsCleaner$0(LogCleaner.java:147)
    org.apache.hadoop.hbase.master.cleaner.LogCleaner$$Lambda$145/1295746159.run(Unknown Source)
    java.lang.Thread.run(Thread.java:748)
Thread 400 (master/a83bc24e6e49:0:becomeActiveMaster-EventThread):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@35f01bca
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:501)
Thread 399 (master/a83bc24e6e49:0:becomeActiveMaster-SendThread(localhost:55163)):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:349)
    org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
Thread 383 (PEWorker-16):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 382 (PEWorker-15):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 8
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 381 (PEWorker-14):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 380 (PEWorker-13):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 9
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 379 (PEWorker-12):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 8
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 378 (PEWorker-11):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 377 (PEWorker-10):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 8
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 376 (PEWorker-9):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 9
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 375 (PEWorker-8):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 10
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 374 (PEWorker-7):
  State: TIMED_WAITING
  Blocked count: 3
  Waited count: 10
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 373 (PEWorker-6):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 372 (PEWorker-5):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 9
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 371 (PEWorker-4):
  State: TIMED_WAITING
  Blocked count: 43
  Waited count: 105
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:168)
    org.apache.hadoop.hbase.client.HTable.put(HTable.java:540)
    org.apache.hadoop.hbase.MetaTableAccessor.putsToMetaTable(MetaTableAccessor.java:1390)
    org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1549)
    org.apache.hadoop.hbase.MetaTableAccessor.addRegionsToMeta(MetaTableAccessor.java:1521)
    org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addRegionsToMeta(CreateTableProcedure.java:394)
    org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.addTableToMeta(CreateTableProcedure.java:365)
    org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:105)
    org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.executeFromState(CreateTableProcedure.java:52)
    org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:194)
    org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:962)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1662)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1409)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$1100(ProcedureExecutor.java:78)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1979)
Thread 370 (PEWorker-3):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 9
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 369 (PEWorker-2):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 9
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 368 (PEWorker-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:168)
    org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.poll(AbstractProcedureScheduler.java:150)
    org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1967)
Thread 367 (WorkerMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 41
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.DelayQueue.take(DelayQueue.java:223)
    org.apache.hadoop.hbase.procedure2.util.DelayedUtil.takeWithoutInterrupt(DelayedUtil.java:82)
    org.apache.hadoop.hbase.procedure2.TimeoutExecutorThread.run(TimeoutExecutorThread.java:55)
Thread 366 (ProcExecTimeout):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 12
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.DelayQueue.take(DelayQueue.java:223)
    org.apache.hadoop.hbase.procedure2.util.DelayedUtil.takeWithoutInterrupt(DelayedUtil.java:82)
    org.apache.hadoop.hbase.procedure2.TimeoutExecutorThread.run(TimeoutExecutorThread.java:55)
Thread 398 (ResponseProcessor for block BP-483853614-172.17.0.6-1592532751314:blk_1073741829_1005):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
    org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
    java.io.FilterInputStream.read(FilterInputStream.java:83)
    java.io.FilterInputStream.read(FilterInputStream.java:83)
    org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:400)
    org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
    org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1073)
Thread 397 (PacketResponder: BP-483853614-172.17.0.6-1592532751314:blk_1073741829_1005, type=LAST_IN_PIPELINE):
  State: WAITING
  Blocked count: 31
  Waited count: 32
  Waiting on java.util.LinkedList@f2377d5
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.waitForAckHead(BlockReceiver.java:1251)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1323)
    java.lang.Thread.run(Thread.java:748)
Thread 396 (DataXceiver for client DFSClient_NONMAPREDUCE_-1603802076_25 at /127.0.0.1:49394 [Receiving block BP-483853614-172.17.0.6-1592532751314:blk_1073741829_1005]):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
    org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
    java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
    java.io.BufferedInputStream.read(BufferedInputStream.java:345)
    java.io.DataInputStream.read(DataInputStream.java:149)
    org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:206)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:521)
    org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:923)
    org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:854)
Thread 395 (RS-EventLoopGroup-1-2):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 363 (RpcClient-timer-pool1-t1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 20001
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hbase.thirdparty.io.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:579)
    org.apache.hbase.thirdparty.io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:478)
    java.lang.Thread.run(Thread.java:748)
Thread 394 (RS-EventLoopGroup-3-2):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 390 (ReadOnlyZKClient-localhost:55163@0x29e56185):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.DelayQueue.poll(DelayQueue.java:259)
    org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient.run(ReadOnlyZKClient.java:326)
    org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$77/1817365160.run(Unknown Source)
    java.lang.Thread.run(Thread.java:748)
Thread 336 (RS:0;a83bc24e6e49:45768):
  State: TIMED_WAITING
  Blocked count: 232
  Waited count: 443
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:81)
    org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:67)
    org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1066)
    org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.runRegionServer(MiniHBaseCluster.java:184)
    org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.access$000(MiniHBaseCluster.java:130)
    org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer$1.run(MiniHBaseCluster.java:168)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:360)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1824)
    org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:341)
    org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.run(MiniHBaseCluster.java:165)
    java.lang.Thread.run(Thread.java:748)
Thread 389 (ActiveMasterInitializationMonitor-1592532757931):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.master.HMaster$InitializationMonitor.run(HMaster.java:281)
    java.lang.Thread.run(Thread.java:748)
Thread 387 (SnapshotHandlerChoreCleaner):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 21
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 386 (master/a83bc24e6e49:0):
  State: WAITING
  Blocked count: 0
  Waited count: 7
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@8b1d090
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    org.apache.hadoop.hbase.master.assignment.AssignmentManager.waitOnAssignQueue(AssignmentManager.java:1893)
    org.apache.hadoop.hbase.master.assignment.AssignmentManager.processAssignQueue(AssignmentManager.java:1913)
    org.apache.hadoop.hbase.master.assignment.AssignmentManager.access$500(AssignmentManager.java:107)
    org.apache.hadoop.hbase.master.assignment.AssignmentManager$2.run(AssignmentManager.java:1855)
Thread 385 (ProcedureDispatcherTimeoutThread):
  State: WAITING
  Blocked count: 0
  Waited count: 3
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4ccd9686
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.DelayQueue.take(DelayQueue.java:211)
    org.apache.hadoop.hbase.procedure2.util.DelayedUtil.takeWithoutInterrupt(DelayedUtil.java:82)
    org.apache.hadoop.hbase.procedure2.RemoteProcedureDispatcher$TimeoutExecutorThread.run(RemoteProcedureDispatcher.java:309)
Thread 384 (DataStreamer for file /user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/MasterProcWALs/pv2-00000000000000000001.log block BP-483853614-172.17.0.6-1592532751314:blk_1073741829_1005):
  State: TIMED_WAITING
  Blocked count: 51
  Waited count: 59
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:672)
Thread 365 (WALProcedureStoreSyncThread):
  State: TIMED_WAITING
  Blocked count: 51
  Waited count: 82
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
    org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.syncLoop(WALProcedureStore.java:828)
    org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.access$000(WALProcedureStore.java:111)
    org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore$1.run(WALProcedureStore.java:316)
Thread 364 (Idle-Rpc-Conn-Sweeper-pool2-t1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 4
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 362 (ReadOnlyZKClient-localhost:55163@0x240781c7-EventThread):
  State: WAITING
  Blocked count: 0
  Waited count: 41
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@341ec9c8
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:501)
Thread 361 (ReadOnlyZKClient-localhost:55163@0x240781c7-SendThread(localhost:55163)):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:349)
    org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
Thread 360 (ReadOnlyZKClient-localhost:55163@0x240781c7):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 60
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.DelayQueue.poll(DelayQueue.java:259)
    org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient.run(ReadOnlyZKClient.java:326)
    org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$77/1817365160.run(Unknown Source)
    java.lang.Thread.run(Thread.java:748)
Thread 359 (Thread-102):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 201
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:672)
Thread 357 (master/a83bc24e6e49:0.splitLogManager..Chore.1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 202
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 340 (org.apache.hadoop.hdfs.PeerCache@2e5a3a4b):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 68
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:253)
    org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:46)
    org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:124)
    java.lang.Thread.run(Thread.java:748)
Thread 338 (Monitor thread for TaskMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 21
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.monitoring.TaskMonitor$MonitorRunnable.run(TaskMonitor.java:302)
    java.lang.Thread.run(Thread.java:748)
Thread 337 (master/a83bc24e6e49:0:becomeActiveMaster):
  State: TIMED_WAITING
  Blocked count: 144
  Waited count: 2208
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.master.TableNamespaceManager.start(TableNamespaceManager.java:110)
    org.apache.hadoop.hbase.master.ClusterSchemaServiceImpl.doStart(ClusterSchemaServiceImpl.java:63)
    org.apache.hbase.thirdparty.com.google.common.util.concurrent.AbstractService.startAsync(AbstractService.java:248)
    org.apache.hadoop.hbase.master.HMaster.initClusterSchemaService(HMaster.java:1323)
    org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:1107)
    org.apache.hadoop.hbase.master.HMaster.startActiveMasterManager(HMaster.java:2125)
    org.apache.hadoop.hbase.master.HMaster.lambda$run$0(HMaster.java:581)
    org.apache.hadoop.hbase.master.HMaster$$Lambda$33/118887253.run(Unknown Source)
    java.lang.Thread.run(Thread.java:748)
Thread 311 (M:0;a83bc24e6e49:44913):
  State: TIMED_WAITING
  Blocked count: 3
  Waited count: 219
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:81)
    org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:67)
    org.apache.hadoop.hbase.master.HMaster.waitForMasterActive(HMaster.java:691)
    org.apache.hadoop.hbase.regionserver.HRegionServer.initializeZooKeeper(HRegionServer.java:934)
    org.apache.hadoop.hbase.regionserver.HRegionServer.preRegistrationInitialization(HRegionServer.java:882)
    org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:981)
    org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:595)
    java.lang.Thread.run(Thread.java:748)
Thread 335 (RpcServer.metaPriority.FPBQ.Fifo.handler=0,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@63f80d04
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 334 (RpcServer.replication.FPBQ.Fifo.handler=2,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@10d1eb23
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 333 (RpcServer.replication.FPBQ.Fifo.handler=1,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@cc05f15
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 332 (RpcServer.replication.FPBQ.Fifo.handler=0,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@44e953a5
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 331 (RpcServer.priority.RWQ.Fifo.read.handler=5,queue=1,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@675af611
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 330 (RpcServer.priority.RWQ.Fifo.read.handler=4,queue=1,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@675af611
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 329 (RpcServer.priority.RWQ.Fifo.read.handler=3,queue=1,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@675af611
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 328 (RpcServer.priority.RWQ.Fifo.read.handler=2,queue=1,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@675af611
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 327 (RpcServer.priority.RWQ.Fifo.read.handler=1,queue=1,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 3
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@675af611
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 326 (RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=45768):
  State: WAITING
  Blocked count: 19
  Waited count: 39
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@78cd912a
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 325 (RpcServer.default.FPBQ.Fifo.handler=4,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@76fb41d1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 324 (RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@780150d0
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 323 (RpcServer.default.FPBQ.Fifo.handler=2,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@48dbcbbf
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 322 (RpcServer.default.FPBQ.Fifo.handler=1,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@5c0b474f
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 321 (RpcServer.default.FPBQ.Fifo.handler=0,queue=0,port=45768):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@70d260d6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 320 (Time-limited test-EventThread):
  State: WAITING
  Blocked count: 7
  Waited count: 6
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@22729cc
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:501)
Thread 319 (Time-limited test-SendThread(localhost:55163)):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:349)
    org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
Thread 318 (MobFileCache #0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 316 (LruBlockCacheStatsExecutor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 314 (Time-limited test.LruBlockCache.EvictionThread):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 21
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread.run(LruBlockCache.java:884)
    java.lang.Thread.run(Thread.java:748)
Thread 313 (RS-EventLoopGroup-3-1):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 310 (RpcServer.metaPriority.FPBQ.Fifo.handler=0,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 3
  Waiting on java.util.concurrent.Semaphore$NonfairSync@4ae5a807
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 309 (RpcServer.replication.FPBQ.Fifo.handler=2,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@621a5af3
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 308 (RpcServer.replication.FPBQ.Fifo.handler=1,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@740bd152
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 307 (RpcServer.replication.FPBQ.Fifo.handler=0,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@39c4ebc1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 306 (RpcServer.priority.RWQ.Fifo.read.handler=5,queue=1,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5e06d96e
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 305 (RpcServer.priority.RWQ.Fifo.read.handler=4,queue=1,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5e06d96e
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 304 (RpcServer.priority.RWQ.Fifo.read.handler=3,queue=1,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5e06d96e
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 303 (RpcServer.priority.RWQ.Fifo.read.handler=2,queue=1,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5e06d96e
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 302 (RpcServer.priority.RWQ.Fifo.read.handler=1,queue=1,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5e06d96e
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 301 (RpcServer.priority.RWQ.Fifo.write.handler=0,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 199
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@6efbdd9f
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner(RpcExecutor.java:309)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 300 (RpcServer.default.FPBQ.Fifo.handler=4,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 3
  Waiting on java.util.concurrent.Semaphore$NonfairSync@44501053
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 299 (RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@5ad461fb
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 298 (RpcServer.default.FPBQ.Fifo.handler=2,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@32710e66
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 297 (RpcServer.default.FPBQ.Fifo.handler=1,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@2d63a92
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 296 (RpcServer.default.FPBQ.Fifo.handler=0,queue=0,port=44913):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.concurrent.Semaphore$NonfairSync@46c07013
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
    org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner(FastPathBalancedQueueRpcExecutor.java:104)
    org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)
Thread 295 (Time-limited test-EventThread):
  State: WAITING
  Blocked count: 4
  Waited count: 11
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@3fe21a89
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:501)
Thread 294 (Time-limited test-SendThread(localhost:55163)):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:349)
    org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
Thread 293 (RS-EventLoopGroup-1-1):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:114)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:251)
    org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:276)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
    org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:748)
Thread 292 (HBase-Metrics2-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 67
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 287 (LeaseRenewer:root@localhost:35543):
  State: TIMED_WAITING
  Blocked count: 6
  Waited count: 216
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
    org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
    org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
    java.lang.Thread.run(Thread.java:748)
Thread 284 (ProcessThread(sid:0 cport:55163):):
  State: WAITING
  Blocked count: 0
  Waited count: 209
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@116c2e34
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.zookeeper.server.PrepRequestProcessor.run(PrepRequestProcessor.java:122)
Thread 283 (SyncThread:0):
  State: WAITING
  Blocked count: 1
  Waited count: 200
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@67c572ee
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:127)
Thread 282 (SessionTracker):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 103
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.zookeeper.server.SessionTrackerImpl.run(SessionTrackerImpl.java:146)
Thread 281 (NIOServerCxn.Factory:0.0.0.0/0.0.0.0:55163):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:173)
    java.lang.Thread.run(Thread.java:748)
Thread 279 (java.util.concurrent.ThreadPoolExecutor$Worker@32ea1592[State = -1, empty queue]):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 274 (refreshUsed-/root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/cluster_41a19304-2004-3bdd-2aa9-a2e65ee31048/dfs/data/data1/current/BP-483853614-172.17.0.6-1592532751314):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:176)
    java.lang.Thread.run(Thread.java:748)
Thread 273 (refreshUsed-/root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/cluster_41a19304-2004-3bdd-2aa9-a2e65ee31048/dfs/data/data2/current/BP-483853614-172.17.0.6-1592532751314):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:176)
    java.lang.Thread.run(Thread.java:748)
Thread 266 (VolumeScannerThread(/root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/cluster_41a19304-2004-3bdd-2aa9-a2e65ee31048/dfs/data/data2)):
  State: TIMED_WAITING
  Blocked count: 45
  Waited count: 2
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:627)
Thread 265 (VolumeScannerThread(/root/hbase-2.2.4/hbase-server/target/test-data/cdc56936-4ebf-9f5f-bba2-8a645dcf9baf/cluster_41a19304-2004-3bdd-2aa9-a2e65ee31048/dfs/data/data1)):
  State: TIMED_WAITING
  Blocked count: 5
  Waited count: 2
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:627)
Thread 262 (IPC Parameter Sending Thread #0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 223
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
    java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
    java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 261 (IPC Client (1763695868) connection to localhost/127.0.0.1:35543 from root):
  State: TIMED_WAITING
  Blocked count: 78
  Waited count: 79
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1014)
    org.apache.hadoop.ipc.Client$Connection.run(Client.java:1058)
Thread 260 (IPC Server handler 9 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 214
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 259 (IPC Server handler 8 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 216
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 258 (IPC Server handler 7 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 216
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 257 (IPC Server handler 6 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 219
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 256 (IPC Server handler 5 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 214
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 255 (IPC Server handler 4 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 223
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 254 (IPC Server handler 3 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 222
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 253 (IPC Server handler 2 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 213
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 252 (IPC Server handler 1 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 223
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 251 (IPC Server handler 0 on 45123):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 218
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 245 (IPC Server listener on 45123):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:1041)
Thread 248 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1216)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:1199)
Thread 76 (org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c2570c6):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
    sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
    org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
    org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
    java.lang.Thread.run(Thread.java:748)
Thread 250 (pool-7-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 249 (BP-483853614-172.17.0.6-1592532751314 heartbeating to localhost/127.0.0.1:35543):
  State: TIMED_WAITING
  Blocked count: 102
  Waited count: 238
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:130)
    org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:650)
    org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:775)
    java.lang.Thread.run(Thread.java:748)
Thread 247 (IPC Server idle connection scanner for port 45123):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 22
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 246 (Socket Reader #1 for port 45123):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:979)
    org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:958)
Thread 244 (org.apache.hadoop.util.JvmPauseMonitor$Monitor@32e78277):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 410
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:187)
    java.lang.Thread.run(Thread.java:748)
Thread 83 (nioEventLoopGroup-2-1):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)
    io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
    io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
    java.lang.Thread.run(Thread.java:748)
Thread 82 (Timer-5):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 81 (Timer-4):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 80 (Timer-3):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 79 (880516596@qtp-452420408-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45389):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:498)
    org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192)
    org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)
    org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708)
    org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Thread 78 (127168941@qtp-452420408-0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 4
  Stack:
    java.lang.Object.wait(Native Method)
    org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:626)
Thread 77 (pool-6-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 71 (CacheReplicationMonitor(1251519830)):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
    org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
Thread 70 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@d3153c):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:3997)
    java.lang.Thread.run(Thread.java:748)
Thread 69 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1324eb60):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:3906)
    java.lang.Thread.run(Thread.java:748)
Thread 68 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@f958ff1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 42
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:3864)
    java.lang.Thread.run(Thread.java:748)
Thread 67 (org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@5652d4d):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 106
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:414)
    java.lang.Thread.run(Thread.java:748)
Thread 65 (pool-5-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 64 (IPC Server handler 9 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 219
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 63 (IPC Server handler 8 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 220
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 62 (IPC Server handler 7 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 219
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 61 (IPC Server handler 6 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 220
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 60 (IPC Server handler 5 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 219
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 59 (IPC Server handler 4 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 221
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 58 (IPC Server handler 3 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 219
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 57 (IPC Server handler 2 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 220
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 56 (IPC Server handler 1 on 35543):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 221
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 55 (IPC Server handler 0 on 35543):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 221
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:286)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2475)
Thread 46 (IPC Server listener on 35543):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:1041)
Thread 49 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1216)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:1199)
Thread 43 (Block report processor):
  State: WAITING
  Blocked count: 0
  Waited count: 12
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@591904dd
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:4010)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:3999)
Thread 42 (ReplicationMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 70
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3750)
    java.lang.Thread.run(Thread.java:748)
Thread 44 (org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@3070bfae):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 42
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:419)
    java.lang.Thread.run(Thread.java:748)
Thread 54 (DecommissionMonitor-0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 69
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 53 (org.apache.hadoop.hdfs.server.blockmanagement.PendingReplicationBlocks$PendingReplicationMonitor@14aa7400):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.PendingReplicationBlocks$PendingReplicationMonitor.run(PendingReplicationBlocks.java:237)
    java.lang.Thread.run(Thread.java:748)
Thread 48 (IPC Server idle connection scanner for port 35543):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 22
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 47 (Socket Reader #1 for port 35543):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:979)
    org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:958)
Thread 45 (FSEditLogAsync):
  State: WAITING
  Blocked count: 0
  Waited count: 62
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@1bcc3a06
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.dequeueEdit(FSEditLogAsync.java:166)
    org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:174)
    java.lang.Thread.run(Thread.java:748)
Thread 41 (Timer-2):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 40 (Timer-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 39 (Timer-0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 7
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 38 (1456341796@qtp-1395578830-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44990):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:498)
    org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192)
    org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)
    org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708)
    org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Thread 37 (434361292@qtp-1395578830-0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 4
  Stack:
    java.lang.Object.wait(Native Method)
    org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:626)
Thread 36 (pool-3-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 34 (org.apache.hadoop.util.JvmPauseMonitor$Monitor@178537b1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 413
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:187)
    java.lang.Thread.run(Thread.java:748)
Thread 26 (org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.ref.ReferenceQueue$Lock@7b5beb40
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
    org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3213)
    java.lang.Thread.run(Thread.java:748)
Thread 25 (Time-limited test):
  State: RUNNABLE
  Blocked count: 61
  Waited count: 2071
  Stack:
    sun.management.ThreadImpl.getThreadInfo1(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:178)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:139)
    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:168)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    java.lang.reflect.Method.invoke(Method.java:498)
    org.apache.hadoop.hbase.util.Threads$PrintThreadInfoLazyHolder$1.printThreadInfo(Threads.java:294)
    org.apache.hadoop.hbase.util.Threads.printThreadInfo(Threads.java:341)
    org.apache.hadoop.hbase.util.JVMClusterUtil.waitForEvent(JVMClusterUtil.java:228)
    org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:197)
    org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:413)
    org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:259)
    org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:116)
    org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1142)
    org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1107)
    org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1061)
    org.apache.hadoop.hbase.client.TestAsyncBufferMutator.setUp(TestAsyncBufferMutator.java:80)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Thread 21 (surefire-forkedjvm-command-thread):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    java.io.FileInputStream.readBytes(Native Method)
    java.io.FileInputStream.read(FileInputStream.java:255)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
    java.io.BufferedInputStream.read(BufferedInputStream.java:265)
    java.io.DataInputStream.readInt(DataInputStream.java:387)
    org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:113)
    org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:383)
    java.lang.Thread.run(Thread.java:748)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 269
  Waited count: 175
  Waiting on java.lang.ref.ReferenceQueue$Lock@4ce08395
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 4
  Waited count: 4
  Waiting on java.lang.ref.Reference$Lock@f3a135c
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    java.lang.ref.Reference.tryHandlePending(Reference.java:191)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
Thread 1 (main):
  State: TIMED_WAITING
  Blocked count: 3
  Waited count: 3
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.FutureTask.awaitDone(FutureTask.java:426)
    java.util.concurrent.FutureTask.get(FutureTask.java:204)
    org.junit.internal.runners.statements.FailOnTimeout.getResult(FailOnTimeout.java:141)
    org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:127)
    org.junit.rules.RunRules.evaluate(RunRules.java:20)
    org.junit.runners.ParentRunner.run(ParentRunner.java:363)
    org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
    org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
    org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
    org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
    org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
    org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
    org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
    org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-06-19 02:15:58,174 ERROR [Time-limited test] hbase.MiniHBaseCluster(264): Error starting cluster
java.lang.RuntimeException: Master not initialized after 200000ms
	at org.apache.hadoop.hbase.util.JVMClusterUtil.waitForEvent(JVMClusterUtil.java:229)
	at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:197)
	at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:413)
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:259)
	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:116)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1142)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1107)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1061)
	at org.apache.hadoop.hbase.client.TestAsyncBufferMutator.setUp(TestAsyncBufferMutator.java:80)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
2020-06-19 02:15:58,177 DEBUG [Time-limited test] util.JVMClusterUtil(247): Shutting down HBase Cluster
2020-06-19 02:15:58,177 DEBUG [Time-limited test] util.JVMClusterUtil(267): Found active master hash=767488409, stopped=false
2020-06-19 02:15:58,177 INFO  [Time-limited test] master.ServerManager(897): Cluster shutdown requested of master=a83bc24e6e49,44913,1592532754956
2020-06-19 02:15:58,179 WARN  [WorkerMonitor] procedure2.ProcedureExecutor$WorkerMonitor(2082): Worker stuck PEWorker-4(pid=4), run time 3mins, 17.727sec
2020-06-19 02:15:58,181 INFO  [Time-limited test] procedure2.ProcedureExecutor(635): Stopping
2020-06-19 02:15:58,181 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2020-06-19 02:15:58,181 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2020-06-19 02:15:58,187 DEBUG [Time-limited test] zookeeper.ReadOnlyZKClient(363): Close zookeeper connection 0x240781c7 to localhost:55163
2020-06-19 02:15:58,187 DEBUG [Time-limited test-EventThread] zookeeper.ZKUtil(356): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2020-06-19 02:15:58,187 DEBUG [Time-limited test] ipc.AbstractRpcClient(497): Stopping rpc client
2020-06-19 02:15:58,187 DEBUG [Time-limited test-EventThread] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2020-06-19 02:15:58,190 INFO  [Time-limited test] regionserver.HRegionServer(2228): ***** STOPPING region server 'a83bc24e6e49,45768,1592532755920' *****
2020-06-19 02:15:58,191 INFO  [Time-limited test] regionserver.HRegionServer(2242): STOPPED: Shutdown requested
2020-06-19 02:15:58,191 INFO  [RS:0;a83bc24e6e49:45768] regionserver.SplitLogWorker(169): Sending interrupt to stop the worker thread
2020-06-19 02:15:58,192 INFO  [SplitLogWorker-a83bc24e6e49:45768] regionserver.SplitLogWorker(151): SplitLogWorker interrupted. Exiting. 
2020-06-19 02:15:58,193 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HeapMemoryManager(221): Stopping
2020-06-19 02:15:58,193 INFO  [SplitLogWorker-a83bc24e6e49:45768] regionserver.SplitLogWorker(160): SplitLogWorker a83bc24e6e49,45768,1592532755920 exiting
2020-06-19 02:15:58,195 INFO  [RS:0;a83bc24e6e49:45768] flush.RegionServerFlushTableProcedureManager(116): Stopping region server flush procedure manager gracefully.
2020-06-19 02:15:58,196 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(382): MemStoreFlusher.0 exiting
2020-06-19 02:15:58,196 INFO  [RS:0;a83bc24e6e49:45768] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2020-06-19 02:15:58,196 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(382): MemStoreFlusher.1 exiting
2020-06-19 02:15:58,197 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1140): stopping server a83bc24e6e49,45768,1592532755920
2020-06-19 02:15:58,197 DEBUG [RS:0;a83bc24e6e49:45768] zookeeper.ReadOnlyZKClient(363): Close zookeeper connection 0x29e56185 to localhost:55163
2020-06-19 02:15:58,197 DEBUG [RS:0;a83bc24e6e49:45768] ipc.AbstractRpcClient(497): Stopping rpc client
2020-06-19 02:15:58,198 INFO  [RS:0;a83bc24e6e49:45768] regionserver.CompactSplit(418): Waiting for Split Thread to finish...
2020-06-19 02:15:58,198 INFO  [RS:0;a83bc24e6e49:45768] regionserver.CompactSplit(418): Waiting for Large Compaction Thread to finish...
2020-06-19 02:15:58,198 INFO  [RS:0;a83bc24e6e49:45768] regionserver.CompactSplit(418): Waiting for Small Compaction Thread to finish...
2020-06-19 02:15:58,200 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1468): Waiting on 1 regions to close
2020-06-19 02:15:58,200 DEBUG [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1472): Online Regions={1588230740=hbase:meta,,1.1588230740}
2020-06-19 02:15:58,201 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(1597): Closing 1588230740, disabling compactions & flushes
2020-06-19 02:15:58,201 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(1637): Updates disabled for region hbase:meta,,1.1588230740
2020-06-19 02:15:58,225 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] wal.WALSplitUtil(421): Wrote file=hdfs://localhost:35543/user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/data/hbase/meta/1588230740/recovered.edits/23.seqid, newMaxSeqId=23, maxSeqId=1
2020-06-19 02:15:58,228 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] coprocessor.CoprocessorHost(310): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2020-06-19 02:15:58,231 INFO  [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(1754): Closed hbase:meta,,1.1588230740
2020-06-19 02:15:58,231 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] regionserver.HRegion(1552): Region close journal:
null at 1592532958200
	Waiting for close lock at 1592532958201
	Running coprocessor pre-close hooks at 1592532958201
	Disabling compacts and flushes for region at 1592532958201
	Disabling writes for close at 1592532958201
	Writing region close event to WAL at 1592532958202
	Running coprocessor post-close hooks at 1592532958227
	Closed at 1592532958231
2020-06-19 02:15:58,231 DEBUG [RS_CLOSE_META-regionserver/a83bc24e6e49:0-0] handler.CloseRegionHandler(130): Closed hbase:meta,,1.1588230740
2020-06-19 02:15:58,387 INFO  [regionserver/a83bc24e6e49:0.Chore.1] hbase.ScheduledChore(183): Chore: CompactionChecker was stopped
2020-06-19 02:15:58,387 INFO  [regionserver/a83bc24e6e49:0.Chore.1] hbase.ScheduledChore(183): Chore: MemstoreFlusherChore was stopped
2020-06-19 02:15:58,401 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1166): stopping server a83bc24e6e49,45768,1592532755920; all regions closed.
2020-06-19 02:15:58,405 INFO  [regionserver/a83bc24e6e49:0.leaseChecker] regionserver.Leases(149): Closed leases
2020-06-19 02:15:58,430 DEBUG [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(860): Moved 1 WAL file(s) to /user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/oldWALs
2020-06-19 02:15:58,430 INFO  [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(863): Closed WAL: AsyncFSWAL a83bc24e6e49%2C45768%2C1592532755920.meta:.meta(num 1592532759748)
2020-06-19 02:15:58,437 WARN  [Close-WAL-Writer-0] asyncfs.FanOutOneBlockAsyncDFSOutputHelper(602): complete file /user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/WALs/a83bc24e6e49,45768,1592532755920/a83bc24e6e49%2C45768%2C1592532755920.1592532760496 not finished, retry = 0
2020-06-19 02:15:58,545 DEBUG [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(860): Moved 1 WAL file(s) to /user/root/test-data/f4e8f9fa-66a3-dbfb-9bca-20c5b57bebf3/oldWALs
2020-06-19 02:15:58,546 INFO  [RS:0;a83bc24e6e49:45768] wal.AbstractFSWAL(863): Closed WAL: AsyncFSWAL a83bc24e6e49%2C45768%2C1592532755920:(num 1592532760496)
2020-06-19 02:15:58,546 DEBUG [RS:0;a83bc24e6e49:45768] ipc.AbstractRpcClient(497): Stopping rpc client
2020-06-19 02:15:58,546 INFO  [RS:0;a83bc24e6e49:45768] regionserver.Leases(149): Closed leases
2020-06-19 02:15:58,547 INFO  [RS:0;a83bc24e6e49:45768] hbase.ChoreService(332): Chore service for: regionserver/a83bc24e6e49:0 had [[ScheduledChore: Name: CompactedHFilesCleaner Period: 120000 Unit: MILLISECONDS], [ScheduledChore: Name: CompactionThroughputTuner Period: 60000 Unit: MILLISECONDS]] on shutdown
2020-06-19 02:15:58,548 INFO  [regionserver/a83bc24e6e49:0.logRoller] regionserver.LogRoller(202): LogRoller exiting.
2020-06-19 02:15:58,549 INFO  [RS:0;a83bc24e6e49:45768] ipc.NettyRpcServer(144): Stopping server on /172.17.0.6:45768
2020-06-19 02:15:58,559 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/a83bc24e6e49,45768,1592532755920
2020-06-19 02:15:58,559 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2020-06-19 02:15:58,559 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): regionserver:45768-0x172ca595eb70001, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2020-06-19 02:15:58,561 INFO  [RS:0;a83bc24e6e49:45768] regionserver.HRegionServer(1222): Exiting; stopping=a83bc24e6e49,45768,1592532755920; zookeeper connection closed.
2020-06-19 02:15:58,562 INFO  [RegionServerTracker-0] master.RegionServerTracker(171): RegionServer ephemeral node deleted, processing expiration [a83bc24e6e49,45768,1592532755920]
2020-06-19 02:15:58,563 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@5fb4d7c0] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(222): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@5fb4d7c0
2020-06-19 02:15:58,563 DEBUG [RegionServerTracker-0] master.DeadServer(133): Added a83bc24e6e49,45768,1592532755920; numProcessing=1
2020-06-19 02:15:58,563 INFO  [RegionServerTracker-0] master.ServerManager(562): Cluster shutdown set; a83bc24e6e49,45768,1592532755920 expired; onlineServers=0
2020-06-19 02:15:58,563 INFO  [RegionServerTracker-0] regionserver.HRegionServer(2228): ***** STOPPING region server 'a83bc24e6e49,44913,1592532754956' *****
2020-06-19 02:15:58,563 INFO  [Time-limited test] util.JVMClusterUtil(345): Shutdown of 1 master(s) and 1 regionserver(s) complete
2020-06-19 02:15:58,563 INFO  [RegionServerTracker-0] regionserver.HRegionServer(2242): STOPPED: Cluster shutdown set; onlineServer=0
2020-06-19 02:15:58,566 DEBUG [M:0;a83bc24e6e49:44913] ipc.AbstractRpcClient(202): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@79ee3ce7, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=true, bind address=a83bc24e6e49/172.17.0.6:0
2020-06-19 02:15:58,566 DEBUG [M:0;a83bc24e6e49:44913] regionserver.HRegionServer(997): About to register with Master.
2020-06-19 02:15:58,566 INFO  [M:0;a83bc24e6e49:44913] regionserver.HRegionServer(1140): stopping server a83bc24e6e49,44913,1592532754956
2020-06-19 02:15:58,567 INFO  [M:0;a83bc24e6e49:44913] regionserver.HRegionServer(1166): stopping server a83bc24e6e49,44913,1592532754956; all regions closed.
2020-06-19 02:15:58,567 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(477): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2020-06-19 02:15:58,567 DEBUG [M:0;a83bc24e6e49:44913] ipc.AbstractRpcClient(497): Stopping rpc client
2020-06-19 02:15:58,567 DEBUG [Time-limited test-EventThread] zookeeper.ZKUtil(356): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2020-06-19 02:15:58,567 INFO  [M:0;a83bc24e6e49:44913] hbase.ChoreService(332): Chore service for: master/a83bc24e6e49:0 had [] on shutdown
2020-06-19 02:15:58,568 DEBUG [M:0;a83bc24e6e49:44913] master.HMaster(1467): Stopping service threads
2020-06-19 02:15:58,569 DEBUG [M:0;a83bc24e6e49:44913] zookeeper.ZKUtil(612): master:44913-0x172ca595eb70000, quorum=localhost:55163, baseZNode=/hbase Unable to get data of znode /hbase/master because node does not exist (not an error)
2020-06-19 02:15:58,569 WARN  [M:0;a83bc24e6e49:44913] master.ActiveMasterManager(271): Failed get of master address: java.io.IOException: Can't get master address from ZooKeeper; znode data == null
2020-06-19 02:15:58,569 INFO  [M:0;a83bc24e6e49:44913] assignment.AssignmentManager(286): Stopping assignment manager
2020-06-19 02:15:58,571 INFO  [M:0;a83bc24e6e49:44913] procedure2.RemoteProcedureDispatcher(113): Stopping procedure remote dispatcher
msx-listener ERROR: unable to obtain test name!
msx-listener test Failure 
msx-listener writeFile testName is 
msx-listener failed
msx-listener failureMessage: Shutting down
msx-listener stackTrace: java.io.IOException: Shutting down
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:266)
	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:116)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1142)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1107)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1061)
	at org.apache.hadoop.hbase.client.TestAsyncBufferMutator.setUp(TestAsyncBufferMutator.java:80)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: Master not initialized after 200000ms
	at org.apache.hadoop.hbase.util.JVMClusterUtil.waitForEvent(JVMClusterUtil.java:229)
	at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:197)
	at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:413)
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:259)
	... 18 more

msx-listener ERROR: unable to obtain test name!
msx-listener test Failure 
msx-listener writeFile testName is 
msx-listener INFO: file existed /root/parameter_test_controller/shared/warn_results/Warn-2020-06-19-02-15-58
msx-listener failed
msx-listener failureMessage: null
msx-listener stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hbase.client.TestAsyncBufferMutator.tearDown(TestAsyncBufferMutator.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)

msx-listener all testRunFinished
2020-06-19 02:15:58,607 INFO  [master/a83bc24e6e49:0.splitLogManager..Chore.1] hbase.ScheduledChore(183): Chore: SplitLogManager Timeout Monitor was stopped
2020-06-19 02:15:58,673 INFO  [pool-1-thread-1] regionserver.ShutdownHook$ShutdownHookThread(114): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@62ca7977
2020-06-19 02:15:58,673 INFO  [pool-1-thread-1] regionserver.ShutdownHook$ShutdownHookThread(123): Starting fs shutdown hook thread.
2020-06-19 02:15:58,698 INFO  [pool-1-thread-1] regionserver.ShutdownHook$ShutdownHookThread(137): Shutdown hook finished.
