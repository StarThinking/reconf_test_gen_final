reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105648561-172.17.0.17-1595329473039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-d59944e9-2f7a-4487-b0ac-c60c09bb726b,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-3db83021-64f1-46c3-abb1-797c078facc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-54f264a5-cf42-4350-b96e-875a09d36787,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-cb43132f-86d7-43fd-9e6f-c9690f712de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-93e99cfb-c3ae-41c7-ab92-5bfc796f233b,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-86dd197f-fe9f-457a-b9f0-1f6a89e1cbce,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-bdf5e0ca-e017-4ab2-a1b0-25f98dd609ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-1441a7b9-d1c0-450c-833d-1a97092cad59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105648561-172.17.0.17-1595329473039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-d59944e9-2f7a-4487-b0ac-c60c09bb726b,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-3db83021-64f1-46c3-abb1-797c078facc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-54f264a5-cf42-4350-b96e-875a09d36787,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-cb43132f-86d7-43fd-9e6f-c9690f712de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-93e99cfb-c3ae-41c7-ab92-5bfc796f233b,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-86dd197f-fe9f-457a-b9f0-1f6a89e1cbce,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-bdf5e0ca-e017-4ab2-a1b0-25f98dd609ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-1441a7b9-d1c0-450c-833d-1a97092cad59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099503478-172.17.0.17-1595329547009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-56d2f032-d2e9-4ba7-8b14-b46dacd8cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-c0719c3b-9204-4415-bb32-d9f146e2046e,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-1e77e02f-c875-48c4-9235-a842931e3c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-160d4bd9-487f-40a5-b018-4fc9b769d8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-bdcffbc2-647a-4fc2-95e6-3c4598795e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-0d5d26ea-facf-44c3-a6e4-73a760ec0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-85df1df9-7492-48f6-83fe-e2ff7e55009d,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-c54360ee-c1cb-4330-a678-fe721e730d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099503478-172.17.0.17-1595329547009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-56d2f032-d2e9-4ba7-8b14-b46dacd8cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-c0719c3b-9204-4415-bb32-d9f146e2046e,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-1e77e02f-c875-48c4-9235-a842931e3c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-160d4bd9-487f-40a5-b018-4fc9b769d8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-bdcffbc2-647a-4fc2-95e6-3c4598795e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-0d5d26ea-facf-44c3-a6e4-73a760ec0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-85df1df9-7492-48f6-83fe-e2ff7e55009d,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-c54360ee-c1cb-4330-a678-fe721e730d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980446967-172.17.0.17-1595329748826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-9daccb98-3aee-4968-b2b5-18bbbcf104df,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-41b7db5e-04e9-4332-9cf4-84537986cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c54a1922-f3eb-4e67-b4fe-82794655b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-0020562f-9502-4ead-b3e3-ec1a76be87cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-143fc496-a7bf-45b9-8e4c-f2e46485cf64,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-1487b042-1b8a-461d-83b9-355a45f42282,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-957e3cf8-4850-4db9-b02b-20c70d6ba971,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-b6fa9c53-0326-445e-a392-7865af55e934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980446967-172.17.0.17-1595329748826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-9daccb98-3aee-4968-b2b5-18bbbcf104df,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-41b7db5e-04e9-4332-9cf4-84537986cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c54a1922-f3eb-4e67-b4fe-82794655b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-0020562f-9502-4ead-b3e3-ec1a76be87cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-143fc496-a7bf-45b9-8e4c-f2e46485cf64,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-1487b042-1b8a-461d-83b9-355a45f42282,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-957e3cf8-4850-4db9-b02b-20c70d6ba971,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-b6fa9c53-0326-445e-a392-7865af55e934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604443220-172.17.0.17-1595329858833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-c9bc02c9-0ce7-44c3-9fb7-db60741d0a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-7882bbad-a8ff-4c57-952e-6b2336c47630,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-a3d238a0-ee86-4a7d-a031-537820c5d05a,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-2bd9f746-0445-4f38-ae30-547395135b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-22cceef8-f8aa-468b-97da-c5ed8db4ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-a053a349-f67f-48b8-acaf-0a31576eac18,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-694200ea-8f62-4c8e-9322-4d984b213821,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-94a1c437-1a11-4e2a-bdd9-c3df009c95dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604443220-172.17.0.17-1595329858833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-c9bc02c9-0ce7-44c3-9fb7-db60741d0a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-7882bbad-a8ff-4c57-952e-6b2336c47630,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-a3d238a0-ee86-4a7d-a031-537820c5d05a,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-2bd9f746-0445-4f38-ae30-547395135b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-22cceef8-f8aa-468b-97da-c5ed8db4ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-a053a349-f67f-48b8-acaf-0a31576eac18,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-694200ea-8f62-4c8e-9322-4d984b213821,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-94a1c437-1a11-4e2a-bdd9-c3df009c95dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379310000-172.17.0.17-1595329997136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-f1a5a04f-9190-463f-9d90-658664da448a,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-c1efcdac-367f-4443-99ab-15bd45ee8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-dcfe9b9d-fafb-4b73-98c5-2dd8ca3999b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-2f4cfb43-7603-40c2-adf8-58262da3fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d8fd125c-1b81-467a-a5e6-7b5772d5d232,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-5f51bdfd-2da3-4dde-8bdb-7bb627f17759,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-841e327e-4dc1-4c57-abf0-e919360c0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-538f6f20-8f3e-4ab2-8e4e-6ab7111db84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379310000-172.17.0.17-1595329997136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-f1a5a04f-9190-463f-9d90-658664da448a,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-c1efcdac-367f-4443-99ab-15bd45ee8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-dcfe9b9d-fafb-4b73-98c5-2dd8ca3999b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-2f4cfb43-7603-40c2-adf8-58262da3fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d8fd125c-1b81-467a-a5e6-7b5772d5d232,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-5f51bdfd-2da3-4dde-8bdb-7bb627f17759,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-841e327e-4dc1-4c57-abf0-e919360c0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-538f6f20-8f3e-4ab2-8e4e-6ab7111db84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294959171-172.17.0.17-1595331066364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38924,DS-cb08b476-7171-4b04-a7d7-916b7d93111b,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-f322be6e-c651-4918-9d91-adbbbef48a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-33410b48-b444-43b0-97b8-7b695662ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-e489da00-13e1-43dc-a4d8-85afaeb3ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-286c3580-2477-4f9c-82a4-08f8838fd5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-b32ae56f-ecc6-42b4-97e1-d030cb66f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-42594c00-6a46-4301-b7a3-f8da35fc6445,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-cae93c99-6877-4b2d-b8b7-0012c128f860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294959171-172.17.0.17-1595331066364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38924,DS-cb08b476-7171-4b04-a7d7-916b7d93111b,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-f322be6e-c651-4918-9d91-adbbbef48a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-33410b48-b444-43b0-97b8-7b695662ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-e489da00-13e1-43dc-a4d8-85afaeb3ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-286c3580-2477-4f9c-82a4-08f8838fd5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-b32ae56f-ecc6-42b4-97e1-d030cb66f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-42594c00-6a46-4301-b7a3-f8da35fc6445,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-cae93c99-6877-4b2d-b8b7-0012c128f860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707112508-172.17.0.17-1595331347981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45011,DS-05c97900-53d8-40c4-a71b-1a09a4f46ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-c57350ae-fa4c-4626-a773-a6047d16a626,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-9c84d6fe-d3de-4d5a-958d-44249fba7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-58219223-8926-4f16-8cd8-d4b3fb2653e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-2cdbe17e-b9df-4930-8ec3-752dad5898c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-617f75fd-da46-4916-ad19-79a01966aac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-a32f2169-b354-4a1a-97bb-26ed803354d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-d443cbd0-74d2-4a9a-aca7-9330ea6c6a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707112508-172.17.0.17-1595331347981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45011,DS-05c97900-53d8-40c4-a71b-1a09a4f46ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-c57350ae-fa4c-4626-a773-a6047d16a626,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-9c84d6fe-d3de-4d5a-958d-44249fba7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-58219223-8926-4f16-8cd8-d4b3fb2653e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-2cdbe17e-b9df-4930-8ec3-752dad5898c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-617f75fd-da46-4916-ad19-79a01966aac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-a32f2169-b354-4a1a-97bb-26ed803354d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-d443cbd0-74d2-4a9a-aca7-9330ea6c6a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588424666-172.17.0.17-1595331381409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-63feca7a-9a4d-4da5-a873-ca5f5caec580,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-00a0a8a9-91d5-4924-af45-fc89f430d93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-5f3b9cd3-3170-4c50-911b-9aaf665d06a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-6d6bb7f0-a609-4082-b93c-3a23b2d88427,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-50b8b2f4-ccfd-4144-99a5-5130b94cf18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-bbdcdd7f-3ef5-43f6-b8a2-23dffe774e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-0ae6c869-c2c0-45a8-83d7-8b6b95630e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-423f9ff1-5e62-4aac-83de-7925adead4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588424666-172.17.0.17-1595331381409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-63feca7a-9a4d-4da5-a873-ca5f5caec580,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-00a0a8a9-91d5-4924-af45-fc89f430d93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-5f3b9cd3-3170-4c50-911b-9aaf665d06a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-6d6bb7f0-a609-4082-b93c-3a23b2d88427,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-50b8b2f4-ccfd-4144-99a5-5130b94cf18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-bbdcdd7f-3ef5-43f6-b8a2-23dffe774e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-0ae6c869-c2c0-45a8-83d7-8b6b95630e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-423f9ff1-5e62-4aac-83de-7925adead4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526480186-172.17.0.17-1595331789856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45091,DS-9e419cb0-6e8e-4721-8d29-ab0a66526c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-a8ed8d9c-6288-4152-b847-655300d5ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-6af0cce4-faa1-422a-afe1-bd4844f7de89,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-3ee666e3-c2fd-4b72-99cd-9fff64e7a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-f97212fe-4ad7-4c7b-adad-bb9d4b5c1f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-3d8dbcf4-0689-48af-9f20-8d1907704ead,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-75ee21b4-a8c9-4c4b-a2b4-af1942a3426e,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-276164d5-cbe3-42e1-add7-03632130b49f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526480186-172.17.0.17-1595331789856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45091,DS-9e419cb0-6e8e-4721-8d29-ab0a66526c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-a8ed8d9c-6288-4152-b847-655300d5ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-6af0cce4-faa1-422a-afe1-bd4844f7de89,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-3ee666e3-c2fd-4b72-99cd-9fff64e7a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-f97212fe-4ad7-4c7b-adad-bb9d4b5c1f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-3d8dbcf4-0689-48af-9f20-8d1907704ead,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-75ee21b4-a8c9-4c4b-a2b4-af1942a3426e,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-276164d5-cbe3-42e1-add7-03632130b49f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253431505-172.17.0.17-1595331903414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-a69c1056-239c-47e1-8fff-ba0f38a98519,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-3a7ad152-72aa-49eb-9ea4-ccfb9dc52677,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1e454781-a0dc-43b8-b654-4273e897fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-7869ff87-36f4-42ba-ba18-6ceeb7376991,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-cc36560c-582a-40fe-af37-304675b1fa02,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-8cd90f4a-1e53-4d15-9cd5-69d096b027d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0024cddc-9e1c-449f-9f1f-76bedb130584,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-7f1d20ef-cd08-46cc-8a4e-f546b5ccdf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253431505-172.17.0.17-1595331903414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-a69c1056-239c-47e1-8fff-ba0f38a98519,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-3a7ad152-72aa-49eb-9ea4-ccfb9dc52677,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1e454781-a0dc-43b8-b654-4273e897fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-7869ff87-36f4-42ba-ba18-6ceeb7376991,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-cc36560c-582a-40fe-af37-304675b1fa02,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-8cd90f4a-1e53-4d15-9cd5-69d096b027d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0024cddc-9e1c-449f-9f1f-76bedb130584,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-7f1d20ef-cd08-46cc-8a4e-f546b5ccdf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078704548-172.17.0.17-1595331996900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41811,DS-ef0a69e7-ed0f-49e9-946d-10c406626b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-5c60bc7f-3063-4947-ba3b-77afba8ac713,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-a197980e-779c-4680-a2b5-8ffa4f7c1f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-2293e994-fa1b-43d3-8cbb-bb5f0d862557,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-52f1a12a-05d0-470d-93cb-0c554860824c,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-4f32ad99-22ed-4618-86c1-4140a445b114,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-3bf89614-9b43-4a56-9d08-f116e83550d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-145ad246-4bfb-473d-b2b5-8e41647bec86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078704548-172.17.0.17-1595331996900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41811,DS-ef0a69e7-ed0f-49e9-946d-10c406626b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-5c60bc7f-3063-4947-ba3b-77afba8ac713,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-a197980e-779c-4680-a2b5-8ffa4f7c1f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-2293e994-fa1b-43d3-8cbb-bb5f0d862557,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-52f1a12a-05d0-470d-93cb-0c554860824c,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-4f32ad99-22ed-4618-86c1-4140a445b114,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-3bf89614-9b43-4a56-9d08-f116e83550d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-145ad246-4bfb-473d-b2b5-8e41647bec86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946740503-172.17.0.17-1595333057493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-8e156783-7aae-47b7-b85c-82b8f5ee4cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-7bd567d6-2575-4d9a-9f48-7ee90d530575,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-a351bad1-be7a-4057-ae97-977bf082f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-145ba187-3e37-4bc1-9171-026d0017146b,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-8a6cf587-5543-4c76-b65d-d53973402112,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-e9682fb7-c19f-408d-a926-4403df127fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-0e58566c-ab6a-4b71-b666-45552d9d3002,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-ca01fc42-90c4-4e99-9d40-1a2a0b8cf6fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946740503-172.17.0.17-1595333057493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-8e156783-7aae-47b7-b85c-82b8f5ee4cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-7bd567d6-2575-4d9a-9f48-7ee90d530575,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-a351bad1-be7a-4057-ae97-977bf082f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-145ba187-3e37-4bc1-9171-026d0017146b,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-8a6cf587-5543-4c76-b65d-d53973402112,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-e9682fb7-c19f-408d-a926-4403df127fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-0e58566c-ab6a-4b71-b666-45552d9d3002,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-ca01fc42-90c4-4e99-9d40-1a2a0b8cf6fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645914043-172.17.0.17-1595333638206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-223a53e0-87dc-47ca-b602-e89a3c769f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-3faf08a2-0f1a-435c-9f78-2cebeb9307f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-c149e4f7-e3fa-4922-b7e6-d55976d0563b,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-d0e689fd-6d59-4d2c-971f-d523ce953b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-28634281-93a5-4597-8fb3-c5ac2f3a67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-263d8819-c02b-4bc0-98cc-160a80dbccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-d0926c50-4372-4176-9318-55b719513250,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-0b55b8d5-2036-45c2-ab9d-bae4ac4bdbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645914043-172.17.0.17-1595333638206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-223a53e0-87dc-47ca-b602-e89a3c769f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-3faf08a2-0f1a-435c-9f78-2cebeb9307f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-c149e4f7-e3fa-4922-b7e6-d55976d0563b,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-d0e689fd-6d59-4d2c-971f-d523ce953b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-28634281-93a5-4597-8fb3-c5ac2f3a67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-263d8819-c02b-4bc0-98cc-160a80dbccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-d0926c50-4372-4176-9318-55b719513250,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-0b55b8d5-2036-45c2-ab9d-bae4ac4bdbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5122
