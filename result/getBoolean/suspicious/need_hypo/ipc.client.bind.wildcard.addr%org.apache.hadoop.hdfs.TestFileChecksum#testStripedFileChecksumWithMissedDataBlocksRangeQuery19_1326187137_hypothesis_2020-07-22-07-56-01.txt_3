reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087826520-172.17.0.19-1595404976953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40001,DS-c435727a-ee58-408f-b771-729b417041fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-cbc41f84-407b-4603-9837-2e0d8f5d2df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-4bf3cdfe-5acd-491a-8070-c0eac65afe20,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-1bac9062-4a19-4849-9965-760b3c5c24f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-1788cdf9-13a2-4ae5-b757-23bbee34c1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-75a715cc-ceba-40e3-95ae-060278af55fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-dabe2f52-b4e6-41fb-8ce4-d0801cd1e287,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-05c465ad-b569-4822-9ca7-0bd3b81d9d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087826520-172.17.0.19-1595404976953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40001,DS-c435727a-ee58-408f-b771-729b417041fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-cbc41f84-407b-4603-9837-2e0d8f5d2df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-4bf3cdfe-5acd-491a-8070-c0eac65afe20,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-1bac9062-4a19-4849-9965-760b3c5c24f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-1788cdf9-13a2-4ae5-b757-23bbee34c1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-75a715cc-ceba-40e3-95ae-060278af55fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-dabe2f52-b4e6-41fb-8ce4-d0801cd1e287,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-05c465ad-b569-4822-9ca7-0bd3b81d9d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782675175-172.17.0.19-1595405087562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-a275b3c2-b501-4414-ae42-9617005b2e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-b8ee9a7d-a805-42b6-a88c-e9f84567e230,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-b0f1b728-19c6-4fa5-9805-6fe179f88d28,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-724a39c0-6d82-411e-9e55-0425fe638b21,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-f34af2fc-97c6-464a-8b8a-67a55596f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-4a6a0047-7efc-4840-a5c0-4f273397b819,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e0e05787-4b4c-46bb-b9cd-4d50be37739c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-932c1531-66e0-4872-a098-b80d348b609b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782675175-172.17.0.19-1595405087562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-a275b3c2-b501-4414-ae42-9617005b2e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-b8ee9a7d-a805-42b6-a88c-e9f84567e230,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-b0f1b728-19c6-4fa5-9805-6fe179f88d28,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-724a39c0-6d82-411e-9e55-0425fe638b21,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-f34af2fc-97c6-464a-8b8a-67a55596f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-4a6a0047-7efc-4840-a5c0-4f273397b819,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e0e05787-4b4c-46bb-b9cd-4d50be37739c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-932c1531-66e0-4872-a098-b80d348b609b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860410722-172.17.0.19-1595406396113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-c7fae24e-baa0-4f81-be2f-01fc9b8952b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-b72854c3-fdc8-41a3-b7ef-e0b2a4ee288b,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-90ce7af6-055d-4e09-bff9-ba5875472e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-7deb17f0-954f-49dc-9eb9-6f6752140f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-e6217eb9-58c7-482b-bad0-8011a470b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-7c80ea89-d2b6-401b-a019-5cb808efe074,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-e872fbf9-b824-4834-ad48-b37bfe026ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-b6926a32-38fc-4c97-a9a0-dd5b50a81170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860410722-172.17.0.19-1595406396113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-c7fae24e-baa0-4f81-be2f-01fc9b8952b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-b72854c3-fdc8-41a3-b7ef-e0b2a4ee288b,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-90ce7af6-055d-4e09-bff9-ba5875472e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-7deb17f0-954f-49dc-9eb9-6f6752140f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-e6217eb9-58c7-482b-bad0-8011a470b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-7c80ea89-d2b6-401b-a019-5cb808efe074,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-e872fbf9-b824-4834-ad48-b37bfe026ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-b6926a32-38fc-4c97-a9a0-dd5b50a81170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579567825-172.17.0.19-1595407317006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43213,DS-b06c26ff-8f9d-46ef-9b95-48f20e053bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-93ad9620-f3d0-4348-9f89-6d2a0b491fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-0cd22071-87d5-47e1-b2c5-58dd041d7594,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-73e04e40-8f36-42f5-b7a0-5af5592eab84,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-1b41f172-1568-40c9-98a8-c8a9c2a3ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-a75ac320-e5b5-4ab9-89ba-614a92206e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-9b3c4091-baad-4fc6-b3b1-b90995acc843,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-da31a10b-d43c-4017-af53-accd358743ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579567825-172.17.0.19-1595407317006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43213,DS-b06c26ff-8f9d-46ef-9b95-48f20e053bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-93ad9620-f3d0-4348-9f89-6d2a0b491fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-0cd22071-87d5-47e1-b2c5-58dd041d7594,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-73e04e40-8f36-42f5-b7a0-5af5592eab84,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-1b41f172-1568-40c9-98a8-c8a9c2a3ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-a75ac320-e5b5-4ab9-89ba-614a92206e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-9b3c4091-baad-4fc6-b3b1-b90995acc843,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-da31a10b-d43c-4017-af53-accd358743ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059197544-172.17.0.19-1595407389439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-37511e3e-dfb4-48b6-bcf2-00421eda4391,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-7d864a25-8d95-4e0c-8b4d-c3e92b8f3d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-3e46ee1d-f0cb-4acc-80e5-1b068a59640b,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-b0abe348-b5da-4c20-af7a-4411589f4822,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-40e750ee-243c-4e55-a3ca-1613b2f6ff91,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-555da00a-d177-4c1e-b16d-115666c855b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-47b7352f-edca-463a-9cc5-f30be994099f,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-b22b9ef2-3193-4d84-8466-4ab9b8a95c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059197544-172.17.0.19-1595407389439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-37511e3e-dfb4-48b6-bcf2-00421eda4391,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-7d864a25-8d95-4e0c-8b4d-c3e92b8f3d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-3e46ee1d-f0cb-4acc-80e5-1b068a59640b,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-b0abe348-b5da-4c20-af7a-4411589f4822,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-40e750ee-243c-4e55-a3ca-1613b2f6ff91,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-555da00a-d177-4c1e-b16d-115666c855b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-47b7352f-edca-463a-9cc5-f30be994099f,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-b22b9ef2-3193-4d84-8466-4ab9b8a95c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421187853-172.17.0.19-1595407610184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45628,DS-15afdb11-c1a1-4813-9821-7f75a7e4455d,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-f269b942-4e7d-4213-9daa-cbffc87f119c,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-491afa28-1b2c-48ce-b6a4-69de80a11aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-6c1b4a5c-c1c7-4799-8d7c-bd38cc4d1259,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-1cd3f535-baf0-4c4f-93dd-5f3b381152b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-274fc247-1ccc-4964-be28-a5964412e724,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-5d6d7bfc-861b-4af9-8ea1-db6c1af28d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d303ebb0-737d-4bae-8b04-500154ed003c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421187853-172.17.0.19-1595407610184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45628,DS-15afdb11-c1a1-4813-9821-7f75a7e4455d,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-f269b942-4e7d-4213-9daa-cbffc87f119c,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-491afa28-1b2c-48ce-b6a4-69de80a11aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-6c1b4a5c-c1c7-4799-8d7c-bd38cc4d1259,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-1cd3f535-baf0-4c4f-93dd-5f3b381152b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-274fc247-1ccc-4964-be28-a5964412e724,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-5d6d7bfc-861b-4af9-8ea1-db6c1af28d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d303ebb0-737d-4bae-8b04-500154ed003c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002857327-172.17.0.19-1595407786421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-60ba8ea6-efa2-4b3a-b298-5872a487eaac,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-b8c3b655-f23b-415c-b1e0-73201addc385,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-2658a7ef-8bc8-46ab-bbe7-44f3acedd525,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-5143c4a3-7a21-4184-8d97-356a47193816,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-d055f390-7625-4cbc-a63b-f3be40e3d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-fe4f4e1b-33e5-4b15-a87d-a0a5f64acbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-00fab664-1404-4495-bd22-bde7cda7f73c,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-3d6ef28b-b3cf-4e92-b633-8947e9101397,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002857327-172.17.0.19-1595407786421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-60ba8ea6-efa2-4b3a-b298-5872a487eaac,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-b8c3b655-f23b-415c-b1e0-73201addc385,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-2658a7ef-8bc8-46ab-bbe7-44f3acedd525,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-5143c4a3-7a21-4184-8d97-356a47193816,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-d055f390-7625-4cbc-a63b-f3be40e3d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-fe4f4e1b-33e5-4b15-a87d-a0a5f64acbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-00fab664-1404-4495-bd22-bde7cda7f73c,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-3d6ef28b-b3cf-4e92-b633-8947e9101397,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942754893-172.17.0.19-1595408032472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-0bcf7579-61cf-4d30-9217-216c59576f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-8a02c2f6-5509-4c39-a9b8-99d9760ee38f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-fc108bdb-acde-439d-a19d-ca9bac911336,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-91493b17-e768-4561-aa86-53716f2a2967,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-1f7994ba-c740-4271-9c23-fdab7364a552,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-cb5e3ce3-f34e-44fe-8421-dd0006146ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-f9cf46b9-125c-4884-b89e-b18a014412fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-d5bf6201-590a-49e5-8ed1-595e3612e327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942754893-172.17.0.19-1595408032472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-0bcf7579-61cf-4d30-9217-216c59576f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-8a02c2f6-5509-4c39-a9b8-99d9760ee38f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-fc108bdb-acde-439d-a19d-ca9bac911336,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-91493b17-e768-4561-aa86-53716f2a2967,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-1f7994ba-c740-4271-9c23-fdab7364a552,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-cb5e3ce3-f34e-44fe-8421-dd0006146ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-f9cf46b9-125c-4884-b89e-b18a014412fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-d5bf6201-590a-49e5-8ed1-595e3612e327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090017907-172.17.0.19-1595408099388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-7bb25313-86f5-4ac1-8579-e9b36279e972,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-a0e33587-4fc9-4e28-aadd-fb19cee77ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-1979f536-5626-4704-8dad-71a9f5a48138,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-a6f61f49-b0c7-4e76-b4b9-5757b7c15b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-09618102-6866-4278-9ec8-5dc219bfadec,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-d84371dc-2597-46ae-863e-444df3e32b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-749fd781-8493-4cda-9298-e777bdfe01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-2372f2d8-c0d9-4390-a3b1-610314a51a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090017907-172.17.0.19-1595408099388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-7bb25313-86f5-4ac1-8579-e9b36279e972,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-a0e33587-4fc9-4e28-aadd-fb19cee77ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-1979f536-5626-4704-8dad-71a9f5a48138,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-a6f61f49-b0c7-4e76-b4b9-5757b7c15b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-09618102-6866-4278-9ec8-5dc219bfadec,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-d84371dc-2597-46ae-863e-444df3e32b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-749fd781-8493-4cda-9298-e777bdfe01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-2372f2d8-c0d9-4390-a3b1-610314a51a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717574640-172.17.0.19-1595408265447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-67428b7a-1ecf-4e1d-a673-b7e95108c520,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-cd4cb425-59bf-4a83-bd3b-bf6cdf55d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-c4101faf-1d75-4cf9-bc01-968b278b2457,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-4594b2c5-cfaf-47fa-ab1b-443bb4f3b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-6618af32-5d13-4a1f-bce7-7257c6c0e980,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d6e9d106-0d3b-4971-a618-4a6ea153ed04,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-ffa53708-c969-40ee-bea6-752fe86fb055,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-7faad2a0-43c2-4d80-b727-2351db2a0517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717574640-172.17.0.19-1595408265447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-67428b7a-1ecf-4e1d-a673-b7e95108c520,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-cd4cb425-59bf-4a83-bd3b-bf6cdf55d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-c4101faf-1d75-4cf9-bc01-968b278b2457,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-4594b2c5-cfaf-47fa-ab1b-443bb4f3b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-6618af32-5d13-4a1f-bce7-7257c6c0e980,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d6e9d106-0d3b-4971-a618-4a6ea153ed04,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-ffa53708-c969-40ee-bea6-752fe86fb055,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-7faad2a0-43c2-4d80-b727-2351db2a0517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102991188-172.17.0.19-1595408446930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-43ad461e-787e-4401-8606-cffdbdf305f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-7554a0b6-a515-4ca2-9313-21606330a91f,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-97d11c6a-1953-4653-a1d1-d386913aa02d,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-4620f8e7-8175-4fe4-befc-58da0222cdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-233a695d-e5ee-4e5c-b5eb-47334003f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-2532fb47-a455-4f49-9c9e-68f9bf4edecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-ab4a5126-41da-43c3-8555-f70a3d1b02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-5432eb82-a7ae-46ee-8844-fa6164e6ccfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102991188-172.17.0.19-1595408446930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-43ad461e-787e-4401-8606-cffdbdf305f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-7554a0b6-a515-4ca2-9313-21606330a91f,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-97d11c6a-1953-4653-a1d1-d386913aa02d,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-4620f8e7-8175-4fe4-befc-58da0222cdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-233a695d-e5ee-4e5c-b5eb-47334003f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-2532fb47-a455-4f49-9c9e-68f9bf4edecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-ab4a5126-41da-43c3-8555-f70a3d1b02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-5432eb82-a7ae-46ee-8844-fa6164e6ccfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371631884-172.17.0.19-1595408862095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-bf0f0df3-f15f-4c36-98b8-5084be81a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-38eace5c-40c7-49fc-b407-2f50b617d4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1892411c-bdaa-4912-a356-9c578f4a6d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-79adbad7-9cbc-4ef1-8aaf-bba4132ca1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-a079c332-db68-4d9b-96ad-65118b34be30,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-dae74af5-6be4-44a5-91b5-4e57a3bcbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-c33a4289-b633-40f2-92df-916f58f466e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-e6df9955-89fe-43e8-812b-945768f2b301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371631884-172.17.0.19-1595408862095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-bf0f0df3-f15f-4c36-98b8-5084be81a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-38eace5c-40c7-49fc-b407-2f50b617d4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1892411c-bdaa-4912-a356-9c578f4a6d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-79adbad7-9cbc-4ef1-8aaf-bba4132ca1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-a079c332-db68-4d9b-96ad-65118b34be30,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-dae74af5-6be4-44a5-91b5-4e57a3bcbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-c33a4289-b633-40f2-92df-916f58f466e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-e6df9955-89fe-43e8-812b-945768f2b301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5296
