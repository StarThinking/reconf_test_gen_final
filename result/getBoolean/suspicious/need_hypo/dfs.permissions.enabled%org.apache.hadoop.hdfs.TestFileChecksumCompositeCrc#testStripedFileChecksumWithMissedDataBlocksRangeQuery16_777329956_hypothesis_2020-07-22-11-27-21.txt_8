reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427000393-172.17.0.11-1595417257820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-2238218d-62fc-417e-a5bc-c3e291199e47,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-4325319a-9c3b-47b9-8922-a65c8467c9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-3fb60a9f-f94a-44ef-baf0-544ac4833f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-7b27ac50-493a-4924-a143-23e5b0319795,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-a13d5035-db5f-406f-8ef5-0f722aa597f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-4ce9e7af-35f9-4a2e-9999-4c5e1d169054,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-f50eae25-fdbc-461b-8c58-8e0e6d264487,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-a56abddb-9263-4e78-b9a5-7d8ea04a9c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427000393-172.17.0.11-1595417257820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-2238218d-62fc-417e-a5bc-c3e291199e47,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-4325319a-9c3b-47b9-8922-a65c8467c9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-3fb60a9f-f94a-44ef-baf0-544ac4833f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-7b27ac50-493a-4924-a143-23e5b0319795,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-a13d5035-db5f-406f-8ef5-0f722aa597f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-4ce9e7af-35f9-4a2e-9999-4c5e1d169054,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-f50eae25-fdbc-461b-8c58-8e0e6d264487,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-a56abddb-9263-4e78-b9a5-7d8ea04a9c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339127728-172.17.0.11-1595417426570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35293,DS-00ce303a-da8f-452e-bb0f-25a596326f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-bae3d10c-ebb7-4280-a5cb-2aaac6a60f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-5d62d1d9-7336-4aba-af03-69652d4e0fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-2c42b567-8f28-4778-bda9-3dc64bd0409a,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-030655eb-6963-442b-80b8-55ccfa2bb737,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-f876d059-2cd5-48e8-a82a-360eb563fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-24d021f1-7b7e-49ef-8003-77904116a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-0be6a2ff-60d1-4c35-ad70-75f015927d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339127728-172.17.0.11-1595417426570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35293,DS-00ce303a-da8f-452e-bb0f-25a596326f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-bae3d10c-ebb7-4280-a5cb-2aaac6a60f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-5d62d1d9-7336-4aba-af03-69652d4e0fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-2c42b567-8f28-4778-bda9-3dc64bd0409a,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-030655eb-6963-442b-80b8-55ccfa2bb737,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-f876d059-2cd5-48e8-a82a-360eb563fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-24d021f1-7b7e-49ef-8003-77904116a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-0be6a2ff-60d1-4c35-ad70-75f015927d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018548116-172.17.0.11-1595417689753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-7b432d5f-aefd-495e-84de-40f6158da673,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-4f8acde9-2f8d-4835-9f0b-8465dbadf62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-c2a5a3ca-dfa5-43da-99df-a1ac1c209d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-f85f1dd1-3fc7-445e-9f6d-ca8ee0e5dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-6c72d685-5ffc-43c0-b68f-b6c38b35e4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-8d1f3ddd-8a19-470c-bb58-177444becfde,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-acb7f11f-beef-45e3-a753-45124f5ef209,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-3db325ba-688f-4a79-910b-25c405c39b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018548116-172.17.0.11-1595417689753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-7b432d5f-aefd-495e-84de-40f6158da673,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-4f8acde9-2f8d-4835-9f0b-8465dbadf62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-c2a5a3ca-dfa5-43da-99df-a1ac1c209d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-f85f1dd1-3fc7-445e-9f6d-ca8ee0e5dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-6c72d685-5ffc-43c0-b68f-b6c38b35e4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-8d1f3ddd-8a19-470c-bb58-177444becfde,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-acb7f11f-beef-45e3-a753-45124f5ef209,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-3db325ba-688f-4a79-910b-25c405c39b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222292231-172.17.0.11-1595417739133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-d3d8f298-b7dd-4329-9579-7f94f1f5bd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-e2106e85-5a35-4286-9cf1-cdf145044149,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-d3b71724-7000-4ed4-8508-6357975e7024,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-b89c4ce0-4720-4da3-b70b-9f699cf90dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-6b1bf551-a04b-4917-bb0b-1a44aefdb443,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-52301b1a-a85f-4477-ae1b-5d684ee437e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-8effed1d-0bd3-4d39-920a-94d7268faedd,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-7f3e1cb7-3795-4f94-84d6-02a88078cacf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222292231-172.17.0.11-1595417739133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-d3d8f298-b7dd-4329-9579-7f94f1f5bd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-e2106e85-5a35-4286-9cf1-cdf145044149,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-d3b71724-7000-4ed4-8508-6357975e7024,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-b89c4ce0-4720-4da3-b70b-9f699cf90dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-6b1bf551-a04b-4917-bb0b-1a44aefdb443,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-52301b1a-a85f-4477-ae1b-5d684ee437e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-8effed1d-0bd3-4d39-920a-94d7268faedd,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-7f3e1cb7-3795-4f94-84d6-02a88078cacf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958778896-172.17.0.11-1595417934577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-f9914051-b741-4cf7-bc69-bc2239caace7,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-c21dd250-daa1-4070-b513-3bf2bdfed686,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-a6fa2add-5dba-4eaa-b237-465e11be22d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-ddf4a02b-b12c-4ebc-9710-d86d3ccce6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-ce2cb0c5-3ef2-4e18-9525-ebbf45cb0ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-e6ddeba5-4c25-4b5c-9f55-2873855eaf46,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-ed57a710-4113-4e7e-b9b2-6e34da4b293f,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-2308e58e-9b8e-49b1-a62d-5fa29ff1006f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958778896-172.17.0.11-1595417934577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-f9914051-b741-4cf7-bc69-bc2239caace7,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-c21dd250-daa1-4070-b513-3bf2bdfed686,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-a6fa2add-5dba-4eaa-b237-465e11be22d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-ddf4a02b-b12c-4ebc-9710-d86d3ccce6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-ce2cb0c5-3ef2-4e18-9525-ebbf45cb0ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-e6ddeba5-4c25-4b5c-9f55-2873855eaf46,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-ed57a710-4113-4e7e-b9b2-6e34da4b293f,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-2308e58e-9b8e-49b1-a62d-5fa29ff1006f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583431507-172.17.0.11-1595418340612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-f84d9655-328f-4a73-9a70-1a312864099e,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-145bafa9-6095-4f04-9d41-2aa9a99d4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-5f9cf40c-e53f-4702-bdb9-51bccbc88e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-c9424fa8-057d-4443-b16d-22c04cba8255,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a742bd26-acd3-4e54-89cc-789d1088bea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-e24e1c0f-ca6b-480c-9254-099601645149,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-08a7a01c-a93e-46c5-acd5-e14f02cbc4af,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-71e202ca-3ddd-4047-af50-983686d7ac91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583431507-172.17.0.11-1595418340612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-f84d9655-328f-4a73-9a70-1a312864099e,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-145bafa9-6095-4f04-9d41-2aa9a99d4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-5f9cf40c-e53f-4702-bdb9-51bccbc88e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-c9424fa8-057d-4443-b16d-22c04cba8255,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a742bd26-acd3-4e54-89cc-789d1088bea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-e24e1c0f-ca6b-480c-9254-099601645149,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-08a7a01c-a93e-46c5-acd5-e14f02cbc4af,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-71e202ca-3ddd-4047-af50-983686d7ac91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874896623-172.17.0.11-1595418631952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-f0689107-0d63-4edc-8ebc-dd01a83938ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-0aa444aa-6d74-4da5-9495-9ea04db693b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-8ea70a30-10ab-4a25-b287-7db12ea6410b,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-b78f0655-4622-499a-9b8b-b687349af452,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-798473b9-b5d8-4310-bb80-8dce0234c083,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-5f1daad2-58fa-4041-ae9b-cd357d13066e,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-fd2e2702-f85f-48c2-aba7-2b025cb09d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-72b33299-3257-45e3-bf75-cafca9d9f090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874896623-172.17.0.11-1595418631952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-f0689107-0d63-4edc-8ebc-dd01a83938ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-0aa444aa-6d74-4da5-9495-9ea04db693b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-8ea70a30-10ab-4a25-b287-7db12ea6410b,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-b78f0655-4622-499a-9b8b-b687349af452,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-798473b9-b5d8-4310-bb80-8dce0234c083,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-5f1daad2-58fa-4041-ae9b-cd357d13066e,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-fd2e2702-f85f-48c2-aba7-2b025cb09d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-72b33299-3257-45e3-bf75-cafca9d9f090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109721562-172.17.0.11-1595419121379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-e20d2196-f54e-4ad4-9b9e-93ea359f683e,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-1a41ef89-d4d6-4e05-ad01-5ed01f62b270,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-ccff7ec6-fd71-4b0f-9817-6fa04b27d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-6e2b62a9-3b59-4919-be1c-db0c3c17dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-d4981a90-4a37-4ac3-9787-6d9c48800f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-69d15ecc-295e-489b-adac-8d676bfd5eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-69649d50-2295-475c-b06a-bfd76ca6fd82,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-b5029360-37f9-466c-b507-19520fdcc6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109721562-172.17.0.11-1595419121379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-e20d2196-f54e-4ad4-9b9e-93ea359f683e,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-1a41ef89-d4d6-4e05-ad01-5ed01f62b270,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-ccff7ec6-fd71-4b0f-9817-6fa04b27d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-6e2b62a9-3b59-4919-be1c-db0c3c17dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-d4981a90-4a37-4ac3-9787-6d9c48800f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-69d15ecc-295e-489b-adac-8d676bfd5eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-69649d50-2295-475c-b06a-bfd76ca6fd82,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-b5029360-37f9-466c-b507-19520fdcc6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557384853-172.17.0.11-1595420143717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-bde1917a-c840-4e84-8e2d-c39eeb5216c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-1e5eea2a-5d6b-406b-bcfe-61a0898f2396,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-ad617670-9eda-447e-a400-8afe2b4d64e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-bd24bf99-7772-4d05-a027-d0e295176aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-b4c1c692-8229-4e52-8995-1580c73ba107,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-4f0cfb0a-b092-4b98-b20c-f7879e286cec,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-a9c82b35-d177-4835-80cc-ed723a9d95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-086b16fa-7e5d-40d9-8163-517105db392f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557384853-172.17.0.11-1595420143717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-bde1917a-c840-4e84-8e2d-c39eeb5216c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-1e5eea2a-5d6b-406b-bcfe-61a0898f2396,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-ad617670-9eda-447e-a400-8afe2b4d64e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-bd24bf99-7772-4d05-a027-d0e295176aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-b4c1c692-8229-4e52-8995-1580c73ba107,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-4f0cfb0a-b092-4b98-b20c-f7879e286cec,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-a9c82b35-d177-4835-80cc-ed723a9d95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-086b16fa-7e5d-40d9-8163-517105db392f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977862879-172.17.0.11-1595420188786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-00ead358-542f-4347-b0ec-efa3fae3c657,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-cedc7672-3492-44b8-826e-eb4dd2f75ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-8c05b40e-f4c7-471a-900f-56bc96132fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-b2bbec86-e11a-4e56-8787-88ebdaf3d750,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-c5469932-e90e-4090-8b87-62ac43f6e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-51bd3605-bf8d-4687-bc3c-9eb2d5afe0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-90d0efb1-50e7-421e-9ede-b1688dff1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-fe6fd467-1586-4f64-84c8-03b6d1f677cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977862879-172.17.0.11-1595420188786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-00ead358-542f-4347-b0ec-efa3fae3c657,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-cedc7672-3492-44b8-826e-eb4dd2f75ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-8c05b40e-f4c7-471a-900f-56bc96132fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-b2bbec86-e11a-4e56-8787-88ebdaf3d750,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-c5469932-e90e-4090-8b87-62ac43f6e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-51bd3605-bf8d-4687-bc3c-9eb2d5afe0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-90d0efb1-50e7-421e-9ede-b1688dff1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-fe6fd467-1586-4f64-84c8-03b6d1f677cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013560370-172.17.0.11-1595420411176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-93dd490d-bf1c-44b1-ab7e-c07374bfe8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-f75c96c2-9c9b-4e32-9456-6d92017b85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-a1c77bfd-35d8-434a-9070-168062283f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-c5b75641-2a61-4f82-9f97-0f2eb29b5d81,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-2fb7870d-c007-4147-92a6-3dc0e2b3824f,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-7e103851-049d-438f-bda6-1c8baae35288,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-6565516b-e402-4922-b4d9-3c795caa68ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-a33d76a0-1e22-4843-9b1c-7aed24a8f2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013560370-172.17.0.11-1595420411176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-93dd490d-bf1c-44b1-ab7e-c07374bfe8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-f75c96c2-9c9b-4e32-9456-6d92017b85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-a1c77bfd-35d8-434a-9070-168062283f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-c5b75641-2a61-4f82-9f97-0f2eb29b5d81,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-2fb7870d-c007-4147-92a6-3dc0e2b3824f,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-7e103851-049d-438f-bda6-1c8baae35288,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-6565516b-e402-4922-b4d9-3c795caa68ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-a33d76a0-1e22-4843-9b1c-7aed24a8f2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442881675-172.17.0.11-1595420670238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35430,DS-83121c8a-9b4e-40ad-b3e4-2e8b8b60b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-691e0133-32ec-4eb6-9f0e-75f08b16a7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-d1d7b776-b212-401d-b10a-34e7934793fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-b6ac281b-aacf-4c3f-b5b4-0995d0f21f18,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-753400b7-6f05-4c4c-a5a1-857ce8319030,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-48cf08e3-d292-4c4f-9a1e-6a2a4baf999a,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-5b0fd57f-17f4-446e-bb3b-46d90338d581,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-e0235278-d9c9-48c2-a9d8-7daa193c071a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442881675-172.17.0.11-1595420670238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35430,DS-83121c8a-9b4e-40ad-b3e4-2e8b8b60b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-691e0133-32ec-4eb6-9f0e-75f08b16a7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-d1d7b776-b212-401d-b10a-34e7934793fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-b6ac281b-aacf-4c3f-b5b4-0995d0f21f18,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-753400b7-6f05-4c4c-a5a1-857ce8319030,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-48cf08e3-d292-4c4f-9a1e-6a2a4baf999a,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-5b0fd57f-17f4-446e-bb3b-46d90338d581,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-e0235278-d9c9-48c2-a9d8-7daa193c071a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129376171-172.17.0.11-1595421280052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-9cdd738a-5579-4c93-9eaa-853581f010c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-44ea65b1-12c8-48a0-b9a6-a30defaf0c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-f8fcf8cf-ef24-4bec-8c1b-22e8c54f18ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-1a0ac05b-6910-4f8d-b598-bcddc120cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-0b3598e6-5d03-457f-98b5-763e1db1d646,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-98c687e2-1d4e-449b-8b00-56ca34ce988c,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-8b26d995-8553-4e20-b568-307dee2923d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-a5287785-3461-43f0-9bd2-2512d52cf445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129376171-172.17.0.11-1595421280052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-9cdd738a-5579-4c93-9eaa-853581f010c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-44ea65b1-12c8-48a0-b9a6-a30defaf0c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-f8fcf8cf-ef24-4bec-8c1b-22e8c54f18ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-1a0ac05b-6910-4f8d-b598-bcddc120cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-0b3598e6-5d03-457f-98b5-763e1db1d646,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-98c687e2-1d4e-449b-8b00-56ca34ce988c,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-8b26d995-8553-4e20-b568-307dee2923d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-a5287785-3461-43f0-9bd2-2512d52cf445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970840673-172.17.0.11-1595421485700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-42985f5b-c506-4c0c-99a5-f403a20d2546,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-95012739-00fa-4427-8e38-a588c7a902b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-5c0c7151-b9b6-466c-afa4-a20c8bd47b82,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ac66c2fa-9af4-45fe-ad2f-f4950eedea77,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-cfd9dabc-542e-4517-8fce-58d2e1ca76dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-75d0620a-448a-444b-80d8-4b1d3630b04c,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-5d9998b0-1d89-4bfc-839b-bb9f2428b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-17187399-ae63-47b0-a106-353c301977f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970840673-172.17.0.11-1595421485700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-42985f5b-c506-4c0c-99a5-f403a20d2546,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-95012739-00fa-4427-8e38-a588c7a902b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-5c0c7151-b9b6-466c-afa4-a20c8bd47b82,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ac66c2fa-9af4-45fe-ad2f-f4950eedea77,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-cfd9dabc-542e-4517-8fce-58d2e1ca76dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-75d0620a-448a-444b-80d8-4b1d3630b04c,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-5d9998b0-1d89-4bfc-839b-bb9f2428b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-17187399-ae63-47b0-a106-353c301977f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160631121-172.17.0.11-1595421758799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-a82b4556-6ed1-4a50-b1e6-f958b7b4be62,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-21eba27d-65a3-4c43-b6b3-cf3cefe28151,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-fb5dd95d-a618-42e5-81d8-10d6b03aafba,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-f92fa067-eeef-4ff0-ab5d-a431874cfee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-889809c2-3c39-4cef-b877-6bcd9a5a8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-66d1e8c0-bb84-4f77-9e70-553a80c99a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-59cf0260-bd64-4cdd-8c27-b24cc82a1e37,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-06eb0e7c-071d-481a-bdf0-723d03d67cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160631121-172.17.0.11-1595421758799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-a82b4556-6ed1-4a50-b1e6-f958b7b4be62,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-21eba27d-65a3-4c43-b6b3-cf3cefe28151,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-fb5dd95d-a618-42e5-81d8-10d6b03aafba,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-f92fa067-eeef-4ff0-ab5d-a431874cfee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-889809c2-3c39-4cef-b877-6bcd9a5a8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-66d1e8c0-bb84-4f77-9e70-553a80c99a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-59cf0260-bd64-4cdd-8c27-b24cc82a1e37,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-06eb0e7c-071d-481a-bdf0-723d03d67cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580719544-172.17.0.11-1595422043355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-f82f3746-5702-442c-8b99-9a7621850bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-acb80e16-80fd-4cc6-9209-fd34528d7e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-036d931c-17ef-426f-8b7b-8d0030181c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-fd467dc7-8b75-428b-963c-92fe1eed5f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-d5e2cbaa-6562-40c3-b583-69e1ef5f97d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-3dd746cd-86d6-482c-9dbf-80ea089e7c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-c6354880-164d-4361-913c-d9a9618ec0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-a727daae-b8b0-49ca-8548-380f97ba3b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580719544-172.17.0.11-1595422043355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-f82f3746-5702-442c-8b99-9a7621850bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-acb80e16-80fd-4cc6-9209-fd34528d7e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-036d931c-17ef-426f-8b7b-8d0030181c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-fd467dc7-8b75-428b-963c-92fe1eed5f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-d5e2cbaa-6562-40c3-b583-69e1ef5f97d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-3dd746cd-86d6-482c-9dbf-80ea089e7c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-c6354880-164d-4361-913c-d9a9618ec0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-a727daae-b8b0-49ca-8548-380f97ba3b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528558662-172.17.0.11-1595422093808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35882,DS-65e1a8a8-783b-402a-b8ac-2b5569825082,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-300f68bd-8bd9-4495-ae4b-9a996205d225,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-b872e10a-4d64-47e8-8f03-b9c92391e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-34c92a27-8966-45de-aa0b-214385266e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-f32154a8-6c11-4520-ab33-a541cbbe9c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-4228ab00-f5ef-4122-8f49-12f66d6a5e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-c45973a9-eb11-421b-b653-970aeccc8165,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-e877f277-3378-44ab-a0f2-857f10d940d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528558662-172.17.0.11-1595422093808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35882,DS-65e1a8a8-783b-402a-b8ac-2b5569825082,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-300f68bd-8bd9-4495-ae4b-9a996205d225,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-b872e10a-4d64-47e8-8f03-b9c92391e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-34c92a27-8966-45de-aa0b-214385266e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-f32154a8-6c11-4520-ab33-a541cbbe9c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-4228ab00-f5ef-4122-8f49-12f66d6a5e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-c45973a9-eb11-421b-b653-970aeccc8165,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-e877f277-3378-44ab-a0f2-857f10d940d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550781598-172.17.0.11-1595422269084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45051,DS-cd44bc6d-df9f-4a14-9d6e-41319c2aef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-208b78ab-2ab7-42d9-a296-5a0e312c27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-7daaeaff-4901-45f9-a3ea-368a37c93e76,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-65150a0e-aa4b-4d05-b35f-35545c6b9a97,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-60ca29ff-8e35-43a3-aab6-304d55926576,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-d65dc28e-b5cd-4e0b-b63d-c5e0dcead4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-965094b4-524a-4905-a1fb-40ff1d300388,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-4416f585-a42e-4331-92e6-f8f0f0442041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550781598-172.17.0.11-1595422269084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45051,DS-cd44bc6d-df9f-4a14-9d6e-41319c2aef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-208b78ab-2ab7-42d9-a296-5a0e312c27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-7daaeaff-4901-45f9-a3ea-368a37c93e76,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-65150a0e-aa4b-4d05-b35f-35545c6b9a97,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-60ca29ff-8e35-43a3-aab6-304d55926576,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-d65dc28e-b5cd-4e0b-b63d-c5e0dcead4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-965094b4-524a-4905-a1fb-40ff1d300388,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-4416f585-a42e-4331-92e6-f8f0f0442041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24028002-172.17.0.11-1595422484746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-8c18abe4-4b91-4d47-8a0e-5ae4c41518e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-0be42a74-0bf9-4c1e-a738-bf2a677fe835,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-2e2b852c-c5ca-4579-972e-d22a6636f32d,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-9844f0cb-99e6-4669-913f-6f83c3658262,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-72e3d8c0-bc3f-423a-b109-6523a4925134,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-2b1a3edf-f92e-4cb6-a8c6-51253edfdc48,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-7ae000af-93fa-4402-8b4b-eade9bf5c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-f6728f7f-c6a7-4645-975a-1089c828d1bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24028002-172.17.0.11-1595422484746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-8c18abe4-4b91-4d47-8a0e-5ae4c41518e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-0be42a74-0bf9-4c1e-a738-bf2a677fe835,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-2e2b852c-c5ca-4579-972e-d22a6636f32d,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-9844f0cb-99e6-4669-913f-6f83c3658262,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-72e3d8c0-bc3f-423a-b109-6523a4925134,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-2b1a3edf-f92e-4cb6-a8c6-51253edfdc48,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-7ae000af-93fa-4402-8b4b-eade9bf5c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-f6728f7f-c6a7-4645-975a-1089c828d1bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104882801-172.17.0.11-1595423304600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36894,DS-cafbbb88-44d6-470c-b8d7-0b060699af62,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-74bd460e-8753-494f-ae0a-967219e77dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-d7f9051a-8a02-4761-9c4a-f22cafd63554,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ca78e8ea-e7ec-49e8-a986-49107af20e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-81640f38-98f4-4a9a-83bb-d2105457f481,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-b8398d40-dc90-4494-aa23-635393c470de,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-cc1486cb-7c26-4db4-aa6e-449ee7b6b3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-42d8f1de-146e-4b6f-a532-9f8ab03f9e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104882801-172.17.0.11-1595423304600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36894,DS-cafbbb88-44d6-470c-b8d7-0b060699af62,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-74bd460e-8753-494f-ae0a-967219e77dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-d7f9051a-8a02-4761-9c4a-f22cafd63554,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ca78e8ea-e7ec-49e8-a986-49107af20e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-81640f38-98f4-4a9a-83bb-d2105457f481,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-b8398d40-dc90-4494-aa23-635393c470de,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-cc1486cb-7c26-4db4-aa6e-449ee7b6b3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-42d8f1de-146e-4b6f-a532-9f8ab03f9e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067752130-172.17.0.11-1595423446865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35081,DS-5a5d1bbb-f051-471e-8dfb-b0b497e3efe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-3f7be4f8-b71b-4c0f-a4ae-ae5719ca564a,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-815b2e3e-a4f0-41b7-a6ff-fcecf0dc9db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-6b4f7d8b-edb1-4110-aff1-bf8292a1b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-c0d509a0-18f4-48be-806c-f84d515d243f,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-58f3b9e2-fe78-4bf8-8979-3194fefb6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-7a9353a2-cc0b-4467-b173-22705ddc5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-4597c25d-c8c2-4dd5-9e8b-470fb03ed387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067752130-172.17.0.11-1595423446865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35081,DS-5a5d1bbb-f051-471e-8dfb-b0b497e3efe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-3f7be4f8-b71b-4c0f-a4ae-ae5719ca564a,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-815b2e3e-a4f0-41b7-a6ff-fcecf0dc9db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-6b4f7d8b-edb1-4110-aff1-bf8292a1b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-c0d509a0-18f4-48be-806c-f84d515d243f,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-58f3b9e2-fe78-4bf8-8979-3194fefb6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-7a9353a2-cc0b-4467-b173-22705ddc5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-4597c25d-c8c2-4dd5-9e8b-470fb03ed387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 7072
