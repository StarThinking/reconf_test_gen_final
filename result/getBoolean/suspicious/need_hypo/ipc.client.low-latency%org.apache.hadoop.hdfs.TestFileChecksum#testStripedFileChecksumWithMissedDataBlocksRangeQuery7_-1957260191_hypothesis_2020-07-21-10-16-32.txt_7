reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516439973-172.17.0.6-1595326609121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-602bd287-735b-42d0-8061-ba63de796feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-690b0389-b1fe-4316-9604-fccbb961358f,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-914e2342-5bb5-4fb3-90e2-3237ac607b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-60a9c9bc-2e92-47ea-991f-27370aba9843,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-38b04a8c-490d-490c-8241-7baa7dd2143a,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-07136f6d-a097-4db2-a51b-2b534c7add38,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-bea129a7-af50-401c-b0e2-efc344a71faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-303525a3-7978-4b6b-98cc-23f14b13b915,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516439973-172.17.0.6-1595326609121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-602bd287-735b-42d0-8061-ba63de796feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-690b0389-b1fe-4316-9604-fccbb961358f,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-914e2342-5bb5-4fb3-90e2-3237ac607b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-60a9c9bc-2e92-47ea-991f-27370aba9843,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-38b04a8c-490d-490c-8241-7baa7dd2143a,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-07136f6d-a097-4db2-a51b-2b534c7add38,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-bea129a7-af50-401c-b0e2-efc344a71faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-303525a3-7978-4b6b-98cc-23f14b13b915,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822070408-172.17.0.6-1595326689716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-7cc470f8-3102-4288-892f-7a8aac201f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-8f2da367-62cf-4abf-820a-f22fb5c1020b,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-6b8e198e-f263-4123-9346-011e917218ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-8d1d2972-ae4e-429a-bb1c-ca358834114a,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-0d8a5680-f3d1-443c-8c4e-6eb123302482,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-c4c099e8-6efc-49eb-85b0-d95d8aca5626,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-1820597d-dda1-46bf-a3c2-8dc2b3f26e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-b23c9ab9-d97c-42a8-a370-bcd982641800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822070408-172.17.0.6-1595326689716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-7cc470f8-3102-4288-892f-7a8aac201f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-8f2da367-62cf-4abf-820a-f22fb5c1020b,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-6b8e198e-f263-4123-9346-011e917218ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-8d1d2972-ae4e-429a-bb1c-ca358834114a,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-0d8a5680-f3d1-443c-8c4e-6eb123302482,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-c4c099e8-6efc-49eb-85b0-d95d8aca5626,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-1820597d-dda1-46bf-a3c2-8dc2b3f26e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-b23c9ab9-d97c-42a8-a370-bcd982641800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675828896-172.17.0.6-1595326855086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35280,DS-085f327c-2a9e-4fee-907f-d7602278f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-0d9d940a-6111-49b1-925a-2a9dcb2a4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-0cd284c9-e20e-4e08-9039-36546e54910a,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-cfc33510-716f-443d-8e8e-94ee7434c425,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-48c72fdd-0195-4638-9c68-f9fe379c7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-db3d44d4-c67f-4ec5-a80d-64d86414a3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-7369fb63-d28a-4358-a6d5-7668661a6087,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-5655f7e2-010b-495d-9547-6084560308e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675828896-172.17.0.6-1595326855086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35280,DS-085f327c-2a9e-4fee-907f-d7602278f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-0d9d940a-6111-49b1-925a-2a9dcb2a4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-0cd284c9-e20e-4e08-9039-36546e54910a,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-cfc33510-716f-443d-8e8e-94ee7434c425,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-48c72fdd-0195-4638-9c68-f9fe379c7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-db3d44d4-c67f-4ec5-a80d-64d86414a3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-7369fb63-d28a-4358-a6d5-7668661a6087,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-5655f7e2-010b-495d-9547-6084560308e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046815994-172.17.0.6-1595327121282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-cae10ffb-da8f-4766-a034-1e7b06588988,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-5264d928-2e6b-451a-85aa-485ce51301af,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-36473fb2-c924-4e14-b004-d9c8009dce90,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-4e73b6a8-6704-475d-aedf-464eaff0f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-216f53ff-0325-4d7b-be53-9b60d8a8a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-9da97bf5-4324-4b51-9ea2-9117b5702ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-42e8fcf5-bfe1-4ff3-adca-5d3646a43fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-3a330c41-3849-4f15-891e-2585664ee92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046815994-172.17.0.6-1595327121282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-cae10ffb-da8f-4766-a034-1e7b06588988,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-5264d928-2e6b-451a-85aa-485ce51301af,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-36473fb2-c924-4e14-b004-d9c8009dce90,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-4e73b6a8-6704-475d-aedf-464eaff0f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-216f53ff-0325-4d7b-be53-9b60d8a8a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-9da97bf5-4324-4b51-9ea2-9117b5702ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-42e8fcf5-bfe1-4ff3-adca-5d3646a43fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-3a330c41-3849-4f15-891e-2585664ee92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210717281-172.17.0.6-1595327376710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41045,DS-fb5188fa-caf5-4fdb-bfc0-f1ee2b29cfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-9e328ac4-9a27-42fd-a9d4-c9935aea4046,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-368d0c9c-3b75-4c4d-bc91-5f188a4ac7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-725c35bb-3126-4152-8a56-5847cd81af14,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-6b164baf-e2c7-4e02-894c-eeb47735ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-a6f59581-50c9-4f67-a751-51eddfdc6611,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-159af1d3-2942-4e85-85ba-c2fd3bf34890,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-83db7f6b-a4d7-4666-a039-e552ac440be4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210717281-172.17.0.6-1595327376710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41045,DS-fb5188fa-caf5-4fdb-bfc0-f1ee2b29cfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-9e328ac4-9a27-42fd-a9d4-c9935aea4046,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-368d0c9c-3b75-4c4d-bc91-5f188a4ac7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-725c35bb-3126-4152-8a56-5847cd81af14,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-6b164baf-e2c7-4e02-894c-eeb47735ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-a6f59581-50c9-4f67-a751-51eddfdc6611,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-159af1d3-2942-4e85-85ba-c2fd3bf34890,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-83db7f6b-a4d7-4666-a039-e552ac440be4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132704073-172.17.0.6-1595327515308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46852,DS-937e594f-33b7-48bc-b7fd-5ae0f77ba42e,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-54d42939-d587-4476-8675-f9f0768ac40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-63d0d7a7-d499-4fdf-9804-f9e7ed01f61a,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-bd1f4dac-8f4c-4b7f-984a-5c7b36b082fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-ffa4485f-8a2d-4116-b9cf-459a40a89ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-e672b246-46ff-4d79-8acc-f72f5ff564d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-1fa002f6-5e03-41b1-9828-b0d4d0536db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-3d5c93c4-d899-4a4b-88fc-4a05db2c0b1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132704073-172.17.0.6-1595327515308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46852,DS-937e594f-33b7-48bc-b7fd-5ae0f77ba42e,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-54d42939-d587-4476-8675-f9f0768ac40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-63d0d7a7-d499-4fdf-9804-f9e7ed01f61a,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-bd1f4dac-8f4c-4b7f-984a-5c7b36b082fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-ffa4485f-8a2d-4116-b9cf-459a40a89ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-e672b246-46ff-4d79-8acc-f72f5ff564d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-1fa002f6-5e03-41b1-9828-b0d4d0536db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-3d5c93c4-d899-4a4b-88fc-4a05db2c0b1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874693995-172.17.0.6-1595327863114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36014,DS-801d0f21-46ec-4d8f-a6ce-e8a26978eb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-39c5541c-9141-480b-a620-ac6cf8a27b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-2961c304-03d3-46cb-829f-bb48a4825928,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-baaed515-44c3-4391-bd5b-f4086ba14fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-2b12b3a3-5bbc-4711-badd-4668155d6794,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-be2269ee-209d-47c9-babb-84ec46431484,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-9f557907-a508-4996-bd81-2cf45d500b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-e2913f63-2a5f-4f67-9740-a12969c7e2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874693995-172.17.0.6-1595327863114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36014,DS-801d0f21-46ec-4d8f-a6ce-e8a26978eb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-39c5541c-9141-480b-a620-ac6cf8a27b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-2961c304-03d3-46cb-829f-bb48a4825928,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-baaed515-44c3-4391-bd5b-f4086ba14fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-2b12b3a3-5bbc-4711-badd-4668155d6794,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-be2269ee-209d-47c9-babb-84ec46431484,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-9f557907-a508-4996-bd81-2cf45d500b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-e2913f63-2a5f-4f67-9740-a12969c7e2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094829170-172.17.0.6-1595328168739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45805,DS-d1fca18a-aca8-4602-86d2-cee568462d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-1c879d9c-f8c4-40fc-b01c-270ac07a2296,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-bc24376a-ad6c-4d9b-b607-2cb0ce87498a,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-b0fe9fa1-2ee8-479a-a926-ed2ec7376ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-8fffc752-fdff-48dc-bc61-6df77ce92dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-ab3aabfc-481c-4309-ac71-900d9965607e,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-ebe77c5c-3dc1-4ae6-bc90-d1fb31f75c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ee39977b-45c6-4de1-8a27-61417ef11d28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094829170-172.17.0.6-1595328168739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45805,DS-d1fca18a-aca8-4602-86d2-cee568462d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-1c879d9c-f8c4-40fc-b01c-270ac07a2296,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-bc24376a-ad6c-4d9b-b607-2cb0ce87498a,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-b0fe9fa1-2ee8-479a-a926-ed2ec7376ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-8fffc752-fdff-48dc-bc61-6df77ce92dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-ab3aabfc-481c-4309-ac71-900d9965607e,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-ebe77c5c-3dc1-4ae6-bc90-d1fb31f75c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ee39977b-45c6-4de1-8a27-61417ef11d28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226716725-172.17.0.6-1595328339286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33466,DS-c02a1b64-3722-4d07-af66-9037f0194537,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-26fdea86-6842-41a3-ae72-a355a1ee0e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-2d461c9c-d185-4a35-b393-0fa7c4260bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-9eb8f0f4-2199-4038-8ca7-51354f84011f,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e3ea1308-6d78-4609-812a-8a1204428f96,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-9016e147-186c-4411-a57b-d0f0d606599d,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-9a38d1f7-32a2-40b1-9234-7d14eb878d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-1209a999-5c85-427c-9ba8-810b2190b55a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226716725-172.17.0.6-1595328339286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33466,DS-c02a1b64-3722-4d07-af66-9037f0194537,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-26fdea86-6842-41a3-ae72-a355a1ee0e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-2d461c9c-d185-4a35-b393-0fa7c4260bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-9eb8f0f4-2199-4038-8ca7-51354f84011f,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e3ea1308-6d78-4609-812a-8a1204428f96,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-9016e147-186c-4411-a57b-d0f0d606599d,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-9a38d1f7-32a2-40b1-9234-7d14eb878d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-1209a999-5c85-427c-9ba8-810b2190b55a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507639337-172.17.0.6-1595328512240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41634,DS-15e8b3a1-57f5-4a22-83af-ef7c190483dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-a22d1836-92fa-4817-83fb-66db4c86be99,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-16a0abf2-6d3b-4b36-9ce3-8da6be45cf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-aa311e8b-603b-4c82-8ca7-4ce27675f381,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-10412bc4-a821-4332-b38c-a6ce28a7950d,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ce45b46d-dfbc-4bf2-ac02-b08bc78446c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-65b7b495-9052-4096-9ffe-4cd1f104e942,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-7643f2cf-73dc-4c0e-b967-2761ff36f661,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507639337-172.17.0.6-1595328512240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41634,DS-15e8b3a1-57f5-4a22-83af-ef7c190483dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-a22d1836-92fa-4817-83fb-66db4c86be99,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-16a0abf2-6d3b-4b36-9ce3-8da6be45cf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-aa311e8b-603b-4c82-8ca7-4ce27675f381,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-10412bc4-a821-4332-b38c-a6ce28a7950d,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ce45b46d-dfbc-4bf2-ac02-b08bc78446c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-65b7b495-9052-4096-9ffe-4cd1f104e942,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-7643f2cf-73dc-4c0e-b967-2761ff36f661,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212153876-172.17.0.6-1595328644637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-f4dcaf71-d76d-4dda-934b-c57eba760311,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-3668e2bb-f6dc-4295-9415-66218b245033,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a3fcdeee-a463-4853-a287-656d38d884a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-2c39cb62-494a-4491-b571-fa968888dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-a08dc7d7-1016-4573-aa81-a6ad42c7759a,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-150fe7bc-e6f4-48cd-9c98-7bf8839ec341,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-e0879f6d-9f4e-4d22-a69e-6590d993dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-34a53da8-4b30-454e-bfa6-b7acbd9dfa96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212153876-172.17.0.6-1595328644637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-f4dcaf71-d76d-4dda-934b-c57eba760311,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-3668e2bb-f6dc-4295-9415-66218b245033,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a3fcdeee-a463-4853-a287-656d38d884a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-2c39cb62-494a-4491-b571-fa968888dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-a08dc7d7-1016-4573-aa81-a6ad42c7759a,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-150fe7bc-e6f4-48cd-9c98-7bf8839ec341,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-e0879f6d-9f4e-4d22-a69e-6590d993dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-34a53da8-4b30-454e-bfa6-b7acbd9dfa96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677029871-172.17.0.6-1595328811694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-344bfb52-a12c-496e-8df9-73987b96e2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-51a13c70-c481-41ba-9d79-9396ea36703a,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-e2f70fe5-b540-4c2c-9c95-b28d57c1c0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-7e937b1a-6ba9-4d62-a8af-d6213aa7f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-f95929b5-d565-4ab2-a76b-e96f34dd3aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-6e8a123c-7cfe-4535-886b-69c62b2ff34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-5f481c7d-7a5d-4934-8aaf-5abac8280009,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-10017231-f26d-4371-9108-8f517e33562e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677029871-172.17.0.6-1595328811694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-344bfb52-a12c-496e-8df9-73987b96e2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-51a13c70-c481-41ba-9d79-9396ea36703a,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-e2f70fe5-b540-4c2c-9c95-b28d57c1c0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-7e937b1a-6ba9-4d62-a8af-d6213aa7f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-f95929b5-d565-4ab2-a76b-e96f34dd3aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-6e8a123c-7cfe-4535-886b-69c62b2ff34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-5f481c7d-7a5d-4934-8aaf-5abac8280009,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-10017231-f26d-4371-9108-8f517e33562e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608972635-172.17.0.6-1595329079387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-a439dc7a-cf97-4184-b87d-18c4299046cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-eca59109-94ee-4b18-8a57-758b11b97b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-c2e48355-0778-41aa-ab0c-16135efa140e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-24230f51-a1d2-4d79-a607-786608284ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-2678a9ef-e885-468b-9971-e0a6fac4455c,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-1e860d29-a270-4a9a-826d-5da9f4ec8bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-2cca1d54-9621-4b5e-96b2-047436c39acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-b27c8b24-1f6e-43fd-be18-9c8ae4784879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608972635-172.17.0.6-1595329079387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-a439dc7a-cf97-4184-b87d-18c4299046cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-eca59109-94ee-4b18-8a57-758b11b97b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-c2e48355-0778-41aa-ab0c-16135efa140e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-24230f51-a1d2-4d79-a607-786608284ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-2678a9ef-e885-468b-9971-e0a6fac4455c,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-1e860d29-a270-4a9a-826d-5da9f4ec8bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-2cca1d54-9621-4b5e-96b2-047436c39acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-b27c8b24-1f6e-43fd-be18-9c8ae4784879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956321978-172.17.0.6-1595329210443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-7a4a424f-d658-4b7b-894d-1cabb3ca666b,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-16f81454-2d08-4bb2-8430-9b32a2fff64f,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-1a15abc8-b72d-4284-9c99-aeca5d03dc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-d047d09b-d162-413e-94d5-91febd92bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-336155a9-32ee-4091-8a33-7f42e490fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-1e9bd99c-5380-450c-83ba-6f926049bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-b7eccdf8-e705-41ee-9dcf-eaf57869144a,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-9333ed40-f581-45f7-8ad4-3ec741ce2f78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956321978-172.17.0.6-1595329210443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-7a4a424f-d658-4b7b-894d-1cabb3ca666b,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-16f81454-2d08-4bb2-8430-9b32a2fff64f,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-1a15abc8-b72d-4284-9c99-aeca5d03dc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-d047d09b-d162-413e-94d5-91febd92bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-336155a9-32ee-4091-8a33-7f42e490fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-1e9bd99c-5380-450c-83ba-6f926049bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-b7eccdf8-e705-41ee-9dcf-eaf57869144a,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-9333ed40-f581-45f7-8ad4-3ec741ce2f78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861094757-172.17.0.6-1595329441824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-152f0a88-b14b-48c0-a1cc-e93b84a95008,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-0e41f573-dd0d-4aa9-a411-7ab05fd9cc23,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-feed52f8-c412-4f2a-a93e-2d09405f071a,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-14ed3741-3c82-4081-a7d4-18899015b901,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-96d6647a-9451-4b2e-8a6f-7dd46f9ab66b,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-cdc98ad1-dc7f-470b-aae3-b23a342062f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-72596da7-2407-436d-9afc-62d5b0acd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-e892b7ff-7abb-4e84-9b94-75ead6464c52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861094757-172.17.0.6-1595329441824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-152f0a88-b14b-48c0-a1cc-e93b84a95008,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-0e41f573-dd0d-4aa9-a411-7ab05fd9cc23,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-feed52f8-c412-4f2a-a93e-2d09405f071a,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-14ed3741-3c82-4081-a7d4-18899015b901,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-96d6647a-9451-4b2e-8a6f-7dd46f9ab66b,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-cdc98ad1-dc7f-470b-aae3-b23a342062f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-72596da7-2407-436d-9afc-62d5b0acd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-e892b7ff-7abb-4e84-9b94-75ead6464c52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553962789-172.17.0.6-1595329490952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-32f7b57d-0570-4710-8bd4-6bb4283a2045,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-8621ea92-4bf3-46a3-bdb8-451d2ada74ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-c0d12279-80eb-487f-8505-71c45ab656f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-bef73f0c-7200-4475-ad82-f13e8c903a56,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-5461910d-c192-4a3a-8d3d-ece293a369b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-77685156-73bc-48a3-a3e5-6684ec377ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-ab458e5b-878e-4695-b875-5a15d95a2c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-b319ab9e-2cd6-4a29-8617-c7b9741ebaae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553962789-172.17.0.6-1595329490952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-32f7b57d-0570-4710-8bd4-6bb4283a2045,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-8621ea92-4bf3-46a3-bdb8-451d2ada74ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-c0d12279-80eb-487f-8505-71c45ab656f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-bef73f0c-7200-4475-ad82-f13e8c903a56,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-5461910d-c192-4a3a-8d3d-ece293a369b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-77685156-73bc-48a3-a3e5-6684ec377ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-ab458e5b-878e-4695-b875-5a15d95a2c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-b319ab9e-2cd6-4a29-8617-c7b9741ebaae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408394455-172.17.0.6-1595329768914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-97d31345-a15d-4047-824a-670f3e4d047a,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-accb8591-9800-46ee-9db2-8e03f789f851,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-2d6027e0-9064-4303-9b46-03a075f92ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-0f177feb-4b87-41b8-82a5-40da2b02de11,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-92099bd5-ce2b-40fe-b1b9-3ca651967568,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-f78339c8-d7c4-4e8f-992f-04949cabf0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-243089ef-9f58-4742-ab39-d4d5acabe102,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-710b4cac-c8cd-4bae-8c9e-64a700d9dc61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408394455-172.17.0.6-1595329768914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-97d31345-a15d-4047-824a-670f3e4d047a,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-accb8591-9800-46ee-9db2-8e03f789f851,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-2d6027e0-9064-4303-9b46-03a075f92ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-0f177feb-4b87-41b8-82a5-40da2b02de11,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-92099bd5-ce2b-40fe-b1b9-3ca651967568,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-f78339c8-d7c4-4e8f-992f-04949cabf0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-243089ef-9f58-4742-ab39-d4d5acabe102,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-710b4cac-c8cd-4bae-8c9e-64a700d9dc61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108018900-172.17.0.6-1595329909476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-98773405-4989-43af-836f-e3baa8ce615f,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-1bed12d1-f04c-412f-b393-8573b8a16861,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-00088f2b-7f23-418f-aa77-5ec96087c5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-9712d8b9-8af3-42c2-a38b-47ce265cbe34,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-8650c0fd-de75-45da-8a80-1ea0c9bc96b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-f2f12753-a959-481c-b72c-1951c0c012ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-412e654e-2c12-4a55-8da8-0865d1235d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-bec683fb-5502-4bcf-a68f-b9969db110f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108018900-172.17.0.6-1595329909476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-98773405-4989-43af-836f-e3baa8ce615f,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-1bed12d1-f04c-412f-b393-8573b8a16861,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-00088f2b-7f23-418f-aa77-5ec96087c5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-9712d8b9-8af3-42c2-a38b-47ce265cbe34,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-8650c0fd-de75-45da-8a80-1ea0c9bc96b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-f2f12753-a959-481c-b72c-1951c0c012ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-412e654e-2c12-4a55-8da8-0865d1235d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-bec683fb-5502-4bcf-a68f-b9969db110f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347395353-172.17.0.6-1595330531015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-2bff47a5-b099-45d6-a21b-a588ae19fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-5dc84c96-654e-41c0-a48f-51901aa21c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-bb30dd93-a959-423e-a593-16fb4f7f87b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-2066233b-d8e6-4dc3-8148-2a67bb8a1d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-a16f7855-d638-4fff-b097-af4e6a3fd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-19a0de31-76ad-470f-909e-58b2d8257298,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-0eafd432-ec9f-436d-a67d-40311299b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-2cd66b4f-b546-41bd-9eff-25eb8dfe3a4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347395353-172.17.0.6-1595330531015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-2bff47a5-b099-45d6-a21b-a588ae19fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-5dc84c96-654e-41c0-a48f-51901aa21c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-bb30dd93-a959-423e-a593-16fb4f7f87b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-2066233b-d8e6-4dc3-8148-2a67bb8a1d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-a16f7855-d638-4fff-b097-af4e6a3fd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-19a0de31-76ad-470f-909e-58b2d8257298,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-0eafd432-ec9f-436d-a67d-40311299b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-2cd66b4f-b546-41bd-9eff-25eb8dfe3a4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098806475-172.17.0.6-1595330581181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46655,DS-aebe7b97-13a2-471b-a171-33477fcc5ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-1de48a7e-01b0-4904-b755-dfb372804b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-f18a34bb-8cd4-4d8b-a7e6-d596cc8220e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-ad1098bc-ac20-4f4a-b75d-7a526c31b070,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-c1793e9b-55c2-4d50-8d77-23a32c024a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-74dedb3f-615e-4db5-9175-fb994e422a56,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-552394cd-5cee-40dd-8f12-71c2424873a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-e5ecf6eb-89ac-4895-8a42-c8c0d295958f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098806475-172.17.0.6-1595330581181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46655,DS-aebe7b97-13a2-471b-a171-33477fcc5ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-1de48a7e-01b0-4904-b755-dfb372804b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-f18a34bb-8cd4-4d8b-a7e6-d596cc8220e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-ad1098bc-ac20-4f4a-b75d-7a526c31b070,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-c1793e9b-55c2-4d50-8d77-23a32c024a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-74dedb3f-615e-4db5-9175-fb994e422a56,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-552394cd-5cee-40dd-8f12-71c2424873a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-e5ecf6eb-89ac-4895-8a42-c8c0d295958f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781760939-172.17.0.6-1595331116837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-a5996466-b25f-4927-8784-ffdd35ba0e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-7ce59df1-d16f-46d7-b3c8-639e906e6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-8557f99f-f35f-49a2-9b65-10764bd9c773,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-2d2653c5-581a-4f41-83a1-3317a0a414b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-b45aab41-5139-4eb8-a0e9-459811bf6173,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-5cd20dc8-9ab9-459c-ac90-daffa6bd0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-63416bfb-1879-4c96-8c4c-dac6ebbab93e,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-d719ffef-b6bf-4baa-8944-f788ef68ff1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781760939-172.17.0.6-1595331116837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-a5996466-b25f-4927-8784-ffdd35ba0e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-7ce59df1-d16f-46d7-b3c8-639e906e6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-8557f99f-f35f-49a2-9b65-10764bd9c773,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-2d2653c5-581a-4f41-83a1-3317a0a414b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-b45aab41-5139-4eb8-a0e9-459811bf6173,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-5cd20dc8-9ab9-459c-ac90-daffa6bd0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-63416bfb-1879-4c96-8c4c-dac6ebbab93e,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-d719ffef-b6bf-4baa-8944-f788ef68ff1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126648321-172.17.0.6-1595331260354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-c287f32f-b58b-4f68-ada1-b5049276175e,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-8ae73ea9-e787-4749-9da7-dfe15f32a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-01677723-5faf-4092-9a08-5b58a44cd440,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-eeb2bc6b-7de4-48f7-ab4d-6dfdad216e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-14757389-8a73-4fe7-be77-ad95e1a059db,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-fd200b6e-5f6a-4002-b61b-490d9a47b589,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-ae7bda50-221b-4ed7-ad25-191b39c44434,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-667bdf40-41c5-4987-aeec-6f9614ab2c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126648321-172.17.0.6-1595331260354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-c287f32f-b58b-4f68-ada1-b5049276175e,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-8ae73ea9-e787-4749-9da7-dfe15f32a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-01677723-5faf-4092-9a08-5b58a44cd440,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-eeb2bc6b-7de4-48f7-ab4d-6dfdad216e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-14757389-8a73-4fe7-be77-ad95e1a059db,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-fd200b6e-5f6a-4002-b61b-490d9a47b589,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-ae7bda50-221b-4ed7-ad25-191b39c44434,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-667bdf40-41c5-4987-aeec-6f9614ab2c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224996645-172.17.0.6-1595331399386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-c0680401-cc50-4e9d-950e-4f1cf4f12279,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-b06bc835-9e74-4037-b09f-6a9acb3919de,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-ddc156ec-e2dd-47b2-9438-0e6830b92357,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-40af1277-1bc9-4ab4-ab7a-cf2888b83298,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-5ce79a40-8331-44f5-b1e9-e3f5e5aa1615,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-a9b7f87a-e786-4976-9894-95668fc002f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-ae2ce78c-e2de-49b7-bf46-f7f47461484a,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-a9ef108d-2d73-49f8-a9eb-8aaf1e020b63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224996645-172.17.0.6-1595331399386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-c0680401-cc50-4e9d-950e-4f1cf4f12279,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-b06bc835-9e74-4037-b09f-6a9acb3919de,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-ddc156ec-e2dd-47b2-9438-0e6830b92357,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-40af1277-1bc9-4ab4-ab7a-cf2888b83298,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-5ce79a40-8331-44f5-b1e9-e3f5e5aa1615,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-a9b7f87a-e786-4976-9894-95668fc002f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-ae2ce78c-e2de-49b7-bf46-f7f47461484a,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-a9ef108d-2d73-49f8-a9eb-8aaf1e020b63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63803567-172.17.0.6-1595331487126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-73a76440-ff01-4f01-b38a-1170863c1010,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-ff3547c5-0a5c-4921-9049-19c940ced752,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-80e85f20-cd6d-4f6e-998b-51e363833ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-470b6e24-a1a7-4261-8155-ebd6c0912445,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-8bce12e2-4d24-494a-ae59-5bd2a6a25650,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-d9788823-8fdf-40e5-8ac3-dc3223193b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-7a226073-10f4-4580-823e-00beed894ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-eb931739-b283-45db-a7af-99ab55378d0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63803567-172.17.0.6-1595331487126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-73a76440-ff01-4f01-b38a-1170863c1010,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-ff3547c5-0a5c-4921-9049-19c940ced752,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-80e85f20-cd6d-4f6e-998b-51e363833ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-470b6e24-a1a7-4261-8155-ebd6c0912445,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-8bce12e2-4d24-494a-ae59-5bd2a6a25650,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-d9788823-8fdf-40e5-8ac3-dc3223193b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-7a226073-10f4-4580-823e-00beed894ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-eb931739-b283-45db-a7af-99ab55378d0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603060135-172.17.0.6-1595331626997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32915,DS-fd9866d6-6d78-4616-8159-ddbe1afc9955,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-26faf7fd-a01f-4745-9b59-f49f9fcd420d,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-f926441b-9e2a-4ca8-a3c9-979c905985f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-d09fa878-27a7-42d7-8b6f-254747c4d1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-7d807706-2807-4833-8f92-8308cc95d296,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-e56cd8d1-874f-445e-9e9a-252371befefb,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-115af80d-9a99-41d2-ba7d-363e956c8547,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-f1c798c4-27c9-4b09-a601-b96838e675f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603060135-172.17.0.6-1595331626997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32915,DS-fd9866d6-6d78-4616-8159-ddbe1afc9955,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-26faf7fd-a01f-4745-9b59-f49f9fcd420d,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-f926441b-9e2a-4ca8-a3c9-979c905985f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-d09fa878-27a7-42d7-8b6f-254747c4d1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-7d807706-2807-4833-8f92-8308cc95d296,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-e56cd8d1-874f-445e-9e9a-252371befefb,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-115af80d-9a99-41d2-ba7d-363e956c8547,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-f1c798c4-27c9-4b09-a601-b96838e675f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940332258-172.17.0.6-1595331663290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-a864e822-e111-4d5c-ba8f-e159ad9e818f,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-48b93b02-9f6f-4c0f-bff9-c5ce737dc193,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-a31b012b-17db-40c7-b79b-87d47f64cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-c061a002-e609-442b-98a4-be67ee7b4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-3f26505e-a97f-43d0-80c1-a406d468702c,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-cb672227-decc-4545-9da5-24bc8dd0683e,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-7a00cf40-34c5-410b-a8a9-08cf7fb1b413,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-55d5943b-9dee-4446-bbcd-5f27f0e9368e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940332258-172.17.0.6-1595331663290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-a864e822-e111-4d5c-ba8f-e159ad9e818f,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-48b93b02-9f6f-4c0f-bff9-c5ce737dc193,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-a31b012b-17db-40c7-b79b-87d47f64cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-c061a002-e609-442b-98a4-be67ee7b4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-3f26505e-a97f-43d0-80c1-a406d468702c,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-cb672227-decc-4545-9da5-24bc8dd0683e,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-7a00cf40-34c5-410b-a8a9-08cf7fb1b413,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-55d5943b-9dee-4446-bbcd-5f27f0e9368e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052057203-172.17.0.6-1595331934572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-f9f809d7-82ce-4044-9c95-5d131c2b0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-36942953-7362-404f-b7be-bc74d775ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-ddabe9ae-8a83-4c51-b5b3-818ecb84dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-3bee8910-91e1-409d-8ea2-82c19fc38c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-d2c583ef-07e1-4c80-b09a-499289fb670d,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-3650f928-5865-4d71-923a-a0ba274531ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-98960251-e13d-41bd-9ee1-40e24d2094cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-64031079-18d6-46ad-90c0-d8ee646b3bbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052057203-172.17.0.6-1595331934572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-f9f809d7-82ce-4044-9c95-5d131c2b0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-36942953-7362-404f-b7be-bc74d775ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-ddabe9ae-8a83-4c51-b5b3-818ecb84dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-3bee8910-91e1-409d-8ea2-82c19fc38c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-d2c583ef-07e1-4c80-b09a-499289fb670d,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-3650f928-5865-4d71-923a-a0ba274531ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-98960251-e13d-41bd-9ee1-40e24d2094cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-64031079-18d6-46ad-90c0-d8ee646b3bbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867077822-172.17.0.6-1595332012511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-1318ceb0-a811-4bec-8a5b-dacfa4cb1a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-c1ac9bfe-c6d8-4b25-8a20-bd07fff7b562,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-c24d9569-97f4-430e-83dd-90dbc93e99f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-14f9f4d8-dc10-4db3-a020-0a2053750ded,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-1b113329-fb9d-42ee-b0f8-3093a8b5273f,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-0581a2b2-2b85-443d-ae6f-710a18f1d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-545378f9-5ab2-4012-88b1-3580064c28e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-9e1918d3-b616-44bd-b8a6-53f2b978c709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867077822-172.17.0.6-1595332012511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-1318ceb0-a811-4bec-8a5b-dacfa4cb1a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-c1ac9bfe-c6d8-4b25-8a20-bd07fff7b562,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-c24d9569-97f4-430e-83dd-90dbc93e99f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-14f9f4d8-dc10-4db3-a020-0a2053750ded,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-1b113329-fb9d-42ee-b0f8-3093a8b5273f,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-0581a2b2-2b85-443d-ae6f-710a18f1d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-545378f9-5ab2-4012-88b1-3580064c28e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-9e1918d3-b616-44bd-b8a6-53f2b978c709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940409724-172.17.0.6-1595332146610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-549824f2-5101-4eba-abea-5dafa67d3731,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-51a667be-3d19-403b-a505-7c5f1b9fdb19,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-a5d705f4-749e-4f7f-9a21-73f6724ae2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-df78c7ec-08d7-43ee-9adf-b40a214add0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-9b883da1-3d4b-4319-9a5f-7cdc2e401c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-0be7dc4c-f17a-4fab-940f-40e63488757e,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-3ccca194-6450-4739-9452-6e2d68c3b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-ece65e27-1d7d-4bbd-ab5e-363aa3ad8f50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940409724-172.17.0.6-1595332146610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-549824f2-5101-4eba-abea-5dafa67d3731,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-51a667be-3d19-403b-a505-7c5f1b9fdb19,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-a5d705f4-749e-4f7f-9a21-73f6724ae2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-df78c7ec-08d7-43ee-9adf-b40a214add0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-9b883da1-3d4b-4319-9a5f-7cdc2e401c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-0be7dc4c-f17a-4fab-940f-40e63488757e,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-3ccca194-6450-4739-9452-6e2d68c3b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-ece65e27-1d7d-4bbd-ab5e-363aa3ad8f50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310111353-172.17.0.6-1595332489069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-edddb345-a1a7-48ca-890a-055f67b328be,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-e11c68db-aca9-4a43-9dcb-373b44401abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-3e701169-5263-4d77-bf4e-e42bdaabca06,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-d43d3ac5-1f92-463f-bc7a-834e9d3bd047,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-2756c4ca-19ad-44a4-bcbc-3db7618593a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-2c3392bb-0b22-41ee-a626-be5d36030e38,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-94c5f49e-aeda-4980-b7b5-32f8527e7913,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-780c03df-7b10-4c2c-bc74-59245459359a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310111353-172.17.0.6-1595332489069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-edddb345-a1a7-48ca-890a-055f67b328be,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-e11c68db-aca9-4a43-9dcb-373b44401abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-3e701169-5263-4d77-bf4e-e42bdaabca06,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-d43d3ac5-1f92-463f-bc7a-834e9d3bd047,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-2756c4ca-19ad-44a4-bcbc-3db7618593a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-2c3392bb-0b22-41ee-a626-be5d36030e38,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-94c5f49e-aeda-4980-b7b5-32f8527e7913,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-780c03df-7b10-4c2c-bc74-59245459359a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937323005-172.17.0.6-1595332538590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-8d4b5576-579e-4e72-93da-0e63fa3b3a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-8578d223-663a-4b6a-9cb7-55ce83483407,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-5deed32d-4f0b-4353-991b-88bd01be9a71,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-f26f1197-3217-43c4-93fe-4e8bee521e43,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-13053e47-782f-4444-a6c6-1e0b9190520a,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-1f727f0e-6316-4e26-9656-caba39aa40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-c66f59fc-8a86-4cf8-b9a5-ac827dc2e779,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-4001bd0f-6181-4e73-b683-390589aa7653,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937323005-172.17.0.6-1595332538590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-8d4b5576-579e-4e72-93da-0e63fa3b3a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-8578d223-663a-4b6a-9cb7-55ce83483407,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-5deed32d-4f0b-4353-991b-88bd01be9a71,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-f26f1197-3217-43c4-93fe-4e8bee521e43,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-13053e47-782f-4444-a6c6-1e0b9190520a,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-1f727f0e-6316-4e26-9656-caba39aa40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-c66f59fc-8a86-4cf8-b9a5-ac827dc2e779,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-4001bd0f-6181-4e73-b683-390589aa7653,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437289815-172.17.0.6-1595332673618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39908,DS-b9663c3a-4a55-4db1-ab85-d218a8f2b769,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-56cced8e-85fb-4d09-8cf9-cfeed9a8867a,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-bf4f1ccf-a33b-4af0-99c3-8e630c0fbd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-e933780b-f52a-468d-a606-b04a5a3d090b,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-ab1df856-fdbe-47c1-922f-5817bc827ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-5a13be03-af86-49ce-bc47-64c8974ac289,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-386536d7-2f11-495c-b755-331b60444f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-061063aa-cf2e-4881-8cf3-69c56bb5071f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437289815-172.17.0.6-1595332673618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39908,DS-b9663c3a-4a55-4db1-ab85-d218a8f2b769,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-56cced8e-85fb-4d09-8cf9-cfeed9a8867a,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-bf4f1ccf-a33b-4af0-99c3-8e630c0fbd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-e933780b-f52a-468d-a606-b04a5a3d090b,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-ab1df856-fdbe-47c1-922f-5817bc827ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-5a13be03-af86-49ce-bc47-64c8974ac289,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-386536d7-2f11-495c-b755-331b60444f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-061063aa-cf2e-4881-8cf3-69c56bb5071f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830433065-172.17.0.6-1595332845735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-d4ec76f4-97b6-4531-9ef5-e8321783508c,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-f88201f6-a91f-411a-a3a0-2e1ff716e80b,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-c6bbe1a8-5104-40e0-992c-19e9515837bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-847fa7c1-1077-4d21-9d20-53e681a2c7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f77395ad-9dee-47c3-8f41-4c8f027e6777,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-b2fba63b-add2-4ab5-818c-2d6345104198,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-489d8a37-191f-4595-87ad-4c8dc5505a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a1416eec-308b-4a16-93c0-1f18bdad2ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830433065-172.17.0.6-1595332845735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-d4ec76f4-97b6-4531-9ef5-e8321783508c,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-f88201f6-a91f-411a-a3a0-2e1ff716e80b,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-c6bbe1a8-5104-40e0-992c-19e9515837bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-847fa7c1-1077-4d21-9d20-53e681a2c7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f77395ad-9dee-47c3-8f41-4c8f027e6777,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-b2fba63b-add2-4ab5-818c-2d6345104198,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-489d8a37-191f-4595-87ad-4c8dc5505a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a1416eec-308b-4a16-93c0-1f18bdad2ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776478126-172.17.0.6-1595332940404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-8e8ae1dd-e143-4aa6-ba2e-2430968f8098,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-9f0bc448-326b-4472-acef-5c2c5f9f129f,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-17cd7c50-5d30-4fc8-81f4-e64668018bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-5464687f-eb40-481c-9ec9-7ac042a33532,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-fd13a3ba-a015-4e87-8174-e7fe1a4cc406,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-bc8d31cc-6133-4fb5-b5a9-5034f3b0b09d,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-a91d45f1-0ff3-460e-ac98-51c7a1425ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-e78966c0-92c6-4c39-9a15-b3065126ada3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776478126-172.17.0.6-1595332940404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-8e8ae1dd-e143-4aa6-ba2e-2430968f8098,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-9f0bc448-326b-4472-acef-5c2c5f9f129f,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-17cd7c50-5d30-4fc8-81f4-e64668018bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-5464687f-eb40-481c-9ec9-7ac042a33532,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-fd13a3ba-a015-4e87-8174-e7fe1a4cc406,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-bc8d31cc-6133-4fb5-b5a9-5034f3b0b09d,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-a91d45f1-0ff3-460e-ac98-51c7a1425ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-e78966c0-92c6-4c39-9a15-b3065126ada3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431263763-172.17.0.6-1595333160634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-b7c40180-4b1f-4c63-a462-7d04d0e7b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-de41716d-ae79-49aa-a873-fee0d58788a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-99387471-7985-4ec5-8329-190cb164be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-f5147870-6097-4e47-9ff4-14fb0f9c7d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-46501b96-f4be-48b4-8abb-cd2a59bfc4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-e9dd7e09-b11b-4c01-bf1b-13b74feb1c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-36f8db52-2f25-4544-9196-0f59c1d275ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-34c7d0f5-5515-4c36-94af-ad08b6404eda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431263763-172.17.0.6-1595333160634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-b7c40180-4b1f-4c63-a462-7d04d0e7b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-de41716d-ae79-49aa-a873-fee0d58788a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-99387471-7985-4ec5-8329-190cb164be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-f5147870-6097-4e47-9ff4-14fb0f9c7d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-46501b96-f4be-48b4-8abb-cd2a59bfc4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-e9dd7e09-b11b-4c01-bf1b-13b74feb1c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-36f8db52-2f25-4544-9196-0f59c1d275ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-34c7d0f5-5515-4c36-94af-ad08b6404eda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801004578-172.17.0.6-1595333209746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40420,DS-d391013b-9627-43ac-96e1-5847f0e76a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-9811cd69-57fb-4858-9900-4bb618822fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-a87b676b-5f40-40ba-a690-320e4e458e98,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-64a346ba-6425-4641-8378-6b57556fb15d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-b4e1b929-6fbd-4b81-a104-e5c8187b143c,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-3c01f93c-982f-471b-baf3-5270406deaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-30f23d22-352a-4273-912f-a0229ee50d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-1cf829c1-2663-4bb0-94a5-0e9f1f7f1cab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801004578-172.17.0.6-1595333209746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40420,DS-d391013b-9627-43ac-96e1-5847f0e76a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-9811cd69-57fb-4858-9900-4bb618822fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-a87b676b-5f40-40ba-a690-320e4e458e98,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-64a346ba-6425-4641-8378-6b57556fb15d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-b4e1b929-6fbd-4b81-a104-e5c8187b143c,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-3c01f93c-982f-471b-baf3-5270406deaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-30f23d22-352a-4273-912f-a0229ee50d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-1cf829c1-2663-4bb0-94a5-0e9f1f7f1cab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 19 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: might be true error
Total execution time in seconds : 6641
