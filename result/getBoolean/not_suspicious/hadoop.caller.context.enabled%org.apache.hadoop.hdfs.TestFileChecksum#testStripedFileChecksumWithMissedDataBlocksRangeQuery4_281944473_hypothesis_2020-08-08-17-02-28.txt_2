reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46161573-172.17.0.11-1596906278931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-b72c1704-85a3-4ee3-8235-91216cfca81d,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-aed0f2ea-d446-45df-99d7-13fb9d7ca08d,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-f5360292-fea3-4c3c-af01-77e003faf00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-85c5fde7-8eec-4d02-8c5c-f15701abc113,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-5f40e3e0-5745-40d9-b5ad-ed6e180b95ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-a0d056d3-6a9f-4c85-bfa7-5d538453bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-93df761d-4e99-4471-a4a0-be0827921aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-19a74454-424d-4563-8e5f-c22570edf6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46161573-172.17.0.11-1596906278931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-b72c1704-85a3-4ee3-8235-91216cfca81d,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-aed0f2ea-d446-45df-99d7-13fb9d7ca08d,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-f5360292-fea3-4c3c-af01-77e003faf00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-85c5fde7-8eec-4d02-8c5c-f15701abc113,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-5f40e3e0-5745-40d9-b5ad-ed6e180b95ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-a0d056d3-6a9f-4c85-bfa7-5d538453bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-93df761d-4e99-4471-a4a0-be0827921aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-19a74454-424d-4563-8e5f-c22570edf6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420442053-172.17.0.11-1596906438738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43740,DS-7463c2e8-0a2e-4494-ab0f-31e2eab7502c,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-941aa239-c166-40fb-9694-18ffb89d448d,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-bcb0d878-c601-44f4-8845-f8a1941bde35,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-3348fed2-6ceb-402b-9113-28e59fc6110c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-9de64102-6a51-4619-804a-bc623d86fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-2ec95d72-9e12-4c10-9665-69ae1a148d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-60841f77-0170-4536-abdf-5163040c1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-6fb093ec-115c-4017-937d-833acfa7f75d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420442053-172.17.0.11-1596906438738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43740,DS-7463c2e8-0a2e-4494-ab0f-31e2eab7502c,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-941aa239-c166-40fb-9694-18ffb89d448d,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-bcb0d878-c601-44f4-8845-f8a1941bde35,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-3348fed2-6ceb-402b-9113-28e59fc6110c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-9de64102-6a51-4619-804a-bc623d86fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-2ec95d72-9e12-4c10-9665-69ae1a148d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-60841f77-0170-4536-abdf-5163040c1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-6fb093ec-115c-4017-937d-833acfa7f75d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537211121-172.17.0.11-1596906472463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-137e2be2-e0e1-4a42-8848-ae1497986a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-33ef53ea-39a1-4edf-84b0-02fa6b9aa509,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-3abd20e3-44f9-4ac4-b9a9-f51952fcddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-b43df1cf-4397-4ee0-a4f2-0c30e60877d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-35cc5de5-1a91-46a1-967d-7b042bb8e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-5c09ce7e-21ce-4c8d-ac9c-1fcf776bcd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-f8dfce45-37f2-4717-871e-00fd3521107b,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-d3538c4c-4fee-465d-9d76-5767d1dcfb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537211121-172.17.0.11-1596906472463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-137e2be2-e0e1-4a42-8848-ae1497986a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-33ef53ea-39a1-4edf-84b0-02fa6b9aa509,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-3abd20e3-44f9-4ac4-b9a9-f51952fcddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-b43df1cf-4397-4ee0-a4f2-0c30e60877d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-35cc5de5-1a91-46a1-967d-7b042bb8e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-5c09ce7e-21ce-4c8d-ac9c-1fcf776bcd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-f8dfce45-37f2-4717-871e-00fd3521107b,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-d3538c4c-4fee-465d-9d76-5767d1dcfb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977066374-172.17.0.11-1596906549031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36692,DS-c3cef839-6beb-4234-b331-dc9c199918f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-f92870f3-1be3-4dd2-8d65-1beb35f3273e,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-46e8a63b-ce4b-41e6-90cf-7a78338a308a,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-91ad1b30-9a5c-44fe-9e38-d1066803550a,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-f85750c3-a2d1-4c19-bcba-1e80652bd547,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-b62be8be-0962-4436-8c2a-0b63423f3e90,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-b585487b-079f-447c-82fa-bcaaa0d5f567,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-431c93b5-14cf-46f0-ad58-d79594715ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977066374-172.17.0.11-1596906549031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36692,DS-c3cef839-6beb-4234-b331-dc9c199918f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-f92870f3-1be3-4dd2-8d65-1beb35f3273e,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-46e8a63b-ce4b-41e6-90cf-7a78338a308a,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-91ad1b30-9a5c-44fe-9e38-d1066803550a,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-f85750c3-a2d1-4c19-bcba-1e80652bd547,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-b62be8be-0962-4436-8c2a-0b63423f3e90,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-b585487b-079f-447c-82fa-bcaaa0d5f567,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-431c93b5-14cf-46f0-ad58-d79594715ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311786801-172.17.0.11-1596906583727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46000,DS-2491833c-59f3-449b-aabb-5175c30e80ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-b6e9495e-75c2-4af3-ae87-163871f9caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-800a6330-740c-474a-ae6f-65682d5e4187,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-33e56498-b676-4515-b0e2-7d0ec2dcfb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f7f86981-93c5-423f-9687-72e738443ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-31de9898-bd0f-4bfc-915a-11abedb672e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-a9c94586-a692-43d1-b76d-2fb284b6984c,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-9b2a5f7b-a848-4de2-88f7-1cfc51c03444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311786801-172.17.0.11-1596906583727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46000,DS-2491833c-59f3-449b-aabb-5175c30e80ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-b6e9495e-75c2-4af3-ae87-163871f9caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-800a6330-740c-474a-ae6f-65682d5e4187,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-33e56498-b676-4515-b0e2-7d0ec2dcfb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f7f86981-93c5-423f-9687-72e738443ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-31de9898-bd0f-4bfc-915a-11abedb672e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-a9c94586-a692-43d1-b76d-2fb284b6984c,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-9b2a5f7b-a848-4de2-88f7-1cfc51c03444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973124369-172.17.0.11-1596906867566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-956cf0b3-cb0e-415e-bbae-c0cff90295c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-42f8777e-3a4c-43b1-9a38-07135a68f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-de56875a-0da1-4273-999e-bfd5b9ebc667,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-63ad3249-cb83-469d-9f72-29471d12fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-43c20fe4-0b1e-4e72-b8da-85bafebcf776,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-7b7d2b83-f518-493d-8dd8-104849c88829,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-4c50e2e2-9add-43b8-be52-217897168366,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-9b367aa6-83df-4790-b774-3fa8cc462fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973124369-172.17.0.11-1596906867566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-956cf0b3-cb0e-415e-bbae-c0cff90295c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-42f8777e-3a4c-43b1-9a38-07135a68f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-de56875a-0da1-4273-999e-bfd5b9ebc667,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-63ad3249-cb83-469d-9f72-29471d12fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-43c20fe4-0b1e-4e72-b8da-85bafebcf776,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-7b7d2b83-f518-493d-8dd8-104849c88829,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-4c50e2e2-9add-43b8-be52-217897168366,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-9b367aa6-83df-4790-b774-3fa8cc462fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074417382-172.17.0.11-1596907205968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-64c5c346-e09f-4cb5-bab7-5c58e28bcf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-e7869ebe-2f50-45ed-869c-986da2eb597d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-7ddd5e3a-2542-4bff-a5fe-7cc43364c2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-75e01f61-6a02-413b-b6c0-7c5b26ff0f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-c00440d9-c8bd-48d8-aa70-9cf2a2bd3b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-229f7103-9a94-4e9f-93aa-0cf9027e4b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-4d4b4ab4-d322-4879-98a2-751d184a3980,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-bbb48f7e-0b41-412b-87d3-ec4afe20a9d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074417382-172.17.0.11-1596907205968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-64c5c346-e09f-4cb5-bab7-5c58e28bcf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-e7869ebe-2f50-45ed-869c-986da2eb597d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-7ddd5e3a-2542-4bff-a5fe-7cc43364c2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-75e01f61-6a02-413b-b6c0-7c5b26ff0f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-c00440d9-c8bd-48d8-aa70-9cf2a2bd3b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-229f7103-9a94-4e9f-93aa-0cf9027e4b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-4d4b4ab4-d322-4879-98a2-751d184a3980,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-bbb48f7e-0b41-412b-87d3-ec4afe20a9d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725672590-172.17.0.11-1596907659138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-c93b9e60-3156-4443-87ff-97a99cfb99b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-d2153486-bfb9-42cc-b317-11b626f50284,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-feac5464-66d0-4835-9a64-8d81f86b790f,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-31b8817b-1329-4760-8e5f-5ee9d20e4549,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-8993bfbc-3338-4a14-9dbc-88f2c59f4ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-9d86ec30-50cf-401a-bc85-e8a085a06a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-ce7a465e-76bb-4a73-a683-baff96c73b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-252194d0-57ee-4890-a2b3-75f988d6b8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725672590-172.17.0.11-1596907659138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-c93b9e60-3156-4443-87ff-97a99cfb99b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-d2153486-bfb9-42cc-b317-11b626f50284,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-feac5464-66d0-4835-9a64-8d81f86b790f,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-31b8817b-1329-4760-8e5f-5ee9d20e4549,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-8993bfbc-3338-4a14-9dbc-88f2c59f4ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-9d86ec30-50cf-401a-bc85-e8a085a06a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-ce7a465e-76bb-4a73-a683-baff96c73b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-252194d0-57ee-4890-a2b3-75f988d6b8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483033497-172.17.0.11-1596908867501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-0cb5859c-16e8-46fe-b40a-87edbe6715a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-62456a7b-be0b-41df-9b82-2bbfa33e4c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-91c10560-0aa7-43c8-b441-28394d3a0817,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-29abad21-e2d1-4cc6-be01-dbfa620a6480,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-d6cd9f11-1c6a-4519-8b01-61a3bc098799,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-2ea2eb5a-b979-40ac-82ef-40ab65189373,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-b3f0db17-d44a-41ed-ba38-cf13bb4533d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-0ca7c87f-4427-4dbc-ac54-3bab617b26f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483033497-172.17.0.11-1596908867501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-0cb5859c-16e8-46fe-b40a-87edbe6715a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-62456a7b-be0b-41df-9b82-2bbfa33e4c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-91c10560-0aa7-43c8-b441-28394d3a0817,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-29abad21-e2d1-4cc6-be01-dbfa620a6480,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-d6cd9f11-1c6a-4519-8b01-61a3bc098799,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-2ea2eb5a-b979-40ac-82ef-40ab65189373,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-b3f0db17-d44a-41ed-ba38-cf13bb4533d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-0ca7c87f-4427-4dbc-ac54-3bab617b26f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299529225-172.17.0.11-1596909179136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-0e600533-521d-4314-a113-8d6d9c6cf259,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-97bb1065-a3cd-4ced-92b4-7c9a54164a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-26f24b42-6bdf-4a65-bb44-7ba93a34d254,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-20828014-37b3-4a64-993a-42e5bf9754d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-83fe26c5-77a2-42ea-97ac-ec780685deae,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-4508b317-173e-4d58-a582-76ea15899f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-7d941567-87ff-4259-82e9-617e0aed9ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-287b282c-2ce0-40f3-b6f5-081b6076f235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299529225-172.17.0.11-1596909179136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-0e600533-521d-4314-a113-8d6d9c6cf259,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-97bb1065-a3cd-4ced-92b4-7c9a54164a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-26f24b42-6bdf-4a65-bb44-7ba93a34d254,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-20828014-37b3-4a64-993a-42e5bf9754d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-83fe26c5-77a2-42ea-97ac-ec780685deae,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-4508b317-173e-4d58-a582-76ea15899f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-7d941567-87ff-4259-82e9-617e0aed9ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-287b282c-2ce0-40f3-b6f5-081b6076f235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825786541-172.17.0.11-1596909388714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33322,DS-aeca9bf7-a5eb-4906-9ee8-7bea9c348418,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-5d8ca138-88b9-446b-92ad-2b9837175abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3ee582c8-cede-49a6-8274-355867d84e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-66802d5d-50ef-4d59-b7d7-881327fe8827,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-76bb5cd5-0c70-4c71-9ab9-dae9fa241f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-217192cd-3cb1-4c04-8a87-0d7443697f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-7b0c6788-bf46-4b9c-82ed-006288284ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-5262d145-c2b3-4f5f-b75e-1b3faabfdc19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825786541-172.17.0.11-1596909388714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33322,DS-aeca9bf7-a5eb-4906-9ee8-7bea9c348418,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-5d8ca138-88b9-446b-92ad-2b9837175abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3ee582c8-cede-49a6-8274-355867d84e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-66802d5d-50ef-4d59-b7d7-881327fe8827,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-76bb5cd5-0c70-4c71-9ab9-dae9fa241f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-217192cd-3cb1-4c04-8a87-0d7443697f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-7b0c6788-bf46-4b9c-82ed-006288284ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-5262d145-c2b3-4f5f-b75e-1b3faabfdc19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359381399-172.17.0.11-1596909510052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-910a605d-c2ea-4ae7-8ab2-9aa722b9340b,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-5f339391-9a95-4e9d-af19-cc9d0b60a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-3d337adf-73b0-426d-bd05-52b4bde59dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-ff7602bd-6128-467d-a78b-76cf0c8b0c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-242ee4ef-2a37-4392-b994-ff2b687ffc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-42318b09-d381-427c-8834-507e0a08b247,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-10c37dbf-208e-471f-961f-da6be2cbe80d,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-cb80ab03-c424-4fd2-aa10-ee9b5e683795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359381399-172.17.0.11-1596909510052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-910a605d-c2ea-4ae7-8ab2-9aa722b9340b,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-5f339391-9a95-4e9d-af19-cc9d0b60a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-3d337adf-73b0-426d-bd05-52b4bde59dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-ff7602bd-6128-467d-a78b-76cf0c8b0c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-242ee4ef-2a37-4392-b994-ff2b687ffc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-42318b09-d381-427c-8834-507e0a08b247,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-10c37dbf-208e-471f-961f-da6be2cbe80d,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-cb80ab03-c424-4fd2-aa10-ee9b5e683795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438263355-172.17.0.11-1596909581759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33598,DS-dd8969af-c860-4b27-9d14-d290b66f1844,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-0283c98c-9f0f-471a-840a-427dfe23e373,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-56305adf-e018-42d3-80a1-1f47c2f2863b,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-57be5ebf-89f9-4026-ac8c-9935849cb59f,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-4b0dc354-be9c-4786-9ce2-6b48310a9610,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-9e98be68-6458-4774-9ff3-5a2f4e61c0df,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-75f7ee71-214f-4f80-9708-8890dd05ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-10c07fa1-a082-4950-9819-1d433497296e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438263355-172.17.0.11-1596909581759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33598,DS-dd8969af-c860-4b27-9d14-d290b66f1844,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-0283c98c-9f0f-471a-840a-427dfe23e373,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-56305adf-e018-42d3-80a1-1f47c2f2863b,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-57be5ebf-89f9-4026-ac8c-9935849cb59f,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-4b0dc354-be9c-4786-9ce2-6b48310a9610,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-9e98be68-6458-4774-9ff3-5a2f4e61c0df,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-75f7ee71-214f-4f80-9708-8890dd05ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-10c07fa1-a082-4950-9819-1d433497296e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605408864-172.17.0.11-1596909682859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46591,DS-85d45791-9f95-41b2-817f-7ab9b46686bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-47e37a2e-e0f2-4d7f-8434-af62a1642b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-01b21549-2a3b-498d-82cd-418d9f6d8075,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1665d573-b737-4982-8685-684513652e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-51315751-80b5-4051-a96c-920cdc83b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-85a9364d-53ff-42f3-ae5d-d205de918c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-8f6d86f5-0e6a-4b5b-a1c5-955da3e40bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-cbbb3d45-8eb4-4bf5-a927-c749050d133a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605408864-172.17.0.11-1596909682859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46591,DS-85d45791-9f95-41b2-817f-7ab9b46686bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-47e37a2e-e0f2-4d7f-8434-af62a1642b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-01b21549-2a3b-498d-82cd-418d9f6d8075,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1665d573-b737-4982-8685-684513652e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-51315751-80b5-4051-a96c-920cdc83b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-85a9364d-53ff-42f3-ae5d-d205de918c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-8f6d86f5-0e6a-4b5b-a1c5-955da3e40bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-cbbb3d45-8eb4-4bf5-a927-c749050d133a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712828829-172.17.0.11-1596909714652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-211521be-c902-4b22-a23d-a8c89c22e2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-d08db3c5-e9e6-4e4c-854e-b69b3dc8b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-008169b0-f08b-4810-8a9f-f9eb5056363d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-fd4666e6-2a31-4345-99c6-e500451f58e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-7c5c76fb-a960-44a9-8058-68504a508a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-16a7698b-3621-4478-8213-63ee6b2daaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-d4cae5cc-ff96-4e24-916d-3c533133e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-546bfa77-3b50-447c-9648-b096c46154bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712828829-172.17.0.11-1596909714652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-211521be-c902-4b22-a23d-a8c89c22e2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-d08db3c5-e9e6-4e4c-854e-b69b3dc8b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-008169b0-f08b-4810-8a9f-f9eb5056363d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-fd4666e6-2a31-4345-99c6-e500451f58e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-7c5c76fb-a960-44a9-8058-68504a508a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-16a7698b-3621-4478-8213-63ee6b2daaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-d4cae5cc-ff96-4e24-916d-3c533133e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-546bfa77-3b50-447c-9648-b096c46154bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329496809-172.17.0.11-1596910026086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-7fd198a5-b4f3-468d-983c-3f179aad18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-009c5246-4f87-4b28-a5fb-1659b2f58671,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-8a0c1edb-f1c1-403b-b818-0c5b5eb93c08,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-6d06e40a-9d97-471b-9df1-d56bfaef3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-844e1b3e-fa54-4a25-9a47-3b302805076d,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-ec1c510c-e7cb-4b26-8981-1d05fbaf4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-53481e0e-0d2f-49a7-93cf-cc2b41aad213,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-4d609f46-852c-4961-ab5c-50813a870c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329496809-172.17.0.11-1596910026086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-7fd198a5-b4f3-468d-983c-3f179aad18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-009c5246-4f87-4b28-a5fb-1659b2f58671,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-8a0c1edb-f1c1-403b-b818-0c5b5eb93c08,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-6d06e40a-9d97-471b-9df1-d56bfaef3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-844e1b3e-fa54-4a25-9a47-3b302805076d,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-ec1c510c-e7cb-4b26-8981-1d05fbaf4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-53481e0e-0d2f-49a7-93cf-cc2b41aad213,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-4d609f46-852c-4961-ab5c-50813a870c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323743037-172.17.0.11-1596910135268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-5966d483-5486-4744-b47b-b22538fc9464,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-be01d7db-2017-4a23-b43e-51306e85e1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-03be581f-86ba-4c8f-9538-8a33ba32ca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-8204e5d4-c89b-48f0-b28a-deb83b6f4de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-25956538-76df-4aaa-9491-297c1164d672,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-be5f0669-d303-4192-bc6b-db5ff441d02c,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-d27fe017-31c8-410d-a1d9-6e581d505327,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-3c131e62-6432-4c24-9ffd-010c0926feb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323743037-172.17.0.11-1596910135268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-5966d483-5486-4744-b47b-b22538fc9464,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-be01d7db-2017-4a23-b43e-51306e85e1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-03be581f-86ba-4c8f-9538-8a33ba32ca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-8204e5d4-c89b-48f0-b28a-deb83b6f4de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-25956538-76df-4aaa-9491-297c1164d672,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-be5f0669-d303-4192-bc6b-db5ff441d02c,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-d27fe017-31c8-410d-a1d9-6e581d505327,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-3c131e62-6432-4c24-9ffd-010c0926feb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847693820-172.17.0.11-1596910469762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40283,DS-5b2b197d-ceb8-414f-a592-d1c49c349ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-fa9e9389-67e1-4758-b80f-08c266d5b435,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-e7e35abb-40ba-4223-abb6-6a46a15af571,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-ff51e0dc-e4da-4b5b-870c-664735b60df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-0d273714-a54a-44f1-8fa8-6533c02fcdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-a8f3744b-fa18-4a8b-812a-1986c7c0ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-f9224636-faa0-4438-864a-8e7239533e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-ded6cd63-a310-40a9-8404-b5d65b5e9a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847693820-172.17.0.11-1596910469762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40283,DS-5b2b197d-ceb8-414f-a592-d1c49c349ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-fa9e9389-67e1-4758-b80f-08c266d5b435,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-e7e35abb-40ba-4223-abb6-6a46a15af571,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-ff51e0dc-e4da-4b5b-870c-664735b60df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-0d273714-a54a-44f1-8fa8-6533c02fcdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-a8f3744b-fa18-4a8b-812a-1986c7c0ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-f9224636-faa0-4438-864a-8e7239533e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-ded6cd63-a310-40a9-8404-b5d65b5e9a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649161197-172.17.0.11-1596910671807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42976,DS-068981c3-a756-4789-be29-aee449de3b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-8158e786-d9e7-4242-9541-07475f8a2942,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-64212af4-424b-411e-ad4b-722ee85eed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-d641cc3c-9b04-4aa9-916d-e576613b843b,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-4db40525-665a-4cc7-972d-f8d6efb2c349,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-5b6c8623-c385-4e43-8e34-54fa7f148d99,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-d810352d-3734-4788-8fa9-7d111e00518f,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-4216f7f5-29be-42de-9b9c-638972225087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649161197-172.17.0.11-1596910671807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42976,DS-068981c3-a756-4789-be29-aee449de3b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-8158e786-d9e7-4242-9541-07475f8a2942,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-64212af4-424b-411e-ad4b-722ee85eed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-d641cc3c-9b04-4aa9-916d-e576613b843b,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-4db40525-665a-4cc7-972d-f8d6efb2c349,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-5b6c8623-c385-4e43-8e34-54fa7f148d99,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-d810352d-3734-4788-8fa9-7d111e00518f,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-4216f7f5-29be-42de-9b9c-638972225087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477029768-172.17.0.11-1596910743854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-3a9c60a5-71da-44e7-9f0a-1297f704b824,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-f3fed716-1cef-4ebb-9cbc-b9dd4e62bf87,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-e4e9b106-5b20-4891-b3bc-847b36bd2743,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-a111b568-3773-4a5a-bdb3-bbe1fb475256,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-1c637834-67d0-43e0-be43-0d7db82944e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-15e8a1f4-9b65-43c6-a856-9e700c8c5613,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-5d4d42ed-e50b-4d9f-b50c-9dee4379b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-3c33efe9-0d5f-4550-b2a6-7b9d9ab9d3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477029768-172.17.0.11-1596910743854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-3a9c60a5-71da-44e7-9f0a-1297f704b824,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-f3fed716-1cef-4ebb-9cbc-b9dd4e62bf87,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-e4e9b106-5b20-4891-b3bc-847b36bd2743,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-a111b568-3773-4a5a-bdb3-bbe1fb475256,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-1c637834-67d0-43e0-be43-0d7db82944e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-15e8a1f4-9b65-43c6-a856-9e700c8c5613,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-5d4d42ed-e50b-4d9f-b50c-9dee4379b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-3c33efe9-0d5f-4550-b2a6-7b9d9ab9d3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969569506-172.17.0.11-1596911009311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-6cd1f2a0-9f8a-4350-b401-4e331e25d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-52137478-6f82-4d57-9748-0ba2b700d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-85baef0f-4f6f-49d1-99a5-1e55748ff1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-598011df-422e-4743-945a-ca104c97d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a3c6579b-8fc2-4a56-9170-fbeed98f23f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-4fd01b06-23db-4227-bcce-3ce101a8dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-d2ef5f8a-1b17-4a44-9f15-6f1b8c9ca228,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-ab4a3f11-0255-4d5b-9a7e-d6e4658446d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969569506-172.17.0.11-1596911009311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-6cd1f2a0-9f8a-4350-b401-4e331e25d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-52137478-6f82-4d57-9748-0ba2b700d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-85baef0f-4f6f-49d1-99a5-1e55748ff1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-598011df-422e-4743-945a-ca104c97d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a3c6579b-8fc2-4a56-9170-fbeed98f23f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-4fd01b06-23db-4227-bcce-3ce101a8dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-d2ef5f8a-1b17-4a44-9f15-6f1b8c9ca228,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-ab4a3f11-0255-4d5b-9a7e-d6e4658446d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193273163-172.17.0.11-1596911253435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39253,DS-809f7230-1095-4c3e-8793-4b4a01093472,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-c1fe0ef3-6fbf-4862-a608-10d04b763925,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-ffa09849-6d44-4449-85c4-d194a4d2f398,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-89201464-92fa-407c-afe5-9f1972fba7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-242bb1da-9f7e-4fc4-989f-1ef51ba6893b,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-7403725a-6875-4126-a338-dada66bd892f,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-a2baeae6-9951-418f-9252-b725b2f6cab8,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-cd11e23d-9e44-44de-ba57-a2d2d9f510d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193273163-172.17.0.11-1596911253435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39253,DS-809f7230-1095-4c3e-8793-4b4a01093472,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-c1fe0ef3-6fbf-4862-a608-10d04b763925,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-ffa09849-6d44-4449-85c4-d194a4d2f398,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-89201464-92fa-407c-afe5-9f1972fba7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-242bb1da-9f7e-4fc4-989f-1ef51ba6893b,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-7403725a-6875-4126-a338-dada66bd892f,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-a2baeae6-9951-418f-9252-b725b2f6cab8,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-cd11e23d-9e44-44de-ba57-a2d2d9f510d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5309
