reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940533080-172.17.0.7-1595362043463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-477bd252-e643-4d0d-9a26-03bf1204cd11,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-4fead2fa-fa57-4b54-9821-4ff6fe26327f,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-6d0ff32b-c2f3-4a87-a41e-0e4517ef5275,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-5b8078cb-907c-4828-b8e2-cd900d7349ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-088c3e5b-68e3-44d1-a45a-c6b0b6361d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-038742cc-9e62-446c-bdd0-d3bf85064ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-aa701306-08ba-44da-89da-6c82b9a53394,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-69267851-f434-481e-842e-6716ca697953,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940533080-172.17.0.7-1595362043463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-477bd252-e643-4d0d-9a26-03bf1204cd11,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-4fead2fa-fa57-4b54-9821-4ff6fe26327f,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-6d0ff32b-c2f3-4a87-a41e-0e4517ef5275,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-5b8078cb-907c-4828-b8e2-cd900d7349ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-088c3e5b-68e3-44d1-a45a-c6b0b6361d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-038742cc-9e62-446c-bdd0-d3bf85064ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-aa701306-08ba-44da-89da-6c82b9a53394,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-69267851-f434-481e-842e-6716ca697953,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390392585-172.17.0.7-1595363110562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32842,DS-90560a27-4364-4173-9864-47194e64680c,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-6f90e7ca-d5f3-4976-aab9-923a493b5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-e26d6931-0658-4a92-b89e-dcd1368d3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-4d0dce4a-3e79-4fc4-8653-4ebe93c6d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-72bf254c-a4aa-4407-93b9-d1ee5a91d57e,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-a9a35aa6-9b03-461f-80e6-cd9099a1aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-314338eb-58ae-4c6b-aa2b-888d2c13d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-8c3a5e46-d013-4d35-92b8-176778ce1c79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390392585-172.17.0.7-1595363110562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32842,DS-90560a27-4364-4173-9864-47194e64680c,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-6f90e7ca-d5f3-4976-aab9-923a493b5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-e26d6931-0658-4a92-b89e-dcd1368d3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-4d0dce4a-3e79-4fc4-8653-4ebe93c6d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-72bf254c-a4aa-4407-93b9-d1ee5a91d57e,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-a9a35aa6-9b03-461f-80e6-cd9099a1aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-314338eb-58ae-4c6b-aa2b-888d2c13d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-8c3a5e46-d013-4d35-92b8-176778ce1c79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843334765-172.17.0.7-1595363391715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-ed5fb911-1c46-4db2-893f-68deb230b893,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-0d706200-db2a-4d63-aaff-b59d4d79eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-9b108dd8-a6ab-4024-adce-c9dc4432a247,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-2294d9d8-a10b-404b-8ddf-d4b1ad59f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-916a5ecf-cf2a-45f9-be69-8eb074161ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-9ca4b319-1a5a-47c2-9fb0-30652378153b,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-cc078456-8ae7-44b8-bb96-636d315ceed7,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-46c8d616-c05c-4173-b93a-68f45e1b8373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843334765-172.17.0.7-1595363391715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-ed5fb911-1c46-4db2-893f-68deb230b893,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-0d706200-db2a-4d63-aaff-b59d4d79eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-9b108dd8-a6ab-4024-adce-c9dc4432a247,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-2294d9d8-a10b-404b-8ddf-d4b1ad59f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-916a5ecf-cf2a-45f9-be69-8eb074161ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-9ca4b319-1a5a-47c2-9fb0-30652378153b,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-cc078456-8ae7-44b8-bb96-636d315ceed7,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-46c8d616-c05c-4173-b93a-68f45e1b8373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567992349-172.17.0.7-1595363500921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-4cb42e9d-462e-4208-81bd-46ba9a121405,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-ab12f6c4-1a79-44f6-b116-6024808cdde4,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-b426ca09-2803-414e-bc0f-5a925f928206,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-1890f68f-51a3-41cf-abc4-ff614c43363f,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-a3287eeb-5e84-4ea9-9a8f-6a3be234219d,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-9ef5f65c-0ae8-4c1e-bfa8-9596fa327bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-86a56120-245e-4fe4-b977-b02541e2625b,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-3a878bcd-2eb9-41f3-b4ff-d2b7149f5f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567992349-172.17.0.7-1595363500921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-4cb42e9d-462e-4208-81bd-46ba9a121405,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-ab12f6c4-1a79-44f6-b116-6024808cdde4,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-b426ca09-2803-414e-bc0f-5a925f928206,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-1890f68f-51a3-41cf-abc4-ff614c43363f,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-a3287eeb-5e84-4ea9-9a8f-6a3be234219d,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-9ef5f65c-0ae8-4c1e-bfa8-9596fa327bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-86a56120-245e-4fe4-b977-b02541e2625b,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-3a878bcd-2eb9-41f3-b4ff-d2b7149f5f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413486054-172.17.0.7-1595363569263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-7890555b-a831-4fe2-b4d1-3eb2571abc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-f2858285-64a5-4286-bad5-cb56e855d760,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-fd264032-4175-4738-9ade-f40d0639ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-9b4862b8-b25b-4f3b-8dab-e8f5d83220a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-33682143-e7f5-45a6-b416-b08913f73e57,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-76589ea5-9db3-49fa-8404-b2007012337b,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-9c92d068-23fa-4350-86d9-d32b4678a429,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-37194d1e-1933-4528-b527-52cf79e2ee2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413486054-172.17.0.7-1595363569263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-7890555b-a831-4fe2-b4d1-3eb2571abc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-f2858285-64a5-4286-bad5-cb56e855d760,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-fd264032-4175-4738-9ade-f40d0639ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-9b4862b8-b25b-4f3b-8dab-e8f5d83220a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-33682143-e7f5-45a6-b416-b08913f73e57,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-76589ea5-9db3-49fa-8404-b2007012337b,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-9c92d068-23fa-4350-86d9-d32b4678a429,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-37194d1e-1933-4528-b527-52cf79e2ee2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484977589-172.17.0.7-1595363644219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39370,DS-a744565f-54dd-4838-895b-a27d7d334fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-a44ba7d5-5b81-4681-b557-40232e816c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a6183160-d9ff-467d-baf2-2cfb2b52c0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-0fc00535-10ec-4279-ad88-72e593153644,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-ad58d064-3fb0-472c-bd49-dd423060aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-398718a9-1fb7-4d77-aea0-2eddd796b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-0c231468-0111-460a-a41f-cc5bef293ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-b72ac1da-38fe-4d25-a1de-ba7a059966a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484977589-172.17.0.7-1595363644219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39370,DS-a744565f-54dd-4838-895b-a27d7d334fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-a44ba7d5-5b81-4681-b557-40232e816c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a6183160-d9ff-467d-baf2-2cfb2b52c0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-0fc00535-10ec-4279-ad88-72e593153644,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-ad58d064-3fb0-472c-bd49-dd423060aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-398718a9-1fb7-4d77-aea0-2eddd796b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-0c231468-0111-460a-a41f-cc5bef293ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-b72ac1da-38fe-4d25-a1de-ba7a059966a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216447995-172.17.0.7-1595363708077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-d4da2889-e7cf-40fe-b861-8f125a8bf73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-a6a4eeac-3c28-40bc-b15b-1b50a0f6961d,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-8676e92c-6fb7-47ac-ba7d-639bc73ba493,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-71e5f004-8e49-4b4c-9fe8-89c6413e0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-3966b421-4490-43ec-a336-a1496e8cec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-5fd799e8-e7c3-43a7-b6d7-ceb509973f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-9b40ad72-7c48-4204-b59f-f7c45f49cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-65cb5a3f-d547-4949-afcd-eecbf448c207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216447995-172.17.0.7-1595363708077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-d4da2889-e7cf-40fe-b861-8f125a8bf73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-a6a4eeac-3c28-40bc-b15b-1b50a0f6961d,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-8676e92c-6fb7-47ac-ba7d-639bc73ba493,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-71e5f004-8e49-4b4c-9fe8-89c6413e0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-3966b421-4490-43ec-a336-a1496e8cec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-5fd799e8-e7c3-43a7-b6d7-ceb509973f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-9b40ad72-7c48-4204-b59f-f7c45f49cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-65cb5a3f-d547-4949-afcd-eecbf448c207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960957848-172.17.0.7-1595363787477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-9e3feafa-87ef-4d61-90dc-409046acab77,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-2e1af5dc-2291-4666-a2be-2a36013a630f,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-400537b3-5769-4e9c-a651-3e0ccfd476b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-19e944f2-6c91-4a9f-bf9a-ec0930f6c861,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-b18bb858-ff2f-4c97-8943-68d5de65628b,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-f0c2962b-21bb-427d-b9ce-336d82819825,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-165e758f-4fd9-4c17-85ac-32178186fd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-317bfb4b-e49e-4c85-b2b3-39d1c24db2ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960957848-172.17.0.7-1595363787477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-9e3feafa-87ef-4d61-90dc-409046acab77,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-2e1af5dc-2291-4666-a2be-2a36013a630f,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-400537b3-5769-4e9c-a651-3e0ccfd476b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-19e944f2-6c91-4a9f-bf9a-ec0930f6c861,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-b18bb858-ff2f-4c97-8943-68d5de65628b,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-f0c2962b-21bb-427d-b9ce-336d82819825,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-165e758f-4fd9-4c17-85ac-32178186fd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-317bfb4b-e49e-4c85-b2b3-39d1c24db2ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880451098-172.17.0.7-1595363896792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43329,DS-4f6d1cdf-5cdb-4a8e-a35f-cdcab2b9c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-3470abea-18e6-4443-95d8-4e50cf98bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-2befe881-ecad-43e9-8b5a-8791cc3b5bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-495f5f76-29ff-4f58-9197-bbf708d0eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-91695a86-59a0-4a29-997c-56f6ed63010b,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f0c78ba1-53b8-4a96-b647-c8b810d4d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-28b1a0e1-f060-4cb0-9e13-e6c1d43ff260,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-82d8797d-5555-4266-9ecc-a6b51231ccf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880451098-172.17.0.7-1595363896792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43329,DS-4f6d1cdf-5cdb-4a8e-a35f-cdcab2b9c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-3470abea-18e6-4443-95d8-4e50cf98bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-2befe881-ecad-43e9-8b5a-8791cc3b5bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-495f5f76-29ff-4f58-9197-bbf708d0eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-91695a86-59a0-4a29-997c-56f6ed63010b,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f0c78ba1-53b8-4a96-b647-c8b810d4d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-28b1a0e1-f060-4cb0-9e13-e6c1d43ff260,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-82d8797d-5555-4266-9ecc-a6b51231ccf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10230290-172.17.0.7-1595363969666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45431,DS-dfcd6e27-877a-4ad3-a243-05e23f12d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-46921877-34e9-46a8-ad55-26795a1698a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-db7c5f27-b406-4b48-b9ff-8d96d85f4538,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-ae20cb41-62aa-4871-95bb-6b097cc655b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-f8927ad1-df68-46d1-8ce8-29c97a621575,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-4eb14f0e-cabe-4e80-bd0a-a70a4b2d8351,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-77d5cc5c-2923-4934-ab17-1dd089c9e081,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-920674fb-e067-4fcb-aabb-f12005cf8c5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10230290-172.17.0.7-1595363969666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45431,DS-dfcd6e27-877a-4ad3-a243-05e23f12d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-46921877-34e9-46a8-ad55-26795a1698a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-db7c5f27-b406-4b48-b9ff-8d96d85f4538,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-ae20cb41-62aa-4871-95bb-6b097cc655b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-f8927ad1-df68-46d1-8ce8-29c97a621575,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-4eb14f0e-cabe-4e80-bd0a-a70a4b2d8351,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-77d5cc5c-2923-4934-ab17-1dd089c9e081,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-920674fb-e067-4fcb-aabb-f12005cf8c5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809779698-172.17.0.7-1595364220134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42346,DS-57b44014-f7f9-45f2-a234-f9d5a51252dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-a7b23eba-a011-4de1-8ec6-a2dfcf4b3989,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-7f825761-4a45-428e-8cfc-c35b79696d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-101f2c27-ebee-4b51-b9aa-7f399db16267,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-f1f27441-0599-430e-8e07-c789a96b170b,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-5e933d08-43ec-4def-ad91-4ad1302f1972,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-1d770172-6e78-49c3-b1f2-b672a5caa9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-ec4a0925-9859-4dec-985d-d21afa4ea839,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809779698-172.17.0.7-1595364220134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42346,DS-57b44014-f7f9-45f2-a234-f9d5a51252dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-a7b23eba-a011-4de1-8ec6-a2dfcf4b3989,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-7f825761-4a45-428e-8cfc-c35b79696d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-101f2c27-ebee-4b51-b9aa-7f399db16267,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-f1f27441-0599-430e-8e07-c789a96b170b,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-5e933d08-43ec-4def-ad91-4ad1302f1972,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-1d770172-6e78-49c3-b1f2-b672a5caa9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-ec4a0925-9859-4dec-985d-d21afa4ea839,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405652201-172.17.0.7-1595364455042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43157,DS-aae2caf6-c7bf-45e6-99e6-f9f05179c09a,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-2288f778-a7d6-4f37-994c-ec171bc46ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-69d6a634-1bb8-4a96-82bc-1f908ef07e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-b2482489-f5a5-41b4-b60b-8935497201f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-1ab8ab12-42d4-4386-871a-e6690615742c,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-644cfd12-a14f-490e-b2c5-54a8cdc1e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-c0c2e9f7-4809-46ad-b518-4a9c545fe3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-40830761-2095-43da-8e48-c83614074bce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405652201-172.17.0.7-1595364455042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43157,DS-aae2caf6-c7bf-45e6-99e6-f9f05179c09a,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-2288f778-a7d6-4f37-994c-ec171bc46ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-69d6a634-1bb8-4a96-82bc-1f908ef07e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-b2482489-f5a5-41b4-b60b-8935497201f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-1ab8ab12-42d4-4386-871a-e6690615742c,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-644cfd12-a14f-490e-b2c5-54a8cdc1e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-c0c2e9f7-4809-46ad-b518-4a9c545fe3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-40830761-2095-43da-8e48-c83614074bce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837021720-172.17.0.7-1595364530939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39448,DS-5c4777b7-2058-4d8d-90f9-157c12304ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-8add7a40-8c6c-42bd-8333-9cff8a125423,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7cee13e9-c3b9-422c-8f9b-fe46afbb56c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-1b62e9e8-ffab-4b0f-8001-2bb6eaf9d720,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-fb1ffae3-eca5-4b32-bce3-d1d02c45e448,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-8b3abe2a-9728-47a0-aba0-4729c34373ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-453d9a2f-6ac1-4178-a28d-c1d3bfbb223b,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-e4633399-1805-46d9-8aa5-c59c936fb968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837021720-172.17.0.7-1595364530939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39448,DS-5c4777b7-2058-4d8d-90f9-157c12304ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-8add7a40-8c6c-42bd-8333-9cff8a125423,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7cee13e9-c3b9-422c-8f9b-fe46afbb56c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-1b62e9e8-ffab-4b0f-8001-2bb6eaf9d720,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-fb1ffae3-eca5-4b32-bce3-d1d02c45e448,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-8b3abe2a-9728-47a0-aba0-4729c34373ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-453d9a2f-6ac1-4178-a28d-c1d3bfbb223b,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-e4633399-1805-46d9-8aa5-c59c936fb968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487614412-172.17.0.7-1595364640679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-62bd2df5-c5e5-4593-b291-dbf64a54a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9e145f8d-87b9-4125-b798-653cb0a84e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-135e14d5-4c1d-42ec-ab90-70c0adf92ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-811072c2-7663-42ba-835a-f371fbddf253,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-45237d03-1dca-4f4c-9ffc-49a698fe22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-a5b75a9c-1db0-4b39-98a7-530b980b0e73,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-f76645bd-6a37-4c52-97d0-135866b66050,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-c3c601b0-17aa-432f-9af7-ad0d4e68ac52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487614412-172.17.0.7-1595364640679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-62bd2df5-c5e5-4593-b291-dbf64a54a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9e145f8d-87b9-4125-b798-653cb0a84e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-135e14d5-4c1d-42ec-ab90-70c0adf92ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-811072c2-7663-42ba-835a-f371fbddf253,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-45237d03-1dca-4f4c-9ffc-49a698fe22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-a5b75a9c-1db0-4b39-98a7-530b980b0e73,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-f76645bd-6a37-4c52-97d0-135866b66050,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-c3c601b0-17aa-432f-9af7-ad0d4e68ac52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462212030-172.17.0.7-1595365332695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46235,DS-acf2e482-779d-4faa-b6ba-116080ba88ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-053f4c16-49b7-4cff-9cf7-772bea84f876,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-d5336962-de0a-46ea-9530-317d7652f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-ea03f732-ad08-4f72-af96-7ccc2eba9e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-ef243a1d-ea86-4e6c-94e2-1628665086e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-95e5a721-0602-4467-8bba-ee638907fc82,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-6d3ec81f-9c6a-47ae-baa3-657d211fb259,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-50477c11-8485-47c3-9fc3-ec0d76f35e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462212030-172.17.0.7-1595365332695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46235,DS-acf2e482-779d-4faa-b6ba-116080ba88ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-053f4c16-49b7-4cff-9cf7-772bea84f876,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-d5336962-de0a-46ea-9530-317d7652f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-ea03f732-ad08-4f72-af96-7ccc2eba9e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-ef243a1d-ea86-4e6c-94e2-1628665086e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-95e5a721-0602-4467-8bba-ee638907fc82,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-6d3ec81f-9c6a-47ae-baa3-657d211fb259,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-50477c11-8485-47c3-9fc3-ec0d76f35e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515221361-172.17.0.7-1595365472085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32895,DS-75fa6a24-cd1b-48f5-95d6-f2740461dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-0330b3d3-4d9c-4b08-9750-8caef96bc8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-4036b4ce-4190-414c-a6cf-1512bb6f0815,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-596fb790-746c-4c55-aafe-18798009eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-caf6fb8c-d380-4515-9667-05ab102e98b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-7dcfb170-6f48-43f3-8fa3-080bdbd308df,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-e2f67646-cc2f-4da4-8949-1a61e6345197,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-094f49d3-b772-40ba-8871-4c5f6302e818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515221361-172.17.0.7-1595365472085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32895,DS-75fa6a24-cd1b-48f5-95d6-f2740461dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-0330b3d3-4d9c-4b08-9750-8caef96bc8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-4036b4ce-4190-414c-a6cf-1512bb6f0815,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-596fb790-746c-4c55-aafe-18798009eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-caf6fb8c-d380-4515-9667-05ab102e98b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-7dcfb170-6f48-43f3-8fa3-080bdbd308df,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-e2f67646-cc2f-4da4-8949-1a61e6345197,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-094f49d3-b772-40ba-8871-4c5f6302e818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736157140-172.17.0.7-1595366180959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-b1ed80cf-9b5f-47ee-82de-742223a157cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-47a4764a-244f-4c20-806e-87193b17f742,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-e90d3cb7-3442-4105-9cde-68279b904c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-1e651157-2b34-49b2-9981-6274526e42e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-115b30e5-885c-47f6-8680-8f550f1769a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-93a61dd0-ac40-4313-b484-c2118b196228,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-8fd760e0-3542-4381-8afc-fa6f2372599c,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-d6fa3c1f-5c11-47f1-a1a6-71c32b7f50a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736157140-172.17.0.7-1595366180959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-b1ed80cf-9b5f-47ee-82de-742223a157cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-47a4764a-244f-4c20-806e-87193b17f742,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-e90d3cb7-3442-4105-9cde-68279b904c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-1e651157-2b34-49b2-9981-6274526e42e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-115b30e5-885c-47f6-8680-8f550f1769a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-93a61dd0-ac40-4313-b484-c2118b196228,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-8fd760e0-3542-4381-8afc-fa6f2372599c,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-d6fa3c1f-5c11-47f1-a1a6-71c32b7f50a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709509674-172.17.0.7-1595366222623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-d901a092-e635-4a3b-92e1-98e4aab96554,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-e061e05e-57fe-4098-bd31-d224430923f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-01d7cfd7-c3e1-4c37-8c6e-886b1889b4de,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-b7d6443f-c3db-4357-8a46-49bcc0f578a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-a2118b4d-4ac1-4e4a-9400-12ac3f9e43b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-31d50a23-d40c-42eb-be02-949ad2b07622,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-d4b8c15b-c3ae-4f35-a328-c72cb137d348,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-d615c8a8-4011-4eaf-b6fc-c7564edc2381,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709509674-172.17.0.7-1595366222623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-d901a092-e635-4a3b-92e1-98e4aab96554,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-e061e05e-57fe-4098-bd31-d224430923f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-01d7cfd7-c3e1-4c37-8c6e-886b1889b4de,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-b7d6443f-c3db-4357-8a46-49bcc0f578a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-a2118b4d-4ac1-4e4a-9400-12ac3f9e43b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-31d50a23-d40c-42eb-be02-949ad2b07622,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-d4b8c15b-c3ae-4f35-a328-c72cb137d348,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-d615c8a8-4011-4eaf-b6fc-c7564edc2381,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399341940-172.17.0.7-1595366260936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-a4ea84e5-00e3-4bcf-a43f-653c4b370063,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f31cb5f6-c2fc-452a-97f2-159f5361246f,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-150edc07-d955-49fb-84cf-c67fab2a7859,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-ef6e52bb-7d0a-411b-992d-3639b4cb6a16,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-93ce97c7-6e9a-45a7-8e48-d42de78fffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-5eefeb6e-28ea-4a94-99c2-e22a2ae4174e,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-44671164-fa3b-42c8-bef6-8200ac90c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-5f45f808-7122-49ed-8b2f-94391139d8ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399341940-172.17.0.7-1595366260936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-a4ea84e5-00e3-4bcf-a43f-653c4b370063,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f31cb5f6-c2fc-452a-97f2-159f5361246f,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-150edc07-d955-49fb-84cf-c67fab2a7859,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-ef6e52bb-7d0a-411b-992d-3639b4cb6a16,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-93ce97c7-6e9a-45a7-8e48-d42de78fffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-5eefeb6e-28ea-4a94-99c2-e22a2ae4174e,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-44671164-fa3b-42c8-bef6-8200ac90c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-5f45f808-7122-49ed-8b2f-94391139d8ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295907881-172.17.0.7-1595366295783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-647c0a64-a48e-417c-880f-2ac7cb614ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-77569844-236d-4aed-8929-f6e40e2a551e,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-d949a412-a655-401f-852e-12d67abb6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-e9438ed7-1283-4497-8c4f-847d97c201fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-87f874b9-c4a0-4b6d-8173-f97e3f9f3338,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-c605fd69-4d0b-4839-9b6b-6ca17e465e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-21eb7780-c8ae-4e55-b0d7-db06a137473d,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-4eea7349-c168-4b58-8de7-13cb21bd97e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295907881-172.17.0.7-1595366295783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-647c0a64-a48e-417c-880f-2ac7cb614ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-77569844-236d-4aed-8929-f6e40e2a551e,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-d949a412-a655-401f-852e-12d67abb6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-e9438ed7-1283-4497-8c4f-847d97c201fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-87f874b9-c4a0-4b6d-8173-f97e3f9f3338,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-c605fd69-4d0b-4839-9b6b-6ca17e465e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-21eb7780-c8ae-4e55-b0d7-db06a137473d,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-4eea7349-c168-4b58-8de7-13cb21bd97e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788357524-172.17.0.7-1595366378713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-5636d9ec-9168-4f65-ac95-1630d1d4db25,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-4c866784-3e0d-4076-bfa0-212f370836f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-84851e50-c165-4812-acae-6ccf30a8c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-8ada2492-60f0-43ce-9ac0-56f054ba4f90,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-1d9929c5-fca8-48f5-afe9-5199eaacafdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-89983a4d-86e8-4ecf-80ac-502fa06a5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-80dae1b5-e9f1-48e2-852b-a47c83edc2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-b7c896c9-f326-4505-84cd-fe01e5a6d02d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788357524-172.17.0.7-1595366378713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-5636d9ec-9168-4f65-ac95-1630d1d4db25,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-4c866784-3e0d-4076-bfa0-212f370836f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-84851e50-c165-4812-acae-6ccf30a8c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-8ada2492-60f0-43ce-9ac0-56f054ba4f90,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-1d9929c5-fca8-48f5-afe9-5199eaacafdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-89983a4d-86e8-4ecf-80ac-502fa06a5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-80dae1b5-e9f1-48e2-852b-a47c83edc2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-b7c896c9-f326-4505-84cd-fe01e5a6d02d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629955198-172.17.0.7-1595366422070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-30dbafbe-64ea-4549-91fd-56b22fd8f57a,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-015db77a-afc2-4fbb-a1a5-37902c9e0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-0a71fed6-5160-4332-b1ee-0a29181a38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-6f4160d2-9919-42fc-951b-c72b4056053c,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-c93cc5a6-dc6e-448c-b7d5-3ac4ee11f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-42308e1e-5655-4d42-93ab-0377beefa6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-49bb40c0-3406-479c-8c8b-84910fc7f736,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-1acec51f-bb7b-4214-953c-e388eda285d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629955198-172.17.0.7-1595366422070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-30dbafbe-64ea-4549-91fd-56b22fd8f57a,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-015db77a-afc2-4fbb-a1a5-37902c9e0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-0a71fed6-5160-4332-b1ee-0a29181a38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-6f4160d2-9919-42fc-951b-c72b4056053c,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-c93cc5a6-dc6e-448c-b7d5-3ac4ee11f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-42308e1e-5655-4d42-93ab-0377beefa6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-49bb40c0-3406-479c-8c8b-84910fc7f736,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-1acec51f-bb7b-4214-953c-e388eda285d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306300095-172.17.0.7-1595367148012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34409,DS-6ee4b05e-1981-4024-9f0a-94b24c717b09,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-373a69d9-9c90-4afd-aea9-a30bd26b0469,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-39ebf348-7255-4f00-9d49-93226a94ed23,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-ca4a7e49-ec59-45c8-b57c-5a57970263a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-a58c8a71-f355-4d68-88eb-b101d458fc40,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-c9639e2a-002b-462f-a7e4-ec9a1c965d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b0faff54-d83f-4ca5-9997-997907d10622,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-ebd88b07-bb3e-49d0-adab-f1c2c8edfee7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306300095-172.17.0.7-1595367148012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34409,DS-6ee4b05e-1981-4024-9f0a-94b24c717b09,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-373a69d9-9c90-4afd-aea9-a30bd26b0469,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-39ebf348-7255-4f00-9d49-93226a94ed23,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-ca4a7e49-ec59-45c8-b57c-5a57970263a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-a58c8a71-f355-4d68-88eb-b101d458fc40,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-c9639e2a-002b-462f-a7e4-ec9a1c965d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b0faff54-d83f-4ca5-9997-997907d10622,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-ebd88b07-bb3e-49d0-adab-f1c2c8edfee7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.caching.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869396584-172.17.0.7-1595367474971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-25b16a60-af0e-4e10-b815-a184af6c0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-ace7380d-ff6c-41d0-b0fe-7bb8da4356f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-861a2c7f-9a2d-4b96-ba5c-074a75470618,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-694bc128-958c-4729-9bee-1e255d9b504a,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-d25cbc46-1fa6-4a0c-a014-e112a8d94c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-493fb323-ebb9-487c-bb9d-87d89be8df10,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-7604a1dd-58b7-46f0-8855-81948ce9448f,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-72cd0e70-1a35-4336-95f8-cb169e2b1fea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869396584-172.17.0.7-1595367474971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-25b16a60-af0e-4e10-b815-a184af6c0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-ace7380d-ff6c-41d0-b0fe-7bb8da4356f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-861a2c7f-9a2d-4b96-ba5c-074a75470618,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-694bc128-958c-4729-9bee-1e255d9b504a,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-d25cbc46-1fa6-4a0c-a014-e112a8d94c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-493fb323-ebb9-487c-bb9d-87d89be8df10,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-7604a1dd-58b7-46f0-8855-81948ce9448f,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-72cd0e70-1a35-4336-95f8-cb169e2b1fea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5834
