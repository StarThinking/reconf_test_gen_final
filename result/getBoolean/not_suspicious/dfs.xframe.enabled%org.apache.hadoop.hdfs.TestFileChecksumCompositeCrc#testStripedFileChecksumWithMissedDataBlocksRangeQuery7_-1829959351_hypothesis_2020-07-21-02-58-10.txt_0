reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994833118-172.17.0.16-1595300431197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-854ef44b-d104-4185-aeae-2edf39e2a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-64112db9-727e-4d00-96dc-27d53c71c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-069382c2-2626-4961-8d90-1a985b8e8f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-107e7b2c-0a54-4441-8fbd-f80f6748b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-11a1b725-d62d-4603-9240-fc7ef6baa58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-07a18308-e15c-4f11-84dc-256e3dc60631,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-411216e1-2fbb-4e26-8b8b-24c1be54c344,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-04733721-85b1-4151-a40a-4d9dc1034a17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994833118-172.17.0.16-1595300431197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-854ef44b-d104-4185-aeae-2edf39e2a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-64112db9-727e-4d00-96dc-27d53c71c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-069382c2-2626-4961-8d90-1a985b8e8f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-107e7b2c-0a54-4441-8fbd-f80f6748b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-11a1b725-d62d-4603-9240-fc7ef6baa58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-07a18308-e15c-4f11-84dc-256e3dc60631,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-411216e1-2fbb-4e26-8b8b-24c1be54c344,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-04733721-85b1-4151-a40a-4d9dc1034a17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675698344-172.17.0.16-1595300468659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-5c8be526-d9bb-45bb-8bfc-456795ffafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-3f6de95b-6288-4d1b-b74b-0fa698d0d5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-4f7e7e15-18a7-4b79-96ef-90d095efbb73,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-b16a2c16-b518-4e91-b91f-1145c828a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-4538176f-c55c-4753-b624-06183b342083,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-4f3070e1-1da8-4cca-a106-b34576358e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-09a0b862-9214-4798-a4bf-22b23f6d925b,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-63c8c2ca-f58f-4f7d-a794-6ce23bffa6f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675698344-172.17.0.16-1595300468659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-5c8be526-d9bb-45bb-8bfc-456795ffafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-3f6de95b-6288-4d1b-b74b-0fa698d0d5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-4f7e7e15-18a7-4b79-96ef-90d095efbb73,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-b16a2c16-b518-4e91-b91f-1145c828a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-4538176f-c55c-4753-b624-06183b342083,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-4f3070e1-1da8-4cca-a106-b34576358e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-09a0b862-9214-4798-a4bf-22b23f6d925b,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-63c8c2ca-f58f-4f7d-a794-6ce23bffa6f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149577414-172.17.0.16-1595300506387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-6f3ad624-9a3d-4c52-9f98-b9df0ab096b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-87d2edf7-6258-4da3-9a7e-0c0495d9e788,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-a7326996-9c6d-473f-a146-c2a359a856cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-d92aaf8f-21b0-4e84-91b4-3701e65c5937,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a2cc91c7-1686-40eb-9279-dacaed8ce4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-7197e912-9529-40d0-9a7b-2bd3a419f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-d7bbedbb-995d-4380-9fbf-85fc1c6f39fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-e5e859d2-fe10-4552-b808-cedfdbb1db1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149577414-172.17.0.16-1595300506387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-6f3ad624-9a3d-4c52-9f98-b9df0ab096b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-87d2edf7-6258-4da3-9a7e-0c0495d9e788,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-a7326996-9c6d-473f-a146-c2a359a856cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-d92aaf8f-21b0-4e84-91b4-3701e65c5937,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a2cc91c7-1686-40eb-9279-dacaed8ce4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-7197e912-9529-40d0-9a7b-2bd3a419f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-d7bbedbb-995d-4380-9fbf-85fc1c6f39fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-e5e859d2-fe10-4552-b808-cedfdbb1db1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527851438-172.17.0.16-1595300543489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-cf30d7c2-f419-4113-ac3d-0b06e6897351,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-72cd850f-2c27-44ec-a47d-92d82c886984,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-9b63ea6f-3e82-49fe-a3b7-deedc513973f,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-0cb8abe4-94c8-407b-a6c5-82c9b809d74e,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-dacef4a1-974a-4925-9db6-5916e7f16af0,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-cbfc727c-86d4-4142-b768-f6b7c73a9ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-7370be85-7191-4d2e-88d4-2dd6cbb13274,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-cf997916-a140-4356-b743-65c5021d93ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527851438-172.17.0.16-1595300543489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-cf30d7c2-f419-4113-ac3d-0b06e6897351,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-72cd850f-2c27-44ec-a47d-92d82c886984,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-9b63ea6f-3e82-49fe-a3b7-deedc513973f,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-0cb8abe4-94c8-407b-a6c5-82c9b809d74e,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-dacef4a1-974a-4925-9db6-5916e7f16af0,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-cbfc727c-86d4-4142-b768-f6b7c73a9ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-7370be85-7191-4d2e-88d4-2dd6cbb13274,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-cf997916-a140-4356-b743-65c5021d93ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899242783-172.17.0.16-1595300923609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39479,DS-f497bf32-0849-4235-8c51-7b2740e6bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-baae601b-b453-409b-95e3-dc85167961d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-546fd3b9-e982-431e-8d8b-a6d59f879182,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-8f6f7f26-598c-4c29-b163-fe6de1a4e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-54dba036-adea-468a-9293-b6cd26176ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-8a4798bf-1b18-4c0c-82d5-9d0c7cf7543b,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-af1e797c-b77f-46dd-b44a-d894009ec476,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-55cea5cb-56a7-4ef3-ba11-f4051f3132e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899242783-172.17.0.16-1595300923609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39479,DS-f497bf32-0849-4235-8c51-7b2740e6bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-baae601b-b453-409b-95e3-dc85167961d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-546fd3b9-e982-431e-8d8b-a6d59f879182,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-8f6f7f26-598c-4c29-b163-fe6de1a4e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-54dba036-adea-468a-9293-b6cd26176ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-8a4798bf-1b18-4c0c-82d5-9d0c7cf7543b,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-af1e797c-b77f-46dd-b44a-d894009ec476,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-55cea5cb-56a7-4ef3-ba11-f4051f3132e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089584149-172.17.0.16-1595300963812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-be600d75-2b7f-47c9-95a4-ed3945d57e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-e1ad5c41-4d7c-4f88-9ae5-ab903824f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-9a67ea2b-40e3-451f-81fc-2206059f4c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-9e683c05-8fb2-46dd-8620-1cb54eafeb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-6fa419e7-5ee8-458c-823c-e4bc559e0125,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-84d63143-e692-42e8-a6fb-e5b5be61d233,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-d8639f96-4ef4-4f29-91f1-34db97f88805,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-3fa48f21-0f7d-47e9-8da1-0ce289965bea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089584149-172.17.0.16-1595300963812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-be600d75-2b7f-47c9-95a4-ed3945d57e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-e1ad5c41-4d7c-4f88-9ae5-ab903824f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-9a67ea2b-40e3-451f-81fc-2206059f4c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-9e683c05-8fb2-46dd-8620-1cb54eafeb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-6fa419e7-5ee8-458c-823c-e4bc559e0125,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-84d63143-e692-42e8-a6fb-e5b5be61d233,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-d8639f96-4ef4-4f29-91f1-34db97f88805,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-3fa48f21-0f7d-47e9-8da1-0ce289965bea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126996179-172.17.0.16-1595301049374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-61cf9ea0-109b-411e-9549-0ace49decff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-5a34fb61-4238-4c61-8365-84a280f1ddab,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-e6dc84a4-38f3-4c03-bf4b-de411f64f4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-a62ac6d7-9c4d-466f-be71-9fa83ef295a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-f8022913-2bca-441e-ab13-1c782f5f6024,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-f86587e8-0473-42a8-9f3b-ca6bf5ca52a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-1cbc334b-0c75-40cd-98cb-88c65fabfb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-c40ab5a7-f843-49c6-baf5-cb92495bd368,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126996179-172.17.0.16-1595301049374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-61cf9ea0-109b-411e-9549-0ace49decff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-5a34fb61-4238-4c61-8365-84a280f1ddab,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-e6dc84a4-38f3-4c03-bf4b-de411f64f4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-a62ac6d7-9c4d-466f-be71-9fa83ef295a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-f8022913-2bca-441e-ab13-1c782f5f6024,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-f86587e8-0473-42a8-9f3b-ca6bf5ca52a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-1cbc334b-0c75-40cd-98cb-88c65fabfb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-c40ab5a7-f843-49c6-baf5-cb92495bd368,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823128293-172.17.0.16-1595301152834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-d97809cc-9931-4e25-8fa2-127b34bb02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-5710036e-65f1-4c29-8376-47ae430b2dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-f2cbd15e-6062-4c84-ae07-75a64ac1d667,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-fe658479-d909-4c6c-b93a-ac440e5bd855,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-fc7ffb38-dec9-4edb-ae6f-a2f75f71f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-5f2e2128-1088-46d0-ab54-3859945b6043,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-bc55d31c-3a1b-44d8-b3a9-878fc2ce052c,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-5174a046-7ca1-4bed-96cf-3d35805f646f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823128293-172.17.0.16-1595301152834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-d97809cc-9931-4e25-8fa2-127b34bb02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-5710036e-65f1-4c29-8376-47ae430b2dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-f2cbd15e-6062-4c84-ae07-75a64ac1d667,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-fe658479-d909-4c6c-b93a-ac440e5bd855,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-fc7ffb38-dec9-4edb-ae6f-a2f75f71f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-5f2e2128-1088-46d0-ab54-3859945b6043,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-bc55d31c-3a1b-44d8-b3a9-878fc2ce052c,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-5174a046-7ca1-4bed-96cf-3d35805f646f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871234786-172.17.0.16-1595301825115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35040,DS-f698f553-a55a-4fe4-8f7e-e73f76cd1604,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-909aa68d-9012-4752-a415-63dd82c1145f,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-ee43a188-c730-475b-bc7c-cf6635178cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-68b753e8-0abd-4a57-af29-21e12e167eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-241d5b5a-b848-4345-af5b-a09ad9c0b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-5dd3c8b0-6149-405f-800f-c122e7f4393e,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-90f226b4-62f4-4b0c-a247-0e36d6945460,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-c4efd437-62fa-4d55-b0c2-9b521a5ce8bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871234786-172.17.0.16-1595301825115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35040,DS-f698f553-a55a-4fe4-8f7e-e73f76cd1604,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-909aa68d-9012-4752-a415-63dd82c1145f,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-ee43a188-c730-475b-bc7c-cf6635178cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-68b753e8-0abd-4a57-af29-21e12e167eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-241d5b5a-b848-4345-af5b-a09ad9c0b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-5dd3c8b0-6149-405f-800f-c122e7f4393e,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-90f226b4-62f4-4b0c-a247-0e36d6945460,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-c4efd437-62fa-4d55-b0c2-9b521a5ce8bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470477862-172.17.0.16-1595301946237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-8012227a-d63a-4d28-adf3-67437d6826f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-ca1723cd-c87d-4310-a5c8-77cb1b7f52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-856999ba-679e-49df-a3e9-3f1df6c80228,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-808402d1-3c65-4b13-91a1-4b9b5c98007d,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-0635278f-e1ba-46f1-9745-2dff5a47d481,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-bbb8d353-0c98-4503-b6b9-ef76065355cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-9423f1b6-1da9-4db4-9408-78bb094ed2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-1db11415-5283-4b7e-9bdb-25b968d7e19f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470477862-172.17.0.16-1595301946237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-8012227a-d63a-4d28-adf3-67437d6826f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-ca1723cd-c87d-4310-a5c8-77cb1b7f52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-856999ba-679e-49df-a3e9-3f1df6c80228,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-808402d1-3c65-4b13-91a1-4b9b5c98007d,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-0635278f-e1ba-46f1-9745-2dff5a47d481,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-bbb8d353-0c98-4503-b6b9-ef76065355cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-9423f1b6-1da9-4db4-9408-78bb094ed2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-1db11415-5283-4b7e-9bdb-25b968d7e19f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532065594-172.17.0.16-1595302148654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-44e5f9d9-0889-49a7-9645-1c4776c10a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-cf4d8a56-363f-404c-9d9d-ff0b11ce2198,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-fee476ff-ad8c-4a0b-80d9-7376f8615127,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-73f7e21b-5ec4-4859-a97a-a0c74cc8a891,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-5132d7f1-461b-426a-8520-879c57698975,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-3a1a19c8-08db-423f-9e3d-24f298f935fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-f87cfb3e-9e7c-406b-9446-871aad639f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-7c7e25be-c7f9-471e-875d-a2406a95d9be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532065594-172.17.0.16-1595302148654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-44e5f9d9-0889-49a7-9645-1c4776c10a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-cf4d8a56-363f-404c-9d9d-ff0b11ce2198,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-fee476ff-ad8c-4a0b-80d9-7376f8615127,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-73f7e21b-5ec4-4859-a97a-a0c74cc8a891,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-5132d7f1-461b-426a-8520-879c57698975,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-3a1a19c8-08db-423f-9e3d-24f298f935fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-f87cfb3e-9e7c-406b-9446-871aad639f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-7c7e25be-c7f9-471e-875d-a2406a95d9be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643952661-172.17.0.16-1595302216455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-12a1c2a8-7bd1-451c-b05e-7b470eb566c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ace11b84-5438-417e-a917-305db3ab381d,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-997aba10-895d-4301-8feb-71d1466305c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-d1a17d54-821b-40ea-8472-31810f31b6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-cf96e7ce-7480-408b-8803-c863c35fe760,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-772ba2bc-0e48-49af-8df8-c789cca237a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-8badfc3e-5f08-412d-9718-7d1582a6f196,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-57b81ab3-4387-4ad0-acf9-b1fb27e810de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643952661-172.17.0.16-1595302216455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-12a1c2a8-7bd1-451c-b05e-7b470eb566c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ace11b84-5438-417e-a917-305db3ab381d,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-997aba10-895d-4301-8feb-71d1466305c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-d1a17d54-821b-40ea-8472-31810f31b6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-cf96e7ce-7480-408b-8803-c863c35fe760,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-772ba2bc-0e48-49af-8df8-c789cca237a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-8badfc3e-5f08-412d-9718-7d1582a6f196,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-57b81ab3-4387-4ad0-acf9-b1fb27e810de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12392739-172.17.0.16-1595302515579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46541,DS-91c1a211-9add-4e48-b1f6-c457f80e5cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-72b46c63-dee6-4648-a310-c929e7f8c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-c8d7eebb-f6dd-4a4e-a3fa-df86421a509b,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-1636a6f5-8aff-4d5a-b53f-930e8b15e805,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-3d25cbba-fc77-4705-8873-1773ebf2057f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-1b752381-4af5-45f1-96fb-ff9cd220a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-54acf010-ddf7-4b15-94d8-d5f0bac7a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-d8e23d89-4d86-4e62-8006-1d64e3e88c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12392739-172.17.0.16-1595302515579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46541,DS-91c1a211-9add-4e48-b1f6-c457f80e5cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-72b46c63-dee6-4648-a310-c929e7f8c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-c8d7eebb-f6dd-4a4e-a3fa-df86421a509b,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-1636a6f5-8aff-4d5a-b53f-930e8b15e805,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-3d25cbba-fc77-4705-8873-1773ebf2057f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-1b752381-4af5-45f1-96fb-ff9cd220a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-54acf010-ddf7-4b15-94d8-d5f0bac7a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-d8e23d89-4d86-4e62-8006-1d64e3e88c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142344817-172.17.0.16-1595302691497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-f05da213-219a-4b69-8be7-80427e31048a,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-52e0a7c0-1b1c-4661-afe0-17d0569a8670,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-afd48e52-0768-4cdc-b78e-b2cc5a0f2355,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-e5de9d31-2a1f-40b5-aaab-cf1a778e29e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-53e1449b-0e34-4694-80c1-6ff91a55ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-afc5d264-e07b-4872-b234-ca6b2b188e27,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-9db4208d-61d7-41e0-9a75-a3a602976711,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-07dee09e-4a6d-46c6-9e8a-8605a789681b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142344817-172.17.0.16-1595302691497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-f05da213-219a-4b69-8be7-80427e31048a,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-52e0a7c0-1b1c-4661-afe0-17d0569a8670,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-afd48e52-0768-4cdc-b78e-b2cc5a0f2355,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-e5de9d31-2a1f-40b5-aaab-cf1a778e29e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-53e1449b-0e34-4694-80c1-6ff91a55ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-afc5d264-e07b-4872-b234-ca6b2b188e27,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-9db4208d-61d7-41e0-9a75-a3a602976711,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-07dee09e-4a6d-46c6-9e8a-8605a789681b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123094115-172.17.0.16-1595302727219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45880,DS-50dbcb94-2132-44bf-866d-15abbe5c3980,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-f5e0893d-102a-49fd-ab0e-ad85ccc5d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-c39ffbc9-3c13-4175-850b-6007745b1d68,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-be10eac1-6e30-43c4-9734-9ef2c94a5f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-c8314b14-fb9d-462c-8948-bed0ce1fbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-f03c64d0-7c1a-4ce6-b7cc-1e6296b66026,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-927b8c68-c5f2-4b11-b61f-e7c9a9547b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-689976f5-edc0-4acc-9981-b04244e297f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123094115-172.17.0.16-1595302727219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45880,DS-50dbcb94-2132-44bf-866d-15abbe5c3980,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-f5e0893d-102a-49fd-ab0e-ad85ccc5d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-c39ffbc9-3c13-4175-850b-6007745b1d68,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-be10eac1-6e30-43c4-9734-9ef2c94a5f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-c8314b14-fb9d-462c-8948-bed0ce1fbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-f03c64d0-7c1a-4ce6-b7cc-1e6296b66026,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-927b8c68-c5f2-4b11-b61f-e7c9a9547b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-689976f5-edc0-4acc-9981-b04244e297f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754564811-172.17.0.16-1595302805215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-cd851507-1593-427d-acd3-a07a16b4e6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-a10cbb35-4e26-4b33-8cd5-d12f77386371,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-d9025d77-0935-46b8-b56b-b6ba0ebc1fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-e0605b0f-3f80-4414-b88b-78ecd14a176b,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-133ae90e-f7c8-43ee-b7b2-bac28607b403,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-16800420-1a23-467e-81eb-ecd48293585d,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-fe8dc4ae-55f4-4343-96b7-06196b368156,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-b5cabc14-1b1a-44b1-9769-aa60f4ce23bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754564811-172.17.0.16-1595302805215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-cd851507-1593-427d-acd3-a07a16b4e6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-a10cbb35-4e26-4b33-8cd5-d12f77386371,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-d9025d77-0935-46b8-b56b-b6ba0ebc1fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-e0605b0f-3f80-4414-b88b-78ecd14a176b,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-133ae90e-f7c8-43ee-b7b2-bac28607b403,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-16800420-1a23-467e-81eb-ecd48293585d,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-fe8dc4ae-55f4-4343-96b7-06196b368156,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-b5cabc14-1b1a-44b1-9769-aa60f4ce23bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008761971-172.17.0.16-1595302843254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33834,DS-bd9d57ce-d80e-4190-9f94-be14a809b7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-888a7c71-0f6c-4123-9ed0-39121a92b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-8720846b-7793-4fc9-9fff-142f53077b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-34b855b0-a4e4-4b8a-a737-d4307ee349a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1c92f00b-dabe-4ab1-bdc2-dbc603310433,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-848cc1a1-b0a9-4404-bf7d-72736f1b19e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-c47f919f-40eb-4bbd-a8a7-38cc4a8dbd13,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-d9a37c96-4512-43ca-904a-d0a3e104d03b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008761971-172.17.0.16-1595302843254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33834,DS-bd9d57ce-d80e-4190-9f94-be14a809b7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-888a7c71-0f6c-4123-9ed0-39121a92b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-8720846b-7793-4fc9-9fff-142f53077b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-34b855b0-a4e4-4b8a-a737-d4307ee349a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1c92f00b-dabe-4ab1-bdc2-dbc603310433,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-848cc1a1-b0a9-4404-bf7d-72736f1b19e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-c47f919f-40eb-4bbd-a8a7-38cc4a8dbd13,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-d9a37c96-4512-43ca-904a-d0a3e104d03b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189212937-172.17.0.16-1595302907226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40859,DS-54b6b9ca-5d7b-4eb0-ba25-a831820983c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-68546e83-a76a-4b91-9be9-f6b839b56616,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-d935e1f2-d7c9-44d8-9bec-bf253d4a83b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-a8602287-43cf-4398-bb57-6508c00b9599,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-99506ee6-1b9f-40e0-8989-0cb34767b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-d3e9a42f-26fb-457f-8140-2c7824c75f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-80ed91b4-5997-4bbb-8450-32251d5dc44b,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-defe52d9-52e0-46b7-9f32-ba09df108454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189212937-172.17.0.16-1595302907226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40859,DS-54b6b9ca-5d7b-4eb0-ba25-a831820983c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-68546e83-a76a-4b91-9be9-f6b839b56616,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-d935e1f2-d7c9-44d8-9bec-bf253d4a83b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-a8602287-43cf-4398-bb57-6508c00b9599,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-99506ee6-1b9f-40e0-8989-0cb34767b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-d3e9a42f-26fb-457f-8140-2c7824c75f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-80ed91b4-5997-4bbb-8450-32251d5dc44b,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-defe52d9-52e0-46b7-9f32-ba09df108454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877757204-172.17.0.16-1595303009386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44680,DS-98e85176-cb34-4134-86fd-28f3680e5924,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-c032b014-c68f-45a8-bdd0-921b202e2e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-3ff838e9-1029-48b8-a558-f8cc96816600,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-e6e53544-bf1a-42bc-a4b1-eeb3dcd4e94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-c0867f30-b226-42f5-a0cf-6292f5de6475,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-5da92061-cbbe-4ce6-b94d-2198dd2fec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-13ebc9e3-fb3f-498e-ac7f-77f1af155186,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-83ba8b8e-bfd7-4609-84cd-606c228d33b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877757204-172.17.0.16-1595303009386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44680,DS-98e85176-cb34-4134-86fd-28f3680e5924,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-c032b014-c68f-45a8-bdd0-921b202e2e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-3ff838e9-1029-48b8-a558-f8cc96816600,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-e6e53544-bf1a-42bc-a4b1-eeb3dcd4e94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-c0867f30-b226-42f5-a0cf-6292f5de6475,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-5da92061-cbbe-4ce6-b94d-2198dd2fec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-13ebc9e3-fb3f-498e-ac7f-77f1af155186,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-83ba8b8e-bfd7-4609-84cd-606c228d33b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063660300-172.17.0.16-1595303087031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-80441a78-47ec-4410-a01b-3df4738fd730,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-8ca3a35e-547b-4fac-9c99-7615540fef15,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b7e927fb-824c-4d66-84c4-340b72c2f371,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-80238306-0328-461d-b9df-d126a90f906b,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-4f8941dd-32e1-400e-a759-8a678c4d7cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-61af6e45-f8bd-4db8-a48a-ed3f14a51640,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-7c52f924-71d6-48c6-83ba-f884a61cb609,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-6cb976b2-8206-4615-a667-11d1c2ca3e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063660300-172.17.0.16-1595303087031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-80441a78-47ec-4410-a01b-3df4738fd730,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-8ca3a35e-547b-4fac-9c99-7615540fef15,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b7e927fb-824c-4d66-84c4-340b72c2f371,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-80238306-0328-461d-b9df-d126a90f906b,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-4f8941dd-32e1-400e-a759-8a678c4d7cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-61af6e45-f8bd-4db8-a48a-ed3f14a51640,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-7c52f924-71d6-48c6-83ba-f884a61cb609,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-6cb976b2-8206-4615-a667-11d1c2ca3e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443229338-172.17.0.16-1595303121957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40244,DS-ce922bc8-9a17-4da5-b931-4833d7626c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-156e2ede-0db4-4228-9090-b49cc07999c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-6e269b92-9bc8-4adb-86c3-d3c77177d132,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-c1f9526f-cbde-4e5d-b93e-e51a9e5e47e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-0627a56d-6d8a-4a44-86c0-5a0054a1b492,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-4a1fbe2d-4ffb-48da-9a83-4aa6606aaf45,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-815f2867-12d6-4c8d-924f-f6d0a1c4b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-bbfc587f-bb7e-4799-a570-73b5fcb6ea0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443229338-172.17.0.16-1595303121957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40244,DS-ce922bc8-9a17-4da5-b931-4833d7626c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-156e2ede-0db4-4228-9090-b49cc07999c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-6e269b92-9bc8-4adb-86c3-d3c77177d132,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-c1f9526f-cbde-4e5d-b93e-e51a9e5e47e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-0627a56d-6d8a-4a44-86c0-5a0054a1b492,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-4a1fbe2d-4ffb-48da-9a83-4aa6606aaf45,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-815f2867-12d6-4c8d-924f-f6d0a1c4b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-bbfc587f-bb7e-4799-a570-73b5fcb6ea0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110456345-172.17.0.16-1595303231826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36397,DS-103ab5e3-0c6a-4204-b8a5-317a652443f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-e99f0048-6b7b-411a-bbd0-f3e3e6766153,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-d4ce7f22-9273-40c1-9a8e-f6d2e53d6765,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-82332459-b704-4996-a898-3d2ee417661b,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-db67798e-daec-4229-821f-36bfbb080d94,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-2d458d68-2ed2-41d2-a0a7-f5bc6cf515c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-ac0944f7-d290-4275-a83e-967f2f8562ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-2421f1da-fa7d-4e07-a031-81a2fb6f1d3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110456345-172.17.0.16-1595303231826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36397,DS-103ab5e3-0c6a-4204-b8a5-317a652443f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-e99f0048-6b7b-411a-bbd0-f3e3e6766153,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-d4ce7f22-9273-40c1-9a8e-f6d2e53d6765,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-82332459-b704-4996-a898-3d2ee417661b,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-db67798e-daec-4229-821f-36bfbb080d94,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-2d458d68-2ed2-41d2-a0a7-f5bc6cf515c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-ac0944f7-d290-4275-a83e-967f2f8562ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-2421f1da-fa7d-4e07-a031-81a2fb6f1d3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105778038-172.17.0.16-1595303307614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-4a670f5f-2be3-4020-9be0-e2f99a75ba2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-7a8bc69d-043f-4256-8851-d57269a5f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-917569d7-9cb5-4853-b0d0-a09e6a492928,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-d9f3bad9-dbf8-4bc2-b5cc-55fd582a9cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-5b63df67-d5ce-4e94-afc9-b031ba210af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-9f02aa32-94c5-40f2-9c50-a7b2296ace1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-6c309c4d-e1d4-48cd-a504-ceab3c33f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ccee15fd-aef6-45d6-a389-655ed03c1ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105778038-172.17.0.16-1595303307614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-4a670f5f-2be3-4020-9be0-e2f99a75ba2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-7a8bc69d-043f-4256-8851-d57269a5f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-917569d7-9cb5-4853-b0d0-a09e6a492928,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-d9f3bad9-dbf8-4bc2-b5cc-55fd582a9cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-5b63df67-d5ce-4e94-afc9-b031ba210af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-9f02aa32-94c5-40f2-9c50-a7b2296ace1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-6c309c4d-e1d4-48cd-a504-ceab3c33f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ccee15fd-aef6-45d6-a389-655ed03c1ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715012916-172.17.0.16-1595303578322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-85338915-82ee-4d75-a98c-d2539423ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-e43986e3-4686-4602-8334-73ccdea1801a,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-85e8670e-30bb-4f29-a414-e98512c0fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-5afd1935-1b73-44e8-ac4e-56896813fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-b9fb9472-e375-4bcc-86ad-7ff0b77458f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-71940e6d-8890-4cab-b105-b60663516bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-17c81614-5e57-4d54-b8e0-51903cd103c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-18831ab2-70cf-41d9-9059-cd66e37bce20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715012916-172.17.0.16-1595303578322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-85338915-82ee-4d75-a98c-d2539423ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-e43986e3-4686-4602-8334-73ccdea1801a,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-85e8670e-30bb-4f29-a414-e98512c0fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-5afd1935-1b73-44e8-ac4e-56896813fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-b9fb9472-e375-4bcc-86ad-7ff0b77458f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-71940e6d-8890-4cab-b105-b60663516bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-17c81614-5e57-4d54-b8e0-51903cd103c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-18831ab2-70cf-41d9-9059-cd66e37bce20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129629017-172.17.0.16-1595303615156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33403,DS-2905eeb8-fca2-41af-ad1f-e81f75e59b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-96040765-440f-49db-a88a-87ade24bb04d,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-b611b3e1-592b-4457-aed9-af93ea1c2d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-4d7ef9cb-cab6-4cae-9a69-7f242f77cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-0ffa1b9b-ae4b-4c62-b4f1-ffda085e48b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-179a151f-e1a2-4f33-899a-6ac1cd5d5160,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-dc7561bb-a71f-4959-b6e7-b6e9927ae7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-92eb7cb6-205f-4ad2-bd7a-873053bcf80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129629017-172.17.0.16-1595303615156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33403,DS-2905eeb8-fca2-41af-ad1f-e81f75e59b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-96040765-440f-49db-a88a-87ade24bb04d,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-b611b3e1-592b-4457-aed9-af93ea1c2d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-4d7ef9cb-cab6-4cae-9a69-7f242f77cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-0ffa1b9b-ae4b-4c62-b4f1-ffda085e48b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-179a151f-e1a2-4f33-899a-6ac1cd5d5160,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-dc7561bb-a71f-4959-b6e7-b6e9927ae7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-92eb7cb6-205f-4ad2-bd7a-873053bcf80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935567511-172.17.0.16-1595303765132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-275b27cf-94d3-4abd-a18c-6fe412484f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-a40ac917-34e6-4467-b91c-184ec22d5615,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-b8d039f8-e217-4e43-a234-70f3a25d8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-da1f7aee-d50a-49e7-bd1e-d48db2e2ea69,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-72e2b3f4-035d-4971-9454-501e4d292e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-bd9a6051-f8a9-417c-a94c-6e23139c5850,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-d89d69eb-fc31-4477-ac60-abf844ec9af5,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-35b55e9a-3304-417b-b056-ccc5752f241f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935567511-172.17.0.16-1595303765132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-275b27cf-94d3-4abd-a18c-6fe412484f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-a40ac917-34e6-4467-b91c-184ec22d5615,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-b8d039f8-e217-4e43-a234-70f3a25d8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-da1f7aee-d50a-49e7-bd1e-d48db2e2ea69,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-72e2b3f4-035d-4971-9454-501e4d292e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-bd9a6051-f8a9-417c-a94c-6e23139c5850,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-d89d69eb-fc31-4477-ac60-abf844ec9af5,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-35b55e9a-3304-417b-b056-ccc5752f241f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928924351-172.17.0.16-1595304385004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-72ed54c3-60ae-44d4-87f0-85e9229d9df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-5e3017cc-78b1-4eda-bf0d-56b4aee59014,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-274cf396-a7a2-4b30-b8a5-8f54960334ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-9cc21965-ad2c-4668-8eeb-72776c703d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-9edcc82a-868d-4ed5-9dee-76a8323c8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-ede6ce77-4548-4001-b0d8-42fa8100420c,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-429670af-dd01-4e1d-92cb-952219a07b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-b0a96124-3e0f-44e7-a5d9-b8a0b51754d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928924351-172.17.0.16-1595304385004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-72ed54c3-60ae-44d4-87f0-85e9229d9df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-5e3017cc-78b1-4eda-bf0d-56b4aee59014,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-274cf396-a7a2-4b30-b8a5-8f54960334ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-9cc21965-ad2c-4668-8eeb-72776c703d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-9edcc82a-868d-4ed5-9dee-76a8323c8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-ede6ce77-4548-4001-b0d8-42fa8100420c,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-429670af-dd01-4e1d-92cb-952219a07b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-b0a96124-3e0f-44e7-a5d9-b8a0b51754d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375119836-172.17.0.16-1595304492935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-19c60d9a-87c3-4dcc-b0a5-2acb1d149924,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-8d6d7873-dfba-46b8-994b-043771672226,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-4296b222-1553-4806-a53b-50e996539a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-4ea87832-8203-4bb2-b212-813fc12fb3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-6c116f7a-87da-41ac-b70d-dc1589b15a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-9c057b58-9b6f-4cc3-9a5a-e7322fa8c933,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-94167e54-559d-4072-adb0-6808783cd279,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-c43b641e-f9bb-4f1e-8091-7b3dac8b7bf0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375119836-172.17.0.16-1595304492935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-19c60d9a-87c3-4dcc-b0a5-2acb1d149924,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-8d6d7873-dfba-46b8-994b-043771672226,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-4296b222-1553-4806-a53b-50e996539a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-4ea87832-8203-4bb2-b212-813fc12fb3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-6c116f7a-87da-41ac-b70d-dc1589b15a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-9c057b58-9b6f-4cc3-9a5a-e7322fa8c933,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-94167e54-559d-4072-adb0-6808783cd279,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-c43b641e-f9bb-4f1e-8091-7b3dac8b7bf0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696221876-172.17.0.16-1595304789405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-a82958c3-5863-4873-87f0-3400492c3d66,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-a8710ab5-5cf7-48ee-b1b7-fa6018345d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-9720e1d3-9df4-4e41-a55a-98e5ef78a3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-3edd6c4f-3a86-4137-9d5c-c5aea868e410,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-ae9b8d90-6102-441f-954b-e273e966f87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-226e5ef0-178e-4bd2-9622-219ad40b46c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-a64b06a8-400f-47e5-b5f4-5af83dba012a,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-b5188dc0-0828-4974-b2a0-e88202b02d2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696221876-172.17.0.16-1595304789405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-a82958c3-5863-4873-87f0-3400492c3d66,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-a8710ab5-5cf7-48ee-b1b7-fa6018345d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-9720e1d3-9df4-4e41-a55a-98e5ef78a3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-3edd6c4f-3a86-4137-9d5c-c5aea868e410,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-ae9b8d90-6102-441f-954b-e273e966f87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-226e5ef0-178e-4bd2-9622-219ad40b46c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-a64b06a8-400f-47e5-b5f4-5af83dba012a,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-b5188dc0-0828-4974-b2a0-e88202b02d2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440592045-172.17.0.16-1595304946793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40137,DS-2a282f88-5b44-4f67-b5d9-4638167e24a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-f8f5c29b-6d3b-4ca1-92e1-295ab92a5494,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-9efcc754-de65-43bf-b7a2-d05daf1dac65,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-af52dae6-d58f-4753-beed-69f33b009bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-e765216b-02ac-4447-9f65-c61efd8e6f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-dfc789c3-43e5-470d-a73b-eac99e3cbb75,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-c4c0e832-3906-4b61-944b-c284e8a5b77a,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-df274d39-e1ca-4051-967f-bcfcd6725afd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440592045-172.17.0.16-1595304946793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40137,DS-2a282f88-5b44-4f67-b5d9-4638167e24a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-f8f5c29b-6d3b-4ca1-92e1-295ab92a5494,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-9efcc754-de65-43bf-b7a2-d05daf1dac65,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-af52dae6-d58f-4753-beed-69f33b009bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-e765216b-02ac-4447-9f65-c61efd8e6f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-dfc789c3-43e5-470d-a73b-eac99e3cbb75,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-c4c0e832-3906-4b61-944b-c284e8a5b77a,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-df274d39-e1ca-4051-967f-bcfcd6725afd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630608767-172.17.0.16-1595305236093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-1d25d788-45f0-4cef-b26d-c267a3ff3789,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-42c466a8-af54-4473-b284-89ee26cd4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-0d7b8bba-ae67-47e4-9d38-2f495ec9197e,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-716dde9c-067d-4c38-8d70-e92da4eb2b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-1e6d8a13-ead5-42f5-9e90-33899022739f,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-01879def-cca2-43c6-92a6-8dd8115cd340,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-b2732ca0-9b68-4350-8a8f-39f3f6757554,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-994fd23e-634d-4ef5-8c6a-8759fa2ebfb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630608767-172.17.0.16-1595305236093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-1d25d788-45f0-4cef-b26d-c267a3ff3789,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-42c466a8-af54-4473-b284-89ee26cd4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-0d7b8bba-ae67-47e4-9d38-2f495ec9197e,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-716dde9c-067d-4c38-8d70-e92da4eb2b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-1e6d8a13-ead5-42f5-9e90-33899022739f,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-01879def-cca2-43c6-92a6-8dd8115cd340,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-b2732ca0-9b68-4350-8a8f-39f3f6757554,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-994fd23e-634d-4ef5-8c6a-8759fa2ebfb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303190928-172.17.0.16-1595305340422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-1af5da6b-6351-43b4-8666-6393222848a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-19fa0712-438f-4f56-b4b1-4d58be2e69e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-9f982c17-deb9-4de2-a356-835910cd65c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-754a66e9-518f-4c67-af73-7612d3357118,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-08a92ba1-6e36-4d9f-9278-fe98cbaa7c72,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-4534eb49-4c88-42e4-b17f-ba5780d4637a,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-a2e353ef-45bd-4a1c-b66a-e8e3530d69f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-42240fae-7dec-4830-b746-627d39829bef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303190928-172.17.0.16-1595305340422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-1af5da6b-6351-43b4-8666-6393222848a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-19fa0712-438f-4f56-b4b1-4d58be2e69e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-9f982c17-deb9-4de2-a356-835910cd65c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-754a66e9-518f-4c67-af73-7612d3357118,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-08a92ba1-6e36-4d9f-9278-fe98cbaa7c72,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-4534eb49-4c88-42e4-b17f-ba5780d4637a,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-a2e353ef-45bd-4a1c-b66a-e8e3530d69f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-42240fae-7dec-4830-b746-627d39829bef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156687600-172.17.0.16-1595305374140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-e44b03e1-a4a9-4a13-9d95-016f649bb200,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9d8947b6-3f42-40af-bfed-f460f318cb68,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-0b6039d9-a16a-43f0-9ca1-cfae1a4c0103,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-ebdbf150-9aa2-46cc-925e-b8737ffcbd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-628eb6aa-5f74-4027-b752-de7184aae76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-4e87a5c0-cf39-4306-8e78-0cf7f7e08eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-9cd4beb4-d051-4155-9099-103daa2dc1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-e02fbf55-8158-42b2-a226-926109248fdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156687600-172.17.0.16-1595305374140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-e44b03e1-a4a9-4a13-9d95-016f649bb200,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9d8947b6-3f42-40af-bfed-f460f318cb68,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-0b6039d9-a16a-43f0-9ca1-cfae1a4c0103,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-ebdbf150-9aa2-46cc-925e-b8737ffcbd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-628eb6aa-5f74-4027-b752-de7184aae76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-4e87a5c0-cf39-4306-8e78-0cf7f7e08eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-9cd4beb4-d051-4155-9099-103daa2dc1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-e02fbf55-8158-42b2-a226-926109248fdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243425681-172.17.0.16-1595305719632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-0734e467-0753-48cb-9aa3-ffa3aa7226ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-66e65729-35e6-4cef-a8d1-5d0cc7bd9d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-9b66a208-d4e4-4443-a218-6b9635078ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-c89506d6-81dd-4e01-9a63-bcf98c93da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-de7ffd24-8d9e-4d35-b286-3571009c38d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-1970adf6-f445-4110-a352-ed2f39929c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-92aca2a3-28ed-49d8-9f84-811efba3e658,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-64255298-ff40-4da0-960c-72ff82dcdcc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243425681-172.17.0.16-1595305719632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-0734e467-0753-48cb-9aa3-ffa3aa7226ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-66e65729-35e6-4cef-a8d1-5d0cc7bd9d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-9b66a208-d4e4-4443-a218-6b9635078ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-c89506d6-81dd-4e01-9a63-bcf98c93da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-de7ffd24-8d9e-4d35-b286-3571009c38d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-1970adf6-f445-4110-a352-ed2f39929c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-92aca2a3-28ed-49d8-9f84-811efba3e658,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-64255298-ff40-4da0-960c-72ff82dcdcc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837148823-172.17.0.16-1595305830037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42172,DS-e7330529-8ad6-43fd-82c5-208c3021eaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-5c70b681-946e-475a-9d40-534588cf5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-374ea191-dda5-452b-81ec-1640a23e767b,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-6f6c6750-2ade-4907-9073-a2f2899cb8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-1b45113d-c162-417a-97b7-672434ce92d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-db5ffa6b-3c21-48f2-a3ac-55f2f7469a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-e2b5585d-a04e-41ae-bb84-caa9af8a684a,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-57ffc4aa-5576-483a-a571-8ec713456b0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837148823-172.17.0.16-1595305830037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42172,DS-e7330529-8ad6-43fd-82c5-208c3021eaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-5c70b681-946e-475a-9d40-534588cf5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-374ea191-dda5-452b-81ec-1640a23e767b,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-6f6c6750-2ade-4907-9073-a2f2899cb8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-1b45113d-c162-417a-97b7-672434ce92d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-db5ffa6b-3c21-48f2-a3ac-55f2f7469a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-e2b5585d-a04e-41ae-bb84-caa9af8a684a,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-57ffc4aa-5576-483a-a571-8ec713456b0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5676
