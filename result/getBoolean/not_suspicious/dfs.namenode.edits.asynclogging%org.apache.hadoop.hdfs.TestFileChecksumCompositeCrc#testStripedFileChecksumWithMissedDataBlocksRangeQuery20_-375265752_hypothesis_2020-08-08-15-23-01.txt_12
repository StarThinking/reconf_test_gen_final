reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71254167-172.17.0.19-1596900228851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-2dc764ad-f957-46c7-a26f-681461733c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-4e8484a0-b3fa-4b38-99b4-b999758a9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-870cb409-19a8-4f60-8065-ecbe1153930f,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-ae99aa52-c63b-4fe0-89e1-d0df491c6fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-1c9823d1-5a44-41a4-8920-91c0869d0447,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-b9e55490-0faf-4e0b-9fb2-7fcc3a820222,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-c2f23a62-684b-45d4-baf8-61ba3900d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-55d78411-ccc1-4e94-b524-07d62b5d90b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71254167-172.17.0.19-1596900228851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-2dc764ad-f957-46c7-a26f-681461733c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-4e8484a0-b3fa-4b38-99b4-b999758a9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-870cb409-19a8-4f60-8065-ecbe1153930f,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-ae99aa52-c63b-4fe0-89e1-d0df491c6fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-1c9823d1-5a44-41a4-8920-91c0869d0447,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-b9e55490-0faf-4e0b-9fb2-7fcc3a820222,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-c2f23a62-684b-45d4-baf8-61ba3900d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-55d78411-ccc1-4e94-b524-07d62b5d90b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784389852-172.17.0.19-1596900432753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-d5ff5a1b-0d2b-4bcf-84cd-625b7577f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-07ff4617-0a47-4983-a42d-98ed9b13ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-256afd0c-93c2-4b94-b34b-c06aa35c87cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-33df9c13-de6d-4210-a475-30ddc3ce3837,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-344cee94-c053-49d6-ae49-ebc0c7409b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-9b238ed7-6d35-4f72-8dc0-e538fe8ccf37,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-c96b2c4a-a18d-4f42-8ae5-57eba3d81491,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-798d7197-9e59-4e75-b564-2fa9aa25963b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784389852-172.17.0.19-1596900432753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-d5ff5a1b-0d2b-4bcf-84cd-625b7577f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-07ff4617-0a47-4983-a42d-98ed9b13ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-256afd0c-93c2-4b94-b34b-c06aa35c87cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-33df9c13-de6d-4210-a475-30ddc3ce3837,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-344cee94-c053-49d6-ae49-ebc0c7409b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-9b238ed7-6d35-4f72-8dc0-e538fe8ccf37,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-c96b2c4a-a18d-4f42-8ae5-57eba3d81491,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-798d7197-9e59-4e75-b564-2fa9aa25963b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533263275-172.17.0.19-1596900469545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-808542f8-c215-4365-afac-a6e075d4226a,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-235a3e24-7a3c-414a-aa72-78894d9ee1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-c07cc14e-aa90-4485-8263-c4565af5445e,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-b2fe5538-97d6-4d57-8d77-578f98f56917,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-a558a79c-0c94-41fa-a9ec-c183fbc0eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-16cf00cd-6702-4710-9993-d04f4f6257b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-8c45bece-0c0c-41d5-b692-b1a099a08137,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-2276ecc6-86b0-4a21-9902-1773da5251bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533263275-172.17.0.19-1596900469545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-808542f8-c215-4365-afac-a6e075d4226a,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-235a3e24-7a3c-414a-aa72-78894d9ee1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-c07cc14e-aa90-4485-8263-c4565af5445e,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-b2fe5538-97d6-4d57-8d77-578f98f56917,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-a558a79c-0c94-41fa-a9ec-c183fbc0eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-16cf00cd-6702-4710-9993-d04f4f6257b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-8c45bece-0c0c-41d5-b692-b1a099a08137,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-2276ecc6-86b0-4a21-9902-1773da5251bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87419628-172.17.0.19-1596900600147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41495,DS-ecd9767f-541e-4447-b57a-b77f087cebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-6be11167-193c-415c-a83d-233af0e862c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-9911a777-9ab1-42d6-a658-c31ab54fcec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-bc0b6c5c-53a6-44ab-be1e-97f8873a8207,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-549b8d5b-2e75-4b11-8760-7dfa2fb19c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-2db2281a-c971-4e13-b8aa-bda3c5221cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-6ccd62c0-b77b-4f70-b32a-7e176b338742,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-1a807846-a88f-4757-bc12-b43ae602d512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87419628-172.17.0.19-1596900600147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41495,DS-ecd9767f-541e-4447-b57a-b77f087cebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-6be11167-193c-415c-a83d-233af0e862c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-9911a777-9ab1-42d6-a658-c31ab54fcec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-bc0b6c5c-53a6-44ab-be1e-97f8873a8207,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-549b8d5b-2e75-4b11-8760-7dfa2fb19c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-2db2281a-c971-4e13-b8aa-bda3c5221cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-6ccd62c0-b77b-4f70-b32a-7e176b338742,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-1a807846-a88f-4757-bc12-b43ae602d512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342530974-172.17.0.19-1596900795876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34862,DS-e42c8385-eb71-4d89-a78c-d688578481b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-792b5f59-2785-4b93-8137-6763920bd04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-a4319568-3fc1-4fbf-8752-fcfebd93eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-0ff62772-ee3d-492f-b7e2-e2e2a00e96df,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-1f885acc-223b-4dfa-8fe3-68881ec21361,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-0549fd71-3b99-4133-b81e-5ea79e7cd385,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-ad7de8ae-b894-4ac5-87cc-880dea0af5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-cc061826-c500-493d-8463-c261cf1d99a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342530974-172.17.0.19-1596900795876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34862,DS-e42c8385-eb71-4d89-a78c-d688578481b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-792b5f59-2785-4b93-8137-6763920bd04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-a4319568-3fc1-4fbf-8752-fcfebd93eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-0ff62772-ee3d-492f-b7e2-e2e2a00e96df,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-1f885acc-223b-4dfa-8fe3-68881ec21361,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-0549fd71-3b99-4133-b81e-5ea79e7cd385,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-ad7de8ae-b894-4ac5-87cc-880dea0af5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-cc061826-c500-493d-8463-c261cf1d99a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564529123-172.17.0.19-1596901249304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-2c8444ff-6151-4fe6-b19d-0b60dc79e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-a5c0d7fb-bc1c-4eb9-be3a-116c6ea46f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-b012fcad-8167-45f9-847f-a60932663be7,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-bf999d16-7287-4f3c-a025-c12011a754d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-488fba77-a4f5-4095-95cb-b7bb34fe6094,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-7fe5b608-934d-47f1-832c-6cffaa9ee9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-d7980179-4b8a-47eb-9e87-d39b353076ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-29bea803-4fd3-4c00-955a-3752b7a0ce3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564529123-172.17.0.19-1596901249304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-2c8444ff-6151-4fe6-b19d-0b60dc79e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-a5c0d7fb-bc1c-4eb9-be3a-116c6ea46f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-b012fcad-8167-45f9-847f-a60932663be7,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-bf999d16-7287-4f3c-a025-c12011a754d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-488fba77-a4f5-4095-95cb-b7bb34fe6094,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-7fe5b608-934d-47f1-832c-6cffaa9ee9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-d7980179-4b8a-47eb-9e87-d39b353076ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-29bea803-4fd3-4c00-955a-3752b7a0ce3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814749699-172.17.0.19-1596901348222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-7029717b-c86e-4168-b22d-7e5198bb1b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-f908c1de-fdf0-40d5-89c3-2782b6be5319,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-824820f9-cc5b-4624-8ec7-6d26cf970877,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-fd6a8dab-a530-44cb-aeef-c04e24939da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-1cb44d7e-9581-4c19-b4c1-128c47f075b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-469cefab-2d27-414e-b90e-fb312d0ab8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-4dd40679-11e7-4bdf-8df6-7e729d53b841,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-50129c2c-38c0-4e21-a2fd-1e36ff994c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814749699-172.17.0.19-1596901348222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-7029717b-c86e-4168-b22d-7e5198bb1b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-f908c1de-fdf0-40d5-89c3-2782b6be5319,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-824820f9-cc5b-4624-8ec7-6d26cf970877,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-fd6a8dab-a530-44cb-aeef-c04e24939da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-1cb44d7e-9581-4c19-b4c1-128c47f075b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-469cefab-2d27-414e-b90e-fb312d0ab8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-4dd40679-11e7-4bdf-8df6-7e729d53b841,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-50129c2c-38c0-4e21-a2fd-1e36ff994c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353443255-172.17.0.19-1596901453977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-92076893-ad89-4343-91a7-c21538185a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-db68e333-5d2b-440d-b9ef-31ee0980d362,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-bf809665-867d-41d9-99d0-94744ab64234,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-1dfe2a51-a8b4-4bf3-beca-26af5f908035,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-47989b78-3ef1-4a8d-a099-29e02d943e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-5958002c-5c71-4e17-86f8-d794abf222fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-04802385-7df0-4b9c-a914-c064a082ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-a7574313-c6aa-424f-99db-a7d18b886d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353443255-172.17.0.19-1596901453977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-92076893-ad89-4343-91a7-c21538185a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-db68e333-5d2b-440d-b9ef-31ee0980d362,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-bf809665-867d-41d9-99d0-94744ab64234,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-1dfe2a51-a8b4-4bf3-beca-26af5f908035,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-47989b78-3ef1-4a8d-a099-29e02d943e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-5958002c-5c71-4e17-86f8-d794abf222fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-04802385-7df0-4b9c-a914-c064a082ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-a7574313-c6aa-424f-99db-a7d18b886d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246582893-172.17.0.19-1596902400060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-02cee5aa-7d88-45cd-831c-5b1253f172b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-f90cea7c-cb47-48e1-9fd4-9e227486f7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-18d29566-659f-4a1b-bfce-437f1021d510,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-8b33fa33-03a7-4493-8078-e7511ef264fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-a8eb48b0-7423-4630-b5ba-abb45af75947,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-25010418-a03f-47ae-9361-a68595a7c761,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-97769b98-c625-44ec-815c-9555ccffcd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-5b1b14ff-0f9b-46a1-9f37-b1560e2f5444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246582893-172.17.0.19-1596902400060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-02cee5aa-7d88-45cd-831c-5b1253f172b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-f90cea7c-cb47-48e1-9fd4-9e227486f7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-18d29566-659f-4a1b-bfce-437f1021d510,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-8b33fa33-03a7-4493-8078-e7511ef264fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-a8eb48b0-7423-4630-b5ba-abb45af75947,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-25010418-a03f-47ae-9361-a68595a7c761,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-97769b98-c625-44ec-815c-9555ccffcd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-5b1b14ff-0f9b-46a1-9f37-b1560e2f5444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409876196-172.17.0.19-1596902490303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-dc157204-8621-44f1-b575-93c79a32fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-0f9ef42e-fff5-4f23-9ce1-f596a8a1b490,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-86366e9d-fb30-405d-90d6-b11347a252fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-46a6238d-6e13-42f6-9403-2cdf54f944e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-09def221-fe19-4de2-b0e6-7ad45c3d7def,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-47a649e8-e5f9-42c9-ab83-47f64ca3d197,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-55264016-db66-442e-845f-2d52d46b04ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-d793cf01-b6ee-405b-8dc4-d1b41bc48f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409876196-172.17.0.19-1596902490303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-dc157204-8621-44f1-b575-93c79a32fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-0f9ef42e-fff5-4f23-9ce1-f596a8a1b490,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-86366e9d-fb30-405d-90d6-b11347a252fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-46a6238d-6e13-42f6-9403-2cdf54f944e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-09def221-fe19-4de2-b0e6-7ad45c3d7def,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-47a649e8-e5f9-42c9-ab83-47f64ca3d197,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-55264016-db66-442e-845f-2d52d46b04ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-d793cf01-b6ee-405b-8dc4-d1b41bc48f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177835343-172.17.0.19-1596902526480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-f397cfcb-3985-4b1e-afef-d906928739c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-ff0cd3c0-ae0b-4428-9e4d-cff1caf01a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-cae793ca-2704-4fc1-86e4-e86beaa50e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-93d32af6-5085-445e-9d1f-7c2b619f88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-5dd2b4dd-2cc4-4708-a5c7-23842e6f5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-f06b58c1-d7f2-423d-b4f9-cf059243f625,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-9a6fd663-4b8e-48cf-9a75-4ecbd5a53958,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-ca3f88b3-cb86-4d1a-aa2c-d10e3908946f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177835343-172.17.0.19-1596902526480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-f397cfcb-3985-4b1e-afef-d906928739c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-ff0cd3c0-ae0b-4428-9e4d-cff1caf01a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-cae793ca-2704-4fc1-86e4-e86beaa50e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-93d32af6-5085-445e-9d1f-7c2b619f88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-5dd2b4dd-2cc4-4708-a5c7-23842e6f5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-f06b58c1-d7f2-423d-b4f9-cf059243f625,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-9a6fd663-4b8e-48cf-9a75-4ecbd5a53958,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-ca3f88b3-cb86-4d1a-aa2c-d10e3908946f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124442178-172.17.0.19-1596902662827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-b116ea99-b363-417c-83c0-a9bb09f9e6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f233cdca-e4b9-4c30-b0fe-c80e23628ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-86e097a0-ece4-4899-ba53-1af6fb99f464,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5b0da1fb-3054-488e-9019-79ea6b61f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-0a665d84-4f03-4eee-9e3d-7f19fb944512,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-0fd2b74c-2c86-4738-b104-3250b9b07fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-4911de1f-2763-4376-b0c8-3b5e5c24b181,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3b14f8c0-3f2d-44be-b626-3ade42553537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124442178-172.17.0.19-1596902662827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-b116ea99-b363-417c-83c0-a9bb09f9e6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f233cdca-e4b9-4c30-b0fe-c80e23628ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-86e097a0-ece4-4899-ba53-1af6fb99f464,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5b0da1fb-3054-488e-9019-79ea6b61f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-0a665d84-4f03-4eee-9e3d-7f19fb944512,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-0fd2b74c-2c86-4738-b104-3250b9b07fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-4911de1f-2763-4376-b0c8-3b5e5c24b181,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3b14f8c0-3f2d-44be-b626-3ade42553537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963711767-172.17.0.19-1596902762542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-2746f52e-5b22-4df2-814e-737eee56be06,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-7ad93d40-a865-419e-a867-2f3f2d6d46f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-b5146c50-1dfe-493f-ae58-444fed1b3a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-f9d5d502-6b93-4571-bf04-ff65b7a465a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-33d1d3ca-dd88-4316-9a1d-0997101cf111,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c59315dd-2ac1-4358-b4f2-82739fafa730,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-e92eb705-5ce9-420c-8d5d-6cd3b5a6e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-7f278620-00b3-45c5-9110-c05d268b9a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963711767-172.17.0.19-1596902762542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-2746f52e-5b22-4df2-814e-737eee56be06,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-7ad93d40-a865-419e-a867-2f3f2d6d46f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-b5146c50-1dfe-493f-ae58-444fed1b3a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-f9d5d502-6b93-4571-bf04-ff65b7a465a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-33d1d3ca-dd88-4316-9a1d-0997101cf111,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c59315dd-2ac1-4358-b4f2-82739fafa730,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-e92eb705-5ce9-420c-8d5d-6cd3b5a6e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-7f278620-00b3-45c5-9110-c05d268b9a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442547527-172.17.0.19-1596902826257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-2e458126-7187-4d1e-9054-731e34b25785,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-b3b229ca-146c-4dbe-969c-2e0485f3a937,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-0afd76dc-df92-4ae9-977e-e0e05ff9bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-ae639b7b-d20d-4350-806c-3430eaf4a074,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-77d4e13d-2e3b-4624-86d7-c776cb871ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-4c1131b8-4514-4eb1-81ee-6cd1edffeb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-32b2956a-a21f-4614-9447-c388432fca83,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-5deaf5f3-f59d-4a8f-894f-f214cabf34b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442547527-172.17.0.19-1596902826257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-2e458126-7187-4d1e-9054-731e34b25785,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-b3b229ca-146c-4dbe-969c-2e0485f3a937,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-0afd76dc-df92-4ae9-977e-e0e05ff9bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-ae639b7b-d20d-4350-806c-3430eaf4a074,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-77d4e13d-2e3b-4624-86d7-c776cb871ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-4c1131b8-4514-4eb1-81ee-6cd1edffeb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-32b2956a-a21f-4614-9447-c388432fca83,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-5deaf5f3-f59d-4a8f-894f-f214cabf34b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852982438-172.17.0.19-1596903000946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-a2392e7f-32fa-44a8-9ab6-1a4e7b5bc14a,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-4cd224dd-d17c-4073-9ece-447856961f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-b724e26d-8f07-4cae-a075-592c5e9eb842,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-dd5e4433-88a4-4d5a-b1e8-efaedfd35df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-0deccb49-cb67-4f03-98d8-13488046e552,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-30f84144-15d7-4513-9c5f-dcbb9f2c20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-3eff9a51-23cf-4d69-960d-554e668b63ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-5fd0fe58-adc9-4002-8e1e-8ca1cbfc1513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852982438-172.17.0.19-1596903000946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-a2392e7f-32fa-44a8-9ab6-1a4e7b5bc14a,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-4cd224dd-d17c-4073-9ece-447856961f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-b724e26d-8f07-4cae-a075-592c5e9eb842,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-dd5e4433-88a4-4d5a-b1e8-efaedfd35df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-0deccb49-cb67-4f03-98d8-13488046e552,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-30f84144-15d7-4513-9c5f-dcbb9f2c20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-3eff9a51-23cf-4d69-960d-554e668b63ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-5fd0fe58-adc9-4002-8e1e-8ca1cbfc1513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599197412-172.17.0.19-1596903459099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-f398529e-a45f-4d77-ab20-ac8d2542e1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-fea024fe-bf73-4b7e-bf14-c3a79797c687,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-a32d62c6-9dea-488e-a983-88eeee13894f,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-8121000d-be35-4f1e-bbfd-d3318b6d1555,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-b9719821-2746-4129-8a06-65b911464ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-62ef83d7-eca9-4a24-974a-03dac394adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-6ef2efdf-9cd3-46e7-a934-1570753e89dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-5c10cf4d-e1b5-46b1-9c6e-5e593f6cc8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599197412-172.17.0.19-1596903459099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-f398529e-a45f-4d77-ab20-ac8d2542e1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-fea024fe-bf73-4b7e-bf14-c3a79797c687,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-a32d62c6-9dea-488e-a983-88eeee13894f,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-8121000d-be35-4f1e-bbfd-d3318b6d1555,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-b9719821-2746-4129-8a06-65b911464ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-62ef83d7-eca9-4a24-974a-03dac394adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-6ef2efdf-9cd3-46e7-a934-1570753e89dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-5c10cf4d-e1b5-46b1-9c6e-5e593f6cc8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352292620-172.17.0.19-1596903492765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33752,DS-0e05a50e-2863-488c-98f9-66932ce01613,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-7083ae3f-9f99-4789-820d-0ff3edb0d0af,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-155e9835-b92c-4c0a-822d-f8ffda8cc547,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-e07dfd4c-221a-4d84-95b3-46d88d389fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-88f8f790-7b63-4346-99da-1e3326a86984,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-40fdf23a-475b-482a-962b-aa6a30377c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-bf68d3c8-651b-421b-97e3-a1b96dd2247d,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b2925242-8dd5-4d8c-a2d6-aa35f8a1b01e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352292620-172.17.0.19-1596903492765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33752,DS-0e05a50e-2863-488c-98f9-66932ce01613,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-7083ae3f-9f99-4789-820d-0ff3edb0d0af,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-155e9835-b92c-4c0a-822d-f8ffda8cc547,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-e07dfd4c-221a-4d84-95b3-46d88d389fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-88f8f790-7b63-4346-99da-1e3326a86984,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-40fdf23a-475b-482a-962b-aa6a30377c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-bf68d3c8-651b-421b-97e3-a1b96dd2247d,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b2925242-8dd5-4d8c-a2d6-aa35f8a1b01e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43097081-172.17.0.19-1596903581656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-3427dd3e-9022-4a9a-8bb1-c34aca988c75,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-1e984a2c-aee2-46bb-b488-ef15da9dedf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-5662f77f-9bfd-4bf8-a0a5-25a174561b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-49b5878a-d60a-43da-9783-ec0089f454f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-eae12b8d-3267-4e79-8823-dcda58d14239,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-74c36613-5b60-48af-9623-10008a1897e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-743701f6-d646-4077-a37b-e94d9fb9622f,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-ee419332-6e72-42a1-9ccb-25d344e28819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43097081-172.17.0.19-1596903581656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-3427dd3e-9022-4a9a-8bb1-c34aca988c75,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-1e984a2c-aee2-46bb-b488-ef15da9dedf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-5662f77f-9bfd-4bf8-a0a5-25a174561b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-49b5878a-d60a-43da-9783-ec0089f454f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-eae12b8d-3267-4e79-8823-dcda58d14239,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-74c36613-5b60-48af-9623-10008a1897e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-743701f6-d646-4077-a37b-e94d9fb9622f,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-ee419332-6e72-42a1-9ccb-25d344e28819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666817798-172.17.0.19-1596904048186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-9fdfff9e-1eba-48fc-a454-e5514bb3722a,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-d0fb3b12-75ac-42ee-9b9c-a2a093fe9dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-7c9e4f38-7339-44d6-923c-20a97d199250,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-83683785-daf4-4865-951f-4aa27122795e,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-f35983e1-9b4f-43ea-a0c2-38b0acb27f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-527ddaa6-4406-4f37-b8df-875599e4ac54,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-4b2f1f94-82ba-4f4f-8213-6de456b7d046,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-a023ea54-20e8-4f1f-8306-4863df3c80f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666817798-172.17.0.19-1596904048186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-9fdfff9e-1eba-48fc-a454-e5514bb3722a,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-d0fb3b12-75ac-42ee-9b9c-a2a093fe9dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-7c9e4f38-7339-44d6-923c-20a97d199250,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-83683785-daf4-4865-951f-4aa27122795e,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-f35983e1-9b4f-43ea-a0c2-38b0acb27f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-527ddaa6-4406-4f37-b8df-875599e4ac54,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-4b2f1f94-82ba-4f4f-8213-6de456b7d046,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-a023ea54-20e8-4f1f-8306-4863df3c80f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968293450-172.17.0.19-1596904409114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35284,DS-c14e4f1a-3ca1-4346-89d0-ae762526c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-d4a4e22b-a5db-46a4-b7fb-d19f37318ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-46213ded-750e-412c-8163-da34026d00b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-8f24531f-f3e5-41bc-94e6-d1762295947c,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-3f29865f-a652-41b3-be48-2e09e74f2c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-d58585ca-8d99-4023-b8cb-db918d92e732,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-1ae95482-d199-4d67-b444-6e95971688e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c83d9306-f88e-4ddf-b9a2-765c3d46a587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968293450-172.17.0.19-1596904409114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35284,DS-c14e4f1a-3ca1-4346-89d0-ae762526c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-d4a4e22b-a5db-46a4-b7fb-d19f37318ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-46213ded-750e-412c-8163-da34026d00b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-8f24531f-f3e5-41bc-94e6-d1762295947c,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-3f29865f-a652-41b3-be48-2e09e74f2c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-d58585ca-8d99-4023-b8cb-db918d92e732,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-1ae95482-d199-4d67-b444-6e95971688e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c83d9306-f88e-4ddf-b9a2-765c3d46a587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765887700-172.17.0.19-1596904720331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35585,DS-ab0e4d51-6d8c-41a4-be68-a4db4ded446c,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-1fc7765c-144b-44ce-9610-447de82e3ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-1cad3b78-f4d4-4bff-9a5d-79cdddb6e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-4b95d2dc-ff7b-4995-a354-36f7c52305e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-298d1ded-1ece-4d08-9c83-fd16f5476d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-bf5c2846-d87d-4a0b-9762-bae39f519e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-9301e630-2aa7-4827-b291-839298607461,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-d55ce577-7698-4e5c-bf47-75704d439fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765887700-172.17.0.19-1596904720331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35585,DS-ab0e4d51-6d8c-41a4-be68-a4db4ded446c,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-1fc7765c-144b-44ce-9610-447de82e3ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-1cad3b78-f4d4-4bff-9a5d-79cdddb6e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-4b95d2dc-ff7b-4995-a354-36f7c52305e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-298d1ded-1ece-4d08-9c83-fd16f5476d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-bf5c2846-d87d-4a0b-9762-bae39f519e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-9301e630-2aa7-4827-b291-839298607461,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-d55ce577-7698-4e5c-bf47-75704d439fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311649698-172.17.0.19-1596904921174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37998,DS-f2356432-ef3c-4465-98aa-d32550d25dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-f86e2fb7-5c8d-4f33-b1a2-8757aa831555,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-71b8442b-4b58-4696-9559-f00c890d2814,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-fffd4cd4-fbe6-4c95-9bdd-6c5a41e04a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-ff442746-ce70-4348-8538-bcf45382bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-fc1de402-f3dd-4491-afb5-131d2adfddcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-4cda8633-c239-4010-a7be-3b39821e1d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-2c874ec4-852f-4331-bcbd-f84183be4e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311649698-172.17.0.19-1596904921174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37998,DS-f2356432-ef3c-4465-98aa-d32550d25dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-f86e2fb7-5c8d-4f33-b1a2-8757aa831555,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-71b8442b-4b58-4696-9559-f00c890d2814,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-fffd4cd4-fbe6-4c95-9bdd-6c5a41e04a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-ff442746-ce70-4348-8538-bcf45382bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-fc1de402-f3dd-4491-afb5-131d2adfddcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-4cda8633-c239-4010-a7be-3b39821e1d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-2c874ec4-852f-4331-bcbd-f84183be4e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108233415-172.17.0.19-1596904950306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40816,DS-76ec1bf3-832a-4d51-b5a2-2695a5b7519f,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-32d72409-7437-48ac-accb-45f9a8423bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-c0c55123-0801-48a4-adb4-ddb8f0a1b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-9e22f74e-4ee8-4e48-b8ff-00c8a9070687,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-4e8468f4-e079-43a4-acdb-431f4b06d156,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-d91a9fc1-a613-4509-bf16-ea3fbfd77743,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-a3eb4426-1bc6-4160-bd2f-cba814af340c,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-dffb922f-85f1-4bd8-ac08-629b19d75e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108233415-172.17.0.19-1596904950306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40816,DS-76ec1bf3-832a-4d51-b5a2-2695a5b7519f,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-32d72409-7437-48ac-accb-45f9a8423bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-c0c55123-0801-48a4-adb4-ddb8f0a1b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-9e22f74e-4ee8-4e48-b8ff-00c8a9070687,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-4e8468f4-e079-43a4-acdb-431f4b06d156,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-d91a9fc1-a613-4509-bf16-ea3fbfd77743,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-a3eb4426-1bc6-4160-bd2f-cba814af340c,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-dffb922f-85f1-4bd8-ac08-629b19d75e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4918
