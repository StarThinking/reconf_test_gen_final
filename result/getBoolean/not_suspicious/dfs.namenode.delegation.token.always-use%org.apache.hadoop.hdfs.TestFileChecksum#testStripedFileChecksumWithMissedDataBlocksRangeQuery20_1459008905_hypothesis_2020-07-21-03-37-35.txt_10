reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223480065-172.17.0.2-1595302877571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-ae09e85d-3b27-4672-9ddf-881637d31762,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-09dff331-6594-413a-9b3a-167bf16531d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-6381f278-74cf-4381-afc7-db07f5e0a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-65a4a5d2-9399-41a6-864f-874cb50da4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-828a2258-c865-40b6-b406-403b4f05392a,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-c5d8a080-0494-4e20-bb4b-89e0de635ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-422f2271-622c-4ab1-95f1-131e85ca0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-7cfdc6d1-c505-4ebd-836f-717276b27600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223480065-172.17.0.2-1595302877571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-ae09e85d-3b27-4672-9ddf-881637d31762,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-09dff331-6594-413a-9b3a-167bf16531d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-6381f278-74cf-4381-afc7-db07f5e0a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-65a4a5d2-9399-41a6-864f-874cb50da4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-828a2258-c865-40b6-b406-403b4f05392a,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-c5d8a080-0494-4e20-bb4b-89e0de635ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-422f2271-622c-4ab1-95f1-131e85ca0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-7cfdc6d1-c505-4ebd-836f-717276b27600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467265226-172.17.0.2-1595303784826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35622,DS-b970360b-d2d6-4e58-a895-1e19360a5fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-02701c47-8155-4837-8f98-8c7a43850bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-bfce448c-46df-4340-9094-39a4ddec7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-31da385e-b1df-45d5-9523-909cc53374c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-568ad8b2-d2e6-4105-990e-ec65bb5e8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-be74f128-c0cd-4031-b00c-f060ea08c3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-2e6d57c5-7037-4873-80bb-cc86d0914c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-22c40ca7-a21d-4a0e-b88a-b0eb2abc314e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467265226-172.17.0.2-1595303784826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35622,DS-b970360b-d2d6-4e58-a895-1e19360a5fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-02701c47-8155-4837-8f98-8c7a43850bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-bfce448c-46df-4340-9094-39a4ddec7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-31da385e-b1df-45d5-9523-909cc53374c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-568ad8b2-d2e6-4105-990e-ec65bb5e8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-be74f128-c0cd-4031-b00c-f060ea08c3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-2e6d57c5-7037-4873-80bb-cc86d0914c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-22c40ca7-a21d-4a0e-b88a-b0eb2abc314e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958528387-172.17.0.2-1595304361604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38724,DS-fd951579-e26e-4e12-91d7-45d22dc742c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-c4a22625-ae64-466a-b91f-b9f2a42b5cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-46a4958c-5009-43bb-8a70-296dc957ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-6c52fec0-f418-4dd4-9861-d68daed01e05,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-9f6b9ba2-d201-468e-b52d-78c38f8045f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-ecd17aac-3751-4917-9224-41d55a6aead4,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-d27b1b7c-5fcc-43a3-af40-e900b176bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-774a18b7-5a83-46b2-95cb-29cd62cce579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958528387-172.17.0.2-1595304361604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38724,DS-fd951579-e26e-4e12-91d7-45d22dc742c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-c4a22625-ae64-466a-b91f-b9f2a42b5cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-46a4958c-5009-43bb-8a70-296dc957ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-6c52fec0-f418-4dd4-9861-d68daed01e05,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-9f6b9ba2-d201-468e-b52d-78c38f8045f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-ecd17aac-3751-4917-9224-41d55a6aead4,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-d27b1b7c-5fcc-43a3-af40-e900b176bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-774a18b7-5a83-46b2-95cb-29cd62cce579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667199628-172.17.0.2-1595304428591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43639,DS-7934d7a9-a0b4-4165-be65-c965868ac6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-11913a43-e493-49ff-bc78-bc9255cb8ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-7edfc80e-2762-446f-85db-b86ac95d5f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-2cc5895d-5d9f-4306-ae97-448031ada085,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-7855fff0-c1ff-4c6e-8b78-8f5add8940c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7dd6ac64-607a-46b9-b24d-ec911775d51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-2534acba-5c73-4724-8cd4-4dbda8806609,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-5366783b-b469-4f17-80f6-a3328db5f6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667199628-172.17.0.2-1595304428591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43639,DS-7934d7a9-a0b4-4165-be65-c965868ac6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-11913a43-e493-49ff-bc78-bc9255cb8ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-7edfc80e-2762-446f-85db-b86ac95d5f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-2cc5895d-5d9f-4306-ae97-448031ada085,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-7855fff0-c1ff-4c6e-8b78-8f5add8940c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7dd6ac64-607a-46b9-b24d-ec911775d51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-2534acba-5c73-4724-8cd4-4dbda8806609,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-5366783b-b469-4f17-80f6-a3328db5f6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402470899-172.17.0.2-1595305220186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-1a38d108-cc99-426b-bc1d-3f8923740f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-c6f705b2-6800-4b21-8002-a360777020fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-ca70c0c5-6617-4b74-a686-07ef524afe52,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-b6bc9fee-2c33-43c8-8360-2a6215ac262e,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-89ca89c8-21ea-4743-9dbf-4061d16d77be,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-97639b07-4302-40fc-9144-f8857fb4df36,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-f1f9f3db-76ad-4144-9209-e3b82a66f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-33b65de4-8876-4673-9a01-ef2b17d5d461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402470899-172.17.0.2-1595305220186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-1a38d108-cc99-426b-bc1d-3f8923740f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-c6f705b2-6800-4b21-8002-a360777020fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-ca70c0c5-6617-4b74-a686-07ef524afe52,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-b6bc9fee-2c33-43c8-8360-2a6215ac262e,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-89ca89c8-21ea-4743-9dbf-4061d16d77be,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-97639b07-4302-40fc-9144-f8857fb4df36,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-f1f9f3db-76ad-4144-9209-e3b82a66f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-33b65de4-8876-4673-9a01-ef2b17d5d461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306120774-172.17.0.2-1595305727958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35088,DS-c8cdf19e-50a0-457e-966b-d663cd3f297c,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-4d8970c0-6486-4cac-9ece-ae98ac85f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-3f19356f-1dd4-45a2-addf-635a8923ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-771ed9e7-fc75-4ede-b16e-b828fa86918d,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-aa00543c-3917-40a8-aa12-f4de7543ab8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-8585193e-6dd9-45e5-a592-77372b040b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-cd527de7-a72e-41d7-8200-0b9834a5f64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-7e60dd25-ad37-4785-a69b-91108a7cc224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306120774-172.17.0.2-1595305727958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35088,DS-c8cdf19e-50a0-457e-966b-d663cd3f297c,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-4d8970c0-6486-4cac-9ece-ae98ac85f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-3f19356f-1dd4-45a2-addf-635a8923ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-771ed9e7-fc75-4ede-b16e-b828fa86918d,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-aa00543c-3917-40a8-aa12-f4de7543ab8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-8585193e-6dd9-45e5-a592-77372b040b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-cd527de7-a72e-41d7-8200-0b9834a5f64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-7e60dd25-ad37-4785-a69b-91108a7cc224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494125787-172.17.0.2-1595305868925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45490,DS-59208bca-68c4-4a9b-a2c2-ca2476e5d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-3cbc2138-f14b-4fc9-af57-0d99b357fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-7efe89a8-6a18-46ab-88f5-20f76299c4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-39283fb9-354b-4c10-a9bc-546198b7046e,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-9e7857e8-d950-4341-88a8-f54f62e8c85a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-0f907e9f-3b71-4cbf-9236-091a1e0fbd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-b7058359-5b47-48f0-94c0-7468f7d11821,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-a03b35ff-e688-4653-b6bb-d49eb3166898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494125787-172.17.0.2-1595305868925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45490,DS-59208bca-68c4-4a9b-a2c2-ca2476e5d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-3cbc2138-f14b-4fc9-af57-0d99b357fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-7efe89a8-6a18-46ab-88f5-20f76299c4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-39283fb9-354b-4c10-a9bc-546198b7046e,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-9e7857e8-d950-4341-88a8-f54f62e8c85a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-0f907e9f-3b71-4cbf-9236-091a1e0fbd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-b7058359-5b47-48f0-94c0-7468f7d11821,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-a03b35ff-e688-4653-b6bb-d49eb3166898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651508269-172.17.0.2-1595305976070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-e7be8edc-815a-423b-bb01-ce2b49495304,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-fd635612-3861-4eb3-a348-59715aea92e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b00387a2-6837-4418-adee-42797ffd2fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-259c5ade-32a6-408b-a8e5-0d5253cbb245,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-5d21b810-ee93-4a1a-bd3c-f06fd9d4ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-c5af828b-a4e5-449f-bfe3-b28c4ecee32f,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-81ce2baa-0f0d-4c3e-a06d-644938591c57,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-6793d3e7-d1ab-4e0e-9fc7-d20e189ef4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651508269-172.17.0.2-1595305976070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-e7be8edc-815a-423b-bb01-ce2b49495304,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-fd635612-3861-4eb3-a348-59715aea92e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b00387a2-6837-4418-adee-42797ffd2fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-259c5ade-32a6-408b-a8e5-0d5253cbb245,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-5d21b810-ee93-4a1a-bd3c-f06fd9d4ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-c5af828b-a4e5-449f-bfe3-b28c4ecee32f,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-81ce2baa-0f0d-4c3e-a06d-644938591c57,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-6793d3e7-d1ab-4e0e-9fc7-d20e189ef4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890700558-172.17.0.2-1595306010383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39048,DS-a508166e-cb8a-4eef-b71b-c29b5a54c168,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-2db50229-b508-4988-94f9-5e232dbbd37d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-b24b7047-b283-4131-8774-2ce2809d2897,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-2555cd8e-2809-4f99-8ca6-4dac0e87d661,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-62c9fecc-16d4-40ed-996c-4b1f3d8fa997,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-cde9dd0c-ca55-484a-ad50-df08e1459fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-a4864e3f-dde4-4271-a77b-5b9a320e652f,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-ed36a0f4-c022-4a2b-b127-4d8712584686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890700558-172.17.0.2-1595306010383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39048,DS-a508166e-cb8a-4eef-b71b-c29b5a54c168,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-2db50229-b508-4988-94f9-5e232dbbd37d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-b24b7047-b283-4131-8774-2ce2809d2897,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-2555cd8e-2809-4f99-8ca6-4dac0e87d661,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-62c9fecc-16d4-40ed-996c-4b1f3d8fa997,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-cde9dd0c-ca55-484a-ad50-df08e1459fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-a4864e3f-dde4-4271-a77b-5b9a320e652f,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-ed36a0f4-c022-4a2b-b127-4d8712584686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650640035-172.17.0.2-1595306116148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35065,DS-a8055d79-b91a-46b4-9f13-5fc3f3ccd9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-d6894f05-d799-4bbf-8a35-54b3e039d075,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-3aeb433b-92b0-4419-9a13-3bbb687331fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-e5296959-5798-41ba-8305-51ec665eab11,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-ec4be4b6-30b8-43df-aba6-b0f8f3fcde7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-bee39b36-6818-4ae0-938c-b45829ea74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-d6714981-1f0d-4bab-9d26-af9355048895,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-15988cf4-2c3f-48c5-aed4-c2ddbdbdad77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650640035-172.17.0.2-1595306116148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35065,DS-a8055d79-b91a-46b4-9f13-5fc3f3ccd9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-d6894f05-d799-4bbf-8a35-54b3e039d075,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-3aeb433b-92b0-4419-9a13-3bbb687331fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-e5296959-5798-41ba-8305-51ec665eab11,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-ec4be4b6-30b8-43df-aba6-b0f8f3fcde7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-bee39b36-6818-4ae0-938c-b45829ea74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-d6714981-1f0d-4bab-9d26-af9355048895,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-15988cf4-2c3f-48c5-aed4-c2ddbdbdad77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595592372-172.17.0.2-1595306410634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-e07bc881-6e43-4a98-8770-2f2edba1ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-22752031-1c7b-4629-b5a9-912e8092bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-1c1c3303-40f3-4cd1-8666-1f07a30c83b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-9ded6718-d708-4023-a40e-2728a0e69b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-5ebbcc45-0ed9-4bae-aa6d-41fceb46f117,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-d4db410c-092c-4c9c-b362-7cfca58e2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-533fd395-6fad-4af8-9d21-4e5777231997,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-643feef3-90c9-4eab-8a1b-9cc4d3de80bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595592372-172.17.0.2-1595306410634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-e07bc881-6e43-4a98-8770-2f2edba1ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-22752031-1c7b-4629-b5a9-912e8092bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-1c1c3303-40f3-4cd1-8666-1f07a30c83b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-9ded6718-d708-4023-a40e-2728a0e69b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-5ebbcc45-0ed9-4bae-aa6d-41fceb46f117,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-d4db410c-092c-4c9c-b362-7cfca58e2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-533fd395-6fad-4af8-9d21-4e5777231997,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-643feef3-90c9-4eab-8a1b-9cc4d3de80bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352772697-172.17.0.2-1595306921346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-a6243c70-5be3-4a17-81fa-2289186e5963,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-e671fe10-35fc-4454-9c56-e44684c35e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-2689285c-69ee-4b8c-9594-be58c8d8233a,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-854d6eb8-9d68-4ad4-ac47-c30544ceb24f,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-3048273b-6c06-41c8-8d50-b8a62a10d1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-d98b7039-a996-4833-a3a0-7f7cf4d326bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-3cf856ad-f421-4221-a134-c024d80a52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-24d51dac-aa99-48d1-9135-7720d4fac304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352772697-172.17.0.2-1595306921346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-a6243c70-5be3-4a17-81fa-2289186e5963,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-e671fe10-35fc-4454-9c56-e44684c35e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-2689285c-69ee-4b8c-9594-be58c8d8233a,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-854d6eb8-9d68-4ad4-ac47-c30544ceb24f,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-3048273b-6c06-41c8-8d50-b8a62a10d1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-d98b7039-a996-4833-a3a0-7f7cf4d326bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-3cf856ad-f421-4221-a134-c024d80a52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-24d51dac-aa99-48d1-9135-7720d4fac304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601671753-172.17.0.2-1595307060861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-99a84ff8-f3e9-4e50-8f90-f59645257b63,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-6693bdb2-3765-4057-9c8b-110673ade469,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-cb989904-be92-43bf-b2fe-11a00bb6ab28,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-7caa3fac-b76a-42f8-a6d5-fdd197cb6144,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-1dbf002d-ac2a-407c-aa0d-de219ce1988c,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-0c95ab2c-1191-45d8-825a-347445db216c,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-a63d68b1-3cb9-4802-a111-d67ef8ce99f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-f8fe6194-ad3c-42c6-b410-bf8016a6f7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601671753-172.17.0.2-1595307060861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-99a84ff8-f3e9-4e50-8f90-f59645257b63,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-6693bdb2-3765-4057-9c8b-110673ade469,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-cb989904-be92-43bf-b2fe-11a00bb6ab28,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-7caa3fac-b76a-42f8-a6d5-fdd197cb6144,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-1dbf002d-ac2a-407c-aa0d-de219ce1988c,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-0c95ab2c-1191-45d8-825a-347445db216c,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-a63d68b1-3cb9-4802-a111-d67ef8ce99f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-f8fe6194-ad3c-42c6-b410-bf8016a6f7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605285410-172.17.0.2-1595307738030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45345,DS-31e50550-845e-4f41-858c-cface5c02fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-bbfa39cb-f4a7-4fd3-b307-cc1116f4555f,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-9b7c3a8d-bf3e-4792-bc19-b70b630d51de,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-f74373ed-f830-49b1-bcab-11fa07d07efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-1d495c9f-7c81-439c-bf81-0de5d6c28aac,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-71eef7d0-0a40-414d-a578-c1a969c93698,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-457e5787-8ef0-47e1-b188-dbecbfa5c351,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-1caee979-6495-4119-bb38-c7b62ea6649b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605285410-172.17.0.2-1595307738030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45345,DS-31e50550-845e-4f41-858c-cface5c02fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-bbfa39cb-f4a7-4fd3-b307-cc1116f4555f,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-9b7c3a8d-bf3e-4792-bc19-b70b630d51de,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-f74373ed-f830-49b1-bcab-11fa07d07efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-1d495c9f-7c81-439c-bf81-0de5d6c28aac,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-71eef7d0-0a40-414d-a578-c1a969c93698,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-457e5787-8ef0-47e1-b188-dbecbfa5c351,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-1caee979-6495-4119-bb38-c7b62ea6649b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5105
