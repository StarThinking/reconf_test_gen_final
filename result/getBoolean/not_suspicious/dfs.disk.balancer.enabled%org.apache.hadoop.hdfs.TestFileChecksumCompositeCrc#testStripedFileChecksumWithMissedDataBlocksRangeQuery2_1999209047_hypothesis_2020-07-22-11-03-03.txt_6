reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437366617-172.17.0.7-1595416164517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-74fbe9f9-d69c-48da-a6e8-49d5221c48b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-629fce67-c005-4f6d-bfcb-42a2db74c5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-566dda00-00f3-4487-8241-505d319ed993,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-cf15e3eb-9b3d-4afc-a300-932aa54bff40,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-11d595f6-c7f0-480c-ac91-8e73f22ea1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-433c9962-13a8-4d24-9a67-46d91736891a,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-fbe3fc04-df46-4f06-952e-f1039e057ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-06e7c9f6-89b4-4890-a143-38ab5b9c154f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437366617-172.17.0.7-1595416164517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-74fbe9f9-d69c-48da-a6e8-49d5221c48b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-629fce67-c005-4f6d-bfcb-42a2db74c5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-566dda00-00f3-4487-8241-505d319ed993,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-cf15e3eb-9b3d-4afc-a300-932aa54bff40,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-11d595f6-c7f0-480c-ac91-8e73f22ea1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-433c9962-13a8-4d24-9a67-46d91736891a,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-fbe3fc04-df46-4f06-952e-f1039e057ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-06e7c9f6-89b4-4890-a143-38ab5b9c154f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730399162-172.17.0.7-1595416227891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-236e4a34-b3a4-4671-99c9-fa130b9e7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-db71631e-6cd4-4803-b10d-1da95a11b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-cffbafcf-f3a6-45b1-9a33-03e4dd6d6bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-06dc8943-c33e-4907-9651-2e5d39cb8d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-6b81e684-cae9-4b67-9bb8-d186cfdb6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-971c37d2-07ac-479e-a75f-55b71546293a,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-9968e24c-96d7-4b28-ba8c-f61ac0afbe46,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-1bf788e9-d2dd-4456-83e4-e8e81df23554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730399162-172.17.0.7-1595416227891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-236e4a34-b3a4-4671-99c9-fa130b9e7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-db71631e-6cd4-4803-b10d-1da95a11b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-cffbafcf-f3a6-45b1-9a33-03e4dd6d6bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-06dc8943-c33e-4907-9651-2e5d39cb8d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-6b81e684-cae9-4b67-9bb8-d186cfdb6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-971c37d2-07ac-479e-a75f-55b71546293a,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-9968e24c-96d7-4b28-ba8c-f61ac0afbe46,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-1bf788e9-d2dd-4456-83e4-e8e81df23554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379592254-172.17.0.7-1595416792954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-ddd45245-ecba-4537-b6a4-66693ef7a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-153763e3-ba32-4005-bcf1-6a8d9d685a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-6d9100eb-1eb3-4d5d-8416-4f4d8b3658c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-07632b43-2692-484a-ace9-14e79d617b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-f9a5bf49-7ee2-4195-b2e8-6b68e95d87be,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-5793d4d4-2ee8-4081-b857-62684ffb49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-b8a4479b-9538-4171-b62b-61293f5639ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-67724b4c-b126-4ab3-ba4c-fe31a6e48326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379592254-172.17.0.7-1595416792954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-ddd45245-ecba-4537-b6a4-66693ef7a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-153763e3-ba32-4005-bcf1-6a8d9d685a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-6d9100eb-1eb3-4d5d-8416-4f4d8b3658c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-07632b43-2692-484a-ace9-14e79d617b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-f9a5bf49-7ee2-4195-b2e8-6b68e95d87be,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-5793d4d4-2ee8-4081-b857-62684ffb49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-b8a4479b-9538-4171-b62b-61293f5639ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-67724b4c-b126-4ab3-ba4c-fe31a6e48326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987019642-172.17.0.7-1595416863300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46574,DS-09437ae7-74b8-4e65-92e6-1bccd5455e35,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-f519d8e9-8224-45bb-8a9c-79605596d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-7ffad7a7-8cfd-4428-98b6-5afdd99dbb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-cfe9554d-1891-49d3-ace4-d9729d9d6fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-94456039-8d7e-4052-aaaa-2fee6d42c759,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-63bc0662-8f7a-4bc9-9682-9ccc1171734b,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-147c4d7f-cded-4568-9dd8-64a6a98b890d,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-4c485a00-840f-4ecf-b491-e807644354a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987019642-172.17.0.7-1595416863300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46574,DS-09437ae7-74b8-4e65-92e6-1bccd5455e35,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-f519d8e9-8224-45bb-8a9c-79605596d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-7ffad7a7-8cfd-4428-98b6-5afdd99dbb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-cfe9554d-1891-49d3-ace4-d9729d9d6fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-94456039-8d7e-4052-aaaa-2fee6d42c759,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-63bc0662-8f7a-4bc9-9682-9ccc1171734b,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-147c4d7f-cded-4568-9dd8-64a6a98b890d,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-4c485a00-840f-4ecf-b491-e807644354a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792277514-172.17.0.7-1595416898274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-54d2e4b9-9295-4978-8795-6579921e2870,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-3f17378c-ceae-4a3d-a269-02e88981aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-9c210aa8-c7f6-4a17-8215-f0ba3a8ed6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-05109e19-0032-498c-ba55-612c8727a1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-8d7147b9-56fa-44ec-b1d4-7e650c3239e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-984ab5f0-e2a8-4448-8cc5-cea1c460fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-73037307-5563-488d-b85f-8151cd27a298,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-cd3291ff-9541-4f5a-96aa-7c669d8bc242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792277514-172.17.0.7-1595416898274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-54d2e4b9-9295-4978-8795-6579921e2870,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-3f17378c-ceae-4a3d-a269-02e88981aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-9c210aa8-c7f6-4a17-8215-f0ba3a8ed6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-05109e19-0032-498c-ba55-612c8727a1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-8d7147b9-56fa-44ec-b1d4-7e650c3239e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-984ab5f0-e2a8-4448-8cc5-cea1c460fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-73037307-5563-488d-b85f-8151cd27a298,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-cd3291ff-9541-4f5a-96aa-7c669d8bc242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504259019-172.17.0.7-1595417348915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-72b8fd8e-e1e0-4b73-83dd-fe4e86f3044d,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-145aac8d-1fe9-4cc7-a803-b26666cfa366,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-784611d7-970e-4785-bed3-e764d87b37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-16484c83-4fdd-4a7e-9940-c3ab4ef097b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-2b64a9a0-1615-4ad5-bdcd-1b3debfb48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-d630427d-3ef0-474e-b50f-cc9ee0ae3625,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-c77aac28-31b3-4ca1-b25b-4ccb5b54d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-14e1cd9f-d61e-4b60-862b-a4076c709c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504259019-172.17.0.7-1595417348915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-72b8fd8e-e1e0-4b73-83dd-fe4e86f3044d,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-145aac8d-1fe9-4cc7-a803-b26666cfa366,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-784611d7-970e-4785-bed3-e764d87b37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-16484c83-4fdd-4a7e-9940-c3ab4ef097b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-2b64a9a0-1615-4ad5-bdcd-1b3debfb48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-d630427d-3ef0-474e-b50f-cc9ee0ae3625,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-c77aac28-31b3-4ca1-b25b-4ccb5b54d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-14e1cd9f-d61e-4b60-862b-a4076c709c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971177376-172.17.0.7-1595417526934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-4c418d70-c86f-42cd-8e08-32cc05aea53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-2cf156c7-2226-4993-9c58-b90473581ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-9b5aea0d-7db5-4b43-9b61-2d8377b6d28c,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-646bda0f-568a-4d69-a569-c483fcf314e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-7af0ae7a-a4ef-4125-9005-32effe2c0465,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-a5c5419e-2bc9-4235-830e-8147024f06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-2e0518c4-0415-4492-8087-ea8514140f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-e2716843-7005-407c-877f-8ed002cb8a50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971177376-172.17.0.7-1595417526934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-4c418d70-c86f-42cd-8e08-32cc05aea53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-2cf156c7-2226-4993-9c58-b90473581ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-9b5aea0d-7db5-4b43-9b61-2d8377b6d28c,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-646bda0f-568a-4d69-a569-c483fcf314e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-7af0ae7a-a4ef-4125-9005-32effe2c0465,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-a5c5419e-2bc9-4235-830e-8147024f06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-2e0518c4-0415-4492-8087-ea8514140f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-e2716843-7005-407c-877f-8ed002cb8a50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596112325-172.17.0.7-1595417784900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-a09635fd-ed26-4b7d-a73f-1fe454fc0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c365904f-bd36-4977-bc13-0f14deaaa688,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-e005d882-681d-4544-8b85-d7b938c7db6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-48637c54-8999-4893-840f-44615d7bd92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-b52d4a06-353f-467a-b92e-8867d872085e,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f5c26fdd-e1ba-483d-b54a-395915b28a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-59cc5441-fec2-418d-9e0b-e8cd895a3d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-58bf4626-edc2-48b3-bb2f-49f602b29a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596112325-172.17.0.7-1595417784900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-a09635fd-ed26-4b7d-a73f-1fe454fc0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c365904f-bd36-4977-bc13-0f14deaaa688,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-e005d882-681d-4544-8b85-d7b938c7db6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-48637c54-8999-4893-840f-44615d7bd92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-b52d4a06-353f-467a-b92e-8867d872085e,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f5c26fdd-e1ba-483d-b54a-395915b28a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-59cc5441-fec2-418d-9e0b-e8cd895a3d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-58bf4626-edc2-48b3-bb2f-49f602b29a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133102072-172.17.0.7-1595418694468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-f78c2773-f4fd-446d-949c-e110ca9fa09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-f62363dd-2633-4ccb-9814-937f265e8582,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-d2039d3a-9f02-4284-9f46-05430887ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-3104deea-905a-4c6a-800a-05b634608b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-82c5a423-0a3f-4e70-b02d-4e67438718f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-bf14acdc-c4c7-4bf4-9805-665038e931d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-717d2847-4f1c-4d39-9e56-7fe148b1b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-24bd962d-cf31-4c25-9290-36928dbd3462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133102072-172.17.0.7-1595418694468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-f78c2773-f4fd-446d-949c-e110ca9fa09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-f62363dd-2633-4ccb-9814-937f265e8582,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-d2039d3a-9f02-4284-9f46-05430887ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-3104deea-905a-4c6a-800a-05b634608b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-82c5a423-0a3f-4e70-b02d-4e67438718f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-bf14acdc-c4c7-4bf4-9805-665038e931d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-717d2847-4f1c-4d39-9e56-7fe148b1b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-24bd962d-cf31-4c25-9290-36928dbd3462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260430515-172.17.0.7-1595418731214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33520,DS-b60289bf-f115-4def-b025-3e315274ee49,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-0abc5eae-f21a-415f-bce8-3d51932526c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-c99e0f3c-c9a6-47dc-a32c-c0672f919cba,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-603579bb-971a-4f85-bedd-36eedd5823b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-6ca382c4-9189-4adc-83e2-a8d19b9060a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-76c3ef1a-ccc1-4ca5-9f61-eaa6d390d10c,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-bac8a75c-e1b3-4d2b-971a-2c6494ebb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-7911b102-11e8-4048-8a0f-67b534ae2e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260430515-172.17.0.7-1595418731214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33520,DS-b60289bf-f115-4def-b025-3e315274ee49,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-0abc5eae-f21a-415f-bce8-3d51932526c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-c99e0f3c-c9a6-47dc-a32c-c0672f919cba,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-603579bb-971a-4f85-bedd-36eedd5823b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-6ca382c4-9189-4adc-83e2-a8d19b9060a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-76c3ef1a-ccc1-4ca5-9f61-eaa6d390d10c,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-bac8a75c-e1b3-4d2b-971a-2c6494ebb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-7911b102-11e8-4048-8a0f-67b534ae2e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408238907-172.17.0.7-1595419110841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-87e208f9-238b-4252-9a6d-a5d438d24b84,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-39b6cfb5-cde9-4c3c-85d7-35dd620c0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-80a853fc-5114-46b8-931c-834be2f5abf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-7a1884b4-5921-4c79-a874-f893836e7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-2121caba-7eda-4b21-994d-42a863d89c87,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-9e316bf2-a518-456b-bf75-384305bea2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-78f9ff77-e1b9-4bc4-928a-ec7c9553d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-2f6d1a73-3f48-430e-9944-0520e8725578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408238907-172.17.0.7-1595419110841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-87e208f9-238b-4252-9a6d-a5d438d24b84,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-39b6cfb5-cde9-4c3c-85d7-35dd620c0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-80a853fc-5114-46b8-931c-834be2f5abf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-7a1884b4-5921-4c79-a874-f893836e7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-2121caba-7eda-4b21-994d-42a863d89c87,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-9e316bf2-a518-456b-bf75-384305bea2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-78f9ff77-e1b9-4bc4-928a-ec7c9553d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-2f6d1a73-3f48-430e-9944-0520e8725578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157351919-172.17.0.7-1595419470239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34323,DS-da46b072-2274-4541-b13a-6032537a0b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-3deb9a80-92f7-4236-a967-b2377ea12b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-d1b998b0-75b7-4559-801a-0d80f4864c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-89715af8-2c38-476c-b4dd-0f57868fd0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-00c27529-6317-4a4d-ad00-1ad4105461aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-ca2af378-f8ae-4f71-8fbc-78ec42777451,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e857162d-6111-48c0-b982-21d5c4a8de35,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-a90c5bf3-8d3a-4c74-9ba4-c6ac1a170d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157351919-172.17.0.7-1595419470239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34323,DS-da46b072-2274-4541-b13a-6032537a0b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-3deb9a80-92f7-4236-a967-b2377ea12b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-d1b998b0-75b7-4559-801a-0d80f4864c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-89715af8-2c38-476c-b4dd-0f57868fd0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-00c27529-6317-4a4d-ad00-1ad4105461aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-ca2af378-f8ae-4f71-8fbc-78ec42777451,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e857162d-6111-48c0-b982-21d5c4a8de35,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-a90c5bf3-8d3a-4c74-9ba4-c6ac1a170d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482456613-172.17.0.7-1595419656617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34120,DS-10720159-1635-4bb7-8c21-21406d8ad91b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-b7b1823d-f57f-4a70-b96c-ff08f4a2c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-c656174b-adf1-4462-b2f8-ef792bff6d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-7209b9c8-6b8c-44e0-8f97-396e507f6349,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-8f16fad2-ed80-4554-8130-12fdaf0f116d,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-503aa243-85c6-43e4-afc2-e2730e77ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-42fa2d92-ff41-45fe-8282-998a44d2b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-def99708-9fcb-4b70-80c7-d4c0793280c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482456613-172.17.0.7-1595419656617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34120,DS-10720159-1635-4bb7-8c21-21406d8ad91b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-b7b1823d-f57f-4a70-b96c-ff08f4a2c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-c656174b-adf1-4462-b2f8-ef792bff6d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-7209b9c8-6b8c-44e0-8f97-396e507f6349,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-8f16fad2-ed80-4554-8130-12fdaf0f116d,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-503aa243-85c6-43e4-afc2-e2730e77ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-42fa2d92-ff41-45fe-8282-998a44d2b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-def99708-9fcb-4b70-80c7-d4c0793280c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998519883-172.17.0.7-1595419801485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41627,DS-bba226cd-8739-43ae-a46b-0bd023deccc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-200aa629-7496-41eb-b1cd-f6dd195b5aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-c8bb112c-3437-4e76-8bcc-eebe227932a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-310e426d-2ca8-42b9-be53-e95a2651fd03,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-150c4e90-f37c-4c50-8188-9d820c930b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-080aa17d-cff3-40c1-811a-70805e6a5a92,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-ef35a68c-092f-4fd2-b0e8-db233037f267,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-9fb9c952-a629-47df-818d-e81b9435e01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998519883-172.17.0.7-1595419801485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41627,DS-bba226cd-8739-43ae-a46b-0bd023deccc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-200aa629-7496-41eb-b1cd-f6dd195b5aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-c8bb112c-3437-4e76-8bcc-eebe227932a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-310e426d-2ca8-42b9-be53-e95a2651fd03,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-150c4e90-f37c-4c50-8188-9d820c930b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-080aa17d-cff3-40c1-811a-70805e6a5a92,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-ef35a68c-092f-4fd2-b0e8-db233037f267,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-9fb9c952-a629-47df-818d-e81b9435e01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269638520-172.17.0.7-1595420326519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-7ecc7cb2-9767-4dbc-b0fd-12579a0866c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-5ce60567-3dcf-43a8-884f-4c6fc564eb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-64fdfa40-a2bc-45bb-b9a1-8cea958a9341,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-3ba3982e-6e71-4fd3-bb65-b2205d3a9f77,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-e32a8e44-259a-470e-9911-d352aa978e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-89bb7a23-9c22-476f-bd4c-3d90cafef6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-c1536a0f-14b1-4a9f-ae80-e0695c0b5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-d83dedce-e0d4-40c3-83a4-be7ada563f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269638520-172.17.0.7-1595420326519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-7ecc7cb2-9767-4dbc-b0fd-12579a0866c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-5ce60567-3dcf-43a8-884f-4c6fc564eb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-64fdfa40-a2bc-45bb-b9a1-8cea958a9341,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-3ba3982e-6e71-4fd3-bb65-b2205d3a9f77,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-e32a8e44-259a-470e-9911-d352aa978e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-89bb7a23-9c22-476f-bd4c-3d90cafef6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-c1536a0f-14b1-4a9f-ae80-e0695c0b5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-d83dedce-e0d4-40c3-83a4-be7ada563f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637267631-172.17.0.7-1595420554706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44377,DS-ec000a4d-b9cd-4368-8f7f-1d5ecad2c290,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-2015ee75-fa80-424f-922b-0f448b216b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-e66935d5-ec30-4483-9bd8-f1f710de2f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-19804dff-410f-4c1f-80f6-4102003cd6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-732194f1-602d-445a-a9d9-a6a91e9866a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-c1d6aa4d-15e9-4ef7-8ac5-6f45e4deff09,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-f92dc4b0-c22c-4c0d-9e85-826de9a617c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-dc00ed31-8477-427b-b85d-50531c6d66a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637267631-172.17.0.7-1595420554706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44377,DS-ec000a4d-b9cd-4368-8f7f-1d5ecad2c290,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-2015ee75-fa80-424f-922b-0f448b216b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-e66935d5-ec30-4483-9bd8-f1f710de2f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-19804dff-410f-4c1f-80f6-4102003cd6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-732194f1-602d-445a-a9d9-a6a91e9866a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-c1d6aa4d-15e9-4ef7-8ac5-6f45e4deff09,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-f92dc4b0-c22c-4c0d-9e85-826de9a617c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-dc00ed31-8477-427b-b85d-50531c6d66a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819451679-172.17.0.7-1595420596612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-131be5e7-3e1c-41c3-89cf-1f31b481bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-69e2819b-a1fb-4e6a-ab46-298021a6eb65,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-c065dee3-c7bb-43fa-95a0-ac430ceed354,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-22ab86a4-449f-4df1-a553-c94b5d82da55,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-11f3405b-3fd7-4ef3-9a62-372c6a92b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-6e85234d-1996-475c-b338-f176d9da517b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-21d35a90-b890-4ff8-95b3-6732d028f34c,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-bfb83e5a-4fb6-4300-9eb0-8e39ce379363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819451679-172.17.0.7-1595420596612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-131be5e7-3e1c-41c3-89cf-1f31b481bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-69e2819b-a1fb-4e6a-ab46-298021a6eb65,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-c065dee3-c7bb-43fa-95a0-ac430ceed354,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-22ab86a4-449f-4df1-a553-c94b5d82da55,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-11f3405b-3fd7-4ef3-9a62-372c6a92b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-6e85234d-1996-475c-b338-f176d9da517b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-21d35a90-b890-4ff8-95b3-6732d028f34c,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-bfb83e5a-4fb6-4300-9eb0-8e39ce379363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154125296-172.17.0.7-1595420711835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35707,DS-d0808f31-814c-41fa-85ca-b50a338968af,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-eab4ab00-f57e-4460-9056-4d2a742cdced,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-04894762-8e63-4498-94f2-59f26df98a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-79098750-03bc-4804-a573-2e9165822f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-51641957-c003-40e5-947a-eafa9af11e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ee2c94f4-3bc9-487b-955b-f3545ffb690f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-bddfc4fd-061e-42a8-9ee5-f3440770c517,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-216c5a5c-beb1-46c7-8292-78f1b3750659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154125296-172.17.0.7-1595420711835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35707,DS-d0808f31-814c-41fa-85ca-b50a338968af,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-eab4ab00-f57e-4460-9056-4d2a742cdced,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-04894762-8e63-4498-94f2-59f26df98a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-79098750-03bc-4804-a573-2e9165822f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-51641957-c003-40e5-947a-eafa9af11e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ee2c94f4-3bc9-487b-955b-f3545ffb690f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-bddfc4fd-061e-42a8-9ee5-f3440770c517,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-216c5a5c-beb1-46c7-8292-78f1b3750659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31695177-172.17.0.7-1595420802741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-61343bda-4d81-41a7-bb63-1db2a3e31eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8ddec6d9-ac39-4c7a-becb-60aaee5ee0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-94618cb5-e455-4a32-9256-b220311cf788,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-e3d74903-7431-4a94-adbd-1fd45ce38169,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-6e3230c2-9824-4af2-a299-4b9b3684ef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-68d9b363-604f-4807-8c95-f59f3a0a5cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-264226e3-362f-4038-8986-4ed26de08656,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-fe8eae86-dbc2-4da6-af01-28c4d25772be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31695177-172.17.0.7-1595420802741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-61343bda-4d81-41a7-bb63-1db2a3e31eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8ddec6d9-ac39-4c7a-becb-60aaee5ee0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-94618cb5-e455-4a32-9256-b220311cf788,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-e3d74903-7431-4a94-adbd-1fd45ce38169,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-6e3230c2-9824-4af2-a299-4b9b3684ef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-68d9b363-604f-4807-8c95-f59f3a0a5cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-264226e3-362f-4038-8986-4ed26de08656,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-fe8eae86-dbc2-4da6-af01-28c4d25772be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5108
