reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553128761-172.17.0.7-1595304443453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-284b52a2-d7fe-4b97-8fa3-ed81bf57911f,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f62d70a1-db88-4cfb-8533-7120b670ae10,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-bc8d584e-b723-446f-93e6-b1cb1fae8b80,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-b665e2c6-06bb-4768-8686-7eb0d58e7f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-6e9e0df2-0c7f-4ff4-b737-70288d78bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-4e2d3647-6d2d-4454-9470-8ae7e4580796,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-5f4c98ba-d4e5-482c-a176-795e4674de8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-b9a0e15a-3097-4d00-bd42-9129e351505b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553128761-172.17.0.7-1595304443453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-284b52a2-d7fe-4b97-8fa3-ed81bf57911f,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f62d70a1-db88-4cfb-8533-7120b670ae10,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-bc8d584e-b723-446f-93e6-b1cb1fae8b80,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-b665e2c6-06bb-4768-8686-7eb0d58e7f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-6e9e0df2-0c7f-4ff4-b737-70288d78bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-4e2d3647-6d2d-4454-9470-8ae7e4580796,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-5f4c98ba-d4e5-482c-a176-795e4674de8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-b9a0e15a-3097-4d00-bd42-9129e351505b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803779387-172.17.0.7-1595304639986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-c433e448-40fa-469f-870c-730b8e6fd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-7b41027f-b5c1-44e3-a2fe-2f9915dfefd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-f70a95fc-a7c6-4266-a05c-e2ce12c1d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-0b3aefbc-83c6-421e-845e-16c424969c04,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-90d6a487-d84c-4a86-b74f-0f348785038e,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-38a35981-f8be-4ae0-80cd-3b14d4f50fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c8438460-3ea8-4593-ab72-67a74145e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c18c69bc-9214-4551-bcbc-446f81122fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803779387-172.17.0.7-1595304639986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-c433e448-40fa-469f-870c-730b8e6fd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-7b41027f-b5c1-44e3-a2fe-2f9915dfefd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-f70a95fc-a7c6-4266-a05c-e2ce12c1d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-0b3aefbc-83c6-421e-845e-16c424969c04,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-90d6a487-d84c-4a86-b74f-0f348785038e,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-38a35981-f8be-4ae0-80cd-3b14d4f50fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c8438460-3ea8-4593-ab72-67a74145e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c18c69bc-9214-4551-bcbc-446f81122fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553583504-172.17.0.7-1595304759339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-9b8dced4-0ce4-40f4-9040-15d72f7945b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-57bbcd9c-1033-446e-98fc-b5c2619d3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-90312ee2-334e-426a-b99e-64f9a7fa5e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-85429617-1dfa-4909-81f4-5e594a90e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-3dc653dc-4408-4e18-86de-837a3c9a2591,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-1cfb9000-95ca-4a1a-8c47-802ca91e5dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-23f8ac29-ac50-438e-9e0d-b2130285d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-31e99bfc-1a6b-41ca-8c80-ef80ada3e47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553583504-172.17.0.7-1595304759339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-9b8dced4-0ce4-40f4-9040-15d72f7945b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-57bbcd9c-1033-446e-98fc-b5c2619d3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-90312ee2-334e-426a-b99e-64f9a7fa5e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-85429617-1dfa-4909-81f4-5e594a90e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-3dc653dc-4408-4e18-86de-837a3c9a2591,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-1cfb9000-95ca-4a1a-8c47-802ca91e5dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-23f8ac29-ac50-438e-9e0d-b2130285d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-31e99bfc-1a6b-41ca-8c80-ef80ada3e47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19961365-172.17.0.7-1595304831855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-809229bc-15fb-478c-821a-d546583301c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-694dd9c0-61a5-4b7b-92c6-0581d48f2eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-8e96d869-83f1-487a-a729-80e38cfead6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-51d657eb-8cb0-4590-a652-808604c0e868,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-2e7ea97f-5bd7-4b82-8d20-c31c2e1307cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-d56a760f-4868-4e83-9194-401f98d6a169,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-f33f4791-affc-4187-b809-fdcd69adcf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-70a08b55-fbae-475d-8311-4fa9a86aadf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19961365-172.17.0.7-1595304831855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-809229bc-15fb-478c-821a-d546583301c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-694dd9c0-61a5-4b7b-92c6-0581d48f2eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-8e96d869-83f1-487a-a729-80e38cfead6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-51d657eb-8cb0-4590-a652-808604c0e868,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-2e7ea97f-5bd7-4b82-8d20-c31c2e1307cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-d56a760f-4868-4e83-9194-401f98d6a169,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-f33f4791-affc-4187-b809-fdcd69adcf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-70a08b55-fbae-475d-8311-4fa9a86aadf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403832966-172.17.0.7-1595305337292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-8b22a037-8a1f-44c8-b21c-d3d14a2f747c,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-68d62887-426a-434d-9677-c0286eddee52,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-df264514-e5f4-4951-9ae2-b9b300cd5678,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-c41d51af-6d24-41cc-8fef-226db1489b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-29924e38-b49c-41ce-be44-6ec9336985e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-8078ee17-bea5-4216-98a2-af22d1a35f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a86b9c15-40f9-4f89-b83c-e6d7a35baa78,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-4da4dfad-4c20-4dd3-8ef8-58ed9601a425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403832966-172.17.0.7-1595305337292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-8b22a037-8a1f-44c8-b21c-d3d14a2f747c,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-68d62887-426a-434d-9677-c0286eddee52,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-df264514-e5f4-4951-9ae2-b9b300cd5678,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-c41d51af-6d24-41cc-8fef-226db1489b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-29924e38-b49c-41ce-be44-6ec9336985e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-8078ee17-bea5-4216-98a2-af22d1a35f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a86b9c15-40f9-4f89-b83c-e6d7a35baa78,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-4da4dfad-4c20-4dd3-8ef8-58ed9601a425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518400404-172.17.0.7-1595305374573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-bc277648-afb6-4520-ad5f-b1c9edcc7825,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-5c20dee0-4174-44de-9b87-133c37b0a740,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-a6f83e73-eb2b-487e-a8ac-1f3bf962efa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-516f26ec-e4dd-4d6a-94fe-9637ea8c4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-28a86a5a-014c-426b-b43e-b1f3dc607da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-5e5f9af5-3a6a-4644-af18-ca276d3ed7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-21167874-761d-40f4-8a7c-8962633e52dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-41bc520a-164a-4ec1-85ab-3951999aa614,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518400404-172.17.0.7-1595305374573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-bc277648-afb6-4520-ad5f-b1c9edcc7825,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-5c20dee0-4174-44de-9b87-133c37b0a740,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-a6f83e73-eb2b-487e-a8ac-1f3bf962efa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-516f26ec-e4dd-4d6a-94fe-9637ea8c4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-28a86a5a-014c-426b-b43e-b1f3dc607da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-5e5f9af5-3a6a-4644-af18-ca276d3ed7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-21167874-761d-40f4-8a7c-8962633e52dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-41bc520a-164a-4ec1-85ab-3951999aa614,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884709107-172.17.0.7-1595305410447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44393,DS-f6104f76-400e-432f-aa11-1c1b00d718d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d1ccb3e2-4145-4b7b-862f-07fb40e7e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-66bbfaa1-3645-4b87-9dc4-2ae24c447ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-61cbdf28-bd43-48bd-87d1-b6fa7a88cfed,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-9d1e38e2-9cd5-4c69-ad04-fba17c784662,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-9dd11f8d-82ea-435c-920b-c32ca4027ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-1188c805-13f6-49ea-a36e-d499c31725c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-ede6b68c-5c74-46e9-9ef6-a65dc84a37ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884709107-172.17.0.7-1595305410447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44393,DS-f6104f76-400e-432f-aa11-1c1b00d718d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d1ccb3e2-4145-4b7b-862f-07fb40e7e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-66bbfaa1-3645-4b87-9dc4-2ae24c447ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-61cbdf28-bd43-48bd-87d1-b6fa7a88cfed,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-9d1e38e2-9cd5-4c69-ad04-fba17c784662,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-9dd11f8d-82ea-435c-920b-c32ca4027ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-1188c805-13f6-49ea-a36e-d499c31725c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-ede6b68c-5c74-46e9-9ef6-a65dc84a37ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622173162-172.17.0.7-1595305448529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-ad04186c-771a-46e7-b7c8-098d46f2ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-6b43c7de-5b08-40cf-aec6-e6f043b2002b,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-06e5a111-e74f-436e-9546-1cb40d27daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-e82da1cc-bfa9-4954-b3f0-5a2a0b04ad89,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-b1860e32-8e41-45a5-bbf6-aa8b73e840e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-b51e0ecf-2f12-4e11-a112-cd1b850fda4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-ba0a364e-0665-4b8a-a555-d64193a16eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-eb95b685-7020-4654-a843-c840cec600d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622173162-172.17.0.7-1595305448529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-ad04186c-771a-46e7-b7c8-098d46f2ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-6b43c7de-5b08-40cf-aec6-e6f043b2002b,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-06e5a111-e74f-436e-9546-1cb40d27daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-e82da1cc-bfa9-4954-b3f0-5a2a0b04ad89,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-b1860e32-8e41-45a5-bbf6-aa8b73e840e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-b51e0ecf-2f12-4e11-a112-cd1b850fda4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-ba0a364e-0665-4b8a-a555-d64193a16eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-eb95b685-7020-4654-a843-c840cec600d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133112269-172.17.0.7-1595305560424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-aa408dec-e8ea-46f6-9a59-e0761ce5f179,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-eb948ef8-5e95-4322-8070-c0a8d328f384,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-64debf41-a36f-4ac2-8d16-6d018e23346f,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-72fb656f-740a-4799-ac75-f8ea652b5703,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-0c219424-0b3e-4413-a0f0-a5eb577b7535,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-c1915f99-97c9-4896-ad1c-f92b6dd2d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-3d7b2d85-173c-4b13-b77c-de28261cfe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-62c2985f-d88d-454b-a24d-75fdb3bd103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133112269-172.17.0.7-1595305560424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-aa408dec-e8ea-46f6-9a59-e0761ce5f179,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-eb948ef8-5e95-4322-8070-c0a8d328f384,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-64debf41-a36f-4ac2-8d16-6d018e23346f,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-72fb656f-740a-4799-ac75-f8ea652b5703,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-0c219424-0b3e-4413-a0f0-a5eb577b7535,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-c1915f99-97c9-4896-ad1c-f92b6dd2d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-3d7b2d85-173c-4b13-b77c-de28261cfe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-62c2985f-d88d-454b-a24d-75fdb3bd103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570840814-172.17.0.7-1595306008416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-f6d98d6e-7734-4dd2-be96-3e2408eef991,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-eca32742-12d0-42d2-afbf-78d226ee6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-772fdc80-0bb4-489b-834d-1adadf3db7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-dc6fc3cc-c6ff-49c5-b5fa-08e4a4b302a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-2c09eb80-bc8f-4325-84be-48d064e20e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-63e3eb1c-b5fb-4720-9eac-a56345a24c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-023edd37-c894-4d34-a8bc-d3d53c73a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-18b78309-0e4f-47cc-9c7a-7100a1e55b98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570840814-172.17.0.7-1595306008416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-f6d98d6e-7734-4dd2-be96-3e2408eef991,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-eca32742-12d0-42d2-afbf-78d226ee6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-772fdc80-0bb4-489b-834d-1adadf3db7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-dc6fc3cc-c6ff-49c5-b5fa-08e4a4b302a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-2c09eb80-bc8f-4325-84be-48d064e20e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-63e3eb1c-b5fb-4720-9eac-a56345a24c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-023edd37-c894-4d34-a8bc-d3d53c73a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-18b78309-0e4f-47cc-9c7a-7100a1e55b98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919736364-172.17.0.7-1595306083681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-57824875-231c-4930-92e1-70e5c813fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-2b74361b-0a1d-4aa8-903c-c19461e33dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-191b2fda-0689-485f-a4a3-e8d69a15ffd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-65b2a518-2568-490f-b4f3-4bee83ed00dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-ddc0c7a6-d2a4-4bc2-b2b0-74a95a04fffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c27f397f-6a64-43fa-bfb2-349a95c5bb66,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-299b090f-e507-4a7f-bb9a-494adaa06bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-152707c1-5a4d-4e1c-ae5f-d2cf4860d2bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919736364-172.17.0.7-1595306083681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-57824875-231c-4930-92e1-70e5c813fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-2b74361b-0a1d-4aa8-903c-c19461e33dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-191b2fda-0689-485f-a4a3-e8d69a15ffd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-65b2a518-2568-490f-b4f3-4bee83ed00dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-ddc0c7a6-d2a4-4bc2-b2b0-74a95a04fffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c27f397f-6a64-43fa-bfb2-349a95c5bb66,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-299b090f-e507-4a7f-bb9a-494adaa06bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-152707c1-5a4d-4e1c-ae5f-d2cf4860d2bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995408380-172.17.0.7-1595306253893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44245,DS-4a07c179-b968-4387-8eda-9b4d5c02d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-ba563e03-2984-4005-b49c-026f08b12b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-084a4d02-89d4-4a98-9052-746b6c926c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-2faad22e-e25a-4485-beff-1cb4d1e52eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-a02ec989-da58-485f-a739-d0cf0dcbd688,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-5a2cf85b-1ffd-46fb-aad4-d34d9fcea5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c865f8c8-e759-4607-b239-2a811252f176,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ff439a05-9de2-44d1-b103-e6de38aeca07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995408380-172.17.0.7-1595306253893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44245,DS-4a07c179-b968-4387-8eda-9b4d5c02d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-ba563e03-2984-4005-b49c-026f08b12b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-084a4d02-89d4-4a98-9052-746b6c926c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-2faad22e-e25a-4485-beff-1cb4d1e52eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-a02ec989-da58-485f-a739-d0cf0dcbd688,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-5a2cf85b-1ffd-46fb-aad4-d34d9fcea5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c865f8c8-e759-4607-b239-2a811252f176,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ff439a05-9de2-44d1-b103-e6de38aeca07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469497786-172.17.0.7-1595306833186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40335,DS-0acbbfba-f922-4404-91ab-5124c8c1ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-faaa08b7-49a7-4cab-83df-3d2eec7018f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-33636866-1d67-4b1e-9313-50be951a7685,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-74d0bdbc-9a9b-44e4-a91c-cdedf7f1ec05,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-c75ce53e-7bf0-4c26-81bf-fa749ac129da,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-ae7ce3e5-9180-43a5-946f-a09eaf948529,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-f0bbefef-89f3-4791-b3b4-96eea83dc3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-24bc335c-9308-453e-999a-dcafdeb10ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469497786-172.17.0.7-1595306833186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40335,DS-0acbbfba-f922-4404-91ab-5124c8c1ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-faaa08b7-49a7-4cab-83df-3d2eec7018f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-33636866-1d67-4b1e-9313-50be951a7685,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-74d0bdbc-9a9b-44e4-a91c-cdedf7f1ec05,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-c75ce53e-7bf0-4c26-81bf-fa749ac129da,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-ae7ce3e5-9180-43a5-946f-a09eaf948529,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-f0bbefef-89f3-4791-b3b4-96eea83dc3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-24bc335c-9308-453e-999a-dcafdeb10ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983864102-172.17.0.7-1595307027830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-a30c50eb-13b6-404a-b5b8-8c529b4e43bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-7da3612f-7911-4aab-97b4-11b0cd97448c,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-b20f66b0-e563-4ff7-9d48-9c4ccacf1f57,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-c1495db5-d2c7-4211-b56b-24a0ab73e49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-563f3e02-389f-47bd-8b6e-f10d7750f11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-29fcc069-815c-4698-adea-fb8952dbd90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-4672ee33-0d41-418c-ac9e-0bf38d9220e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-d81bb8be-6fb9-43d8-bf61-ac90c665dab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983864102-172.17.0.7-1595307027830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-a30c50eb-13b6-404a-b5b8-8c529b4e43bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-7da3612f-7911-4aab-97b4-11b0cd97448c,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-b20f66b0-e563-4ff7-9d48-9c4ccacf1f57,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-c1495db5-d2c7-4211-b56b-24a0ab73e49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-563f3e02-389f-47bd-8b6e-f10d7750f11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-29fcc069-815c-4698-adea-fb8952dbd90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-4672ee33-0d41-418c-ac9e-0bf38d9220e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-d81bb8be-6fb9-43d8-bf61-ac90c665dab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914890680-172.17.0.7-1595307136735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-9db5b662-1887-4f21-91f1-11d0e06cc489,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-6eccac0c-57b7-4f8f-a136-a5d5fb9649ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-35ba5d13-c721-4ac7-8d8a-b734f14531e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-357a546c-0594-4133-9e45-f59ddfb34357,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-2993bdca-e26e-4794-9f2a-cbd4ac47e441,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-18b75206-dc0e-4716-b72b-18a8d4d89c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-d1ffc814-8bf2-4493-9b87-2d72b39f1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-30a98342-786c-4a9d-bf8f-0fae8bda03e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914890680-172.17.0.7-1595307136735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-9db5b662-1887-4f21-91f1-11d0e06cc489,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-6eccac0c-57b7-4f8f-a136-a5d5fb9649ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-35ba5d13-c721-4ac7-8d8a-b734f14531e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-357a546c-0594-4133-9e45-f59ddfb34357,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-2993bdca-e26e-4794-9f2a-cbd4ac47e441,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-18b75206-dc0e-4716-b72b-18a8d4d89c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-d1ffc814-8bf2-4493-9b87-2d72b39f1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-30a98342-786c-4a9d-bf8f-0fae8bda03e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309528579-172.17.0.7-1595307402117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38567,DS-c76944ff-84a2-4d06-ac13-1128c926cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-41024e2a-b513-40e6-bbcd-73ac958e07a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-f036aa2e-33cb-4e6a-bacf-e4e3931e4955,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-1a5c0364-9300-4d68-8cfa-0a4fc951c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-11f30a51-dd57-41fa-9d6a-50ad16504cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-265ac9d4-ef33-43f9-a43e-c6f98096536c,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-fae9ca0e-7740-4f02-998a-63d84fcca65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-c10d8cc8-6a45-4052-b8b8-6206c00a759c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309528579-172.17.0.7-1595307402117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38567,DS-c76944ff-84a2-4d06-ac13-1128c926cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-41024e2a-b513-40e6-bbcd-73ac958e07a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-f036aa2e-33cb-4e6a-bacf-e4e3931e4955,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-1a5c0364-9300-4d68-8cfa-0a4fc951c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-11f30a51-dd57-41fa-9d6a-50ad16504cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-265ac9d4-ef33-43f9-a43e-c6f98096536c,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-fae9ca0e-7740-4f02-998a-63d84fcca65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-c10d8cc8-6a45-4052-b8b8-6206c00a759c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016158643-172.17.0.7-1595307510562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35920,DS-19519c94-7bc6-428f-89f3-4e7e084e6a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-f70e5e67-b749-4a80-94fe-7e7582b44117,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-f5b6d1f9-ec71-4a3b-bfac-2130e3b76d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-0090fdef-6793-4080-bb36-7d40740f6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-6468efd4-18f2-453c-b43f-6653d9532ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-6f2faef8-0664-4682-bb43-f28928cf7442,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-642af9e5-a109-41f0-8722-f3a968d7947c,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-342ae3c2-e997-4413-ba4d-c159c948c9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016158643-172.17.0.7-1595307510562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35920,DS-19519c94-7bc6-428f-89f3-4e7e084e6a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-f70e5e67-b749-4a80-94fe-7e7582b44117,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-f5b6d1f9-ec71-4a3b-bfac-2130e3b76d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-0090fdef-6793-4080-bb36-7d40740f6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-6468efd4-18f2-453c-b43f-6653d9532ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-6f2faef8-0664-4682-bb43-f28928cf7442,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-642af9e5-a109-41f0-8722-f3a968d7947c,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-342ae3c2-e997-4413-ba4d-c159c948c9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770937081-172.17.0.7-1595307628729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-fc906826-1c2a-4950-b9d6-6a879b18137b,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-aa8e88c6-e487-4d67-b2e1-fb4ba9f76a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-a37f6d42-164b-4232-af75-f9c9e3b530d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-7f0c9c3c-d138-4af7-91b1-2dc7ca35130a,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-405c6276-3a2d-464b-bf58-931bce2d6599,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-c1a00730-5afd-4a32-97e7-ef22b673d5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-eba5ad6b-bfdd-452d-b15d-4ef1d74bb40d,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-d98ad611-8190-49cf-8a52-1accdbe27276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770937081-172.17.0.7-1595307628729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-fc906826-1c2a-4950-b9d6-6a879b18137b,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-aa8e88c6-e487-4d67-b2e1-fb4ba9f76a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-a37f6d42-164b-4232-af75-f9c9e3b530d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-7f0c9c3c-d138-4af7-91b1-2dc7ca35130a,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-405c6276-3a2d-464b-bf58-931bce2d6599,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-c1a00730-5afd-4a32-97e7-ef22b673d5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-eba5ad6b-bfdd-452d-b15d-4ef1d74bb40d,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-d98ad611-8190-49cf-8a52-1accdbe27276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537232705-172.17.0.7-1595307940590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-8ea8125c-b41c-43b7-950e-aa9c47dca1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-609d93fa-a9d1-4600-a9fc-cb77a82fa341,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-38bd0ed4-30c0-4222-9eb2-f79fe10f0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-504e3d1c-4b28-4088-a3f9-f5cb8af0ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-e82bd903-f4fe-4751-b9b5-a23ebf1ddd09,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-92063ff6-3fca-43cd-b849-529de613b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-709a0fbb-d918-4470-99c4-c623254dd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-ed5f53f2-d341-4235-a906-42b2b4656682,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537232705-172.17.0.7-1595307940590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-8ea8125c-b41c-43b7-950e-aa9c47dca1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-609d93fa-a9d1-4600-a9fc-cb77a82fa341,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-38bd0ed4-30c0-4222-9eb2-f79fe10f0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-504e3d1c-4b28-4088-a3f9-f5cb8af0ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-e82bd903-f4fe-4751-b9b5-a23ebf1ddd09,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-92063ff6-3fca-43cd-b849-529de613b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-709a0fbb-d918-4470-99c4-c623254dd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-ed5f53f2-d341-4235-a906-42b2b4656682,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532401638-172.17.0.7-1595308296860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-5b6c40a3-09d8-48d0-a0b3-7436fe3e4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-c8e2cce2-c5c2-4c13-a2e8-74dc7bd39df3,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-b8479dbe-53f7-4cc2-8109-fa4cd70b5b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-cf1b14d6-98da-4535-827e-c4823fc9b0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-042dc19c-1606-4336-98cb-79ffcf77522c,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-65026682-f786-4c07-a014-0549274771f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-92a7801e-58c5-4ec8-abc4-db74473b3723,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-b7c002cb-1e57-4618-9fe6-6b4488798e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532401638-172.17.0.7-1595308296860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-5b6c40a3-09d8-48d0-a0b3-7436fe3e4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-c8e2cce2-c5c2-4c13-a2e8-74dc7bd39df3,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-b8479dbe-53f7-4cc2-8109-fa4cd70b5b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-cf1b14d6-98da-4535-827e-c4823fc9b0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-042dc19c-1606-4336-98cb-79ffcf77522c,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-65026682-f786-4c07-a014-0549274771f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-92a7801e-58c5-4ec8-abc4-db74473b3723,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-b7c002cb-1e57-4618-9fe6-6b4488798e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801635498-172.17.0.7-1595308557513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44068,DS-436d0b31-8c65-4981-9ea6-af6d793a52aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-2b9354be-ce9b-4e98-8ff6-89da48212646,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-33c6a752-4fc7-4fd4-b383-17f8165217a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-e3d15ca4-1288-469c-b001-b79c1c75b863,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-5545a04f-78c2-457d-916b-29af9439913c,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-69941fde-5642-45b2-9eae-a418c4a27c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-944cd850-cb2b-4360-a4f7-8dcd26ed1401,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-f9e48d4e-38a0-4751-8229-a1a73e07e5e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801635498-172.17.0.7-1595308557513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44068,DS-436d0b31-8c65-4981-9ea6-af6d793a52aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-2b9354be-ce9b-4e98-8ff6-89da48212646,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-33c6a752-4fc7-4fd4-b383-17f8165217a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-e3d15ca4-1288-469c-b001-b79c1c75b863,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-5545a04f-78c2-457d-916b-29af9439913c,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-69941fde-5642-45b2-9eae-a418c4a27c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-944cd850-cb2b-4360-a4f7-8dcd26ed1401,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-f9e48d4e-38a0-4751-8229-a1a73e07e5e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971370848-172.17.0.7-1595308717910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-5a8948cc-1376-494e-8c80-dcf12adbc95a,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-02ccb4b8-24b8-4400-a67f-cf23b3bf735f,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-ef0ab535-679f-44cd-95ac-858d186bafe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-c86cfc44-a0a3-4e42-8c26-27ff7a128371,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-cd3e719b-8d53-4f3b-91a2-55755151b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-19613992-ae79-4020-9e52-b6952a38c0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-c71d5523-b5e6-4459-8089-9d6a90cb730e,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-20bc3265-98af-4698-855a-87104cca55b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971370848-172.17.0.7-1595308717910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-5a8948cc-1376-494e-8c80-dcf12adbc95a,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-02ccb4b8-24b8-4400-a67f-cf23b3bf735f,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-ef0ab535-679f-44cd-95ac-858d186bafe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-c86cfc44-a0a3-4e42-8c26-27ff7a128371,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-cd3e719b-8d53-4f3b-91a2-55755151b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-19613992-ae79-4020-9e52-b6952a38c0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-c71d5523-b5e6-4459-8089-9d6a90cb730e,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-20bc3265-98af-4698-855a-87104cca55b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100455924-172.17.0.7-1595308866694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-1c654b8c-77a0-4357-a01b-ed08b42fd213,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-71c334df-cf62-4f77-854d-2a220f487431,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-bc4e12f9-9ee4-4ddc-b0ff-4417af4ab6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-45775e53-54f6-4d70-9c07-dacb7071e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-90025fd3-760d-485e-bb39-a0d187cced09,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-d85fbba1-64f3-4b2c-8342-c929d8745949,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-ae8a6a1c-96e9-42b9-941c-b9e2694df9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a7cbe664-4627-4868-a287-3ee665a4e9ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100455924-172.17.0.7-1595308866694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-1c654b8c-77a0-4357-a01b-ed08b42fd213,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-71c334df-cf62-4f77-854d-2a220f487431,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-bc4e12f9-9ee4-4ddc-b0ff-4417af4ab6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-45775e53-54f6-4d70-9c07-dacb7071e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-90025fd3-760d-485e-bb39-a0d187cced09,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-d85fbba1-64f3-4b2c-8342-c929d8745949,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-ae8a6a1c-96e9-42b9-941c-b9e2694df9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a7cbe664-4627-4868-a287-3ee665a4e9ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392642683-172.17.0.7-1595309017015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34741,DS-05b0e498-e596-46cd-8217-33b08b7250fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-4b4f5411-40ec-4383-9142-186d71a1a80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-5eb48ec5-6ee7-46b9-b432-671fe6bddb77,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7a068535-d282-46c0-b0b4-dce770fdb1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6f156aa3-aedd-46c8-94d3-7e0f37556a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-ab5282d3-5e5f-4055-a836-b4f9fbca5838,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-f7d9a03b-a775-4a67-879d-6569bcba3084,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-fc0c55f0-8191-43ab-b316-240f87d256ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392642683-172.17.0.7-1595309017015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34741,DS-05b0e498-e596-46cd-8217-33b08b7250fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-4b4f5411-40ec-4383-9142-186d71a1a80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-5eb48ec5-6ee7-46b9-b432-671fe6bddb77,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7a068535-d282-46c0-b0b4-dce770fdb1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6f156aa3-aedd-46c8-94d3-7e0f37556a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-ab5282d3-5e5f-4055-a836-b4f9fbca5838,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-f7d9a03b-a775-4a67-879d-6569bcba3084,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-fc0c55f0-8191-43ab-b316-240f87d256ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401694519-172.17.0.7-1595309206220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-4a82d8a2-17a5-4680-89d5-b79f2196ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-2f64e79b-7426-4589-af83-527bce16c572,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-1a4b7d0d-d7f6-4642-9e9f-1e318296bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-a73546ce-ad13-45f6-a823-fbb91eed9c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-2fa60b09-7feb-4779-bfb8-d823c37c0b70,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-06c86c51-fef1-4400-b3b7-75cd82281512,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-80c68b2f-ce1f-468d-a08d-3c81b1f70bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-b4cf423d-8cdd-4868-a960-aa0a12e0bf95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401694519-172.17.0.7-1595309206220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-4a82d8a2-17a5-4680-89d5-b79f2196ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-2f64e79b-7426-4589-af83-527bce16c572,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-1a4b7d0d-d7f6-4642-9e9f-1e318296bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-a73546ce-ad13-45f6-a823-fbb91eed9c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-2fa60b09-7feb-4779-bfb8-d823c37c0b70,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-06c86c51-fef1-4400-b3b7-75cd82281512,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-80c68b2f-ce1f-468d-a08d-3c81b1f70bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-b4cf423d-8cdd-4868-a960-aa0a12e0bf95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813448047-172.17.0.7-1595309243200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-c18b1fee-dfdc-475b-97c0-893749342fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-03c9ce0f-b4f7-4279-b718-c08d4cb4b926,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-1db62bdc-6178-460b-a720-a713483ad961,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-dc621e6e-cbcd-4eca-a301-49cda1748ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-8329487b-d0b6-46eb-a796-f4c0494b7840,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-6e9cbb23-92b6-4820-8e73-a1fdbbf369cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-456f756b-117f-4126-af9c-cefe825af3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-79d471bb-dcc5-4de2-b935-f41b8c98213b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813448047-172.17.0.7-1595309243200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-c18b1fee-dfdc-475b-97c0-893749342fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-03c9ce0f-b4f7-4279-b718-c08d4cb4b926,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-1db62bdc-6178-460b-a720-a713483ad961,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-dc621e6e-cbcd-4eca-a301-49cda1748ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-8329487b-d0b6-46eb-a796-f4c0494b7840,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-6e9cbb23-92b6-4820-8e73-a1fdbbf369cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-456f756b-117f-4126-af9c-cefe825af3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-79d471bb-dcc5-4de2-b935-f41b8c98213b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473398225-172.17.0.7-1595309591628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-8b7483e8-a160-468f-acce-778f52f0c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-3dce0e8f-62ca-4971-9369-5116a51b4e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-5a722a23-3aa1-4951-82f9-9908cd4cb1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-6b3e743c-f1fd-487c-922c-02fba00306de,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-f5feae13-7f85-4093-81b8-e25730cc0f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-2a7515c5-8862-427f-b0dd-dfcc612438c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-f4175390-62cd-40b0-a503-fa1534a31545,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-b0226619-8bf9-4ad0-8865-8f12af7fe2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473398225-172.17.0.7-1595309591628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-8b7483e8-a160-468f-acce-778f52f0c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-3dce0e8f-62ca-4971-9369-5116a51b4e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-5a722a23-3aa1-4951-82f9-9908cd4cb1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-6b3e743c-f1fd-487c-922c-02fba00306de,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-f5feae13-7f85-4093-81b8-e25730cc0f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-2a7515c5-8862-427f-b0dd-dfcc612438c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-f4175390-62cd-40b0-a503-fa1534a31545,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-b0226619-8bf9-4ad0-8865-8f12af7fe2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693145452-172.17.0.7-1595309703313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-d6016e80-50f9-4528-bad1-8585967303e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-472e17ca-f5e5-46a5-8060-b09574d4de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-0d9a8e29-908c-46fa-8c31-7d818af801f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-df5351ac-064f-4edc-9df3-95d11bd07eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-6fbce11b-8cbd-44cc-8566-7d0aaa518bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-63d055a0-01f6-4a81-81f0-760e236eddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-96fdf8b4-c59c-4775-a5a1-f2ebcacba866,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-40a92c95-3d77-48f0-a435-c4ff2c394313,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693145452-172.17.0.7-1595309703313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-d6016e80-50f9-4528-bad1-8585967303e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-472e17ca-f5e5-46a5-8060-b09574d4de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-0d9a8e29-908c-46fa-8c31-7d818af801f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-df5351ac-064f-4edc-9df3-95d11bd07eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-6fbce11b-8cbd-44cc-8566-7d0aaa518bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-63d055a0-01f6-4a81-81f0-760e236eddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-96fdf8b4-c59c-4775-a5a1-f2ebcacba866,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-40a92c95-3d77-48f0-a435-c4ff2c394313,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477267518-172.17.0.7-1595309774141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45493,DS-9b4cdc9d-259c-4f6b-9169-da2bbf46c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-51153bb1-e686-4877-9ed8-f858ea215417,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-cc6e2646-a5c6-4ec2-abd3-b0ae749f0128,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-270826a7-7395-4a5d-84cc-a9bd64269835,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-8e3af390-7df6-49e2-ad28-6100c261e160,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-72a99976-d40d-4a87-8f1b-34a869b7f655,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-14fcb61e-8f79-490a-8d9f-19a9e16a1374,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-f9adb70c-d8f7-4c45-a385-af0b47de85d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477267518-172.17.0.7-1595309774141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45493,DS-9b4cdc9d-259c-4f6b-9169-da2bbf46c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-51153bb1-e686-4877-9ed8-f858ea215417,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-cc6e2646-a5c6-4ec2-abd3-b0ae749f0128,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-270826a7-7395-4a5d-84cc-a9bd64269835,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-8e3af390-7df6-49e2-ad28-6100c261e160,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-72a99976-d40d-4a87-8f1b-34a869b7f655,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-14fcb61e-8f79-490a-8d9f-19a9e16a1374,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-f9adb70c-d8f7-4c45-a385-af0b47de85d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5417
