reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779291215-172.17.0.13-1595350525555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36790,DS-ad2c702e-e650-441d-a99f-004b1255bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-a7aaca01-5b6d-4431-9aa4-81beb387e4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-0704bf82-1184-4c59-94a7-0299a809a737,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-6b2df197-124a-44e0-b481-abafee83304d,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-e53ff868-26ea-4363-b20a-3f150faab285,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c8fef941-fd4a-4d5c-98a0-d9841160e947,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e42675ae-d894-45da-8bf2-3f98837b1275,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-d11068b1-3d15-43c5-b7b3-0cd95b03513e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779291215-172.17.0.13-1595350525555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36790,DS-ad2c702e-e650-441d-a99f-004b1255bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-a7aaca01-5b6d-4431-9aa4-81beb387e4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-0704bf82-1184-4c59-94a7-0299a809a737,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-6b2df197-124a-44e0-b481-abafee83304d,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-e53ff868-26ea-4363-b20a-3f150faab285,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c8fef941-fd4a-4d5c-98a0-d9841160e947,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e42675ae-d894-45da-8bf2-3f98837b1275,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-d11068b1-3d15-43c5-b7b3-0cd95b03513e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619566044-172.17.0.13-1595350799591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41636,DS-a3f1bec4-2397-4381-8425-88bc5aef813a,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-1f74feb9-c222-4eef-98bd-66981a1fa4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d788b6d1-c369-407e-93da-e9b7533c8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-0398131d-33ba-4549-9c79-d9407a07753c,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-6bc05ebd-0036-4260-a35b-8ecdc578245d,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-de0d5cdf-59da-4282-aa98-5d7d7e9c4ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-62592458-ef82-4a46-a177-1b73f9db2290,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-efa40079-4a7d-4d8f-b904-b2c1822ffde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619566044-172.17.0.13-1595350799591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41636,DS-a3f1bec4-2397-4381-8425-88bc5aef813a,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-1f74feb9-c222-4eef-98bd-66981a1fa4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d788b6d1-c369-407e-93da-e9b7533c8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-0398131d-33ba-4549-9c79-d9407a07753c,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-6bc05ebd-0036-4260-a35b-8ecdc578245d,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-de0d5cdf-59da-4282-aa98-5d7d7e9c4ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-62592458-ef82-4a46-a177-1b73f9db2290,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-efa40079-4a7d-4d8f-b904-b2c1822ffde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090494134-172.17.0.13-1595351241921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-1d1b32e9-eedb-402f-b399-ccc138b51472,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-3c26a19b-9627-42de-8efc-07402f2792ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-c8c80c2e-8d00-4fe3-ad9e-52d3cf7b95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-ebef2ffa-a391-43cb-a5e4-6138a8eab889,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-ccb6b427-3108-46f4-ab36-bcbb9b37ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-69cfacf3-9581-4c38-b9b3-7eeab9231ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-07e14b6e-3113-43da-afb6-5bf181d25b24,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-645c11fe-953b-4919-b079-0cdb06b51d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090494134-172.17.0.13-1595351241921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-1d1b32e9-eedb-402f-b399-ccc138b51472,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-3c26a19b-9627-42de-8efc-07402f2792ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-c8c80c2e-8d00-4fe3-ad9e-52d3cf7b95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-ebef2ffa-a391-43cb-a5e4-6138a8eab889,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-ccb6b427-3108-46f4-ab36-bcbb9b37ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-69cfacf3-9581-4c38-b9b3-7eeab9231ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-07e14b6e-3113-43da-afb6-5bf181d25b24,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-645c11fe-953b-4919-b079-0cdb06b51d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689465586-172.17.0.13-1595351308640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-2dcf6533-f6ee-4902-b2f9-70816d87aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-140ef5f3-6ca9-4fa9-b542-3b232772be29,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-422d3b1e-c862-4f40-8809-f33c7178431d,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-8a3e242b-fbd1-49a0-b28c-68dc751f1098,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-d0399870-613f-461f-825b-19d35a36db0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e6ee94ec-169d-4552-a7d4-37758d9e323c,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-562d59da-1369-499a-9f43-669a852b6809,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-f9add2e2-68aa-4b7d-a1f3-3df868478973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689465586-172.17.0.13-1595351308640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-2dcf6533-f6ee-4902-b2f9-70816d87aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-140ef5f3-6ca9-4fa9-b542-3b232772be29,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-422d3b1e-c862-4f40-8809-f33c7178431d,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-8a3e242b-fbd1-49a0-b28c-68dc751f1098,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-d0399870-613f-461f-825b-19d35a36db0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e6ee94ec-169d-4552-a7d4-37758d9e323c,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-562d59da-1369-499a-9f43-669a852b6809,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-f9add2e2-68aa-4b7d-a1f3-3df868478973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096899803-172.17.0.13-1595351442521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-d4fd3d60-3e4c-4e87-b411-0ac15bd86eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-fec83fd4-45f8-4434-961e-16d2e5d10f82,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-84f48073-15ff-45df-9a5b-a6a379f1699b,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-9549be5a-6834-4b4b-9137-9dddb07f8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-5c26adae-4e43-4ce2-8f73-d45ddb6cf8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-a92e6cf5-063a-4dfb-8146-924d1f8e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-3bcb9fbb-1e48-46cf-b031-617d6f2807f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-35ec54b0-7f7f-42ae-b731-08323c42a720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096899803-172.17.0.13-1595351442521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-d4fd3d60-3e4c-4e87-b411-0ac15bd86eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-fec83fd4-45f8-4434-961e-16d2e5d10f82,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-84f48073-15ff-45df-9a5b-a6a379f1699b,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-9549be5a-6834-4b4b-9137-9dddb07f8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-5c26adae-4e43-4ce2-8f73-d45ddb6cf8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-a92e6cf5-063a-4dfb-8146-924d1f8e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-3bcb9fbb-1e48-46cf-b031-617d6f2807f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-35ec54b0-7f7f-42ae-b731-08323c42a720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038914223-172.17.0.13-1595351500145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-111077bb-ef09-439b-bd60-6d704180dec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-e49e730b-7af2-461e-b8b2-5aebfe546ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-9dcfc30c-a46b-402f-bba7-3c19c42b8c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-56e9ab7a-3b4e-49f2-8d96-339ec273bf81,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-00bdfed9-f16d-4a46-b12e-57065b55e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-5c31ec19-90c2-405e-b67c-0aa31023a722,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-b937a1b9-8a6b-4430-944b-0bfd095b5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-bb4db7b8-2815-4c4d-a59a-fddecbe83e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038914223-172.17.0.13-1595351500145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-111077bb-ef09-439b-bd60-6d704180dec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-e49e730b-7af2-461e-b8b2-5aebfe546ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-9dcfc30c-a46b-402f-bba7-3c19c42b8c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-56e9ab7a-3b4e-49f2-8d96-339ec273bf81,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-00bdfed9-f16d-4a46-b12e-57065b55e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-5c31ec19-90c2-405e-b67c-0aa31023a722,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-b937a1b9-8a6b-4430-944b-0bfd095b5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-bb4db7b8-2815-4c4d-a59a-fddecbe83e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715881539-172.17.0.13-1595351784157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-7bf59060-1086-45cf-8c09-5d92bfd21db6,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-ae2678d6-f5da-4988-b5c9-0b73330a7bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-b9460ffb-1c8d-4352-901f-6352e65289a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-f7d3de74-471b-45b9-b1e2-b7d271684ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-6ed303e8-ff40-468f-8cec-716836386746,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-a0dfaeda-bb81-4f38-b5a9-738a77a31012,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-b1b0bb5b-d400-45dc-9fab-00b3048f660d,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-dcb9d365-ce48-4766-9382-db77dfbaf0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715881539-172.17.0.13-1595351784157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-7bf59060-1086-45cf-8c09-5d92bfd21db6,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-ae2678d6-f5da-4988-b5c9-0b73330a7bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-b9460ffb-1c8d-4352-901f-6352e65289a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-f7d3de74-471b-45b9-b1e2-b7d271684ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-6ed303e8-ff40-468f-8cec-716836386746,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-a0dfaeda-bb81-4f38-b5a9-738a77a31012,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-b1b0bb5b-d400-45dc-9fab-00b3048f660d,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-dcb9d365-ce48-4766-9382-db77dfbaf0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166612661-172.17.0.13-1595352072058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-11f567dc-daaa-4a9c-96a1-0c651a347c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-e05ba830-f2bc-4530-8e53-7f4132bff061,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-8eca5d80-55e8-487c-b03b-5a1878f579d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a95b0418-d315-452d-8fe3-4c624c821c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-9ecf203a-4625-4524-a242-a908506df95e,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-c7cf2031-0011-49c1-9341-a46db83cccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-33721554-9cd0-4787-83f4-44df886f285f,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-b25234b3-2210-45c7-b51e-ebe63737d465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166612661-172.17.0.13-1595352072058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-11f567dc-daaa-4a9c-96a1-0c651a347c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-e05ba830-f2bc-4530-8e53-7f4132bff061,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-8eca5d80-55e8-487c-b03b-5a1878f579d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a95b0418-d315-452d-8fe3-4c624c821c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-9ecf203a-4625-4524-a242-a908506df95e,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-c7cf2031-0011-49c1-9341-a46db83cccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-33721554-9cd0-4787-83f4-44df886f285f,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-b25234b3-2210-45c7-b51e-ebe63737d465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462273811-172.17.0.13-1595352243838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36891,DS-7b2faf47-5474-459f-8cdf-9717abcbbe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-0b866f4f-cc39-43f2-b99f-f66b8bac59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-2c6dd56d-690a-45aa-a8dd-17dc7d76d789,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-f49b6e95-db92-4740-90ba-7a9e13d6b372,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-67c9aad9-f5f4-46e0-babf-5a4db210a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-79379a6d-c9bb-4bcd-8a9d-e49d0ff23995,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-74110c0b-5e4d-4d90-8a04-cf117f9a25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-684e85e4-8d2e-4249-9b3c-5b0ba06b79c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462273811-172.17.0.13-1595352243838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36891,DS-7b2faf47-5474-459f-8cdf-9717abcbbe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-0b866f4f-cc39-43f2-b99f-f66b8bac59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-2c6dd56d-690a-45aa-a8dd-17dc7d76d789,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-f49b6e95-db92-4740-90ba-7a9e13d6b372,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-67c9aad9-f5f4-46e0-babf-5a4db210a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-79379a6d-c9bb-4bcd-8a9d-e49d0ff23995,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-74110c0b-5e4d-4d90-8a04-cf117f9a25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-684e85e4-8d2e-4249-9b3c-5b0ba06b79c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260803791-172.17.0.13-1595352979484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44331,DS-a167285c-5d9e-41ac-8770-bb48dd381ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-4d740521-0548-4587-9106-33136c4f5d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-a2008878-8dd5-4fe6-adec-a5ad61c57b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-ad555c84-d75c-450b-8397-2eac55b00a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-25272841-a200-4bc1-beae-40149a0a84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-88693995-c17c-428e-9f7e-248a5ea3290f,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-26b51535-4af8-4891-86b5-64ae26b5b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-09fb5dfe-4503-4965-8f91-05ad2d1ece6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260803791-172.17.0.13-1595352979484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44331,DS-a167285c-5d9e-41ac-8770-bb48dd381ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-4d740521-0548-4587-9106-33136c4f5d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-a2008878-8dd5-4fe6-adec-a5ad61c57b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-ad555c84-d75c-450b-8397-2eac55b00a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-25272841-a200-4bc1-beae-40149a0a84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-88693995-c17c-428e-9f7e-248a5ea3290f,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-26b51535-4af8-4891-86b5-64ae26b5b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-09fb5dfe-4503-4965-8f91-05ad2d1ece6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412366221-172.17.0.13-1595353183943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44001,DS-88b79898-cd85-47d1-8f2d-fc149d60f801,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-e7c076ea-1308-4854-9c97-8ea2e78ed861,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-504968ce-ee2e-44b4-8f46-8db62a2dbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-87fc680d-4faf-4613-a0a8-df381e1a0a81,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-f4e02b90-a7e2-4d53-8f25-df1546cf47ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-53434412-761b-4661-bf7e-fd3231c0a760,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-6c95ea31-b25d-4edc-bfc8-a36e56a7b563,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-fab64843-e9cf-4668-a2f2-3407fb2382a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412366221-172.17.0.13-1595353183943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44001,DS-88b79898-cd85-47d1-8f2d-fc149d60f801,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-e7c076ea-1308-4854-9c97-8ea2e78ed861,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-504968ce-ee2e-44b4-8f46-8db62a2dbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-87fc680d-4faf-4613-a0a8-df381e1a0a81,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-f4e02b90-a7e2-4d53-8f25-df1546cf47ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-53434412-761b-4661-bf7e-fd3231c0a760,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-6c95ea31-b25d-4edc-bfc8-a36e56a7b563,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-fab64843-e9cf-4668-a2f2-3407fb2382a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465479805-172.17.0.13-1595353555850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37849,DS-1250a8ba-1750-4ae1-b9f1-e4cd523f72ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-aa9bdf30-76f8-4d74-8aef-bd0a90e54373,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-8078f7eb-2fdd-41c7-a00c-d4afcdd82494,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-2fd99908-bb47-4c18-94ea-9d2a3a9abdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-af20952f-0e1c-4f5c-bbd0-c428ea8f9bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-66415fc9-9a13-49d8-bf29-fc258cd7f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-acc56344-b7e5-4537-ab8c-943d9bb92e98,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-42a4df3c-ccf8-4d40-b537-90fb4cda985b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465479805-172.17.0.13-1595353555850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37849,DS-1250a8ba-1750-4ae1-b9f1-e4cd523f72ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-aa9bdf30-76f8-4d74-8aef-bd0a90e54373,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-8078f7eb-2fdd-41c7-a00c-d4afcdd82494,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-2fd99908-bb47-4c18-94ea-9d2a3a9abdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-af20952f-0e1c-4f5c-bbd0-c428ea8f9bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-66415fc9-9a13-49d8-bf29-fc258cd7f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-acc56344-b7e5-4537-ab8c-943d9bb92e98,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-42a4df3c-ccf8-4d40-b537-90fb4cda985b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426894956-172.17.0.13-1595354274825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44102,DS-939052cf-6a52-465d-b8d5-7b6d4fd3a5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-2244654f-4e74-4ef3-983c-b905a2d93f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-39b6ac67-eaab-4d17-9fc2-bb82f43f9f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-adc9dfbe-393e-4452-ab62-ff44f6ec53af,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c946728f-e169-4646-94dd-d13e5abd6537,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-d6cb01bb-d226-4cc8-a663-f21c637873dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-9b33a7b7-e2a9-40ee-9995-879faf243a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-affea848-90f0-489b-9a0a-fa7a82e55b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426894956-172.17.0.13-1595354274825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44102,DS-939052cf-6a52-465d-b8d5-7b6d4fd3a5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-2244654f-4e74-4ef3-983c-b905a2d93f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-39b6ac67-eaab-4d17-9fc2-bb82f43f9f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-adc9dfbe-393e-4452-ab62-ff44f6ec53af,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c946728f-e169-4646-94dd-d13e5abd6537,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-d6cb01bb-d226-4cc8-a663-f21c637873dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-9b33a7b7-e2a9-40ee-9995-879faf243a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-affea848-90f0-489b-9a0a-fa7a82e55b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445582511-172.17.0.13-1595354380529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39936,DS-ec7e1613-b0ba-4a32-a23e-5aff9021bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-34142c8a-fb96-4b75-bba9-043bb090684a,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-1cb62667-f332-44f0-87a3-5559696df1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9ba094d0-ce5b-43ee-ad90-7316e66597f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-eb519da8-5d59-4412-94c6-366f58d5c751,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-0b4472d7-cc88-48e6-ad75-8c26ac058e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-ab107506-d7ad-4bbb-a263-227d97a15a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d8501ea8-be27-44d8-b59b-fc2a25355a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445582511-172.17.0.13-1595354380529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39936,DS-ec7e1613-b0ba-4a32-a23e-5aff9021bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-34142c8a-fb96-4b75-bba9-043bb090684a,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-1cb62667-f332-44f0-87a3-5559696df1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9ba094d0-ce5b-43ee-ad90-7316e66597f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-eb519da8-5d59-4412-94c6-366f58d5c751,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-0b4472d7-cc88-48e6-ad75-8c26ac058e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-ab107506-d7ad-4bbb-a263-227d97a15a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d8501ea8-be27-44d8-b59b-fc2a25355a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212136524-172.17.0.13-1595354624015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43393,DS-1acb010d-3a47-4893-a0b5-44c34793151c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-0573d687-4caa-4737-9a05-43f1e5b2a0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-ae55e354-b734-48db-bd6a-1b46711260bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-9fc36ee7-8c56-4999-b2c8-6356e3888fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-ab4b4f31-4924-4f42-aeee-c44005cd05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-aed6dea3-0316-4a63-893c-b9a73ca0ecfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-57610262-e95b-43b7-9663-437c7739dee5,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-3f7b1d3f-2781-4cd9-a279-65bf3d61eae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212136524-172.17.0.13-1595354624015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43393,DS-1acb010d-3a47-4893-a0b5-44c34793151c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-0573d687-4caa-4737-9a05-43f1e5b2a0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-ae55e354-b734-48db-bd6a-1b46711260bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-9fc36ee7-8c56-4999-b2c8-6356e3888fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-ab4b4f31-4924-4f42-aeee-c44005cd05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-aed6dea3-0316-4a63-893c-b9a73ca0ecfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-57610262-e95b-43b7-9663-437c7739dee5,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-3f7b1d3f-2781-4cd9-a279-65bf3d61eae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140684597-172.17.0.13-1595354978165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-45f65d0b-ab07-47fe-a123-3454d2d72913,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-fd43483d-9d0f-44b1-8a83-525e696a1f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-4219a4d2-02d9-484a-9648-a00ffbe21c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-ef3a880a-1553-48eb-ac8b-e9b334258385,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-fad8d497-0c70-4dba-aad0-c62cfb45ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-1ccb9411-a8ed-4f29-a8b4-750942f2be2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-8a7456a4-ac40-4096-af97-54625b3ae839,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-c70632e4-1c16-470d-bdd6-5b8cca441a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140684597-172.17.0.13-1595354978165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-45f65d0b-ab07-47fe-a123-3454d2d72913,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-fd43483d-9d0f-44b1-8a83-525e696a1f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-4219a4d2-02d9-484a-9648-a00ffbe21c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-ef3a880a-1553-48eb-ac8b-e9b334258385,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-fad8d497-0c70-4dba-aad0-c62cfb45ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-1ccb9411-a8ed-4f29-a8b4-750942f2be2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-8a7456a4-ac40-4096-af97-54625b3ae839,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-c70632e4-1c16-470d-bdd6-5b8cca441a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5061
