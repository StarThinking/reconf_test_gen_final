reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832356915-172.17.0.12-1595377899505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-1c33c73d-d07c-4259-8816-a113fa98f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-7d8131af-0520-407f-9565-03774d19d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-bf08444d-b05f-4707-9815-55cb57814787,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-6527aa07-a19e-4a43-8185-8952e4a68e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-b694e8fd-aa75-4627-8979-b67a251989e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-479dc892-d498-4ede-9b78-3a7dab23157a,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-86523737-0c96-4072-b42c-f3f731c4614d,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-3ecf3bdc-e50c-4e1c-8350-64ca220fa404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832356915-172.17.0.12-1595377899505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-1c33c73d-d07c-4259-8816-a113fa98f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-7d8131af-0520-407f-9565-03774d19d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-bf08444d-b05f-4707-9815-55cb57814787,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-6527aa07-a19e-4a43-8185-8952e4a68e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-b694e8fd-aa75-4627-8979-b67a251989e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-479dc892-d498-4ede-9b78-3a7dab23157a,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-86523737-0c96-4072-b42c-f3f731c4614d,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-3ecf3bdc-e50c-4e1c-8350-64ca220fa404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726145722-172.17.0.12-1595377963961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-d9239e24-5f07-4768-be33-7f23060ee0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-c9aa6898-e7aa-4ed5-b44d-5d31593b625b,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-10d78bec-4e33-414e-b73c-a84784c89961,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-6d83ddde-5784-45bd-b79b-f275017779a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-41818cb4-3cb8-41ee-9041-b41b467ea8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-a69ed92a-dc6e-4117-8bd2-1c01353c9fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-e1ec4830-c5db-4b9e-a985-2ec8d80ad8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-45dd4084-a358-4a50-a74e-ba23828b7a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726145722-172.17.0.12-1595377963961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-d9239e24-5f07-4768-be33-7f23060ee0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-c9aa6898-e7aa-4ed5-b44d-5d31593b625b,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-10d78bec-4e33-414e-b73c-a84784c89961,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-6d83ddde-5784-45bd-b79b-f275017779a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-41818cb4-3cb8-41ee-9041-b41b467ea8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-a69ed92a-dc6e-4117-8bd2-1c01353c9fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-e1ec4830-c5db-4b9e-a985-2ec8d80ad8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-45dd4084-a358-4a50-a74e-ba23828b7a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720988131-172.17.0.12-1595378350113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41763,DS-6d311141-0d63-486e-8be6-f4f19c261a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-090b9ba9-cb83-4619-ba2e-4458901ef8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-d8a5e672-0a9b-43bc-9300-19e2a0101d00,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-b6c75b8e-594f-4eca-bae6-ca7621d60d41,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-e2093f05-ad6f-440b-a309-374f29bc3f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-3f60765e-8936-4339-b23b-a3f11772216b,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-f0e9f338-2c9b-49f0-ad92-31479e44733e,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-2116ee41-994a-48ef-9110-fc88d0ffa717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720988131-172.17.0.12-1595378350113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41763,DS-6d311141-0d63-486e-8be6-f4f19c261a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-090b9ba9-cb83-4619-ba2e-4458901ef8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-d8a5e672-0a9b-43bc-9300-19e2a0101d00,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-b6c75b8e-594f-4eca-bae6-ca7621d60d41,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-e2093f05-ad6f-440b-a309-374f29bc3f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-3f60765e-8936-4339-b23b-a3f11772216b,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-f0e9f338-2c9b-49f0-ad92-31479e44733e,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-2116ee41-994a-48ef-9110-fc88d0ffa717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116243089-172.17.0.12-1595378542783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-a5c2617c-1ba6-4c76-9669-19ab6af85b16,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-3be1c559-d96c-42f5-96ab-97f82e516233,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-caa66504-0449-4a20-bf71-7db21832b9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-daf5788c-d5a4-4af9-b4f7-607cc4aaa839,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-cb5d6668-303c-4d6e-9ace-8631dc9fba77,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-5d656bea-12cc-4801-8738-9eb016542967,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-e4425d7c-b498-4c3e-bf02-6b37cae9f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-e066c7fa-b917-49b5-a1b4-dbe018aff1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116243089-172.17.0.12-1595378542783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-a5c2617c-1ba6-4c76-9669-19ab6af85b16,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-3be1c559-d96c-42f5-96ab-97f82e516233,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-caa66504-0449-4a20-bf71-7db21832b9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-daf5788c-d5a4-4af9-b4f7-607cc4aaa839,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-cb5d6668-303c-4d6e-9ace-8631dc9fba77,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-5d656bea-12cc-4801-8738-9eb016542967,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-e4425d7c-b498-4c3e-bf02-6b37cae9f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-e066c7fa-b917-49b5-a1b4-dbe018aff1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667490310-172.17.0.12-1595378800193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-9eaa4033-6e1d-4454-847f-81b1e7a2cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-eae9891d-f5a8-4b3f-bdd6-ee5eff151ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-55c0df07-eeae-48f0-bfbf-14191fcee09c,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-c6caf83b-b776-43b4-b6e2-230996bf378e,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-4f5f60e8-03f9-4140-9b89-f755c47dd4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-40504834-a68f-470f-97b3-c3c76f3bb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-4a775c90-044a-4dd6-bee5-5d0a79b02454,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-28c7dd09-e603-4b4f-9735-f8843b793067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667490310-172.17.0.12-1595378800193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-9eaa4033-6e1d-4454-847f-81b1e7a2cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-eae9891d-f5a8-4b3f-bdd6-ee5eff151ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-55c0df07-eeae-48f0-bfbf-14191fcee09c,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-c6caf83b-b776-43b4-b6e2-230996bf378e,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-4f5f60e8-03f9-4140-9b89-f755c47dd4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-40504834-a68f-470f-97b3-c3c76f3bb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-4a775c90-044a-4dd6-bee5-5d0a79b02454,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-28c7dd09-e603-4b4f-9735-f8843b793067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019855542-172.17.0.12-1595378833714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-b1e62c80-5754-48be-a3fb-e3d5f590c0df,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-d78e6158-759e-4790-82d3-1bfb01393d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-817afc01-d591-42d9-8985-71227c5284bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-c5e8f132-794e-4771-bbaa-0cf80edbe74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-d761ee7e-4e4e-4a9b-8f8c-6c76bcb6847f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-993d1c97-70eb-494a-a7d5-0df01df1da53,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-aeeb0ac0-dd15-4d8c-b353-0342a2f12e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-115f3560-dcb2-432d-9063-7fc5ddc3416e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019855542-172.17.0.12-1595378833714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-b1e62c80-5754-48be-a3fb-e3d5f590c0df,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-d78e6158-759e-4790-82d3-1bfb01393d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-817afc01-d591-42d9-8985-71227c5284bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-c5e8f132-794e-4771-bbaa-0cf80edbe74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-d761ee7e-4e4e-4a9b-8f8c-6c76bcb6847f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-993d1c97-70eb-494a-a7d5-0df01df1da53,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-aeeb0ac0-dd15-4d8c-b353-0342a2f12e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-115f3560-dcb2-432d-9063-7fc5ddc3416e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622322919-172.17.0.12-1595379004969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-26331351-7646-4045-9293-6247d202a957,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-4d0183a7-47c2-4bfc-8ee4-2b0f1261bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-3b6bc6c8-3b34-4f68-aa7a-00ba2619f65d,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-51be0cf3-f6ed-47c1-a6e1-4b5ae22efab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-db5196b6-552d-46af-b245-b191834a0803,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-136dbd30-f404-461c-aa51-8f775ec9d292,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-18cfddc3-48e9-4fcc-96e8-895622c32539,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-a0fb6fea-5f8e-4781-88c9-5010765f7345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622322919-172.17.0.12-1595379004969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-26331351-7646-4045-9293-6247d202a957,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-4d0183a7-47c2-4bfc-8ee4-2b0f1261bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-3b6bc6c8-3b34-4f68-aa7a-00ba2619f65d,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-51be0cf3-f6ed-47c1-a6e1-4b5ae22efab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-db5196b6-552d-46af-b245-b191834a0803,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-136dbd30-f404-461c-aa51-8f775ec9d292,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-18cfddc3-48e9-4fcc-96e8-895622c32539,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-a0fb6fea-5f8e-4781-88c9-5010765f7345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789179308-172.17.0.12-1595379213070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33314,DS-025bd4e2-ffe9-4559-b6cc-a90e1277ec7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-bb58cd18-4fee-4b92-bbb6-d2a24efd2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-5a283609-2c21-4654-ae98-a0113c73a312,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-8ff15cf7-05e6-45be-8c03-88ebdcbcc195,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-925f6cd6-ad4b-4053-8324-bc0f8db24252,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-fa9a2d6f-f484-4771-8903-6c1a82a1711c,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-f75a3787-52f5-4e7d-b8b9-ad108583b385,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-c7ac9954-acf2-44ef-a883-9aac075ac056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789179308-172.17.0.12-1595379213070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33314,DS-025bd4e2-ffe9-4559-b6cc-a90e1277ec7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-bb58cd18-4fee-4b92-bbb6-d2a24efd2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-5a283609-2c21-4654-ae98-a0113c73a312,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-8ff15cf7-05e6-45be-8c03-88ebdcbcc195,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-925f6cd6-ad4b-4053-8324-bc0f8db24252,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-fa9a2d6f-f484-4771-8903-6c1a82a1711c,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-f75a3787-52f5-4e7d-b8b9-ad108583b385,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-c7ac9954-acf2-44ef-a883-9aac075ac056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358710339-172.17.0.12-1595379780559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45240,DS-2bdd366c-8693-4fb3-a900-5f235c4ecd37,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-84c942a5-2f53-4de3-beec-10f31e2460fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-4f7e1f00-4e63-426b-8728-4c34d056b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c2ec38b1-7f43-4946-be7d-54714d9083fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-2e1ce6bf-c021-4908-8ad9-4a226197dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-e1327510-d281-4528-bf8f-d6e5778e18a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-bc86b169-7b02-4f1d-ab15-fbcc7700652e,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-150a4b1d-1682-4549-9523-fe83fccbcd75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358710339-172.17.0.12-1595379780559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45240,DS-2bdd366c-8693-4fb3-a900-5f235c4ecd37,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-84c942a5-2f53-4de3-beec-10f31e2460fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-4f7e1f00-4e63-426b-8728-4c34d056b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c2ec38b1-7f43-4946-be7d-54714d9083fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-2e1ce6bf-c021-4908-8ad9-4a226197dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-e1327510-d281-4528-bf8f-d6e5778e18a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-bc86b169-7b02-4f1d-ab15-fbcc7700652e,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-150a4b1d-1682-4549-9523-fe83fccbcd75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524642142-172.17.0.12-1595379884313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-1fc76490-da63-4695-a810-58b3de3130cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-68ce42e2-bdf9-4a29-bece-ad3bd2312af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-9f736abc-7ff4-4ec3-97b0-73448be97302,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-a34b7474-6f9c-4a46-b1ec-9f692e449204,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-dbe3ac1e-b0c6-421f-98ea-3b3e38c005ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-614e1e6d-82ce-4365-ba4c-610c92bacc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-3824837e-7749-4c44-a424-c2b95d02ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-d6b55ea7-2414-4a18-8249-98ca208bb601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524642142-172.17.0.12-1595379884313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-1fc76490-da63-4695-a810-58b3de3130cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-68ce42e2-bdf9-4a29-bece-ad3bd2312af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-9f736abc-7ff4-4ec3-97b0-73448be97302,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-a34b7474-6f9c-4a46-b1ec-9f692e449204,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-dbe3ac1e-b0c6-421f-98ea-3b3e38c005ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-614e1e6d-82ce-4365-ba4c-610c92bacc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-3824837e-7749-4c44-a424-c2b95d02ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-d6b55ea7-2414-4a18-8249-98ca208bb601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371948823-172.17.0.12-1595380045168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45640,DS-52326d6c-fbf0-49dc-8227-874cffcf4c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-cd7c224e-4533-4ccc-9dba-e82f08137fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-a9546803-6a22-4b04-9db3-a570d3429a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-0d92ccc3-48e4-4e92-86b3-7b8be66f3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-6934793e-063f-41d5-adb4-1f91e95bd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-0cbfd7c6-606d-4b8e-a2e3-78b5bc37aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-9e937755-a10b-41cb-992c-6f943025f822,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-98a473fb-3c3e-4044-a711-140b20ea326c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371948823-172.17.0.12-1595380045168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45640,DS-52326d6c-fbf0-49dc-8227-874cffcf4c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-cd7c224e-4533-4ccc-9dba-e82f08137fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-a9546803-6a22-4b04-9db3-a570d3429a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-0d92ccc3-48e4-4e92-86b3-7b8be66f3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-6934793e-063f-41d5-adb4-1f91e95bd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-0cbfd7c6-606d-4b8e-a2e3-78b5bc37aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-9e937755-a10b-41cb-992c-6f943025f822,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-98a473fb-3c3e-4044-a711-140b20ea326c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671536955-172.17.0.12-1595380147416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-df8a3aca-02b3-4c3c-a38b-696e5a2d98af,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-7c092ce6-32fb-46a9-96fe-f71c6b0f5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-be5a79f7-765c-45c4-8abf-ef8a09a91584,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-cbd99e21-e91e-4b8c-90be-1ea27ce97c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-314cc23d-9f01-412d-b70c-3d09e6b6d427,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-41362584-623f-45b9-80a4-3869ac72d168,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-793e8a28-f250-43c8-a553-53c6fd0f69bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-be1794ad-d7e0-4999-9900-83a9a9b1a09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671536955-172.17.0.12-1595380147416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-df8a3aca-02b3-4c3c-a38b-696e5a2d98af,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-7c092ce6-32fb-46a9-96fe-f71c6b0f5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-be5a79f7-765c-45c4-8abf-ef8a09a91584,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-cbd99e21-e91e-4b8c-90be-1ea27ce97c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-314cc23d-9f01-412d-b70c-3d09e6b6d427,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-41362584-623f-45b9-80a4-3869ac72d168,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-793e8a28-f250-43c8-a553-53c6fd0f69bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-be1794ad-d7e0-4999-9900-83a9a9b1a09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538823412-172.17.0.12-1595380291942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-13c8c2d9-c9f7-4354-ab29-9f7f15e862ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-485754b1-4af1-45fb-9b78-119046c0dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-352c7f26-c1fe-4a49-b659-518a7d7822e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-4b6aafba-7406-4ed8-ae2e-554f1be2885f,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-9e975b58-e969-4a5d-90f0-2254976a615e,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-7f6eeb01-7e51-4729-8371-a85806fa22fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-fc3907c7-15e6-43d4-bfa8-d00352c5c06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-3ba0e1df-04f1-474c-a83f-9b368cd631fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538823412-172.17.0.12-1595380291942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-13c8c2d9-c9f7-4354-ab29-9f7f15e862ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-485754b1-4af1-45fb-9b78-119046c0dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-352c7f26-c1fe-4a49-b659-518a7d7822e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-4b6aafba-7406-4ed8-ae2e-554f1be2885f,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-9e975b58-e969-4a5d-90f0-2254976a615e,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-7f6eeb01-7e51-4729-8371-a85806fa22fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-fc3907c7-15e6-43d4-bfa8-d00352c5c06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-3ba0e1df-04f1-474c-a83f-9b368cd631fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704316827-172.17.0.12-1595380930291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-bbc965fd-8b57-4daa-b712-f87caa85ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-9deea58f-9e7a-4388-9cb8-c1a431330fed,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-52c17137-f6f8-456e-9791-35944562d964,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-b1cafb88-9c1b-43ba-9e6d-04b982051d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-ed874ed7-6410-454b-b096-9d6c9c3428c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-26c486cf-9a6b-426a-b5ff-66e987d9f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-bda8b4a8-e9c0-42c5-b78b-6258febdf0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-e788d324-4724-4103-81b1-7ab87c19d4ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704316827-172.17.0.12-1595380930291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-bbc965fd-8b57-4daa-b712-f87caa85ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-9deea58f-9e7a-4388-9cb8-c1a431330fed,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-52c17137-f6f8-456e-9791-35944562d964,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-b1cafb88-9c1b-43ba-9e6d-04b982051d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-ed874ed7-6410-454b-b096-9d6c9c3428c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-26c486cf-9a6b-426a-b5ff-66e987d9f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-bda8b4a8-e9c0-42c5-b78b-6258febdf0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-e788d324-4724-4103-81b1-7ab87c19d4ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255726935-172.17.0.12-1595381128177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-8e2e5695-d241-4770-a018-75f6d347348f,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-bf31a7f5-256b-4191-bb69-0a58cf781ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-3934cdb1-2bcb-411b-9945-94b01ecc75bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-5c61ffba-00c2-4171-9f56-c6a799287211,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-cda4e1b6-5dee-449e-b032-66ef65dc7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-d5ab8ff5-14bf-4d65-b22e-84b7c27fe0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-32c1add1-60fa-474f-bbb6-5eb0f1d186d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-08eb0fe6-049f-479e-99fe-695a280adaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255726935-172.17.0.12-1595381128177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-8e2e5695-d241-4770-a018-75f6d347348f,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-bf31a7f5-256b-4191-bb69-0a58cf781ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-3934cdb1-2bcb-411b-9945-94b01ecc75bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-5c61ffba-00c2-4171-9f56-c6a799287211,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-cda4e1b6-5dee-449e-b032-66ef65dc7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-d5ab8ff5-14bf-4d65-b22e-84b7c27fe0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-32c1add1-60fa-474f-bbb6-5eb0f1d186d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-08eb0fe6-049f-479e-99fe-695a280adaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455147445-172.17.0.12-1595382061456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35023,DS-3071517b-9a7f-4b37-9b63-feaa2b2af36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-0c814c60-cdf3-48b6-805d-67bec71fb5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-867c4469-4341-43be-b26a-9d048d3da548,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-a8a2161b-5543-4a2e-a91c-f98a60ef0a85,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-c2440676-c62e-4b88-97ac-32616b4986b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-609869fa-a666-4374-8bfb-aae6f1b7e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-1262c667-6486-4cbe-aca9-665612da581e,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-f1b466b4-a30b-4c6b-8055-f89c84f438c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455147445-172.17.0.12-1595382061456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35023,DS-3071517b-9a7f-4b37-9b63-feaa2b2af36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-0c814c60-cdf3-48b6-805d-67bec71fb5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-867c4469-4341-43be-b26a-9d048d3da548,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-a8a2161b-5543-4a2e-a91c-f98a60ef0a85,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-c2440676-c62e-4b88-97ac-32616b4986b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-609869fa-a666-4374-8bfb-aae6f1b7e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-1262c667-6486-4cbe-aca9-665612da581e,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-f1b466b4-a30b-4c6b-8055-f89c84f438c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384210176-172.17.0.12-1595382431378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-ca5e9837-4f7d-437b-8797-09e096c2efc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-8fb9b2b0-0342-479f-9221-046d77895c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-99db85e8-73c7-48fe-b88f-22fca2c65e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-acb7e8bb-6412-4933-b75b-f783e28848c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-4829e99c-3d60-48b7-b56c-1a8fa228e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-23569abc-70ed-4879-b50f-b1172fcc7885,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-77ec2c96-9525-4de7-aacf-9363dae91c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-47853d9e-c298-4667-a45b-d8027fa64891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384210176-172.17.0.12-1595382431378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-ca5e9837-4f7d-437b-8797-09e096c2efc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-8fb9b2b0-0342-479f-9221-046d77895c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-99db85e8-73c7-48fe-b88f-22fca2c65e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-acb7e8bb-6412-4933-b75b-f783e28848c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-4829e99c-3d60-48b7-b56c-1a8fa228e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-23569abc-70ed-4879-b50f-b1172fcc7885,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-77ec2c96-9525-4de7-aacf-9363dae91c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-47853d9e-c298-4667-a45b-d8027fa64891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029006975-172.17.0.12-1595382463159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-fbf1682f-929a-43db-bde3-a5d5a0a0b184,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-e61287d4-e2a0-488b-8cd5-01503ea44e58,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-89ad0c2f-18e4-4f0a-a6fe-ad2b107ee868,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-6502c40b-0483-4317-9e80-9cd69cae5312,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-c8d6d66a-ef91-4263-ad3a-006ad28b6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-bea2bb18-aa5f-4b34-81d5-eee037046918,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-f7eb97e4-5874-48a1-b625-96cff1ff8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-5debcec2-f4c3-4d85-8269-bf0c90ce3942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029006975-172.17.0.12-1595382463159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-fbf1682f-929a-43db-bde3-a5d5a0a0b184,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-e61287d4-e2a0-488b-8cd5-01503ea44e58,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-89ad0c2f-18e4-4f0a-a6fe-ad2b107ee868,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-6502c40b-0483-4317-9e80-9cd69cae5312,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-c8d6d66a-ef91-4263-ad3a-006ad28b6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-bea2bb18-aa5f-4b34-81d5-eee037046918,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-f7eb97e4-5874-48a1-b625-96cff1ff8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-5debcec2-f4c3-4d85-8269-bf0c90ce3942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424070387-172.17.0.12-1595382707444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-84c53eb1-94e0-419e-a70b-1934febd78d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-0599fca5-0907-443a-94d4-19fe94b87f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-ebddae54-e4ad-44df-9413-801f273a4efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-f4bfe266-6a03-414d-83ee-f299f0a15ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-64003b52-0287-48a2-a1d2-3271d9ae030f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-2ead2d4d-88ed-4a10-bbea-6072c118bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-f53e2a69-9f67-4aa3-8058-dfe696754291,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-b0b57798-4c99-4d22-97a7-949d5d992d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424070387-172.17.0.12-1595382707444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-84c53eb1-94e0-419e-a70b-1934febd78d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-0599fca5-0907-443a-94d4-19fe94b87f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-ebddae54-e4ad-44df-9413-801f273a4efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-f4bfe266-6a03-414d-83ee-f299f0a15ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-64003b52-0287-48a2-a1d2-3271d9ae030f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-2ead2d4d-88ed-4a10-bbea-6072c118bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-f53e2a69-9f67-4aa3-8058-dfe696754291,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-b0b57798-4c99-4d22-97a7-949d5d992d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4940
