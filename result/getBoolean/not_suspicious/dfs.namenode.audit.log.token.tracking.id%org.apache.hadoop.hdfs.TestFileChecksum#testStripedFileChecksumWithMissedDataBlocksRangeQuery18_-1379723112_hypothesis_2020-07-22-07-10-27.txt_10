reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813228130-172.17.0.9-1595402134794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-4b4eecfa-e4db-481d-bcf4-1d8397b3e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-f9aeeeb3-c78f-44d8-9a05-f2ca8a173c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-a8d3a758-e6e6-48ea-8763-80bff3e2a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-7b9e8a87-2d34-4910-8394-dba49abd0b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-e758576a-d7ba-42ee-908d-e39f6ce04147,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-5d82368d-4c22-489e-b25e-c3ce884df5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-eab5ad62-031e-48b4-850d-f17cc405524c,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-ab549c95-f356-424e-8558-98d579756e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813228130-172.17.0.9-1595402134794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-4b4eecfa-e4db-481d-bcf4-1d8397b3e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-f9aeeeb3-c78f-44d8-9a05-f2ca8a173c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-a8d3a758-e6e6-48ea-8763-80bff3e2a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-7b9e8a87-2d34-4910-8394-dba49abd0b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-e758576a-d7ba-42ee-908d-e39f6ce04147,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-5d82368d-4c22-489e-b25e-c3ce884df5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-eab5ad62-031e-48b4-850d-f17cc405524c,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-ab549c95-f356-424e-8558-98d579756e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696028631-172.17.0.9-1595402235638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41017,DS-3190d35c-a197-4da0-8e3c-2e5a7c7bd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-95364985-7d37-4217-976f-bb1cd3f3a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-9971f90a-c2e8-4e31-a22d-490f2e533244,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-ccac8ef8-1d45-4f74-9266-dc93e61ba302,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-50332037-b15d-4b5b-afd2-4a85db8e85e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-bf2b0291-cb67-411e-856a-9efc6fdd6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-7d269138-c8f9-447e-8ae9-66758e83effa,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f153069a-509a-4a65-a9ed-c172ea3f4d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696028631-172.17.0.9-1595402235638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41017,DS-3190d35c-a197-4da0-8e3c-2e5a7c7bd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-95364985-7d37-4217-976f-bb1cd3f3a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-9971f90a-c2e8-4e31-a22d-490f2e533244,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-ccac8ef8-1d45-4f74-9266-dc93e61ba302,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-50332037-b15d-4b5b-afd2-4a85db8e85e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-bf2b0291-cb67-411e-856a-9efc6fdd6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-7d269138-c8f9-447e-8ae9-66758e83effa,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f153069a-509a-4a65-a9ed-c172ea3f4d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345002243-172.17.0.9-1595402271713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37661,DS-a1594168-49b1-4ff3-b991-b3803b0b7bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5a6bbd11-68b4-4f1b-a0a4-1cb8466e4144,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-1dab738f-c8bd-4810-962a-8a6601008fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-dc59d346-f18b-4fa7-8638-302519862313,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-626370b6-21fd-476f-b305-a9733ac4fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-2a1a760f-0247-40b2-b7de-521f57b91cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-6c8e1bd0-c2f6-4c7d-8a07-ba7ecdd9373e,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-0b6224a6-d00a-4745-bfbd-a3dc24bf8fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345002243-172.17.0.9-1595402271713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37661,DS-a1594168-49b1-4ff3-b991-b3803b0b7bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5a6bbd11-68b4-4f1b-a0a4-1cb8466e4144,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-1dab738f-c8bd-4810-962a-8a6601008fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-dc59d346-f18b-4fa7-8638-302519862313,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-626370b6-21fd-476f-b305-a9733ac4fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-2a1a760f-0247-40b2-b7de-521f57b91cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-6c8e1bd0-c2f6-4c7d-8a07-ba7ecdd9373e,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-0b6224a6-d00a-4745-bfbd-a3dc24bf8fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064209963-172.17.0.9-1595402303326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-47089c54-4ed6-4a4b-acea-75a40980bf37,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-17588a7a-c883-4f46-ab9a-1b60390fab13,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-35670411-a92d-485a-bfd7-60c66d625bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-cc59964e-568e-4ab4-a993-1847ca7ea8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-67505dcf-b551-422a-afd5-5cf3604f67ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-73006b04-3034-48df-8bd2-0eab1c6d4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-10f41e91-01b6-41f1-944b-8390a10d6636,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5c3b49be-a302-4199-944f-96e8d63f42bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064209963-172.17.0.9-1595402303326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-47089c54-4ed6-4a4b-acea-75a40980bf37,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-17588a7a-c883-4f46-ab9a-1b60390fab13,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-35670411-a92d-485a-bfd7-60c66d625bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-cc59964e-568e-4ab4-a993-1847ca7ea8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-67505dcf-b551-422a-afd5-5cf3604f67ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-73006b04-3034-48df-8bd2-0eab1c6d4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-10f41e91-01b6-41f1-944b-8390a10d6636,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5c3b49be-a302-4199-944f-96e8d63f42bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159942358-172.17.0.9-1595402695094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-bdc7d645-51dc-498f-89b8-e90b32735559,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-794049cd-437a-4fbc-a091-841e9116aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-4c845f9e-c4da-4a01-ad59-dceaeef21ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-24f8a5cd-fad4-4eb8-ae43-e715e648c80e,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-aa8847e1-3871-4e45-afbe-cd51e3fb040a,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-d6cf8f11-9753-4f84-a7eb-eaf0d2f23a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-7a96b7a7-bdf6-4950-9549-8e624a7a6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-907fd445-f84d-471f-8afd-f76553734736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159942358-172.17.0.9-1595402695094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-bdc7d645-51dc-498f-89b8-e90b32735559,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-794049cd-437a-4fbc-a091-841e9116aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-4c845f9e-c4da-4a01-ad59-dceaeef21ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-24f8a5cd-fad4-4eb8-ae43-e715e648c80e,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-aa8847e1-3871-4e45-afbe-cd51e3fb040a,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-d6cf8f11-9753-4f84-a7eb-eaf0d2f23a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-7a96b7a7-bdf6-4950-9549-8e624a7a6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-907fd445-f84d-471f-8afd-f76553734736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690564745-172.17.0.9-1595402723734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40779,DS-6b5f62a5-be6c-4445-bef4-51f6d2fc8679,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-f9fdb91c-6395-4811-9629-9438eec18392,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-c7b49f72-8ecb-4bce-9814-a70f1696d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-5c6cc80c-cbe2-4cc6-b2ba-6b25631488f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-e404a2ff-4fc7-45f2-8954-d132c2989163,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-d3340f84-4a95-4eec-9570-aabd1d0f238c,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-e3f276b7-6a94-4958-8860-cce59dd3647b,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-6f525e6a-0550-475b-a22a-1c753dc3f39a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690564745-172.17.0.9-1595402723734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40779,DS-6b5f62a5-be6c-4445-bef4-51f6d2fc8679,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-f9fdb91c-6395-4811-9629-9438eec18392,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-c7b49f72-8ecb-4bce-9814-a70f1696d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-5c6cc80c-cbe2-4cc6-b2ba-6b25631488f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-e404a2ff-4fc7-45f2-8954-d132c2989163,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-d3340f84-4a95-4eec-9570-aabd1d0f238c,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-e3f276b7-6a94-4958-8860-cce59dd3647b,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-6f525e6a-0550-475b-a22a-1c753dc3f39a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554323250-172.17.0.9-1595402917879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-7f3718fa-b4e8-4906-aff1-9f2b1e3001c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-d8b0d177-90ce-4143-8303-8eda1a34a169,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-05055c78-2ce2-4694-aa04-3a27e410ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-014eb768-c508-47c6-a79c-9abfb0f4fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-d1090e4b-43b2-492e-904a-610a829e49e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-1d0905cb-f344-4f10-b411-1195420a3b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-83d07361-02ad-421b-a097-a16a600725bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-c93b73c4-66cf-431c-af8e-024673db0b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554323250-172.17.0.9-1595402917879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-7f3718fa-b4e8-4906-aff1-9f2b1e3001c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-d8b0d177-90ce-4143-8303-8eda1a34a169,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-05055c78-2ce2-4694-aa04-3a27e410ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-014eb768-c508-47c6-a79c-9abfb0f4fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-d1090e4b-43b2-492e-904a-610a829e49e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-1d0905cb-f344-4f10-b411-1195420a3b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-83d07361-02ad-421b-a097-a16a600725bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-c93b73c4-66cf-431c-af8e-024673db0b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3353266-172.17.0.9-1595402989160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-7811f9d3-f824-46e6-a6a0-097485bc5eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-8fff2b68-efcc-4eb6-9388-0d7e58f9fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-04c68468-4d49-405b-86e8-634928873770,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-471699a9-b5da-47fb-b5c8-88b890bffed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-5e29f129-396b-4530-bc26-45dda6a91101,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-68e090ec-5022-4e58-927b-f10fa5b0d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-e03b3ef7-0910-421e-844b-036f36113445,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-88097487-eb91-4c16-a82c-d9a86a37c6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3353266-172.17.0.9-1595402989160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-7811f9d3-f824-46e6-a6a0-097485bc5eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-8fff2b68-efcc-4eb6-9388-0d7e58f9fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-04c68468-4d49-405b-86e8-634928873770,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-471699a9-b5da-47fb-b5c8-88b890bffed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-5e29f129-396b-4530-bc26-45dda6a91101,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-68e090ec-5022-4e58-927b-f10fa5b0d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-e03b3ef7-0910-421e-844b-036f36113445,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-88097487-eb91-4c16-a82c-d9a86a37c6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023416731-172.17.0.9-1595403221965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42775,DS-253d1fd3-5f25-4d0d-ad85-2b715873dd71,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-1bee1b15-c722-4572-8ed0-4dccb6b72b83,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-d00aa141-9751-441d-b051-89071a8672b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-95dd2cb9-f1a1-482d-acfa-ae3bf604eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-4b0b0287-c9fd-4db1-9d7a-79f61db00e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-27a34101-db53-4521-ba4d-ce467870b60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-1c6bf0f5-927e-42f8-adb9-284ce350d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-624bea7b-a753-4f98-8593-c7e058bdae60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023416731-172.17.0.9-1595403221965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42775,DS-253d1fd3-5f25-4d0d-ad85-2b715873dd71,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-1bee1b15-c722-4572-8ed0-4dccb6b72b83,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-d00aa141-9751-441d-b051-89071a8672b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-95dd2cb9-f1a1-482d-acfa-ae3bf604eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-4b0b0287-c9fd-4db1-9d7a-79f61db00e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-27a34101-db53-4521-ba4d-ce467870b60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-1c6bf0f5-927e-42f8-adb9-284ce350d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-624bea7b-a753-4f98-8593-c7e058bdae60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550129317-172.17.0.9-1595404276020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33353,DS-bb5746a2-28cc-4fe1-aad3-945845d6dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-5bafa4ac-2acc-4d72-a2ea-4083cc2d9912,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-37340e5b-ecb6-475f-82d5-43ba7a777c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-b78d8e47-a2ba-46e9-9b08-5dfde833f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-6b8047d8-032d-429a-905d-861a473554da,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-802eef41-be85-4084-a5b4-2af37d932211,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-8eb10324-f66a-40dc-a99d-de0c13f91762,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-0c0ad91b-522d-4783-9bf3-136d82b49a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550129317-172.17.0.9-1595404276020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33353,DS-bb5746a2-28cc-4fe1-aad3-945845d6dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-5bafa4ac-2acc-4d72-a2ea-4083cc2d9912,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-37340e5b-ecb6-475f-82d5-43ba7a777c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-b78d8e47-a2ba-46e9-9b08-5dfde833f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-6b8047d8-032d-429a-905d-861a473554da,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-802eef41-be85-4084-a5b4-2af37d932211,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-8eb10324-f66a-40dc-a99d-de0c13f91762,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-0c0ad91b-522d-4783-9bf3-136d82b49a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94630660-172.17.0.9-1595404992653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-2f630694-20ff-4e36-9477-fd428272d7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-a5c13d7a-2025-44c5-86eb-4cc0cf33b91a,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-466b4a94-d1ff-468c-a536-3e6ad3ca2701,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-9210fe89-d965-4aca-b0ea-4189c72d903d,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-1751f3d6-0db9-4acd-89b8-c4e967e6b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-ecb0d33f-820a-4775-97f3-66aea90122a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-52ce6b16-4b9d-4d66-aff4-9553ab7959db,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-eeb08025-8fca-4abb-83cd-3fc65015867a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94630660-172.17.0.9-1595404992653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-2f630694-20ff-4e36-9477-fd428272d7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-a5c13d7a-2025-44c5-86eb-4cc0cf33b91a,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-466b4a94-d1ff-468c-a536-3e6ad3ca2701,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-9210fe89-d965-4aca-b0ea-4189c72d903d,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-1751f3d6-0db9-4acd-89b8-c4e967e6b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-ecb0d33f-820a-4775-97f3-66aea90122a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-52ce6b16-4b9d-4d66-aff4-9553ab7959db,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-eeb08025-8fca-4abb-83cd-3fc65015867a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620227563-172.17.0.9-1595405243895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-75ac058e-ecc8-480b-a6ed-7c674f49af95,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-310731bb-e911-43f0-9e88-01279eebff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-ed1baf01-1f0f-4621-bccc-3081f76650cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-7c6c99fe-6d90-45cb-9da9-6afd052b9e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-56d31ade-1d7a-46b3-97a4-46a05f6bc317,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-baae2151-28fb-4ffd-91e3-da75d09b8346,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-929fba45-afe9-4ecb-bff3-941cd936e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-aa2a3a12-aaa8-4777-8103-b9ee9d3c8a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620227563-172.17.0.9-1595405243895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-75ac058e-ecc8-480b-a6ed-7c674f49af95,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-310731bb-e911-43f0-9e88-01279eebff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-ed1baf01-1f0f-4621-bccc-3081f76650cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-7c6c99fe-6d90-45cb-9da9-6afd052b9e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-56d31ade-1d7a-46b3-97a4-46a05f6bc317,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-baae2151-28fb-4ffd-91e3-da75d09b8346,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-929fba45-afe9-4ecb-bff3-941cd936e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-aa2a3a12-aaa8-4777-8103-b9ee9d3c8a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800565632-172.17.0.9-1595405279006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46723,DS-9a0879d8-8182-4c06-99ad-51a15fb10e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-e5b4ec51-f2a5-4f54-ab64-fda7b79250f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-f2ac78f1-98ea-47ce-98d1-f7f7a9d7d216,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-6e3f828a-40fd-43d4-972b-d0ec5ceebe80,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-611427b7-5436-44e5-8adb-888c21bfda79,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-56642c7e-3c21-4cdf-9768-58412ce38ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-e94f5077-96ae-49b3-9152-c166f68619b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-237aae67-3d46-4144-b746-badfdef6dbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800565632-172.17.0.9-1595405279006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46723,DS-9a0879d8-8182-4c06-99ad-51a15fb10e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-e5b4ec51-f2a5-4f54-ab64-fda7b79250f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-f2ac78f1-98ea-47ce-98d1-f7f7a9d7d216,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-6e3f828a-40fd-43d4-972b-d0ec5ceebe80,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-611427b7-5436-44e5-8adb-888c21bfda79,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-56642c7e-3c21-4cdf-9768-58412ce38ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-e94f5077-96ae-49b3-9152-c166f68619b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-237aae67-3d46-4144-b746-badfdef6dbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639051327-172.17.0.9-1595405390777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37036,DS-33ff5958-6141-4deb-a018-82d8302fc925,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-94d3cc29-7ad8-4d23-8964-f54b565d5e63,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-6114e115-e043-4b28-8756-720d446fc03d,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-974412e1-738e-49fc-8a6b-a770a347102f,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-7057496f-8178-4581-81eb-37b36300756c,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-dc5fbcb7-9b26-4dd6-a81d-c44d2592f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-34764ed9-6035-44b3-b1f7-f77058cf53e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-c8de0fe1-6c33-46aa-b623-a0cd8b5860bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639051327-172.17.0.9-1595405390777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37036,DS-33ff5958-6141-4deb-a018-82d8302fc925,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-94d3cc29-7ad8-4d23-8964-f54b565d5e63,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-6114e115-e043-4b28-8756-720d446fc03d,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-974412e1-738e-49fc-8a6b-a770a347102f,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-7057496f-8178-4581-81eb-37b36300756c,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-dc5fbcb7-9b26-4dd6-a81d-c44d2592f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-34764ed9-6035-44b3-b1f7-f77058cf53e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-c8de0fe1-6c33-46aa-b623-a0cd8b5860bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566067017-172.17.0.9-1595406051466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42566,DS-71bea8fb-53d8-4fe2-b369-2dc0a6aa6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-14e818dd-db32-4262-a06c-defbbab80287,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-1624c66c-949c-43ac-8803-7b83517c4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-31f47f47-940c-44b9-ae82-c461887f338f,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-ea6f59d2-5867-430e-96cd-6f6e3b5edc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-79b24e9c-0094-411d-af80-739813b978ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-ef8cece4-8c4c-4532-aa7c-a03a6e569c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-c2e98906-f543-4ac3-a210-6dfbca082d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566067017-172.17.0.9-1595406051466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42566,DS-71bea8fb-53d8-4fe2-b369-2dc0a6aa6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-14e818dd-db32-4262-a06c-defbbab80287,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-1624c66c-949c-43ac-8803-7b83517c4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-31f47f47-940c-44b9-ae82-c461887f338f,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-ea6f59d2-5867-430e-96cd-6f6e3b5edc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-79b24e9c-0094-411d-af80-739813b978ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-ef8cece4-8c4c-4532-aa7c-a03a6e569c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-c2e98906-f543-4ac3-a210-6dfbca082d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438713462-172.17.0.9-1595406342089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-3d55652a-3e3f-4824-9e51-9aea41be9765,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-a10a2c47-fe65-4c97-81d1-58b988edd675,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-89f87f7d-eed5-4845-a3dc-7c19c495f109,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8aee561b-5f60-47ce-8fd0-5b926b0ffe45,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-c23f7aeb-ae7a-4db6-a99b-18238ec5a0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-b786e6ad-6102-4c79-8944-0e9444a8df6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-0affd8b8-1b8f-484f-ad7a-2f2d3079452a,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-4a0a19a8-bb7e-44e8-bfb8-9c4893108cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438713462-172.17.0.9-1595406342089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-3d55652a-3e3f-4824-9e51-9aea41be9765,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-a10a2c47-fe65-4c97-81d1-58b988edd675,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-89f87f7d-eed5-4845-a3dc-7c19c495f109,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8aee561b-5f60-47ce-8fd0-5b926b0ffe45,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-c23f7aeb-ae7a-4db6-a99b-18238ec5a0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-b786e6ad-6102-4c79-8944-0e9444a8df6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-0affd8b8-1b8f-484f-ad7a-2f2d3079452a,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-4a0a19a8-bb7e-44e8-bfb8-9c4893108cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4995
