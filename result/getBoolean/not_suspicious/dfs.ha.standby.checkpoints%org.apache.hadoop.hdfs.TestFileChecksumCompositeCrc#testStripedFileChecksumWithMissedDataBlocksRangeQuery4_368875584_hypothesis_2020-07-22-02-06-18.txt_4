reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127975941-172.17.0.10-1595383727841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-a539849e-1248-40ea-aadf-3a749eb91575,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-e0695b90-8b41-42af-8d71-c2c9fbc5f8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-c8738969-5aac-4f1e-8438-d7de0b17e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-30cd9a83-b8e7-4c71-bbdb-649a57d2a551,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-d718f75c-b21d-429b-ae66-13f143f67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-f6be0312-4a8f-43f9-8bfb-f2eca6c443bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-fcbe143e-1b89-4e64-bf9a-91fd32e502c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-a1ba0ebf-a970-491e-8171-89f9cd2fbd16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127975941-172.17.0.10-1595383727841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-a539849e-1248-40ea-aadf-3a749eb91575,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-e0695b90-8b41-42af-8d71-c2c9fbc5f8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-c8738969-5aac-4f1e-8438-d7de0b17e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-30cd9a83-b8e7-4c71-bbdb-649a57d2a551,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-d718f75c-b21d-429b-ae66-13f143f67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-f6be0312-4a8f-43f9-8bfb-f2eca6c443bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-fcbe143e-1b89-4e64-bf9a-91fd32e502c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-a1ba0ebf-a970-491e-8171-89f9cd2fbd16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077435136-172.17.0.10-1595383767283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-3d4a741a-3d0a-4fd2-adcb-906025b3a577,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-543271e9-060b-41b7-95fa-cbb8f8e3a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-20fc8afe-11ab-42f2-bade-68a313988530,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-1cc28945-edd6-44d6-b7dd-42410c3fa567,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-4df35723-1125-4de9-8d28-a8f246fcd6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-57af5ca3-ba3e-47c9-bd94-696f183f7e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-052f77f1-59e1-46b9-a2b6-53b80a89fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-442363a3-e0b1-4fb1-bd14-107fec9bafb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077435136-172.17.0.10-1595383767283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-3d4a741a-3d0a-4fd2-adcb-906025b3a577,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-543271e9-060b-41b7-95fa-cbb8f8e3a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-20fc8afe-11ab-42f2-bade-68a313988530,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-1cc28945-edd6-44d6-b7dd-42410c3fa567,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-4df35723-1125-4de9-8d28-a8f246fcd6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-57af5ca3-ba3e-47c9-bd94-696f183f7e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-052f77f1-59e1-46b9-a2b6-53b80a89fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-442363a3-e0b1-4fb1-bd14-107fec9bafb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325714007-172.17.0.10-1595383931535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-e97e78d2-6e76-4bb1-9913-53ef6fc77670,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-9141f2be-dd0f-42b2-abf9-1273fdec875f,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-adfb0bb3-9be7-4f64-8f59-f5de8f44cb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-2ca58003-6f40-4dd8-b6c5-7aff2f3ad85b,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-47792453-56fa-487a-9a29-7d981e2df947,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-e994ddec-87b7-4fc9-aec9-f69b5518287e,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-79dbcd97-6d7e-4fd5-8dd4-adfd60b4d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-b4df5c70-afdc-496c-8689-43b09c6f215a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325714007-172.17.0.10-1595383931535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-e97e78d2-6e76-4bb1-9913-53ef6fc77670,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-9141f2be-dd0f-42b2-abf9-1273fdec875f,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-adfb0bb3-9be7-4f64-8f59-f5de8f44cb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-2ca58003-6f40-4dd8-b6c5-7aff2f3ad85b,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-47792453-56fa-487a-9a29-7d981e2df947,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-e994ddec-87b7-4fc9-aec9-f69b5518287e,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-79dbcd97-6d7e-4fd5-8dd4-adfd60b4d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-b4df5c70-afdc-496c-8689-43b09c6f215a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704016994-172.17.0.10-1595384018593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-f5d911ca-2afb-4e4c-a732-9ab6fe01e542,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-0903c6d2-37ca-4df2-94f3-591b314222c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-ea1582f0-6998-40c6-bf90-a18a0dc2242f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-56e52a4d-c1f6-4b49-b045-2936d5a46125,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-305277f3-d43d-4946-bd46-2338694c75ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-9bb0017c-10a4-439f-a40d-f78fa7d0c84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-edb50e8d-e582-4b37-bc10-92e6acf3500e,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-bbb36592-d43d-455e-bf82-4b57225fcc45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704016994-172.17.0.10-1595384018593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-f5d911ca-2afb-4e4c-a732-9ab6fe01e542,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-0903c6d2-37ca-4df2-94f3-591b314222c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-ea1582f0-6998-40c6-bf90-a18a0dc2242f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-56e52a4d-c1f6-4b49-b045-2936d5a46125,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-305277f3-d43d-4946-bd46-2338694c75ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-9bb0017c-10a4-439f-a40d-f78fa7d0c84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-edb50e8d-e582-4b37-bc10-92e6acf3500e,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-bbb36592-d43d-455e-bf82-4b57225fcc45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918088355-172.17.0.10-1595384816304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-0a996e8b-e072-47e2-b735-cb6ca50cda6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-69873032-31b7-4af1-9c85-0b72497b9fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4188e550-f559-427f-8fdf-ee34b6b76e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-6bc6265f-e24f-4722-969b-b0afe96c3bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-dabb461c-96de-4e0b-baff-875dbc89e2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-da590ec9-6edf-4d5a-8797-979aeaf5f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-d3d91a62-d2a4-4208-a2d6-281a5ab7496e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-f9429718-7827-48b2-8b44-9597039ea9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918088355-172.17.0.10-1595384816304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-0a996e8b-e072-47e2-b735-cb6ca50cda6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-69873032-31b7-4af1-9c85-0b72497b9fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4188e550-f559-427f-8fdf-ee34b6b76e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-6bc6265f-e24f-4722-969b-b0afe96c3bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-dabb461c-96de-4e0b-baff-875dbc89e2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-da590ec9-6edf-4d5a-8797-979aeaf5f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-d3d91a62-d2a4-4208-a2d6-281a5ab7496e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-f9429718-7827-48b2-8b44-9597039ea9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356371113-172.17.0.10-1595385032940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-c3253881-5fba-42f3-b05f-55e837e5b069,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-fcfbcc59-0b9e-4735-a120-7bbb54ad29ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-f2ced732-3067-48bb-94fb-c3b8c3ac4429,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-39d5fdf0-d346-4c11-b372-c98c6b7ad3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-9739a3eb-9c5d-47b8-af74-8af23f64b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-53b5fc2f-5131-4d0a-ab90-71fea945da26,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-ef1d1f02-d467-494e-b3ef-92f2e67ed2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-ffe3ae21-5a2b-4da7-892d-c2562a852300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356371113-172.17.0.10-1595385032940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-c3253881-5fba-42f3-b05f-55e837e5b069,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-fcfbcc59-0b9e-4735-a120-7bbb54ad29ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-f2ced732-3067-48bb-94fb-c3b8c3ac4429,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-39d5fdf0-d346-4c11-b372-c98c6b7ad3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-9739a3eb-9c5d-47b8-af74-8af23f64b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-53b5fc2f-5131-4d0a-ab90-71fea945da26,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-ef1d1f02-d467-494e-b3ef-92f2e67ed2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-ffe3ae21-5a2b-4da7-892d-c2562a852300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921006995-172.17.0.10-1595385550566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-99e0fbec-0816-49ca-9247-a083552c87d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-f6f6e058-e845-4987-a1a3-a64e83124a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-6d4675bf-18bc-431e-926f-2e5dbe151be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-78f93656-8ea5-443a-a4df-70ca5f281336,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-3d47e840-1514-4474-aa93-d1f6a109445a,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-ecedc1f8-e0f8-492c-93ac-1f5a56dd8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-822c9938-a42d-4402-a146-34565016bc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-1e895b62-5bee-4d7d-a469-239385ca2fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921006995-172.17.0.10-1595385550566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-99e0fbec-0816-49ca-9247-a083552c87d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-f6f6e058-e845-4987-a1a3-a64e83124a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-6d4675bf-18bc-431e-926f-2e5dbe151be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-78f93656-8ea5-443a-a4df-70ca5f281336,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-3d47e840-1514-4474-aa93-d1f6a109445a,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-ecedc1f8-e0f8-492c-93ac-1f5a56dd8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-822c9938-a42d-4402-a146-34565016bc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-1e895b62-5bee-4d7d-a469-239385ca2fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383771866-172.17.0.10-1595385721824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-187037e2-47a5-4609-add1-f37668f18763,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-a4f4f1a2-f4c2-4c95-8602-ad84cde66d71,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-13d5f3cf-071a-4483-9b50-70036d01c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-d073a5f0-4139-4775-82aa-ef57777e3c23,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-efa45063-9c0a-46e1-b887-7c095d8fd4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-4765f3a8-d63a-4217-be23-b35d6ae342f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-e0140716-1cf5-4477-828d-938577742125,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-04300e14-9880-413d-afd4-7d0b2609e1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383771866-172.17.0.10-1595385721824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-187037e2-47a5-4609-add1-f37668f18763,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-a4f4f1a2-f4c2-4c95-8602-ad84cde66d71,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-13d5f3cf-071a-4483-9b50-70036d01c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-d073a5f0-4139-4775-82aa-ef57777e3c23,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-efa45063-9c0a-46e1-b887-7c095d8fd4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-4765f3a8-d63a-4217-be23-b35d6ae342f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-e0140716-1cf5-4477-828d-938577742125,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-04300e14-9880-413d-afd4-7d0b2609e1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293044911-172.17.0.10-1595386046510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-a71b635e-d423-4d30-99bd-9d76827d7019,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-9eab20f4-cab1-4d4c-aa44-62163db1f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-febdab29-8cb1-48b5-a1a6-b84ef6b9d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-697d1586-7742-4518-bf65-18d5e5d1f084,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-f736a608-64e3-4450-bfd1-79dc6433601d,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-a42a9b11-cee3-4cd5-bbf9-da6142bf0c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-c8232796-ce0d-4741-880d-0c64841df3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-7a07527e-61e7-4bbe-b39c-38c3341a57b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293044911-172.17.0.10-1595386046510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-a71b635e-d423-4d30-99bd-9d76827d7019,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-9eab20f4-cab1-4d4c-aa44-62163db1f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-febdab29-8cb1-48b5-a1a6-b84ef6b9d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-697d1586-7742-4518-bf65-18d5e5d1f084,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-f736a608-64e3-4450-bfd1-79dc6433601d,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-a42a9b11-cee3-4cd5-bbf9-da6142bf0c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-c8232796-ce0d-4741-880d-0c64841df3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-7a07527e-61e7-4bbe-b39c-38c3341a57b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134228752-172.17.0.10-1595386254845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-cf922e1e-4190-49b8-ab1c-ebbd369415f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-26150a42-1aa5-4e85-905f-e6f57f61c9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-c79acfcc-f660-4642-bf59-645613e34d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-1dd56c40-dee3-4c8c-895c-aa5984340334,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-ee813539-05ef-4156-84a1-a845abe66e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-57597323-2583-48d0-8b76-649708fe516c,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-5fa9143a-0beb-4e93-8212-58647301f53d,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-d7e7f252-9b93-42ca-b32d-245c2f84695c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134228752-172.17.0.10-1595386254845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-cf922e1e-4190-49b8-ab1c-ebbd369415f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-26150a42-1aa5-4e85-905f-e6f57f61c9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-c79acfcc-f660-4642-bf59-645613e34d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-1dd56c40-dee3-4c8c-895c-aa5984340334,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-ee813539-05ef-4156-84a1-a845abe66e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-57597323-2583-48d0-8b76-649708fe516c,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-5fa9143a-0beb-4e93-8212-58647301f53d,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-d7e7f252-9b93-42ca-b32d-245c2f84695c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068889353-172.17.0.10-1595386289079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-953cc3a8-12b8-467f-993a-cafd55e1abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-fb869aaa-54f2-40b9-8b4d-56580b8bb0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-4cb47166-9eae-42ad-a0cb-b6412f0a9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-ceeb2a2c-fa5c-446e-9009-e0ec4e8611c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-8db92dbf-f332-4ab9-b109-4798a0c6abaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-78c98188-4b28-4047-8f7a-0a842b55b9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-5bc14128-b5ba-4d6b-ad65-e2640e625166,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-d5ec06ef-c255-445e-822e-04c717935719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068889353-172.17.0.10-1595386289079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-953cc3a8-12b8-467f-993a-cafd55e1abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-fb869aaa-54f2-40b9-8b4d-56580b8bb0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-4cb47166-9eae-42ad-a0cb-b6412f0a9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-ceeb2a2c-fa5c-446e-9009-e0ec4e8611c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-8db92dbf-f332-4ab9-b109-4798a0c6abaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-78c98188-4b28-4047-8f7a-0a842b55b9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-5bc14128-b5ba-4d6b-ad65-e2640e625166,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-d5ec06ef-c255-445e-822e-04c717935719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243637886-172.17.0.10-1595386330530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-1eabc628-0d50-433b-9893-8b49a6d6418a,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-9bf69b8b-7d7b-4314-a402-8163c85b612d,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9e27b8a6-bcdd-43cd-9ef5-a5ed757bd3db,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-6d1d8879-8f1f-4992-a0a0-7947d5e166de,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-89d120ed-15cd-4e0b-88a8-2daa61d5dacb,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-881b80ad-d368-4013-ae7a-789ab656e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-75d4468e-fb93-438e-a503-73d9718738ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-c5f91aa2-d186-4c6d-9f92-d6c8502941ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243637886-172.17.0.10-1595386330530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-1eabc628-0d50-433b-9893-8b49a6d6418a,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-9bf69b8b-7d7b-4314-a402-8163c85b612d,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9e27b8a6-bcdd-43cd-9ef5-a5ed757bd3db,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-6d1d8879-8f1f-4992-a0a0-7947d5e166de,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-89d120ed-15cd-4e0b-88a8-2daa61d5dacb,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-881b80ad-d368-4013-ae7a-789ab656e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-75d4468e-fb93-438e-a503-73d9718738ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-c5f91aa2-d186-4c6d-9f92-d6c8502941ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091308325-172.17.0.10-1595386498117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-02fd4e9b-ada0-481b-801c-6b64edf24454,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-af3a034d-1f06-4336-a1a6-a0ace3ab0edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-4107f17a-a435-4dd0-97aa-4ee2f1765f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-faf74634-41c8-45ca-8262-9cadf318e2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ce5043a7-ef32-414f-8ef0-1be282536623,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-58c0a55d-168d-4044-a02c-014a3f763333,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-f8ad87c5-173b-4cec-a497-39f42275287f,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-88ad8350-92b8-4249-ae25-3b08bf83e6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091308325-172.17.0.10-1595386498117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-02fd4e9b-ada0-481b-801c-6b64edf24454,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-af3a034d-1f06-4336-a1a6-a0ace3ab0edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-4107f17a-a435-4dd0-97aa-4ee2f1765f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-faf74634-41c8-45ca-8262-9cadf318e2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ce5043a7-ef32-414f-8ef0-1be282536623,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-58c0a55d-168d-4044-a02c-014a3f763333,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-f8ad87c5-173b-4cec-a497-39f42275287f,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-88ad8350-92b8-4249-ae25-3b08bf83e6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518981263-172.17.0.10-1595387423462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43553,DS-763afb52-90d9-4aaf-9b47-946e476ac3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-ffacacd7-f7ea-47b4-83ca-1033016f0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-edabf196-a62c-467b-86aa-e8139fa82e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-0270b0d0-b1a9-4bba-8bb2-87d1d78eaeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-987cf3f6-c84c-49e6-b020-ed6d9d344826,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-fac0f16a-2e6e-4b90-870a-c4fb82bb0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-b934b31a-3ed4-44f6-bedf-1c4462559d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-6dde4e4e-211f-46b5-9bf2-92aaeffe8aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518981263-172.17.0.10-1595387423462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43553,DS-763afb52-90d9-4aaf-9b47-946e476ac3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-ffacacd7-f7ea-47b4-83ca-1033016f0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-edabf196-a62c-467b-86aa-e8139fa82e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-0270b0d0-b1a9-4bba-8bb2-87d1d78eaeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-987cf3f6-c84c-49e6-b020-ed6d9d344826,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-fac0f16a-2e6e-4b90-870a-c4fb82bb0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-b934b31a-3ed4-44f6-bedf-1c4462559d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-6dde4e4e-211f-46b5-9bf2-92aaeffe8aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064430604-172.17.0.10-1595387459435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41089,DS-1ef6ddf6-8fe0-40c8-83f5-79639b429254,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-613805e0-6016-4827-a7e7-5343dff7da08,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7ce3f25a-77cf-4fc2-9385-41e9e44e442f,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-64aa84bb-cf67-4ca2-a50d-413bba5d2805,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-7c7d8349-59d9-4e4f-8306-68c652137b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-19bd5785-447c-42be-94c5-194f1abcbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-d7a85c7b-f442-4b79-b169-cd534171c265,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-a5b6c3ab-bbd1-4f88-b239-7961442a8702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064430604-172.17.0.10-1595387459435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41089,DS-1ef6ddf6-8fe0-40c8-83f5-79639b429254,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-613805e0-6016-4827-a7e7-5343dff7da08,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7ce3f25a-77cf-4fc2-9385-41e9e44e442f,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-64aa84bb-cf67-4ca2-a50d-413bba5d2805,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-7c7d8349-59d9-4e4f-8306-68c652137b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-19bd5785-447c-42be-94c5-194f1abcbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-d7a85c7b-f442-4b79-b169-cd534171c265,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-a5b6c3ab-bbd1-4f88-b239-7961442a8702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470597894-172.17.0.10-1595387856768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-d4c81d46-ee57-4fa8-895a-5e64c729027e,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-4f854f6e-b5aa-42a6-b84a-99fe81ade41e,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-be9a7d29-d49f-4e67-8c40-e2268fecf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-69eef0bf-8c21-4e2c-a2c7-b05e619330fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-a855d7aa-e3d7-49cc-8cfd-f8bd16a4186e,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-5a9e457e-77b2-4404-95d1-c22c5052a2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-f85fab94-3481-4949-b68e-32ad11abb8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-70f5f4f6-b92c-41c6-bbb3-12782674b2b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470597894-172.17.0.10-1595387856768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-d4c81d46-ee57-4fa8-895a-5e64c729027e,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-4f854f6e-b5aa-42a6-b84a-99fe81ade41e,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-be9a7d29-d49f-4e67-8c40-e2268fecf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-69eef0bf-8c21-4e2c-a2c7-b05e619330fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-a855d7aa-e3d7-49cc-8cfd-f8bd16a4186e,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-5a9e457e-77b2-4404-95d1-c22c5052a2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-f85fab94-3481-4949-b68e-32ad11abb8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-70f5f4f6-b92c-41c6-bbb3-12782674b2b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879412775-172.17.0.10-1595388234140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-1e628d25-c8b0-4328-a522-0aff3c237b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-0515205b-b55e-4dd2-b47a-ddfcd3519d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-88a6eabd-4f4a-4c9d-939d-ead47fbc7885,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-f0c19b4b-705f-4bca-a6e8-279406542e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-bfb28ca1-e1ee-4e43-b514-259e3fbbdc78,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-96149e81-f420-4d46-b3df-cc6ca9fdc61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-c01c4edc-eaae-4edc-a72a-00e9e6c93082,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-e2260992-e352-4538-bb70-8cd3dc23f9d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879412775-172.17.0.10-1595388234140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-1e628d25-c8b0-4328-a522-0aff3c237b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-0515205b-b55e-4dd2-b47a-ddfcd3519d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-88a6eabd-4f4a-4c9d-939d-ead47fbc7885,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-f0c19b4b-705f-4bca-a6e8-279406542e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-bfb28ca1-e1ee-4e43-b514-259e3fbbdc78,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-96149e81-f420-4d46-b3df-cc6ca9fdc61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-c01c4edc-eaae-4edc-a72a-00e9e6c93082,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-e2260992-e352-4538-bb70-8cd3dc23f9d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113700770-172.17.0.10-1595388563532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-5999a3e6-e3fa-463e-bd9b-77e35b058762,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-753f68d6-7bc2-4819-a248-bec944b5425f,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-c03e05f7-8934-4f3f-b9af-1ef1a8cd2d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9b94cd3b-df6d-4068-ab47-295ae71c94c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-2952afca-8ac3-47b5-9ed3-d45adbf5ba16,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-2b37b4d6-a332-4eda-9e0b-cd561c345b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-29dccb3d-8039-4a7c-abf0-528e3679d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-11843f27-1117-461b-ae53-3854bf9476d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113700770-172.17.0.10-1595388563532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-5999a3e6-e3fa-463e-bd9b-77e35b058762,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-753f68d6-7bc2-4819-a248-bec944b5425f,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-c03e05f7-8934-4f3f-b9af-1ef1a8cd2d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9b94cd3b-df6d-4068-ab47-295ae71c94c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-2952afca-8ac3-47b5-9ed3-d45adbf5ba16,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-2b37b4d6-a332-4eda-9e0b-cd561c345b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-29dccb3d-8039-4a7c-abf0-528e3679d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-11843f27-1117-461b-ae53-3854bf9476d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5445
