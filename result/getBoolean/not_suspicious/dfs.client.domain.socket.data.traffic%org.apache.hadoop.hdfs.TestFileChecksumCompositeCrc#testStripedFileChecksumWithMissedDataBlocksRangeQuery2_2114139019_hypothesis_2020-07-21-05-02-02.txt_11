reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612519625-172.17.0.17-1595308350000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33373,DS-1cec5f69-8259-412c-bb11-55b522b8c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b28da964-34ba-49cb-bb0e-240b7710c556,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-52a5f2ec-4018-43ff-90e8-20149af3281f,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-2136b569-1a64-40a0-a7ef-6914a5bb726f,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-b3a855de-aaee-4247-8b8e-0c875e6f42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-f4c7a7da-83cb-4bdb-b590-038133569f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-bb7b2a3a-ec1e-4d37-9e37-918b566107dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-be445e4b-40c2-42f7-9b22-0a0fc1b1c2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612519625-172.17.0.17-1595308350000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33373,DS-1cec5f69-8259-412c-bb11-55b522b8c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b28da964-34ba-49cb-bb0e-240b7710c556,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-52a5f2ec-4018-43ff-90e8-20149af3281f,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-2136b569-1a64-40a0-a7ef-6914a5bb726f,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-b3a855de-aaee-4247-8b8e-0c875e6f42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-f4c7a7da-83cb-4bdb-b590-038133569f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-bb7b2a3a-ec1e-4d37-9e37-918b566107dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-be445e4b-40c2-42f7-9b22-0a0fc1b1c2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412383985-172.17.0.17-1595309221839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44109,DS-00ab20d3-eb92-4617-8492-ebfd79eb05b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-82fa9bcf-4947-4bd1-b766-6bcebc350274,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-331b20f6-6792-4f05-85bc-e0c3d3718534,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-c18aa8a8-8ec0-4fe9-8b50-7a395327f37a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-2d7ba6a0-1f53-46f9-aba9-0f0d8efe0b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-77a8c94f-6df8-42cd-a69f-db0f7fb578d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-68f09f04-0c70-491b-81cf-0c46af2827d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-4371dae7-1397-4ddf-b545-0b67395c5a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412383985-172.17.0.17-1595309221839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44109,DS-00ab20d3-eb92-4617-8492-ebfd79eb05b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-82fa9bcf-4947-4bd1-b766-6bcebc350274,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-331b20f6-6792-4f05-85bc-e0c3d3718534,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-c18aa8a8-8ec0-4fe9-8b50-7a395327f37a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-2d7ba6a0-1f53-46f9-aba9-0f0d8efe0b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-77a8c94f-6df8-42cd-a69f-db0f7fb578d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-68f09f04-0c70-491b-81cf-0c46af2827d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-4371dae7-1397-4ddf-b545-0b67395c5a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466705859-172.17.0.17-1595309660045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45819,DS-b4baa3b7-4301-451e-89c8-06c46953cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-26dc4e6a-f254-4aeb-aded-39d9214a94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-60329d0c-6287-4a41-aa00-ab6c1af7d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-1865f7a7-a444-483d-94a3-87d5166dae80,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-f15b0cb4-f426-4e38-b627-5b5cc1c98d47,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e7353791-30a5-4c5c-bc6e-4a50452ab6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-3fe70e52-4d8c-4116-8c86-a3e89333ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-7d8e5d56-02e4-4ccc-93bb-876ca1f379a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466705859-172.17.0.17-1595309660045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45819,DS-b4baa3b7-4301-451e-89c8-06c46953cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-26dc4e6a-f254-4aeb-aded-39d9214a94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-60329d0c-6287-4a41-aa00-ab6c1af7d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-1865f7a7-a444-483d-94a3-87d5166dae80,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-f15b0cb4-f426-4e38-b627-5b5cc1c98d47,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e7353791-30a5-4c5c-bc6e-4a50452ab6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-3fe70e52-4d8c-4116-8c86-a3e89333ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-7d8e5d56-02e4-4ccc-93bb-876ca1f379a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451045576-172.17.0.17-1595309902675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-589793e0-84d0-4ae7-9b94-3d3aea6e7bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-441cd31e-4f2f-48f1-9a90-93d0243d32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-6026ebf5-bb57-40ff-8410-061296ef08ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-69ef8447-7af5-4a48-86eb-c66dcd6b26a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-9f6fabcd-feff-4efc-a558-2592624e3d24,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-5ccfa9fd-1ee1-4c00-89c9-afedc912ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-bc4424b4-98ab-47ab-abf5-daf31474778c,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-1ccb2be4-1211-4120-ab46-f9aeaf2c0e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451045576-172.17.0.17-1595309902675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-589793e0-84d0-4ae7-9b94-3d3aea6e7bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-441cd31e-4f2f-48f1-9a90-93d0243d32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-6026ebf5-bb57-40ff-8410-061296ef08ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-69ef8447-7af5-4a48-86eb-c66dcd6b26a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-9f6fabcd-feff-4efc-a558-2592624e3d24,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-5ccfa9fd-1ee1-4c00-89c9-afedc912ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-bc4424b4-98ab-47ab-abf5-daf31474778c,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-1ccb2be4-1211-4120-ab46-f9aeaf2c0e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500420504-172.17.0.17-1595310084642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-c7cda408-77de-4dc1-8c6e-ee9e8f2ed2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-1e761359-bdb5-48c5-a187-7fa568277534,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-82c8160b-f7e1-4971-995d-a9f53bd740ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-db849d60-b731-49c5-9109-0b495546b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-2d74faf8-727f-4be2-a328-6ca54624f314,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-d2211b93-3bb8-493c-911b-30e1b983f871,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-7044c4d8-f90a-4fe7-aadd-56ee0e36579c,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c81fe5e1-5afc-49d9-80aa-dce4b1928068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500420504-172.17.0.17-1595310084642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-c7cda408-77de-4dc1-8c6e-ee9e8f2ed2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-1e761359-bdb5-48c5-a187-7fa568277534,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-82c8160b-f7e1-4971-995d-a9f53bd740ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-db849d60-b731-49c5-9109-0b495546b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-2d74faf8-727f-4be2-a328-6ca54624f314,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-d2211b93-3bb8-493c-911b-30e1b983f871,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-7044c4d8-f90a-4fe7-aadd-56ee0e36579c,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c81fe5e1-5afc-49d9-80aa-dce4b1928068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283832708-172.17.0.17-1595310228971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-cb7a31d4-7638-4045-b8ac-9aaee0b93bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-664629d8-bcce-4731-9e97-b28f4a7fa8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-4a858b2c-72fa-439e-85ae-0e42c67c39da,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-780885a9-649e-4c3b-8cc0-a10a5a50afc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-6adf7866-a33f-40bd-a6ae-ae431815d101,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-601673c9-f10c-4cfd-b05d-63255c973926,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-e9279b74-0793-4f2e-b232-cf2845eb98ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-65f89091-3866-4323-975f-c5dd56a878ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283832708-172.17.0.17-1595310228971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-cb7a31d4-7638-4045-b8ac-9aaee0b93bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-664629d8-bcce-4731-9e97-b28f4a7fa8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-4a858b2c-72fa-439e-85ae-0e42c67c39da,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-780885a9-649e-4c3b-8cc0-a10a5a50afc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-6adf7866-a33f-40bd-a6ae-ae431815d101,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-601673c9-f10c-4cfd-b05d-63255c973926,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-e9279b74-0793-4f2e-b232-cf2845eb98ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-65f89091-3866-4323-975f-c5dd56a878ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054092606-172.17.0.17-1595310300560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-f0bac369-786f-4220-87ce-54605100ecb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-312c1872-baa0-4198-bbb6-b01f60f51abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-0165eba8-b03b-44e0-a106-9c3d7085c166,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-d53de483-05ad-4356-b784-21e4a2531e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-fc6bb280-8576-4f6b-bd08-1b0ca4b44bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-5536d1f9-a5bc-4002-a369-28e97b92317c,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-06898bbe-020f-4a78-a8aa-6659f39a0865,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-258d966c-3f99-4acf-b6d3-2af3e463e36f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054092606-172.17.0.17-1595310300560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-f0bac369-786f-4220-87ce-54605100ecb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-312c1872-baa0-4198-bbb6-b01f60f51abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-0165eba8-b03b-44e0-a106-9c3d7085c166,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-d53de483-05ad-4356-b784-21e4a2531e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-fc6bb280-8576-4f6b-bd08-1b0ca4b44bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-5536d1f9-a5bc-4002-a369-28e97b92317c,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-06898bbe-020f-4a78-a8aa-6659f39a0865,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-258d966c-3f99-4acf-b6d3-2af3e463e36f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532081905-172.17.0.17-1595310908471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43989,DS-8a8f734d-a5ff-44e8-9b89-d4b0cc70b490,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-ccac1463-ad81-4f62-97f5-b21abbfca49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-312e692b-4921-4b6f-b12b-f46008817ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-6eb77ef1-cb88-46e8-b0ea-7d1eacd2cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-b9b8ebef-6450-4ad0-970e-1592f84c14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-17a04f32-d8eb-45dc-a3bc-090027381be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-a5164950-9777-422c-a0a0-4ffea40f5f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-f8c574ee-c683-4565-8bd1-2f8dc485a040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532081905-172.17.0.17-1595310908471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43989,DS-8a8f734d-a5ff-44e8-9b89-d4b0cc70b490,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-ccac1463-ad81-4f62-97f5-b21abbfca49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-312e692b-4921-4b6f-b12b-f46008817ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-6eb77ef1-cb88-46e8-b0ea-7d1eacd2cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-b9b8ebef-6450-4ad0-970e-1592f84c14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-17a04f32-d8eb-45dc-a3bc-090027381be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-a5164950-9777-422c-a0a0-4ffea40f5f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-f8c574ee-c683-4565-8bd1-2f8dc485a040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393951104-172.17.0.17-1595310949382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33330,DS-aee26835-101c-4d54-aa6c-67b8ec95b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-9904e3c1-f4ad-4343-bbea-a3bf7856772d,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d6772dbb-c6f6-462f-8af6-c7dc8f270526,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-aab22695-3c0a-4941-b506-d28a3ab2fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-84f97611-d4a2-405f-926f-d51f1e1e86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-5b28d30b-1269-4931-b562-decfd23c65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-042bf2e4-6846-4022-8eeb-3754f10c8225,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-1d6ee229-93df-46e3-99f9-137eed4f76d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393951104-172.17.0.17-1595310949382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33330,DS-aee26835-101c-4d54-aa6c-67b8ec95b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-9904e3c1-f4ad-4343-bbea-a3bf7856772d,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d6772dbb-c6f6-462f-8af6-c7dc8f270526,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-aab22695-3c0a-4941-b506-d28a3ab2fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-84f97611-d4a2-405f-926f-d51f1e1e86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-5b28d30b-1269-4931-b562-decfd23c65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-042bf2e4-6846-4022-8eeb-3754f10c8225,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-1d6ee229-93df-46e3-99f9-137eed4f76d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739893296-172.17.0.17-1595310990733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39523,DS-45e867de-c076-4d1a-a3bb-991f48d78394,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-39b720b9-d07f-4df0-a409-93bdb5512350,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-11f5b53f-d649-4095-a726-8e32241569fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-f2811bd5-37f9-4960-be51-d4ee1fce3d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-27043b8a-4697-4f60-adbc-3d50e70f9348,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-3691b08d-619b-4d4f-b168-60c653efb0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-da81ddbf-2772-48d5-9cf8-4e6264a4d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-e51665c4-3751-4866-9555-c0adcd26863c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739893296-172.17.0.17-1595310990733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39523,DS-45e867de-c076-4d1a-a3bb-991f48d78394,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-39b720b9-d07f-4df0-a409-93bdb5512350,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-11f5b53f-d649-4095-a726-8e32241569fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-f2811bd5-37f9-4960-be51-d4ee1fce3d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-27043b8a-4697-4f60-adbc-3d50e70f9348,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-3691b08d-619b-4d4f-b168-60c653efb0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-da81ddbf-2772-48d5-9cf8-4e6264a4d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-e51665c4-3751-4866-9555-c0adcd26863c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274380778-172.17.0.17-1595311379159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33104,DS-fd439886-3591-40d4-a9b0-01ac1728c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-9d96fd91-6bef-462a-b68b-972723359786,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-82df99f1-7e3c-404b-a668-aaa35cd1eb53,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-7bec7837-c285-4477-b83e-4d539bdfbd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-aa204c00-8842-43a2-a90d-4b57af89bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-fec7c205-e9a7-4745-8892-aaa67fbaeb07,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-56f5e312-86e1-4ae9-a07d-deea9d581ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-35229eed-f9ee-4aa2-bde9-241ad17571d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274380778-172.17.0.17-1595311379159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33104,DS-fd439886-3591-40d4-a9b0-01ac1728c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-9d96fd91-6bef-462a-b68b-972723359786,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-82df99f1-7e3c-404b-a668-aaa35cd1eb53,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-7bec7837-c285-4477-b83e-4d539bdfbd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-aa204c00-8842-43a2-a90d-4b57af89bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-fec7c205-e9a7-4745-8892-aaa67fbaeb07,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-56f5e312-86e1-4ae9-a07d-deea9d581ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-35229eed-f9ee-4aa2-bde9-241ad17571d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653964065-172.17.0.17-1595311617383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-63b2fffd-64d6-4c9b-83dd-91b6b74e7563,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-6f21349d-ad1f-43a7-b12c-f8bae431bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-e0b8c8c9-0401-4545-8056-75e572169637,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-ec1584c6-7f3c-42d4-9a59-590151ab2fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ac7fee5b-0999-46e9-9dd2-1194dd42cd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-32222fc2-1edf-45e5-ad38-314043b4adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-b25ac815-8f57-4998-8455-0dbc37ba5a93,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-3abe60a3-e38a-41f4-9a51-01e4c0c3ee4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653964065-172.17.0.17-1595311617383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-63b2fffd-64d6-4c9b-83dd-91b6b74e7563,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-6f21349d-ad1f-43a7-b12c-f8bae431bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-e0b8c8c9-0401-4545-8056-75e572169637,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-ec1584c6-7f3c-42d4-9a59-590151ab2fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ac7fee5b-0999-46e9-9dd2-1194dd42cd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-32222fc2-1edf-45e5-ad38-314043b4adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-b25ac815-8f57-4998-8455-0dbc37ba5a93,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-3abe60a3-e38a-41f4-9a51-01e4c0c3ee4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446082062-172.17.0.17-1595312036561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-4be2036a-4073-4d79-a409-4cb226a4b879,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-4a619fd1-49df-4222-8ffc-4c4c96fa3c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-0ac25f51-8fba-44e2-8d89-694af73e6d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-8a6777da-c8b6-4745-86c3-ec36c9aa65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-afc17964-d781-4251-b0e3-5531c80a6c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-fca2d2c9-aca6-4a64-ab15-45dbbd9554a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-dd03d5e9-95a0-4878-8a6a-5dfe7654287c,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-5e27f10d-9b12-4023-9466-52c7c288487c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446082062-172.17.0.17-1595312036561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-4be2036a-4073-4d79-a409-4cb226a4b879,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-4a619fd1-49df-4222-8ffc-4c4c96fa3c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-0ac25f51-8fba-44e2-8d89-694af73e6d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-8a6777da-c8b6-4745-86c3-ec36c9aa65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-afc17964-d781-4251-b0e3-5531c80a6c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-fca2d2c9-aca6-4a64-ab15-45dbbd9554a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-dd03d5e9-95a0-4878-8a6a-5dfe7654287c,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-5e27f10d-9b12-4023-9466-52c7c288487c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327338069-172.17.0.17-1595312132025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-6270cc16-3e22-402d-8856-7718263796e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-2aeb0fd0-4181-4f3a-9ab2-ee3421f441b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-be3b583b-1b0d-4622-ac05-a2e81e4b68f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-a863db4e-0364-4e9e-88b1-be3e30e80575,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-1b835f20-c8ed-4729-b841-16f45794314a,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-4573e924-d5f3-4d3c-96fc-9c974200c073,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-c612f82b-350e-475d-bb9c-41cb504b7ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-bd460fe5-5669-4f14-8bd5-76aad42c77b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327338069-172.17.0.17-1595312132025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-6270cc16-3e22-402d-8856-7718263796e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-2aeb0fd0-4181-4f3a-9ab2-ee3421f441b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-be3b583b-1b0d-4622-ac05-a2e81e4b68f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-a863db4e-0364-4e9e-88b1-be3e30e80575,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-1b835f20-c8ed-4729-b841-16f45794314a,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-4573e924-d5f3-4d3c-96fc-9c974200c073,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-c612f82b-350e-475d-bb9c-41cb504b7ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-bd460fe5-5669-4f14-8bd5-76aad42c77b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85982203-172.17.0.17-1595312271175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-7f2b183f-185e-4afb-bd71-216d058c7150,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-80527271-3623-42de-a216-5775c72650c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-6d495295-5b26-42bb-90b0-a6da9d4f8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-e2d8eebd-8d85-4506-b0fa-72e3b1091d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-888dc80d-4c6c-4159-8657-1b21f1f59da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-35ecae0e-86d8-4085-bd90-c2ea6761cb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-3b6bc390-b48a-4b72-adf3-3418417d1ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-830748eb-3634-43bc-a2ec-edfb78a17d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85982203-172.17.0.17-1595312271175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-7f2b183f-185e-4afb-bd71-216d058c7150,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-80527271-3623-42de-a216-5775c72650c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-6d495295-5b26-42bb-90b0-a6da9d4f8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-e2d8eebd-8d85-4506-b0fa-72e3b1091d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-888dc80d-4c6c-4159-8657-1b21f1f59da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-35ecae0e-86d8-4085-bd90-c2ea6761cb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-3b6bc390-b48a-4b72-adf3-3418417d1ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-830748eb-3634-43bc-a2ec-edfb78a17d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762527359-172.17.0.17-1595312519898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-365e88be-0111-4a7a-bda3-f9f900e37809,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-4bcb64a5-aef2-4059-a31f-eb3d55053776,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-cdb84469-ee62-4acb-bf60-4ee21040a886,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-2392a70c-ebc2-411d-9c07-c8cee4ac98a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-15f86118-9ddd-4379-a0cf-b1689ddddf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-bb69a5fe-aeff-4781-a116-c88bbc0ab730,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-f5d72846-f484-48f8-84eb-c68d70594c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-a30a06bf-69c4-4d05-8b60-7316c3b60920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762527359-172.17.0.17-1595312519898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-365e88be-0111-4a7a-bda3-f9f900e37809,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-4bcb64a5-aef2-4059-a31f-eb3d55053776,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-cdb84469-ee62-4acb-bf60-4ee21040a886,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-2392a70c-ebc2-411d-9c07-c8cee4ac98a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-15f86118-9ddd-4379-a0cf-b1689ddddf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-bb69a5fe-aeff-4781-a116-c88bbc0ab730,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-f5d72846-f484-48f8-84eb-c68d70594c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-a30a06bf-69c4-4d05-8b60-7316c3b60920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5147
