reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996396359-172.17.0.20-1596866118819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-1165cbe4-1900-4642-a5ed-a004c560e43e,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-2d957f92-cb3b-4aa2-8b64-8da50ed8ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-69fff261-afdb-445e-9cee-0c4c61f8f203,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-61aaf6cd-4ac0-4e97-a3e1-0dda63fc1447,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-acd8d19f-c85f-410f-8170-cbbdac948f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-fcde1e33-45b1-46d5-bc71-829f65b97c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-9a05b042-f0b0-42e5-b010-5dd712f35f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-b6630b86-2e77-45db-a391-d31c31b712c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996396359-172.17.0.20-1596866118819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-1165cbe4-1900-4642-a5ed-a004c560e43e,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-2d957f92-cb3b-4aa2-8b64-8da50ed8ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-69fff261-afdb-445e-9cee-0c4c61f8f203,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-61aaf6cd-4ac0-4e97-a3e1-0dda63fc1447,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-acd8d19f-c85f-410f-8170-cbbdac948f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-fcde1e33-45b1-46d5-bc71-829f65b97c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-9a05b042-f0b0-42e5-b010-5dd712f35f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-b6630b86-2e77-45db-a391-d31c31b712c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886905282-172.17.0.20-1596866158300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-27ca379f-56eb-46e8-baa9-8c9425e652d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-5f84c365-8fa3-4742-8865-7c0b166abe79,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-48021615-586d-4bb7-a447-ec2e420aa7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-4c34881c-06a1-464f-98b4-a2e5560af762,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-ecafe118-a06f-4053-9deb-388c22a951c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-cd1b9a2d-ca15-437a-8670-0538f79bbf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-54a116ae-1f24-4ca9-a037-c3606666dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-057d1b64-9e04-47e8-ac45-b45bcdaef595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886905282-172.17.0.20-1596866158300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-27ca379f-56eb-46e8-baa9-8c9425e652d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-5f84c365-8fa3-4742-8865-7c0b166abe79,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-48021615-586d-4bb7-a447-ec2e420aa7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-4c34881c-06a1-464f-98b4-a2e5560af762,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-ecafe118-a06f-4053-9deb-388c22a951c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-cd1b9a2d-ca15-437a-8670-0538f79bbf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-54a116ae-1f24-4ca9-a037-c3606666dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-057d1b64-9e04-47e8-ac45-b45bcdaef595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981156141-172.17.0.20-1596866548058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-abebc5b2-53ca-412c-89ea-e4522eaf0b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-ebc6ee75-aab9-451f-ae0d-1e6b8d103f31,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-8cb897bc-da33-4d79-a49c-348c60730365,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-0f7220a6-2e37-490d-8287-f8f37634ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-b4034c69-d354-46ab-a4ae-93e77a78bac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-268452d0-e94e-4e38-b5d8-ec70fef3e386,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-d101d63f-b314-4a63-9369-c79f907f9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-b2bd108a-cd8a-4128-919f-041d6bc9b2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981156141-172.17.0.20-1596866548058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-abebc5b2-53ca-412c-89ea-e4522eaf0b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-ebc6ee75-aab9-451f-ae0d-1e6b8d103f31,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-8cb897bc-da33-4d79-a49c-348c60730365,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-0f7220a6-2e37-490d-8287-f8f37634ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-b4034c69-d354-46ab-a4ae-93e77a78bac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-268452d0-e94e-4e38-b5d8-ec70fef3e386,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-d101d63f-b314-4a63-9369-c79f907f9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-b2bd108a-cd8a-4128-919f-041d6bc9b2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294103480-172.17.0.20-1596866819424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-425dcbef-257f-420a-922f-a946bbb27ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-7ba58000-830b-48cb-acb5-1c9d3505aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-05307506-1467-4e8b-ae0e-4417c72d8dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-e3b97525-73c3-4b8f-a36d-de86ecdda311,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-9e0826a4-d75d-42a1-a037-625a8edac353,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ffba6b10-9dbf-474d-9326-1fe2d10c0d72,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2be72cae-f931-4fdf-a651-c35b012bbfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-4c27976b-1e67-47e5-9eed-a588eaed1641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294103480-172.17.0.20-1596866819424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-425dcbef-257f-420a-922f-a946bbb27ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-7ba58000-830b-48cb-acb5-1c9d3505aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-05307506-1467-4e8b-ae0e-4417c72d8dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-e3b97525-73c3-4b8f-a36d-de86ecdda311,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-9e0826a4-d75d-42a1-a037-625a8edac353,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ffba6b10-9dbf-474d-9326-1fe2d10c0d72,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2be72cae-f931-4fdf-a651-c35b012bbfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-4c27976b-1e67-47e5-9eed-a588eaed1641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958131446-172.17.0.20-1596867000973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-10be29c0-7d23-448b-935c-5c32e585c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-e1f9d916-57fb-4ef7-8fcb-21c4a015be10,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-55705168-57cd-40a1-872b-c3741ad1efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-544cfe5e-3ddb-4584-94b3-1c8993e9467c,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-66cdb72d-f77f-4d43-9b31-3fe635ff990b,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-dcf047dc-0309-4409-a49f-24ffe474cd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-01e27a8f-eea8-4ffd-9afd-ea53499fed77,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-be03c9f1-5877-4930-9954-7dd44f2c41d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958131446-172.17.0.20-1596867000973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-10be29c0-7d23-448b-935c-5c32e585c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-e1f9d916-57fb-4ef7-8fcb-21c4a015be10,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-55705168-57cd-40a1-872b-c3741ad1efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-544cfe5e-3ddb-4584-94b3-1c8993e9467c,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-66cdb72d-f77f-4d43-9b31-3fe635ff990b,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-dcf047dc-0309-4409-a49f-24ffe474cd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-01e27a8f-eea8-4ffd-9afd-ea53499fed77,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-be03c9f1-5877-4930-9954-7dd44f2c41d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769426543-172.17.0.20-1596867085174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-cf887841-4d59-4786-8248-9bbbd7d65c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-166d5041-7742-4115-b40e-0a739473bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-c2251fa8-4f2e-400a-8c1e-4b00b0c47888,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-b67370a8-10da-4c9c-ae8c-a22d3dacf512,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-f9b39f12-65f4-4d79-899e-9cd1db97de20,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-029c38d3-64fc-4c4b-ac2f-4a22f3a8e218,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-5127a8fa-95cd-492e-9593-6d5bd32cabd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-6915f39e-2a67-47ac-ab5d-13c49b3c8e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769426543-172.17.0.20-1596867085174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-cf887841-4d59-4786-8248-9bbbd7d65c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-166d5041-7742-4115-b40e-0a739473bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-c2251fa8-4f2e-400a-8c1e-4b00b0c47888,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-b67370a8-10da-4c9c-ae8c-a22d3dacf512,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-f9b39f12-65f4-4d79-899e-9cd1db97de20,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-029c38d3-64fc-4c4b-ac2f-4a22f3a8e218,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-5127a8fa-95cd-492e-9593-6d5bd32cabd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-6915f39e-2a67-47ac-ab5d-13c49b3c8e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780778419-172.17.0.20-1596867125061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-1f1ee56a-7c2d-48ab-b88d-4df314e6e731,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-69ba7d69-bac0-4167-95e6-53428db90440,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-a0728d74-601d-41ff-9bb3-5271cad8fb48,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-5ed3992f-49ff-4828-b34b-3f5bbc85efab,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-e937d2bb-adfa-41c8-8314-dedeb9f624d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-2dcb079a-e539-4573-9603-e6ea2d94e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-8bf0f506-f16f-4e93-9da7-e7531feb2920,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-806f0ef9-0b4b-4a51-933f-b31b6d351379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780778419-172.17.0.20-1596867125061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-1f1ee56a-7c2d-48ab-b88d-4df314e6e731,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-69ba7d69-bac0-4167-95e6-53428db90440,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-a0728d74-601d-41ff-9bb3-5271cad8fb48,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-5ed3992f-49ff-4828-b34b-3f5bbc85efab,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-e937d2bb-adfa-41c8-8314-dedeb9f624d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-2dcb079a-e539-4573-9603-e6ea2d94e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-8bf0f506-f16f-4e93-9da7-e7531feb2920,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-806f0ef9-0b4b-4a51-933f-b31b6d351379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852015935-172.17.0.20-1596867274859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44662,DS-0a023ee5-2df5-47c5-9621-2d03cfcc4865,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-c3db8c98-b8d7-4db5-abc2-d1acb0e8dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-8953aca6-00b9-4723-82c5-14174846bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-1b1d59f1-5fa1-48b4-98e8-b07fdc09b691,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-725c415a-a630-46dd-86fb-6bd3677e3718,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-d5613999-f580-4f68-bdbc-30f030471f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-dd97b94c-1462-4f59-9a50-408ecbd33582,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-ea47057a-9118-4805-a87c-8a934a534299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852015935-172.17.0.20-1596867274859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44662,DS-0a023ee5-2df5-47c5-9621-2d03cfcc4865,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-c3db8c98-b8d7-4db5-abc2-d1acb0e8dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-8953aca6-00b9-4723-82c5-14174846bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-1b1d59f1-5fa1-48b4-98e8-b07fdc09b691,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-725c415a-a630-46dd-86fb-6bd3677e3718,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-d5613999-f580-4f68-bdbc-30f030471f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-dd97b94c-1462-4f59-9a50-408ecbd33582,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-ea47057a-9118-4805-a87c-8a934a534299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308602907-172.17.0.20-1596867702480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-90003d25-ff0c-401a-95ea-b9ffd6facf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-691c17e9-6fdd-4b11-bbf5-b5b8f9eb2caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-426d172b-109b-4df1-a91d-78822ef2790e,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-184d3045-ad6c-4f4f-a814-24c9144e1a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-e674e6b3-37ce-447a-a0e7-701bd2a17b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-1d220e39-fd15-418b-89cf-b42f48de63d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-b450ba89-f3f1-4d71-bdf4-67469eda10bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-31acb36b-67a0-40d8-b4f1-422b2e72bcd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308602907-172.17.0.20-1596867702480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-90003d25-ff0c-401a-95ea-b9ffd6facf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-691c17e9-6fdd-4b11-bbf5-b5b8f9eb2caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-426d172b-109b-4df1-a91d-78822ef2790e,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-184d3045-ad6c-4f4f-a814-24c9144e1a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-e674e6b3-37ce-447a-a0e7-701bd2a17b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-1d220e39-fd15-418b-89cf-b42f48de63d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-b450ba89-f3f1-4d71-bdf4-67469eda10bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-31acb36b-67a0-40d8-b4f1-422b2e72bcd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787020980-172.17.0.20-1596867847802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36384,DS-9130ed26-a8c8-43bc-ab74-6788b8ddd5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-75d9a922-4152-47ad-8021-be08ab24e667,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-aa764c03-52c7-486b-b1ec-beeb654d0093,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-fef1367d-58b4-4e8d-92bc-afc3d1d3fde7,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-cb10f000-2974-4881-bd5f-684143ac60dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-99fd6ff2-c796-4a9f-b1dd-ed51ff41db94,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-da746377-6a90-48dd-980e-f889e9f943de,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-0a7fc1ad-ec81-43b6-881e-88fd3a4d0372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787020980-172.17.0.20-1596867847802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36384,DS-9130ed26-a8c8-43bc-ab74-6788b8ddd5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-75d9a922-4152-47ad-8021-be08ab24e667,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-aa764c03-52c7-486b-b1ec-beeb654d0093,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-fef1367d-58b4-4e8d-92bc-afc3d1d3fde7,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-cb10f000-2974-4881-bd5f-684143ac60dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-99fd6ff2-c796-4a9f-b1dd-ed51ff41db94,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-da746377-6a90-48dd-980e-f889e9f943de,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-0a7fc1ad-ec81-43b6-881e-88fd3a4d0372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954370969-172.17.0.20-1596867890925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-5e1c3415-b58e-4d45-8b8a-37a5236832c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-9943df04-ad07-4866-8f92-1d8659a05639,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-3b372151-c595-4bda-bbf7-a3eb23c6d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-598f8401-fc9d-40f6-9e35-95c76c1be7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-901ba1bd-f26b-4778-904b-a451f4a188ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-56a5ade4-af66-4548-afa2-d15476cee327,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f3fc8182-28d1-4b1b-836a-83c278ef14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-a164dce9-5cd8-4d04-b77f-de0fa4b3cc6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954370969-172.17.0.20-1596867890925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-5e1c3415-b58e-4d45-8b8a-37a5236832c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-9943df04-ad07-4866-8f92-1d8659a05639,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-3b372151-c595-4bda-bbf7-a3eb23c6d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-598f8401-fc9d-40f6-9e35-95c76c1be7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-901ba1bd-f26b-4778-904b-a451f4a188ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-56a5ade4-af66-4548-afa2-d15476cee327,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f3fc8182-28d1-4b1b-836a-83c278ef14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-a164dce9-5cd8-4d04-b77f-de0fa4b3cc6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173770151-172.17.0.20-1596867990207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-e92aab8a-1e37-46bb-9729-515b2563fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-0f8be611-274a-470b-844d-7f7020ed0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-1476e39b-0b69-486f-b43d-c0d817f0cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-f3658af4-4808-4189-8a56-542ff02a4201,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-6bd15842-d713-462e-967f-2a2fc76747bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-37bdbfb1-3a9a-496d-8c3b-a6f64f116e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-c8a21d8c-81da-4928-abee-00bf54c608d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-48a922f5-7e74-4e21-8f91-fa4eceac238e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173770151-172.17.0.20-1596867990207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-e92aab8a-1e37-46bb-9729-515b2563fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-0f8be611-274a-470b-844d-7f7020ed0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-1476e39b-0b69-486f-b43d-c0d817f0cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-f3658af4-4808-4189-8a56-542ff02a4201,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-6bd15842-d713-462e-967f-2a2fc76747bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-37bdbfb1-3a9a-496d-8c3b-a6f64f116e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-c8a21d8c-81da-4928-abee-00bf54c608d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-48a922f5-7e74-4e21-8f91-fa4eceac238e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206860865-172.17.0.20-1596868518898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40573,DS-012749d5-63b4-4fc9-bb79-c618cdce9cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-e9f59b2c-e729-494f-9b75-0be29dc60e97,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-462a12d9-c8b0-46a1-84b0-cf416f1cba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-eaec62cb-ff4a-42d3-8282-2873d795ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-bd3bbca2-5ded-47f7-a912-321abe33a021,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-ee22a3b4-7c65-413f-9b7a-ff7bc656f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-6e38d1e6-263d-4d32-b20f-4c9afc25e5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-511210d1-7ecb-4990-b96f-e47bf87889ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206860865-172.17.0.20-1596868518898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40573,DS-012749d5-63b4-4fc9-bb79-c618cdce9cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-e9f59b2c-e729-494f-9b75-0be29dc60e97,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-462a12d9-c8b0-46a1-84b0-cf416f1cba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-eaec62cb-ff4a-42d3-8282-2873d795ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-bd3bbca2-5ded-47f7-a912-321abe33a021,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-ee22a3b4-7c65-413f-9b7a-ff7bc656f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-6e38d1e6-263d-4d32-b20f-4c9afc25e5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-511210d1-7ecb-4990-b96f-e47bf87889ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582583792-172.17.0.20-1596869166188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-81c83553-4137-4b2a-bb81-58cc98fc35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-78931ceb-ec2f-47f1-bc87-6f3b82f37158,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-ec4a0d9c-ca0a-43b0-ac5e-2b02e590aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-b9ac66ee-32ba-41cc-ad03-40a5ff69a858,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-3a32c451-a98a-4434-a13b-4968ecdb3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-6a2cd084-a5ac-4f69-b207-151b340214ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-6238b82c-94c5-4595-8e7c-4c7f92ce0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-ccb5feee-5648-4653-ad2a-f07a286c4bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582583792-172.17.0.20-1596869166188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-81c83553-4137-4b2a-bb81-58cc98fc35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-78931ceb-ec2f-47f1-bc87-6f3b82f37158,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-ec4a0d9c-ca0a-43b0-ac5e-2b02e590aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-b9ac66ee-32ba-41cc-ad03-40a5ff69a858,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-3a32c451-a98a-4434-a13b-4968ecdb3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-6a2cd084-a5ac-4f69-b207-151b340214ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-6238b82c-94c5-4595-8e7c-4c7f92ce0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-ccb5feee-5648-4653-ad2a-f07a286c4bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851253794-172.17.0.20-1596869308085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-16c29522-107e-49b2-bb18-835c0fd92a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-f1444cf8-767b-4ed3-ae44-75ded79265d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-9f516487-aede-4c7a-9245-b03021764eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-11a86053-cf90-451c-afcf-699703350729,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-0da29290-f0f9-4702-acab-483a963bdb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-c7a9e8f6-5aaa-455c-9377-f5e427d93aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-71e6ee2b-446c-4c37-b5e2-4d19d48b45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-77f7c357-67c5-4527-8682-190d425526e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851253794-172.17.0.20-1596869308085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-16c29522-107e-49b2-bb18-835c0fd92a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-f1444cf8-767b-4ed3-ae44-75ded79265d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-9f516487-aede-4c7a-9245-b03021764eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-11a86053-cf90-451c-afcf-699703350729,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-0da29290-f0f9-4702-acab-483a963bdb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-c7a9e8f6-5aaa-455c-9377-f5e427d93aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-71e6ee2b-446c-4c37-b5e2-4d19d48b45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-77f7c357-67c5-4527-8682-190d425526e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469097395-172.17.0.20-1596869614134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43004,DS-e4144a14-e8ca-48d4-882e-d1b843d3fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-92d3cbff-3d17-4196-aa41-3e80d332db69,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-d021c40f-379e-4ee7-b797-fa76687c2150,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-f39a96f4-ac38-487a-b0f2-12b159b4293b,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-797bfc12-f85e-474a-85d9-7d70dd03a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-49c65626-eb40-4041-86e3-37e189d47bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-33231da2-8f19-427b-a6d7-237f5eb37311,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-bd1aeedf-9c60-4ded-9f22-a186c98330f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469097395-172.17.0.20-1596869614134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43004,DS-e4144a14-e8ca-48d4-882e-d1b843d3fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-92d3cbff-3d17-4196-aa41-3e80d332db69,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-d021c40f-379e-4ee7-b797-fa76687c2150,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-f39a96f4-ac38-487a-b0f2-12b159b4293b,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-797bfc12-f85e-474a-85d9-7d70dd03a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-49c65626-eb40-4041-86e3-37e189d47bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-33231da2-8f19-427b-a6d7-237f5eb37311,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-bd1aeedf-9c60-4ded-9f22-a186c98330f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645624506-172.17.0.20-1596870217261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-71403a9b-8cbe-4e1d-9e9f-edf74e426590,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-30e4b666-bf29-417b-94f5-f9c6417922e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-4c76f2cc-4af6-469a-b621-f7bf6155aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-93ca365c-1cf4-4dee-9c81-99ca8bdfcfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-71074699-54f8-4dcf-a0ec-99e967093d98,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-44d753e2-09a4-4a83-a758-378eaeb18bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-8d90ec22-739a-4d59-a48f-a1b89a4a8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-bbdf9406-92c6-4f16-bd98-f75c1b53a279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645624506-172.17.0.20-1596870217261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-71403a9b-8cbe-4e1d-9e9f-edf74e426590,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-30e4b666-bf29-417b-94f5-f9c6417922e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-4c76f2cc-4af6-469a-b621-f7bf6155aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-93ca365c-1cf4-4dee-9c81-99ca8bdfcfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-71074699-54f8-4dcf-a0ec-99e967093d98,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-44d753e2-09a4-4a83-a758-378eaeb18bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-8d90ec22-739a-4d59-a48f-a1b89a4a8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-bbdf9406-92c6-4f16-bd98-f75c1b53a279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216657062-172.17.0.20-1596870373750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36187,DS-c1609dda-8c2c-41b1-b4fb-0c95e0be5e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-5a02641a-75a5-4118-869f-2864b1d2d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-787fb81b-4581-4c81-8aca-8b5847099279,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-e66e4f50-4b24-4f77-a4eb-2b6138861294,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-a281cea5-0530-468f-b226-350b4f231847,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-9ee4d6e1-fd38-40cf-8415-4e69bd6a318d,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-d3cd8783-f4f9-4f9c-8a7a-77048cc5cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-0ac4ab56-5f64-45a5-80b4-b201e024f8d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216657062-172.17.0.20-1596870373750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36187,DS-c1609dda-8c2c-41b1-b4fb-0c95e0be5e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-5a02641a-75a5-4118-869f-2864b1d2d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-787fb81b-4581-4c81-8aca-8b5847099279,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-e66e4f50-4b24-4f77-a4eb-2b6138861294,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-a281cea5-0530-468f-b226-350b4f231847,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-9ee4d6e1-fd38-40cf-8415-4e69bd6a318d,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-d3cd8783-f4f9-4f9c-8a7a-77048cc5cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-0ac4ab56-5f64-45a5-80b4-b201e024f8d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870308905-172.17.0.20-1596870475750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42735,DS-8a48393f-37cb-4033-a091-a91b03d7cb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-30e5935a-f55c-416c-88b9-4d03a40b49c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-785c422e-8f4d-4656-b628-44569df8caad,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-a537f097-88a5-4463-8bfb-e981a998053b,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-cd91987a-550c-479d-9c62-8f1903892631,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-114fe017-6f24-47b7-9b89-4417293896a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-88d04e04-4d96-48e3-99b0-6e05eae8ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-64791f8c-aae4-4487-b8d1-e8e808ec1302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870308905-172.17.0.20-1596870475750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42735,DS-8a48393f-37cb-4033-a091-a91b03d7cb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-30e5935a-f55c-416c-88b9-4d03a40b49c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-785c422e-8f4d-4656-b628-44569df8caad,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-a537f097-88a5-4463-8bfb-e981a998053b,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-cd91987a-550c-479d-9c62-8f1903892631,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-114fe017-6f24-47b7-9b89-4417293896a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-88d04e04-4d96-48e3-99b0-6e05eae8ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-64791f8c-aae4-4487-b8d1-e8e808ec1302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570434749-172.17.0.20-1596870512271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35725,DS-6ac630e7-258e-4709-b79e-546668c5fd61,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-bca9a3eb-22a9-4d7c-9239-5664921933db,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7efc7917-dc91-461f-a542-286cfe73ac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-ae8fbd20-6460-4b02-928d-af8700923a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-c6df9864-df22-4095-8b75-646a4b6e03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-48f7fd03-6799-4ff7-a338-6815a571af36,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-74722899-70a7-4cad-a0f7-e2addd3001e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-fd89195c-8b09-41f0-8ec8-474d4c3c88d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570434749-172.17.0.20-1596870512271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35725,DS-6ac630e7-258e-4709-b79e-546668c5fd61,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-bca9a3eb-22a9-4d7c-9239-5664921933db,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7efc7917-dc91-461f-a542-286cfe73ac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-ae8fbd20-6460-4b02-928d-af8700923a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-c6df9864-df22-4095-8b75-646a4b6e03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-48f7fd03-6799-4ff7-a338-6815a571af36,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-74722899-70a7-4cad-a0f7-e2addd3001e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-fd89195c-8b09-41f0-8ec8-474d4c3c88d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791684453-172.17.0.20-1596870830848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-3e985cf0-ae76-49f3-adb9-011c45c92bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-33246d5c-e62c-4d69-a8f1-0e54fc8b7620,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-5762cf14-e587-4bc1-b6dc-105d808a95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-f1d7bb7a-72fa-45c6-8760-09d39dca0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-eb6e3716-6462-418a-be78-eaffa18f27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-63816e76-aec6-4d16-9a8b-155cdf49eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-df7ccd1d-2837-478d-9846-4d75e2e8fee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-dac3df62-e171-4286-abe0-cbef053f2641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791684453-172.17.0.20-1596870830848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-3e985cf0-ae76-49f3-adb9-011c45c92bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-33246d5c-e62c-4d69-a8f1-0e54fc8b7620,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-5762cf14-e587-4bc1-b6dc-105d808a95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-f1d7bb7a-72fa-45c6-8760-09d39dca0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-eb6e3716-6462-418a-be78-eaffa18f27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-63816e76-aec6-4d16-9a8b-155cdf49eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-df7ccd1d-2837-478d-9846-4d75e2e8fee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-dac3df62-e171-4286-abe0-cbef053f2641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849980401-172.17.0.20-1596870908141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36504,DS-24c3606f-68fa-46c2-8bcb-e17dc33b5fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-4a3bea4c-8cda-4e19-8d86-0a23dc5fcd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-796d10d7-c36e-4d65-a80d-4689d7ccbb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-ca6d02bc-fc16-4e28-b327-b3924403b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-be24452b-1658-4874-903a-413eaadde857,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-3dd5afce-9341-4275-a6cd-d8b85cf761ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-0410170c-a14a-423f-8b4d-4d822f2858cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-8eeeead5-80ec-49f0-a721-c9ed1ba50814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849980401-172.17.0.20-1596870908141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36504,DS-24c3606f-68fa-46c2-8bcb-e17dc33b5fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-4a3bea4c-8cda-4e19-8d86-0a23dc5fcd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-796d10d7-c36e-4d65-a80d-4689d7ccbb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-ca6d02bc-fc16-4e28-b327-b3924403b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-be24452b-1658-4874-903a-413eaadde857,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-3dd5afce-9341-4275-a6cd-d8b85cf761ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-0410170c-a14a-423f-8b4d-4d822f2858cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-8eeeead5-80ec-49f0-a721-c9ed1ba50814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000472905-172.17.0.20-1596870973263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39604,DS-8232f3ed-d16d-4e2b-a6d9-9cbee9ad99d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-fbd160d8-a670-4f50-9e85-a8e572525972,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-1d873836-70ae-47e9-9d20-bbaa33401b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-cd2a5044-d022-4b16-878b-29d58a357e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-8cb3d490-2ff6-4392-ab6d-f970f304a94c,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-2bbc0298-a667-4c12-998b-5b4a85b1cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-8f510116-9e9a-47b8-bd32-20aab37df468,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0e0996b8-8cfb-4fcc-bb15-88393062cf84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000472905-172.17.0.20-1596870973263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39604,DS-8232f3ed-d16d-4e2b-a6d9-9cbee9ad99d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-fbd160d8-a670-4f50-9e85-a8e572525972,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-1d873836-70ae-47e9-9d20-bbaa33401b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-cd2a5044-d022-4b16-878b-29d58a357e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-8cb3d490-2ff6-4392-ab6d-f970f304a94c,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-2bbc0298-a667-4c12-998b-5b4a85b1cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-8f510116-9e9a-47b8-bd32-20aab37df468,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0e0996b8-8cfb-4fcc-bb15-88393062cf84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247661293-172.17.0.20-1596871086368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45699,DS-231fedd3-e966-4425-9085-76430175fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-8fc26e0f-8750-4b68-96e6-62d48a01d6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-fac6b964-8eb5-459e-8f58-05201cf7b600,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-cc791dc1-3667-464b-82f3-f58fd88d7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-47428c8d-d0b6-4a16-82df-3cab15d7b3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-537cfce5-dcd6-42f0-85d4-5995d2f3d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-dbc5b046-1670-4d97-bfae-ab48755c683b,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-ebd8f30d-90e3-4eea-8400-c43ea426be22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247661293-172.17.0.20-1596871086368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45699,DS-231fedd3-e966-4425-9085-76430175fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-8fc26e0f-8750-4b68-96e6-62d48a01d6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-fac6b964-8eb5-459e-8f58-05201cf7b600,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-cc791dc1-3667-464b-82f3-f58fd88d7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-47428c8d-d0b6-4a16-82df-3cab15d7b3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-537cfce5-dcd6-42f0-85d4-5995d2f3d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-dbc5b046-1670-4d97-bfae-ab48755c683b,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-ebd8f30d-90e3-4eea-8400-c43ea426be22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582235714-172.17.0.20-1596871122330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-afac820d-63a8-4b05-bcc7-0071963ada2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-6d5e6fc0-2192-42f6-9a69-e618aeaeae51,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-e30d4f29-bcbc-40e7-a538-e66514338bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-3c433d2f-8705-479e-90fb-27fcc1c72bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-87a04701-5f3c-4e84-a6fa-237e6a173398,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-b57528db-0be1-4054-869d-9845cad774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-69d08723-8e24-4889-8a31-6cdae5f82a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-fcda73ab-36bb-47de-92f3-793105b02776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582235714-172.17.0.20-1596871122330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-afac820d-63a8-4b05-bcc7-0071963ada2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-6d5e6fc0-2192-42f6-9a69-e618aeaeae51,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-e30d4f29-bcbc-40e7-a538-e66514338bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-3c433d2f-8705-479e-90fb-27fcc1c72bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-87a04701-5f3c-4e84-a6fa-237e6a173398,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-b57528db-0be1-4054-869d-9845cad774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-69d08723-8e24-4889-8a31-6cdae5f82a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-fcda73ab-36bb-47de-92f3-793105b02776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5292
