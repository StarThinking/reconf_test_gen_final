reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401931763-172.17.0.9-1595389447860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-40fbc0b7-e5c7-4a97-826a-47e0f56a298b,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-5a219193-752c-4b78-bc85-761450ae0efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-2e366a14-d402-4333-a53e-12bbbc44421b,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-34cf8129-63f8-4306-8b78-022105c5936c,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-135c919b-29ec-4d80-a924-901c3ee71cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-c1407c01-3594-424a-8510-82dde50a1238,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-6aabc3a3-7328-4036-a6f5-9b9e073fa961,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-fd74cc49-dbc5-4e59-a463-8161f4d369d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401931763-172.17.0.9-1595389447860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-40fbc0b7-e5c7-4a97-826a-47e0f56a298b,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-5a219193-752c-4b78-bc85-761450ae0efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-2e366a14-d402-4333-a53e-12bbbc44421b,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-34cf8129-63f8-4306-8b78-022105c5936c,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-135c919b-29ec-4d80-a924-901c3ee71cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-c1407c01-3594-424a-8510-82dde50a1238,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-6aabc3a3-7328-4036-a6f5-9b9e073fa961,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-fd74cc49-dbc5-4e59-a463-8161f4d369d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804515026-172.17.0.9-1595389516281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44482,DS-6b98908d-6d86-4254-bd01-bbe516852bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-65ae3e41-90c3-4a8f-b3fd-5df45a9a2017,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-71368ee4-e384-4958-9a39-d1f1726e7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-44d1c582-05d0-41e4-8e5e-9c68aff1e233,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-4e44782b-9abd-4878-828b-80d58dc08f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-9cc9702a-cc8f-477d-ba57-c02e8940243f,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-7c10b990-bd70-4a43-9b59-15b9343780de,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-64117e51-a2fa-46cb-80e2-f9685462e20c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804515026-172.17.0.9-1595389516281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44482,DS-6b98908d-6d86-4254-bd01-bbe516852bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-65ae3e41-90c3-4a8f-b3fd-5df45a9a2017,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-71368ee4-e384-4958-9a39-d1f1726e7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-44d1c582-05d0-41e4-8e5e-9c68aff1e233,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-4e44782b-9abd-4878-828b-80d58dc08f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-9cc9702a-cc8f-477d-ba57-c02e8940243f,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-7c10b990-bd70-4a43-9b59-15b9343780de,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-64117e51-a2fa-46cb-80e2-f9685462e20c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013524000-172.17.0.9-1595389762373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-0c455583-3062-4b30-945a-faa058dae080,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-3cc55e81-ab1a-4f94-96a0-79c173a06a30,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-46e263a1-933d-486e-beb5-5d0723655f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-82849d5a-c519-4715-971a-db5684c7b7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-3de2f1aa-f503-4fcf-a466-6aa72b4e31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-9cf07d32-3054-4508-ac5f-8dc8189abfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-dad31e86-bf79-4da0-b2aa-7bd9a0a82859,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-57b1b59e-839a-4c91-bfa7-88f7b6120e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013524000-172.17.0.9-1595389762373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-0c455583-3062-4b30-945a-faa058dae080,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-3cc55e81-ab1a-4f94-96a0-79c173a06a30,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-46e263a1-933d-486e-beb5-5d0723655f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-82849d5a-c519-4715-971a-db5684c7b7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-3de2f1aa-f503-4fcf-a466-6aa72b4e31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-9cf07d32-3054-4508-ac5f-8dc8189abfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-dad31e86-bf79-4da0-b2aa-7bd9a0a82859,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-57b1b59e-839a-4c91-bfa7-88f7b6120e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310195944-172.17.0.9-1595390018554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-d5aa5fec-8361-46d1-b205-db21869df49b,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-010cadf5-2e37-4174-8da7-e18e9a4d3346,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-5e63b581-9d71-4159-8821-2ef147b5685e,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-0522d18c-253c-49a1-a396-d68d98715126,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-465e8b13-59dc-476b-ba3f-f93d321d8071,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-c882374d-a90b-42f5-ba23-8b8d27c68fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-f87ab99f-8430-4016-829a-32cbd77c9ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-5596d0e6-448b-441f-8837-1ea8c6683f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310195944-172.17.0.9-1595390018554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-d5aa5fec-8361-46d1-b205-db21869df49b,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-010cadf5-2e37-4174-8da7-e18e9a4d3346,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-5e63b581-9d71-4159-8821-2ef147b5685e,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-0522d18c-253c-49a1-a396-d68d98715126,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-465e8b13-59dc-476b-ba3f-f93d321d8071,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-c882374d-a90b-42f5-ba23-8b8d27c68fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-f87ab99f-8430-4016-829a-32cbd77c9ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-5596d0e6-448b-441f-8837-1ea8c6683f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768893450-172.17.0.9-1595390142286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44992,DS-d4c70df9-165c-4ff5-8e7a-d866b9c0af7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-e79c5fad-ae62-4feb-b625-ca2b7d6384c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-3c24b035-b057-41c0-a267-7698326618a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e8e37562-fd4a-4f64-9aa7-075c4e38b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-bcd50f1f-7b08-4c66-b4a6-71722abe650f,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-94426529-9833-496b-a7be-fb80161749ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-97c1775e-9695-4ee8-8e09-dd9c8fdbda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-b83a211f-f26f-425d-a079-a57cd8ab6d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768893450-172.17.0.9-1595390142286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44992,DS-d4c70df9-165c-4ff5-8e7a-d866b9c0af7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-e79c5fad-ae62-4feb-b625-ca2b7d6384c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-3c24b035-b057-41c0-a267-7698326618a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e8e37562-fd4a-4f64-9aa7-075c4e38b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-bcd50f1f-7b08-4c66-b4a6-71722abe650f,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-94426529-9833-496b-a7be-fb80161749ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-97c1775e-9695-4ee8-8e09-dd9c8fdbda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-b83a211f-f26f-425d-a079-a57cd8ab6d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191141580-172.17.0.9-1595390303689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-45cfdedb-8d2a-4d74-a328-8577e7153003,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-6b3eaca3-ac6e-4337-943d-edcb7ce6b170,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-1cbf8f7a-6cee-4220-98b8-7d53dc855ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-10a261a5-c2fa-402f-8f48-677371d9844f,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ba5d49fe-4221-450b-9c69-e218d4bfd7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-0edb62fa-69fe-436a-845e-c011726ebddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f94cd131-96fd-4303-ac61-26c3f5a05952,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-1e846756-51d3-4cf0-8a45-9fdcfc8b9cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191141580-172.17.0.9-1595390303689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-45cfdedb-8d2a-4d74-a328-8577e7153003,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-6b3eaca3-ac6e-4337-943d-edcb7ce6b170,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-1cbf8f7a-6cee-4220-98b8-7d53dc855ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-10a261a5-c2fa-402f-8f48-677371d9844f,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ba5d49fe-4221-450b-9c69-e218d4bfd7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-0edb62fa-69fe-436a-845e-c011726ebddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f94cd131-96fd-4303-ac61-26c3f5a05952,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-1e846756-51d3-4cf0-8a45-9fdcfc8b9cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102972070-172.17.0.9-1595390465368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34592,DS-4d7760eb-d5eb-48c6-b2fe-4a3a18e1784d,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-34433400-1652-4ca0-964a-beb018e913b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-b6e3e8eb-a8ca-4b43-b3c3-ee4e2e0d1a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-28023d87-9842-4290-a54d-0c2f728dc703,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-32fc71bb-62c0-41f3-80d4-ab4d811e526b,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-fe3870b3-5516-4cca-9dc6-da9ee3e7af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-76adc11d-33bd-4220-b8d1-0aa079dd09f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-127d53e1-7fb4-400d-9bdc-433965fc1628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102972070-172.17.0.9-1595390465368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34592,DS-4d7760eb-d5eb-48c6-b2fe-4a3a18e1784d,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-34433400-1652-4ca0-964a-beb018e913b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-b6e3e8eb-a8ca-4b43-b3c3-ee4e2e0d1a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-28023d87-9842-4290-a54d-0c2f728dc703,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-32fc71bb-62c0-41f3-80d4-ab4d811e526b,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-fe3870b3-5516-4cca-9dc6-da9ee3e7af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-76adc11d-33bd-4220-b8d1-0aa079dd09f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-127d53e1-7fb4-400d-9bdc-433965fc1628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138567418-172.17.0.9-1595391223207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-4cc248f7-faa1-4d36-8cd0-feb884f28864,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-47dbd7db-778f-4df4-ae59-5e49dc73dd52,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e4ae6b0b-5ae0-4f4d-a85d-735e3ff0982e,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-40f95df4-4626-49b9-9730-e8afa47e5195,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-ff26fd0c-19c0-420a-8f78-24105082c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-1caf566e-48af-4429-a25f-cd78e0e34e78,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-316c8da6-2fc3-4421-952f-0f7173f625fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-b1e6afd5-7b14-4e96-acc2-c5e1d7207df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138567418-172.17.0.9-1595391223207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-4cc248f7-faa1-4d36-8cd0-feb884f28864,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-47dbd7db-778f-4df4-ae59-5e49dc73dd52,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e4ae6b0b-5ae0-4f4d-a85d-735e3ff0982e,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-40f95df4-4626-49b9-9730-e8afa47e5195,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-ff26fd0c-19c0-420a-8f78-24105082c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-1caf566e-48af-4429-a25f-cd78e0e34e78,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-316c8da6-2fc3-4421-952f-0f7173f625fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-b1e6afd5-7b14-4e96-acc2-c5e1d7207df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555156995-172.17.0.9-1595391446069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-267395ca-6bb8-498c-bdfd-8a02b1b2804e,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-7ca249b1-f87d-4d26-ba54-5c35549af703,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-a67d6ca9-85e9-41e3-84be-1adff00f1a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-086227d7-3f1e-47a5-874b-672e8029cf19,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-68eebed6-5a85-4d7c-afdc-f1e7e13544af,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-cda0e28e-dba2-48b8-a9f9-449aed8246b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-7ee56fea-f68e-4ed9-b147-d3ced29454ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-009bfefe-6725-4cdd-96d9-6322737bafb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555156995-172.17.0.9-1595391446069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-267395ca-6bb8-498c-bdfd-8a02b1b2804e,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-7ca249b1-f87d-4d26-ba54-5c35549af703,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-a67d6ca9-85e9-41e3-84be-1adff00f1a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-086227d7-3f1e-47a5-874b-672e8029cf19,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-68eebed6-5a85-4d7c-afdc-f1e7e13544af,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-cda0e28e-dba2-48b8-a9f9-449aed8246b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-7ee56fea-f68e-4ed9-b147-d3ced29454ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-009bfefe-6725-4cdd-96d9-6322737bafb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909037320-172.17.0.9-1595391610073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40853,DS-c457fce5-0b53-45e3-8c18-2cc978496138,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-4f645b11-d679-4d19-bcd0-c41b39ee963b,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-6c920901-b608-4b2f-a811-60f9a72f7238,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-1b2540ad-0733-41d3-befc-9095015615fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-4fc67298-3e66-437d-9af5-6ce06d03df77,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-c823a69b-16cb-49d8-853f-5bee14631ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-86bc1995-90ef-4acc-afb3-1e6fb6fc2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-535744e7-f508-47a2-a889-69a513bdb676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909037320-172.17.0.9-1595391610073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40853,DS-c457fce5-0b53-45e3-8c18-2cc978496138,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-4f645b11-d679-4d19-bcd0-c41b39ee963b,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-6c920901-b608-4b2f-a811-60f9a72f7238,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-1b2540ad-0733-41d3-befc-9095015615fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-4fc67298-3e66-437d-9af5-6ce06d03df77,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-c823a69b-16cb-49d8-853f-5bee14631ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-86bc1995-90ef-4acc-afb3-1e6fb6fc2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-535744e7-f508-47a2-a889-69a513bdb676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409721769-172.17.0.9-1595391675624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-873165a2-0af8-4192-adb5-c26437e5d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-d34335ef-07d5-41e2-998d-1e91b6d117e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-6437dd85-93b3-4d70-86d0-1ea9ef1d163f,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-9ae598c0-569e-43dc-a7ff-3afad45f9652,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-74de6e9e-955c-489e-a7fa-3b57aeb9dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-3701e36d-db83-4a55-b017-5d7425171da5,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-0b2d0d83-18cc-4ffc-a01a-37be0421c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-bf18b090-9840-4e8f-af99-fe4d80d2be93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409721769-172.17.0.9-1595391675624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-873165a2-0af8-4192-adb5-c26437e5d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-d34335ef-07d5-41e2-998d-1e91b6d117e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-6437dd85-93b3-4d70-86d0-1ea9ef1d163f,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-9ae598c0-569e-43dc-a7ff-3afad45f9652,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-74de6e9e-955c-489e-a7fa-3b57aeb9dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-3701e36d-db83-4a55-b017-5d7425171da5,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-0b2d0d83-18cc-4ffc-a01a-37be0421c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-bf18b090-9840-4e8f-af99-fe4d80d2be93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805312985-172.17.0.9-1595392665142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-c616c6b9-f4d7-4c66-bc48-36f590e1d134,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-b225c263-7cca-43e8-809b-7812963a4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-f057cd21-d0e5-4e18-ac4d-d866632c3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-5715cb1b-b76a-4fb1-a49e-10e56f936667,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-2889b126-b6f4-4801-825e-2becda823c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-4e51867e-6310-425b-94b1-ef5a3c7c9ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-e284edf6-a563-40eb-be94-cdbd11430304,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-1867c589-39eb-4e28-97fb-8a5eba7963ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805312985-172.17.0.9-1595392665142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-c616c6b9-f4d7-4c66-bc48-36f590e1d134,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-b225c263-7cca-43e8-809b-7812963a4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-f057cd21-d0e5-4e18-ac4d-d866632c3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-5715cb1b-b76a-4fb1-a49e-10e56f936667,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-2889b126-b6f4-4801-825e-2becda823c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-4e51867e-6310-425b-94b1-ef5a3c7c9ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-e284edf6-a563-40eb-be94-cdbd11430304,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-1867c589-39eb-4e28-97fb-8a5eba7963ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625562547-172.17.0.9-1595392821847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-f70f59d5-8245-4192-adff-9cfc3ae8a022,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-c1811ca1-1b57-49d7-8339-39419b92cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-4b683c41-c6d7-4918-90de-60fa4644a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-2518f4b8-e0c7-4cc7-be3c-50f928a3b586,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-8862d360-e3e2-4a6a-93a3-d50e0bd31b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-f216809b-4cf1-47f1-8ff9-7688322c35f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-65944faa-da03-4f3a-8cb2-cc3377cdc2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-fb9bb54f-174c-47ef-8ffa-88331edf28a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625562547-172.17.0.9-1595392821847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-f70f59d5-8245-4192-adff-9cfc3ae8a022,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-c1811ca1-1b57-49d7-8339-39419b92cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-4b683c41-c6d7-4918-90de-60fa4644a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-2518f4b8-e0c7-4cc7-be3c-50f928a3b586,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-8862d360-e3e2-4a6a-93a3-d50e0bd31b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-f216809b-4cf1-47f1-8ff9-7688322c35f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-65944faa-da03-4f3a-8cb2-cc3377cdc2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-fb9bb54f-174c-47ef-8ffa-88331edf28a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732543744-172.17.0.9-1595393395448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-a6b93edc-de77-440a-a7eb-9f99a40b697f,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-cff12a3a-1cfd-4940-b9ae-9be7698931a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-b3eae6bb-5f75-4712-8e62-db94effec4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-5677df57-e590-454e-9325-991738ebc5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-5ba12c40-242f-465f-b42e-db00adce8f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-ac2dd830-df7c-4182-ba67-4ef77e7a4258,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-a8571330-f737-42f1-8a01-d901078185d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-894e6c53-02f8-41c5-9bf3-614e4ac33bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732543744-172.17.0.9-1595393395448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-a6b93edc-de77-440a-a7eb-9f99a40b697f,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-cff12a3a-1cfd-4940-b9ae-9be7698931a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-b3eae6bb-5f75-4712-8e62-db94effec4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-5677df57-e590-454e-9325-991738ebc5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-5ba12c40-242f-465f-b42e-db00adce8f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-ac2dd830-df7c-4182-ba67-4ef77e7a4258,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-a8571330-f737-42f1-8a01-d901078185d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-894e6c53-02f8-41c5-9bf3-614e4ac33bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4859
