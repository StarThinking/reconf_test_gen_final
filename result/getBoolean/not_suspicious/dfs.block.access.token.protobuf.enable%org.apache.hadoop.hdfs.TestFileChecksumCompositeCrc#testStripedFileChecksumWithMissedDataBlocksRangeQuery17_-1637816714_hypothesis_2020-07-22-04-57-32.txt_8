reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757995531-172.17.0.13-1595393988363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-32902e0a-d515-4700-b2db-20fadac80ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-31efa8a4-9e68-44e0-99bb-80f20755ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-459715c8-23c7-48f1-b781-4ff7c390a38f,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-42322217-4354-446c-a1eb-7dbdf36d47e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-ff56fb89-e245-4447-a9d0-84d1e68f7659,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-59a9ca82-4f27-4721-9d3b-c72beb703653,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-f7dcf6fe-45ed-46cb-b972-f2844919acee,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-caab8f90-bda8-4089-ab4a-3b50704c40a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757995531-172.17.0.13-1595393988363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-32902e0a-d515-4700-b2db-20fadac80ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-31efa8a4-9e68-44e0-99bb-80f20755ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-459715c8-23c7-48f1-b781-4ff7c390a38f,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-42322217-4354-446c-a1eb-7dbdf36d47e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-ff56fb89-e245-4447-a9d0-84d1e68f7659,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-59a9ca82-4f27-4721-9d3b-c72beb703653,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-f7dcf6fe-45ed-46cb-b972-f2844919acee,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-caab8f90-bda8-4089-ab4a-3b50704c40a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491717948-172.17.0.13-1595394497550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45038,DS-4993935a-a30f-4317-8b5c-f1666d578c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-ea0b6aed-4801-4618-9aaf-89a4b6aa9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-11a9d46c-e754-4849-924a-406d2d12cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-e7246038-cfc9-4d7a-bc22-77d367b89b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-0234bd93-a0f2-44d9-a795-65c2d94bd214,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-7367b90f-6a09-4031-9e7e-f925acf78357,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-ac45f5c0-8dac-4e81-93e0-4408fa340335,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-56416547-bd01-4455-8e30-2ac9a617f467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491717948-172.17.0.13-1595394497550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45038,DS-4993935a-a30f-4317-8b5c-f1666d578c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-ea0b6aed-4801-4618-9aaf-89a4b6aa9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-11a9d46c-e754-4849-924a-406d2d12cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-e7246038-cfc9-4d7a-bc22-77d367b89b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-0234bd93-a0f2-44d9-a795-65c2d94bd214,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-7367b90f-6a09-4031-9e7e-f925acf78357,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-ac45f5c0-8dac-4e81-93e0-4408fa340335,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-56416547-bd01-4455-8e30-2ac9a617f467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522388939-172.17.0.13-1595394569290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-bfbd1a20-0a25-4d65-90b4-d09a4e85a1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-c4a7c649-54a6-43df-a856-a23190c8f9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-fb4a6e26-4698-4f4d-ba45-81f3d612d206,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-edc3009b-3f71-4b4d-80aa-fc076fa25748,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-158a8e9d-f09d-4033-a7ce-f6808c0cd61c,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-e4688af4-b433-4b5f-aa7b-d71a0f8535ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-d5c4a948-9897-417d-9e53-9d0129bef73f,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-38f9363e-04ae-47b4-a85d-6bd6b7fbc622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522388939-172.17.0.13-1595394569290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-bfbd1a20-0a25-4d65-90b4-d09a4e85a1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-c4a7c649-54a6-43df-a856-a23190c8f9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-fb4a6e26-4698-4f4d-ba45-81f3d612d206,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-edc3009b-3f71-4b4d-80aa-fc076fa25748,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-158a8e9d-f09d-4033-a7ce-f6808c0cd61c,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-e4688af4-b433-4b5f-aa7b-d71a0f8535ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-d5c4a948-9897-417d-9e53-9d0129bef73f,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-38f9363e-04ae-47b4-a85d-6bd6b7fbc622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411753141-172.17.0.13-1595394988425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-9cf57bc5-e9d3-4030-b085-925fdf72b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-542ed9ed-40bb-4677-9539-f71de30bcd58,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-76ab8408-1132-48fd-84df-f781ed17348f,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-8cff1bf2-a83d-412e-8289-ecbd9860f251,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-6873a583-e221-4a21-b88c-6259113e3839,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-78caaf44-00d1-4ead-9338-f0729ec631a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-841ff1a1-ce78-4158-a879-c9eaacea1413,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-6cb8b50a-fa4c-4ac6-af99-22a2aed7e9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411753141-172.17.0.13-1595394988425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-9cf57bc5-e9d3-4030-b085-925fdf72b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-542ed9ed-40bb-4677-9539-f71de30bcd58,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-76ab8408-1132-48fd-84df-f781ed17348f,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-8cff1bf2-a83d-412e-8289-ecbd9860f251,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-6873a583-e221-4a21-b88c-6259113e3839,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-78caaf44-00d1-4ead-9338-f0729ec631a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-841ff1a1-ce78-4158-a879-c9eaacea1413,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-6cb8b50a-fa4c-4ac6-af99-22a2aed7e9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026719737-172.17.0.13-1595396215646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-9d801239-7566-490f-b06d-7166ad4229c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-361d2efd-1917-4f14-85ab-90bb6d9855ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-c43d545f-3ea1-4706-b8bc-b6a37c815c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c5e9957c-90d1-4ef2-b1c3-52522edc8b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-c3efb76e-d934-4307-829f-5d1db34cca25,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-ad78903f-bf85-4977-a09e-30391523b1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-19edd335-c0f3-4371-bfce-522c018d0109,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-56983a9b-9afa-4807-8b2f-526611a35cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026719737-172.17.0.13-1595396215646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-9d801239-7566-490f-b06d-7166ad4229c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-361d2efd-1917-4f14-85ab-90bb6d9855ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-c43d545f-3ea1-4706-b8bc-b6a37c815c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c5e9957c-90d1-4ef2-b1c3-52522edc8b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-c3efb76e-d934-4307-829f-5d1db34cca25,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-ad78903f-bf85-4977-a09e-30391523b1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-19edd335-c0f3-4371-bfce-522c018d0109,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-56983a9b-9afa-4807-8b2f-526611a35cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575300290-172.17.0.13-1595396405750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-66f1ac82-30f2-4c73-adef-047369a34dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-22853fba-1559-442c-8404-ae667a9e484e,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-9164d0b2-0fcc-487d-98e8-12736d365b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-bfd4dd7a-985b-44fb-a915-31c8c8b8581f,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-734d296e-7ef4-41d5-938c-860107549a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-e9e6b52d-eb6a-41c7-8a98-603c8b028fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-6e683558-dee3-4192-aa73-48d3e74ed8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-2356cea1-ab47-4fae-993f-9acd353ed5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575300290-172.17.0.13-1595396405750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-66f1ac82-30f2-4c73-adef-047369a34dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-22853fba-1559-442c-8404-ae667a9e484e,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-9164d0b2-0fcc-487d-98e8-12736d365b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-bfd4dd7a-985b-44fb-a915-31c8c8b8581f,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-734d296e-7ef4-41d5-938c-860107549a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-e9e6b52d-eb6a-41c7-8a98-603c8b028fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-6e683558-dee3-4192-aa73-48d3e74ed8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-2356cea1-ab47-4fae-993f-9acd353ed5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867560786-172.17.0.13-1595396729946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43072,DS-44df4aba-785d-4b80-a968-87b30b1db444,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-7fd7fa03-5090-435c-a8e2-e3916fc4ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-7d6abd5a-46fa-4b3e-bae6-80166b23b042,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-3da85a71-4ec3-4d54-b6eb-eec38a9c2ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-15628870-94f5-4594-a082-31e3eca1a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f22809ba-21d1-4acf-b98e-79f9881dbed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-2507c02c-d9c1-4cad-9de1-520d9048b972,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-1da1c5a1-054d-45d7-b3c7-50d26f9d7136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867560786-172.17.0.13-1595396729946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43072,DS-44df4aba-785d-4b80-a968-87b30b1db444,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-7fd7fa03-5090-435c-a8e2-e3916fc4ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-7d6abd5a-46fa-4b3e-bae6-80166b23b042,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-3da85a71-4ec3-4d54-b6eb-eec38a9c2ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-15628870-94f5-4594-a082-31e3eca1a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f22809ba-21d1-4acf-b98e-79f9881dbed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-2507c02c-d9c1-4cad-9de1-520d9048b972,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-1da1c5a1-054d-45d7-b3c7-50d26f9d7136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843741111-172.17.0.13-1595396757569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35240,DS-aa865230-fb3a-403e-9da0-bc614071dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-e785a92a-5618-49d6-b198-ac0e1c4f831f,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-1f8b0b61-10ae-4117-82c2-9b34df939b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-a9d4b1fc-4fe5-4ee8-907e-d1ac91bffecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-18063e2d-f6f2-47d8-be9e-3579013304a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-a2ca23a3-6cb7-4d6c-b8ec-ddd153c8eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-3c2f1d75-9048-432e-aebd-b9dee472083f,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-75e54b6b-d2ad-4f07-9efa-b5a8e806fa60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843741111-172.17.0.13-1595396757569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35240,DS-aa865230-fb3a-403e-9da0-bc614071dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-e785a92a-5618-49d6-b198-ac0e1c4f831f,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-1f8b0b61-10ae-4117-82c2-9b34df939b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-a9d4b1fc-4fe5-4ee8-907e-d1ac91bffecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-18063e2d-f6f2-47d8-be9e-3579013304a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-a2ca23a3-6cb7-4d6c-b8ec-ddd153c8eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-3c2f1d75-9048-432e-aebd-b9dee472083f,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-75e54b6b-d2ad-4f07-9efa-b5a8e806fa60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842835403-172.17.0.13-1595396829000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-faa9631a-e111-4c88-af16-9a7a68b23af4,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-a38336b3-0385-4d35-9af6-cfdd96015593,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-f2a5cf63-0eff-478b-a551-74a3ac145ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-f5774170-5b82-45e0-949a-accc3844261e,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-2807001e-5ceb-4f31-9313-97ba624b6a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-acbda708-1578-446f-aef5-4b4bb47ae7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-2775f0a9-74a5-44ee-83ea-46883dcd5230,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-21387304-e06f-41d1-ac03-81535084c661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842835403-172.17.0.13-1595396829000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-faa9631a-e111-4c88-af16-9a7a68b23af4,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-a38336b3-0385-4d35-9af6-cfdd96015593,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-f2a5cf63-0eff-478b-a551-74a3ac145ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-f5774170-5b82-45e0-949a-accc3844261e,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-2807001e-5ceb-4f31-9313-97ba624b6a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-acbda708-1578-446f-aef5-4b4bb47ae7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-2775f0a9-74a5-44ee-83ea-46883dcd5230,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-21387304-e06f-41d1-ac03-81535084c661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086084481-172.17.0.13-1595397037591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-f58edca3-7b15-4049-ad68-b06615852ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-2687e7fd-2f10-42ab-98f2-eed8b55432a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-e28105a7-61e9-4ae3-ada9-60b4af90d653,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-92291e42-6a21-4b90-8d82-4acf22c59889,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-dbf683da-00af-4ef6-a17b-7309e94953cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-d3e72d7d-0df3-441f-8773-09fa5afea111,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-968c0965-791f-4fcd-91d5-b503572396ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-d5bbe318-c82f-4505-9bdf-3411cd8e0bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086084481-172.17.0.13-1595397037591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-f58edca3-7b15-4049-ad68-b06615852ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-2687e7fd-2f10-42ab-98f2-eed8b55432a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-e28105a7-61e9-4ae3-ada9-60b4af90d653,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-92291e42-6a21-4b90-8d82-4acf22c59889,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-dbf683da-00af-4ef6-a17b-7309e94953cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-d3e72d7d-0df3-441f-8773-09fa5afea111,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-968c0965-791f-4fcd-91d5-b503572396ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-d5bbe318-c82f-4505-9bdf-3411cd8e0bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514683826-172.17.0.13-1595397068733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-19c2a286-0fb0-432d-88aa-f9cca24f3839,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-0245a84d-23d1-46a3-a021-89563a39ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-27112290-c8fc-48b3-959a-829d330255be,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-ab561d3b-c44d-4b5b-bccd-bca95fbdbdad,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3c6687e7-faa4-45e4-aaf6-81636e39157a,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-e20de762-0abd-452f-a987-c4b29d0e6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-047d5d6c-c494-4ca8-aaee-5c5115b3212c,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-d60a4f13-1a17-4b15-aa8d-2ae1eef440bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514683826-172.17.0.13-1595397068733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-19c2a286-0fb0-432d-88aa-f9cca24f3839,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-0245a84d-23d1-46a3-a021-89563a39ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-27112290-c8fc-48b3-959a-829d330255be,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-ab561d3b-c44d-4b5b-bccd-bca95fbdbdad,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3c6687e7-faa4-45e4-aaf6-81636e39157a,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-e20de762-0abd-452f-a987-c4b29d0e6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-047d5d6c-c494-4ca8-aaee-5c5115b3212c,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-d60a4f13-1a17-4b15-aa8d-2ae1eef440bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693948404-172.17.0.13-1595397816460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37502,DS-d65e02ef-25c8-4132-ab1f-b304a618fc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-a29039e0-b55b-4502-88ce-5f1b98fcf52a,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-6a720759-7177-49ce-875e-aec6d7f9616b,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ed3b3c3c-7975-4fd4-bc7c-968dc70d8e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-9ae94582-fdb5-461d-9fa1-7e2468d31290,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-c0e22f37-fcd9-46ba-8a8e-e0b14d1f0d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-a41d7e23-d0c6-43aa-b235-485cb993e2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-1277cd6a-2ae3-48f9-b2aa-6b6b4ed24d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693948404-172.17.0.13-1595397816460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37502,DS-d65e02ef-25c8-4132-ab1f-b304a618fc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-a29039e0-b55b-4502-88ce-5f1b98fcf52a,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-6a720759-7177-49ce-875e-aec6d7f9616b,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ed3b3c3c-7975-4fd4-bc7c-968dc70d8e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-9ae94582-fdb5-461d-9fa1-7e2468d31290,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-c0e22f37-fcd9-46ba-8a8e-e0b14d1f0d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-a41d7e23-d0c6-43aa-b235-485cb993e2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-1277cd6a-2ae3-48f9-b2aa-6b6b4ed24d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5474
