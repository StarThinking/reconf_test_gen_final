reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061140896-172.17.0.21-1596958743603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-23a93ddc-9053-4542-950b-6fc62f095f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-e9909253-3eba-486e-b000-0d9170ac3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-edd89431-4a79-49c4-a025-1e12f52f569b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-ebb3b02e-d4e8-410a-86a9-4a4a07bc4795,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-fe370bfe-06f7-4f10-b7eb-ff122fe2c5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-b8bd626d-2c69-4979-be0d-e783758f2149,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-c9af00a7-6d1d-41c5-b094-aaa305374d71,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-4c44386c-abc7-486a-9e6c-916ff7d3fcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061140896-172.17.0.21-1596958743603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-23a93ddc-9053-4542-950b-6fc62f095f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-e9909253-3eba-486e-b000-0d9170ac3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-edd89431-4a79-49c4-a025-1e12f52f569b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-ebb3b02e-d4e8-410a-86a9-4a4a07bc4795,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-fe370bfe-06f7-4f10-b7eb-ff122fe2c5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-b8bd626d-2c69-4979-be0d-e783758f2149,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-c9af00a7-6d1d-41c5-b094-aaa305374d71,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-4c44386c-abc7-486a-9e6c-916ff7d3fcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735198921-172.17.0.21-1596958878268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41389,DS-b21a9529-9d2d-4b81-950d-3ef8918fdca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-5a9abe62-b285-4878-a7d4-5e3b3aca14d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-c9e5d367-1818-48ba-af8e-9f3d4d5f5eca,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-c419fe02-e287-47ac-88d5-3f95dcbf95ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-e3abc560-fb42-46fc-93aa-cf2b37fccb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-3cc88703-8b36-43cf-9546-738e081a8f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-22e499bb-46fc-40c1-99e2-121cca950390,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-61fe1b11-889e-43ae-a7c3-c8a34ca9c761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735198921-172.17.0.21-1596958878268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41389,DS-b21a9529-9d2d-4b81-950d-3ef8918fdca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-5a9abe62-b285-4878-a7d4-5e3b3aca14d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-c9e5d367-1818-48ba-af8e-9f3d4d5f5eca,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-c419fe02-e287-47ac-88d5-3f95dcbf95ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-e3abc560-fb42-46fc-93aa-cf2b37fccb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-3cc88703-8b36-43cf-9546-738e081a8f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-22e499bb-46fc-40c1-99e2-121cca950390,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-61fe1b11-889e-43ae-a7c3-c8a34ca9c761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11604549-172.17.0.21-1596959055363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42355,DS-b679a8f8-2257-4f4f-b036-3fb55e13c921,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-a45fd726-e715-4b09-b085-828cf92618d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-5c75133e-b185-46de-a4cb-00195e17c035,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e9fec501-6327-4a2c-9b1d-fe2d3d30f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-a473fbde-58f6-4c9d-a3ad-be568da70613,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-a1421bed-f83e-45ec-ba29-ff90f251b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-bcb0bba2-7fc2-4f93-8635-c0959d208266,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d492a10d-4d6e-450c-85c6-68352a9e90ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11604549-172.17.0.21-1596959055363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42355,DS-b679a8f8-2257-4f4f-b036-3fb55e13c921,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-a45fd726-e715-4b09-b085-828cf92618d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-5c75133e-b185-46de-a4cb-00195e17c035,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e9fec501-6327-4a2c-9b1d-fe2d3d30f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-a473fbde-58f6-4c9d-a3ad-be568da70613,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-a1421bed-f83e-45ec-ba29-ff90f251b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-bcb0bba2-7fc2-4f93-8635-c0959d208266,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d492a10d-4d6e-450c-85c6-68352a9e90ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583795736-172.17.0.21-1596960055119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-ed0e2f21-b891-4d98-9fe4-83bc08188455,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-ac694d01-e4ac-486d-b0d3-d6dd394dee48,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-63020a4e-7944-480c-8a45-68de9d63e37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-932e4a96-0451-4738-99c5-ab956155aa26,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-7b8b1b7f-cf3a-4b9c-a08a-b7b8e6ccd523,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-ed1c50b6-89cd-46b2-ad1b-535122fcfe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-adb6ebde-9928-4e9c-8992-4516166ca8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-96f5af77-a715-4e56-8a12-e6adebef3fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583795736-172.17.0.21-1596960055119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-ed0e2f21-b891-4d98-9fe4-83bc08188455,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-ac694d01-e4ac-486d-b0d3-d6dd394dee48,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-63020a4e-7944-480c-8a45-68de9d63e37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-932e4a96-0451-4738-99c5-ab956155aa26,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-7b8b1b7f-cf3a-4b9c-a08a-b7b8e6ccd523,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-ed1c50b6-89cd-46b2-ad1b-535122fcfe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-adb6ebde-9928-4e9c-8992-4516166ca8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-96f5af77-a715-4e56-8a12-e6adebef3fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835628479-172.17.0.21-1596960315535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-f7d94bbc-b4ee-43db-a6ac-c68c1e3b1386,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-daf26d9a-ca9b-4647-be7f-0f53b16a1c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-7f971571-bcb5-423c-a84f-a167dd098c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-36af3a22-c2d6-435f-956a-0e68c75dcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-056b6331-19a5-4e1a-ab89-07d9b384cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-0599498e-a963-4127-9285-7e771343214d,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-7bee1818-c7f6-4e7c-9972-77b74df0f35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-c140671d-9509-4ffe-92c8-2401cee31b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835628479-172.17.0.21-1596960315535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-f7d94bbc-b4ee-43db-a6ac-c68c1e3b1386,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-daf26d9a-ca9b-4647-be7f-0f53b16a1c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-7f971571-bcb5-423c-a84f-a167dd098c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-36af3a22-c2d6-435f-956a-0e68c75dcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-056b6331-19a5-4e1a-ab89-07d9b384cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-0599498e-a963-4127-9285-7e771343214d,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-7bee1818-c7f6-4e7c-9972-77b74df0f35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-c140671d-9509-4ffe-92c8-2401cee31b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671070390-172.17.0.21-1596960345933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-761f9634-2dbd-4125-afb2-bba754a6b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-ab3fc618-8aff-45fe-ade3-57d4e283e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-0e457eff-db86-40e7-bdf7-e9282308d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-1c68dd4b-3cba-4e17-87de-11d54cff5d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-7961154c-18b2-4a2e-b4e0-31046dc02221,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-b28de727-8d60-4f3e-bf58-2294a5440568,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-4b802890-5bc0-4f90-b04e-a66f61409067,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-5c212bcf-8612-48f6-89f3-79d306baa74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671070390-172.17.0.21-1596960345933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-761f9634-2dbd-4125-afb2-bba754a6b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-ab3fc618-8aff-45fe-ade3-57d4e283e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-0e457eff-db86-40e7-bdf7-e9282308d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-1c68dd4b-3cba-4e17-87de-11d54cff5d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-7961154c-18b2-4a2e-b4e0-31046dc02221,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-b28de727-8d60-4f3e-bf58-2294a5440568,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-4b802890-5bc0-4f90-b04e-a66f61409067,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-5c212bcf-8612-48f6-89f3-79d306baa74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044061792-172.17.0.21-1596961537633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-6ded39de-73a8-4651-b4dd-23611d44af3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-8f356fa3-c21a-47a3-adba-1a8b60ded200,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-6c8ab77b-ce77-487c-a5b0-286562fd0db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-a8bc0213-3e13-4e3e-bdcf-df87209f5d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-a2467c66-da99-42fe-b404-4496d0d9a769,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-e6d79fa2-fc70-4b3c-b102-42d26e567059,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-515aaff8-a298-4464-b307-d96e3676d581,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-08a5df5b-81b1-4131-9601-9fca8c7b6dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044061792-172.17.0.21-1596961537633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-6ded39de-73a8-4651-b4dd-23611d44af3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-8f356fa3-c21a-47a3-adba-1a8b60ded200,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-6c8ab77b-ce77-487c-a5b0-286562fd0db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-a8bc0213-3e13-4e3e-bdcf-df87209f5d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-a2467c66-da99-42fe-b404-4496d0d9a769,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-e6d79fa2-fc70-4b3c-b102-42d26e567059,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-515aaff8-a298-4464-b307-d96e3676d581,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-08a5df5b-81b1-4131-9601-9fca8c7b6dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009222130-172.17.0.21-1596961762558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-e65823dd-8d84-4f05-a45d-b98aef7fff35,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-b43b20a4-dfbe-4967-bb46-3c134b4f53f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-f97d8c37-c901-418f-a789-59c073543d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-6880a96d-679e-4940-a63d-30f9d5a26438,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-13738018-c15d-44e8-9cad-dc1d0e9bdf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-b3ae0dc6-fa8c-4aa6-ba0f-baf08053f3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-08198ed7-95ba-46fc-8e8b-ddde851dfd95,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-2655d059-9de0-482d-8a98-67700bfee110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009222130-172.17.0.21-1596961762558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-e65823dd-8d84-4f05-a45d-b98aef7fff35,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-b43b20a4-dfbe-4967-bb46-3c134b4f53f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-f97d8c37-c901-418f-a789-59c073543d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-6880a96d-679e-4940-a63d-30f9d5a26438,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-13738018-c15d-44e8-9cad-dc1d0e9bdf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-b3ae0dc6-fa8c-4aa6-ba0f-baf08053f3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-08198ed7-95ba-46fc-8e8b-ddde851dfd95,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-2655d059-9de0-482d-8a98-67700bfee110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261247255-172.17.0.21-1596962136633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-63812b1c-a914-4733-91be-88ea21f8fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-384255a8-dc1f-431a-9e99-3c22128852f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-97a85a7b-0427-4c64-8dc8-ecc3d54c8157,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-f2c53b72-2c46-4166-9586-5bf1845f39ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-24772342-a65b-42ce-a8ca-e6e4988430b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-f31ad97d-47c9-4cae-9118-f65ebd998e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-8987d3c5-3b47-41d8-9714-f1e64155503e,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-786897dd-5918-479b-8200-32b904c0530c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261247255-172.17.0.21-1596962136633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-63812b1c-a914-4733-91be-88ea21f8fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-384255a8-dc1f-431a-9e99-3c22128852f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-97a85a7b-0427-4c64-8dc8-ecc3d54c8157,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-f2c53b72-2c46-4166-9586-5bf1845f39ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-24772342-a65b-42ce-a8ca-e6e4988430b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-f31ad97d-47c9-4cae-9118-f65ebd998e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-8987d3c5-3b47-41d8-9714-f1e64155503e,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-786897dd-5918-479b-8200-32b904c0530c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374651577-172.17.0.21-1596962248902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33582,DS-fdd893ad-263e-4edd-9b9c-318538205114,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-d8ad31cc-5bf6-415f-a25a-93a48d93f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-7be2991d-f34e-4747-b635-fe80451a4bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-734c7b14-4c0b-4794-8e17-826152585358,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-5e1707c7-f80a-4b1c-b32f-a3e2eb79a2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-41082d9f-fb73-4d0f-8c2f-d9cb48790b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-2dcc0434-00d7-4ccb-82ed-1b5d8a2eef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-0199cec0-5bbc-4648-8204-13f197e3e4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374651577-172.17.0.21-1596962248902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33582,DS-fdd893ad-263e-4edd-9b9c-318538205114,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-d8ad31cc-5bf6-415f-a25a-93a48d93f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-7be2991d-f34e-4747-b635-fe80451a4bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-734c7b14-4c0b-4794-8e17-826152585358,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-5e1707c7-f80a-4b1c-b32f-a3e2eb79a2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-41082d9f-fb73-4d0f-8c2f-d9cb48790b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-2dcc0434-00d7-4ccb-82ed-1b5d8a2eef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-0199cec0-5bbc-4648-8204-13f197e3e4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805293877-172.17.0.21-1596962288055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-e6d81978-3d5b-4d7c-b59b-55e6c40f2c21,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-195c2daf-1409-4e94-b68d-5b5fb1d24a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-d4817afd-740e-4909-a502-e1495e81d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-aa3e61e0-02da-4fd1-ac2b-b6ce4466d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-2613470f-3a7c-4c9c-a9b4-7a82b839a931,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-b58349c0-d3d5-4401-b442-c5ee4d5c1643,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-36adeaa7-51b1-4ae8-a8ec-bc698ce0af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-6ff7d532-73d7-44a9-858a-8e6ad947d5be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805293877-172.17.0.21-1596962288055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-e6d81978-3d5b-4d7c-b59b-55e6c40f2c21,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-195c2daf-1409-4e94-b68d-5b5fb1d24a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-d4817afd-740e-4909-a502-e1495e81d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-aa3e61e0-02da-4fd1-ac2b-b6ce4466d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-2613470f-3a7c-4c9c-a9b4-7a82b839a931,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-b58349c0-d3d5-4401-b442-c5ee4d5c1643,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-36adeaa7-51b1-4ae8-a8ec-bc698ce0af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-6ff7d532-73d7-44a9-858a-8e6ad947d5be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9105206-172.17.0.21-1596962361998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33489,DS-28262165-0912-44ab-9857-f429c2e878f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-92fe9073-2997-47e4-ae8a-ded27cee2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-929025a7-dcd5-40ae-b4c8-122a385557c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-cca2512c-0c41-4e7e-96dd-9bff2e22ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-a98ad233-94db-4ab4-8007-4e9476575157,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-7c44e7b4-93a2-410c-8901-b770d943b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-a8893c7b-e60f-4c7c-b980-e11f85edf4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-24192a18-00c1-47fb-8b90-373945ab3043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9105206-172.17.0.21-1596962361998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33489,DS-28262165-0912-44ab-9857-f429c2e878f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-92fe9073-2997-47e4-ae8a-ded27cee2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-929025a7-dcd5-40ae-b4c8-122a385557c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-cca2512c-0c41-4e7e-96dd-9bff2e22ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-a98ad233-94db-4ab4-8007-4e9476575157,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-7c44e7b4-93a2-410c-8901-b770d943b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-a8893c7b-e60f-4c7c-b980-e11f85edf4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-24192a18-00c1-47fb-8b90-373945ab3043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889005933-172.17.0.21-1596962936578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37564,DS-982c710d-ed28-4126-be15-e96ada15101d,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-8c85720b-a6c0-4acc-8948-0d072ee2621a,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-71f6ffcd-bcec-46bc-a97c-845c44245c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-bfab2588-6e78-4eba-98cc-390d262775e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-23dc2058-3062-44ea-960c-23e24e72056a,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-c29c38f5-b11b-4966-9a6a-965f0b5e5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-f085ec0d-5059-48f7-a218-4a54aa122bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-775cb0b7-2e81-426d-96e4-180a35f3ef2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889005933-172.17.0.21-1596962936578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37564,DS-982c710d-ed28-4126-be15-e96ada15101d,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-8c85720b-a6c0-4acc-8948-0d072ee2621a,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-71f6ffcd-bcec-46bc-a97c-845c44245c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-bfab2588-6e78-4eba-98cc-390d262775e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-23dc2058-3062-44ea-960c-23e24e72056a,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-c29c38f5-b11b-4966-9a6a-965f0b5e5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-f085ec0d-5059-48f7-a218-4a54aa122bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-775cb0b7-2e81-426d-96e4-180a35f3ef2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617572110-172.17.0.21-1596963448557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-92bcf894-21db-46a7-be1a-37b35855fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-1c85b6f7-e55b-4210-84db-99c0c1b34e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-dc408f7b-81f2-41b3-ab66-87d25d084d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-326cb300-45ba-4a9f-b043-66c6a25bf3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-896edc96-b25a-4393-86ef-dbffe2535119,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-ac3fb4d7-3881-4750-9b75-4bf7ff1bfd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-504e9cbf-ede1-4b5f-bc17-226d5b651054,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-f2bf0ce2-4a3a-4ffc-96c2-bbd907c2c530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617572110-172.17.0.21-1596963448557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-92bcf894-21db-46a7-be1a-37b35855fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-1c85b6f7-e55b-4210-84db-99c0c1b34e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-dc408f7b-81f2-41b3-ab66-87d25d084d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-326cb300-45ba-4a9f-b043-66c6a25bf3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-896edc96-b25a-4393-86ef-dbffe2535119,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-ac3fb4d7-3881-4750-9b75-4bf7ff1bfd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-504e9cbf-ede1-4b5f-bc17-226d5b651054,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-f2bf0ce2-4a3a-4ffc-96c2-bbd907c2c530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999455901-172.17.0.21-1596963731783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-33d89561-9ab1-4234-a5f2-2716a102ef88,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-63bed205-8e21-4b83-b441-a22db5f46f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-28b83af4-1012-4fb7-a79e-2d9c9e4a2859,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-e5503ef4-dd12-4e83-8bde-ae2866273042,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-85cbecef-9673-488a-965c-0a9b00760f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-adc3f5da-1cfe-4b81-8d43-3a6b4646201c,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-296abe34-4a58-4e6a-8b5b-307463dec7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-8e0db71c-83b4-4467-8a1a-1a298fd70b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999455901-172.17.0.21-1596963731783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-33d89561-9ab1-4234-a5f2-2716a102ef88,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-63bed205-8e21-4b83-b441-a22db5f46f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-28b83af4-1012-4fb7-a79e-2d9c9e4a2859,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-e5503ef4-dd12-4e83-8bde-ae2866273042,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-85cbecef-9673-488a-965c-0a9b00760f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-adc3f5da-1cfe-4b81-8d43-3a6b4646201c,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-296abe34-4a58-4e6a-8b5b-307463dec7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-8e0db71c-83b4-4467-8a1a-1a298fd70b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29761844-172.17.0.21-1596963950734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44337,DS-db1e5fdd-18a9-407d-a2ad-b6fbc51756bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-bfbdf4ba-cea1-49c8-99f4-74cca99807bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-0cb35c7b-e38e-4cbf-93b0-72f22e0d30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-2a0cc77b-878e-4d52-96dd-ac5cfa34b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-5bb7a97a-edab-4483-a0d3-e7ab6b4c94b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-547a8183-c03d-4e24-ac36-11ca32257c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-a57327d0-7518-41ba-9b1b-cce65f2f5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-49851f33-7789-422f-a574-83dbb5fc3048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29761844-172.17.0.21-1596963950734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44337,DS-db1e5fdd-18a9-407d-a2ad-b6fbc51756bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-bfbdf4ba-cea1-49c8-99f4-74cca99807bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-0cb35c7b-e38e-4cbf-93b0-72f22e0d30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-2a0cc77b-878e-4d52-96dd-ac5cfa34b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-5bb7a97a-edab-4483-a0d3-e7ab6b4c94b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-547a8183-c03d-4e24-ac36-11ca32257c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-a57327d0-7518-41ba-9b1b-cce65f2f5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-49851f33-7789-422f-a574-83dbb5fc3048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5418
