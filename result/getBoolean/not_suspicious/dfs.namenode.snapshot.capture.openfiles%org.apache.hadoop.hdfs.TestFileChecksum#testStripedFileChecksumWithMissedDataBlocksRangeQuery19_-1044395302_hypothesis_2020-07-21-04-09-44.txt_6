reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470002842-172.17.0.3-1595304603686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-4a2cee92-c71f-4487-9127-1e1c03e34482,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-7c0c9ac9-d3a1-48c6-b87c-8e371cc20098,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-1f41d772-6b9e-4d24-b1b9-45ea4def059d,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-b4a9c07e-b612-4ca4-9336-9fa9eed28447,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-8f953ce1-a7b4-4f27-a251-eef6c4ea201d,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-ce628daf-b867-4f6c-9d67-73f26f281c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-049c0170-f31b-4221-b2a4-ae352e83a631,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-ae94b626-265d-492a-945f-2ae27af66ac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470002842-172.17.0.3-1595304603686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-4a2cee92-c71f-4487-9127-1e1c03e34482,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-7c0c9ac9-d3a1-48c6-b87c-8e371cc20098,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-1f41d772-6b9e-4d24-b1b9-45ea4def059d,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-b4a9c07e-b612-4ca4-9336-9fa9eed28447,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-8f953ce1-a7b4-4f27-a251-eef6c4ea201d,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-ce628daf-b867-4f6c-9d67-73f26f281c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-049c0170-f31b-4221-b2a4-ae352e83a631,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-ae94b626-265d-492a-945f-2ae27af66ac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728967085-172.17.0.3-1595305404097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-075a5ea7-d408-40dc-a35e-03e3ee4d9d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-e17450bb-55f2-4055-bcae-887263291f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-bc9cb44a-284d-4f6a-99e4-33521013dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-e943cf81-ce1c-4bbc-b7d1-ce4b7da26e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-971bb482-74e8-4e3a-8e78-e7f64ada44b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-7c1df5bf-ce54-49e1-b81f-5871491b828e,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-ef8a2c7e-cb36-4347-880b-f140b386e644,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-3eb90741-695e-4c6a-976e-ebe8aedb1c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728967085-172.17.0.3-1595305404097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-075a5ea7-d408-40dc-a35e-03e3ee4d9d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-e17450bb-55f2-4055-bcae-887263291f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-bc9cb44a-284d-4f6a-99e4-33521013dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-e943cf81-ce1c-4bbc-b7d1-ce4b7da26e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-971bb482-74e8-4e3a-8e78-e7f64ada44b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-7c1df5bf-ce54-49e1-b81f-5871491b828e,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-ef8a2c7e-cb36-4347-880b-f140b386e644,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-3eb90741-695e-4c6a-976e-ebe8aedb1c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356038693-172.17.0.3-1595306175075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-9b36b20e-61a2-459e-bd47-c3fa0898d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-5af1d01c-67eb-4dc8-a820-5e779d224100,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-1df04c40-5227-4d9f-b3c4-31c51c822103,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-4666a741-2a70-416a-81a8-d98b1a2b7795,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-3ded6929-eac0-4598-b831-9055f52b123d,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-edb524f1-9ed5-45b8-b12c-4edf897285ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-243e4fcf-19e5-4b44-a9db-1ae3b5f8228d,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7afe623f-23fe-4f5e-bc32-5873ede43107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356038693-172.17.0.3-1595306175075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-9b36b20e-61a2-459e-bd47-c3fa0898d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-5af1d01c-67eb-4dc8-a820-5e779d224100,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-1df04c40-5227-4d9f-b3c4-31c51c822103,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-4666a741-2a70-416a-81a8-d98b1a2b7795,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-3ded6929-eac0-4598-b831-9055f52b123d,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-edb524f1-9ed5-45b8-b12c-4edf897285ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-243e4fcf-19e5-4b44-a9db-1ae3b5f8228d,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7afe623f-23fe-4f5e-bc32-5873ede43107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226571210-172.17.0.3-1595306696305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-7bc20887-f869-45c1-a8f3-cd930dd99fab,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-89c2909e-bbac-40f6-a6ef-c201eb0184d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-8dc9ec1f-ab45-41ca-a286-3fc5930e949f,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-ef988102-3943-48c1-b6a9-b896118c89a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-23f3ba7a-771c-4bcf-ae7d-3cc38d7b097a,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-cd3f4e31-e322-4924-bb0d-ab0e43b8e927,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-a5a2c648-e400-4974-b399-7190d213756b,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-102d5ede-02d3-4d42-b677-afcde7eedbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226571210-172.17.0.3-1595306696305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-7bc20887-f869-45c1-a8f3-cd930dd99fab,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-89c2909e-bbac-40f6-a6ef-c201eb0184d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-8dc9ec1f-ab45-41ca-a286-3fc5930e949f,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-ef988102-3943-48c1-b6a9-b896118c89a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-23f3ba7a-771c-4bcf-ae7d-3cc38d7b097a,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-cd3f4e31-e322-4924-bb0d-ab0e43b8e927,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-a5a2c648-e400-4974-b399-7190d213756b,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-102d5ede-02d3-4d42-b677-afcde7eedbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285637258-172.17.0.3-1595306858798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-73a78e9e-16ed-4d09-83ec-7c52d8ed3397,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-dc34923f-7f6a-4dc2-aff7-6ae074b4f720,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-de12ee23-de52-4721-ae48-210f655676cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-86d702b4-edd9-47cc-92d7-18e8d16222c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-c2c81043-5dcb-4045-84ad-c2984a7d9711,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-f43ca4f8-2cd9-462b-9cb5-d487b31af4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-3d399423-6365-44aa-ac7e-9337cb7251d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-140cfb78-6acb-4368-b8bf-26d37fb147c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285637258-172.17.0.3-1595306858798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-73a78e9e-16ed-4d09-83ec-7c52d8ed3397,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-dc34923f-7f6a-4dc2-aff7-6ae074b4f720,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-de12ee23-de52-4721-ae48-210f655676cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-86d702b4-edd9-47cc-92d7-18e8d16222c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-c2c81043-5dcb-4045-84ad-c2984a7d9711,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-f43ca4f8-2cd9-462b-9cb5-d487b31af4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-3d399423-6365-44aa-ac7e-9337cb7251d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-140cfb78-6acb-4368-b8bf-26d37fb147c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711131634-172.17.0.3-1595307063803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-a3865a1b-5506-4253-b973-c6054d51f1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-814502c6-2c21-46af-b91f-58148bec9f45,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-fa05d6ee-e4db-45aa-8684-edb759bd2a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-e7a4ee86-54ab-4d78-9dcc-2bc7ae80ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-d26c86ac-a5dc-4dfa-983a-583bba6f7a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-75350d7e-923b-4d4f-9922-93a2881b6340,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-46030a94-74ee-405d-8d92-776ac55f8766,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-d8173ea2-f492-4968-9167-64e274650ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711131634-172.17.0.3-1595307063803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-a3865a1b-5506-4253-b973-c6054d51f1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-814502c6-2c21-46af-b91f-58148bec9f45,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-fa05d6ee-e4db-45aa-8684-edb759bd2a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-e7a4ee86-54ab-4d78-9dcc-2bc7ae80ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-d26c86ac-a5dc-4dfa-983a-583bba6f7a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-75350d7e-923b-4d4f-9922-93a2881b6340,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-46030a94-74ee-405d-8d92-776ac55f8766,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-d8173ea2-f492-4968-9167-64e274650ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220219127-172.17.0.3-1595307475060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38607,DS-439ef3b5-f7cd-49c6-9cec-1b67c9216598,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-7ff178b5-566c-4f57-b9da-fd296b844096,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-7bbc5d53-2343-4562-8bb1-b2dc0adfbd09,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-0532f160-2588-410b-a3da-f33750e3e7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-73db720f-d91d-478d-b415-6cda849929b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6abb56bc-931e-4a16-95bf-59793ab2f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-cfe2c528-d206-4687-9c10-bb5511697e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-d55de664-3d70-4a6e-b9ac-7ee6b7b55b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220219127-172.17.0.3-1595307475060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38607,DS-439ef3b5-f7cd-49c6-9cec-1b67c9216598,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-7ff178b5-566c-4f57-b9da-fd296b844096,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-7bbc5d53-2343-4562-8bb1-b2dc0adfbd09,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-0532f160-2588-410b-a3da-f33750e3e7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-73db720f-d91d-478d-b415-6cda849929b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6abb56bc-931e-4a16-95bf-59793ab2f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-cfe2c528-d206-4687-9c10-bb5511697e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-d55de664-3d70-4a6e-b9ac-7ee6b7b55b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803577956-172.17.0.3-1595308400245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-f6621153-3b91-4306-8a36-ac5f94b360da,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-0bf46216-4219-483e-84dc-15fabfb903b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-60659a7e-607f-4782-af85-2f19804626b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-0a33c845-31f0-4041-a803-3b32c95eef17,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a5a83f6a-c832-4a2d-b25f-cf835569230c,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-f2fefeca-6477-4126-b6fb-8325066b5046,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-3f607b8e-68f0-4bdc-a883-27282bc0bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-7ca701a1-c906-457b-9174-8be3346d5b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803577956-172.17.0.3-1595308400245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-f6621153-3b91-4306-8a36-ac5f94b360da,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-0bf46216-4219-483e-84dc-15fabfb903b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-60659a7e-607f-4782-af85-2f19804626b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-0a33c845-31f0-4041-a803-3b32c95eef17,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a5a83f6a-c832-4a2d-b25f-cf835569230c,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-f2fefeca-6477-4126-b6fb-8325066b5046,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-3f607b8e-68f0-4bdc-a883-27282bc0bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-7ca701a1-c906-457b-9174-8be3346d5b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618453677-172.17.0.3-1595308613880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-dbc5ecb9-3c04-4091-9607-6e6f15a102a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-0ff99e7f-d6f9-43f5-8847-71fc0b7943b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-5007debb-d6fa-43f6-8c48-c236b8c0fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-cca17b9d-c2d5-47ce-a442-208fc5db15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-f1270db2-bc91-4ae6-ac97-28c1450bc2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-0b410e60-060d-4905-ba33-43b5508bdcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-8ede7cc6-e8d2-4955-ac5c-991094e308b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-45a4a1fc-368d-4db8-b6b6-32d715ba5d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618453677-172.17.0.3-1595308613880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-dbc5ecb9-3c04-4091-9607-6e6f15a102a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-0ff99e7f-d6f9-43f5-8847-71fc0b7943b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-5007debb-d6fa-43f6-8c48-c236b8c0fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-cca17b9d-c2d5-47ce-a442-208fc5db15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-f1270db2-bc91-4ae6-ac97-28c1450bc2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-0b410e60-060d-4905-ba33-43b5508bdcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-8ede7cc6-e8d2-4955-ac5c-991094e308b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-45a4a1fc-368d-4db8-b6b6-32d715ba5d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274749005-172.17.0.3-1595310902513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-889afd21-401d-4185-83f7-b6f8f52da34a,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-490c3a73-93fc-458a-92b4-12c6b78c31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-54a51789-4690-4af9-bf60-c108506d609c,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-3e014b7b-daf7-43bb-9a21-6224d58eee17,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-84238336-2918-4df2-8f8d-2f96398e2084,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-d43e76ae-fe7d-4150-a335-26ec79d860b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-c71429dd-2fb3-4502-9856-29d890399fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-fb736601-e646-4095-b8a6-920851ce2057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274749005-172.17.0.3-1595310902513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-889afd21-401d-4185-83f7-b6f8f52da34a,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-490c3a73-93fc-458a-92b4-12c6b78c31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-54a51789-4690-4af9-bf60-c108506d609c,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-3e014b7b-daf7-43bb-9a21-6224d58eee17,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-84238336-2918-4df2-8f8d-2f96398e2084,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-d43e76ae-fe7d-4150-a335-26ec79d860b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-c71429dd-2fb3-4502-9856-29d890399fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-fb736601-e646-4095-b8a6-920851ce2057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954673302-172.17.0.3-1595312075931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-b7891b9e-b19c-4859-bd1a-ff6a78ff2344,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-24970a33-e94b-446f-9086-b154b20cca76,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-a94ecffc-a01b-455b-b952-a67370561752,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-1bcec65e-5264-4198-9343-df413cb1cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-5b4b6ef5-d5f5-409b-9bd9-f03ff82fa00a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-b4628eaf-5724-497a-8493-20fc59400780,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-708e688d-505f-44fa-920f-088e44520e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-6f2559e4-2f54-4c53-91b6-a74bb7b1d7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954673302-172.17.0.3-1595312075931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-b7891b9e-b19c-4859-bd1a-ff6a78ff2344,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-24970a33-e94b-446f-9086-b154b20cca76,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-a94ecffc-a01b-455b-b952-a67370561752,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-1bcec65e-5264-4198-9343-df413cb1cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-5b4b6ef5-d5f5-409b-9bd9-f03ff82fa00a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-b4628eaf-5724-497a-8493-20fc59400780,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-708e688d-505f-44fa-920f-088e44520e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-6f2559e4-2f54-4c53-91b6-a74bb7b1d7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386040889-172.17.0.3-1595312536090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-ed7506cb-52ab-46f2-af58-66f98250de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-adeab396-d8e8-48f8-a2f3-4608e8e6cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-7ab95995-01c6-4d55-b789-b276b72ab1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-037024c8-fcef-4e1a-a1f7-7bb02d271c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-4a11e39d-ecea-4f52-8a06-ae8d609baac7,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-e903b1a9-9996-4549-b49e-b9e9e47e31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-d8c3ad1e-20c1-48e1-a916-a240d6499544,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-8e939c0d-109a-43b0-bdc5-61fbafdea7d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386040889-172.17.0.3-1595312536090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-ed7506cb-52ab-46f2-af58-66f98250de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-adeab396-d8e8-48f8-a2f3-4608e8e6cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-7ab95995-01c6-4d55-b789-b276b72ab1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-037024c8-fcef-4e1a-a1f7-7bb02d271c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-4a11e39d-ecea-4f52-8a06-ae8d609baac7,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-e903b1a9-9996-4549-b49e-b9e9e47e31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-d8c3ad1e-20c1-48e1-a916-a240d6499544,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-8e939c0d-109a-43b0-bdc5-61fbafdea7d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 7978
