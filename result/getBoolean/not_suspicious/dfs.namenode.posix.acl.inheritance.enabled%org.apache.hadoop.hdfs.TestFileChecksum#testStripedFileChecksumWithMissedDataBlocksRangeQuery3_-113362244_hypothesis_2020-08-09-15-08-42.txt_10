reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620587992-172.17.0.6-1596986545609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-c669017a-f7c4-4768-8669-ce7831ca71ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-de97abd9-8454-4526-b412-d3f5e40ab2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-790df5c1-fc01-4a88-8140-ada08ada6890,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-9ec17ffb-f027-493b-a8de-2ef5d440979e,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-39deb3c2-c828-4a04-8901-9947deed555c,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-a1f10fda-e7c0-4893-890f-22d6602fc0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-3fe399d7-e62e-4d5f-8dab-ca0adb9bd9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-96fdda47-7352-4bd1-ba45-2a5602a5744d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620587992-172.17.0.6-1596986545609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-c669017a-f7c4-4768-8669-ce7831ca71ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-de97abd9-8454-4526-b412-d3f5e40ab2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-790df5c1-fc01-4a88-8140-ada08ada6890,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-9ec17ffb-f027-493b-a8de-2ef5d440979e,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-39deb3c2-c828-4a04-8901-9947deed555c,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-a1f10fda-e7c0-4893-890f-22d6602fc0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-3fe399d7-e62e-4d5f-8dab-ca0adb9bd9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-96fdda47-7352-4bd1-ba45-2a5602a5744d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372411209-172.17.0.6-1596986630311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-fca3bb8f-9e61-4ba0-be30-d339b08fd473,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-4615cd81-3741-4c6f-a85b-c2ee0a13996d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c4f96c6e-70ab-44c5-8ea6-2c92ea0b0e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-370390ae-9101-42fd-8bfe-ea0a8bd98b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-d7150759-a2e7-4782-8118-8fe64cfe93e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-4550ca4e-5331-403d-8063-d64361963bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-841da3f2-05bf-4b39-ba83-97bf48ab37d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c6551cc3-8220-4e9d-9430-67d7b3a788de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372411209-172.17.0.6-1596986630311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-fca3bb8f-9e61-4ba0-be30-d339b08fd473,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-4615cd81-3741-4c6f-a85b-c2ee0a13996d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c4f96c6e-70ab-44c5-8ea6-2c92ea0b0e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-370390ae-9101-42fd-8bfe-ea0a8bd98b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-d7150759-a2e7-4782-8118-8fe64cfe93e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-4550ca4e-5331-403d-8063-d64361963bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-841da3f2-05bf-4b39-ba83-97bf48ab37d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c6551cc3-8220-4e9d-9430-67d7b3a788de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085955067-172.17.0.6-1596986961777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46223,DS-b4ef2507-116a-4dc5-8985-5f4d12ad3ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-fd7449d0-4c02-4028-9752-0e3975410f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-7d8b87f2-78c2-4474-a75b-d6cc353ef9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-4d0b1279-e556-47ef-9127-ae26e4770b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-5e80cfb0-935a-44e6-bcb9-26f72bee3abc,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-b4660909-576e-4484-b9f8-86b5151e691f,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-5e13081a-928e-465c-8ef7-0a754466f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-b57ddcef-4236-400d-a5a0-df920951eabd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085955067-172.17.0.6-1596986961777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46223,DS-b4ef2507-116a-4dc5-8985-5f4d12ad3ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-fd7449d0-4c02-4028-9752-0e3975410f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-7d8b87f2-78c2-4474-a75b-d6cc353ef9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-4d0b1279-e556-47ef-9127-ae26e4770b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-5e80cfb0-935a-44e6-bcb9-26f72bee3abc,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-b4660909-576e-4484-b9f8-86b5151e691f,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-5e13081a-928e-465c-8ef7-0a754466f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-b57ddcef-4236-400d-a5a0-df920951eabd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432013208-172.17.0.6-1596987072907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36604,DS-a4cc3098-a173-4e4c-ba7d-492247b76813,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-88236fbc-3118-468e-9035-8cb4ab214f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-8c0d4d1e-1477-4272-9488-a422fff26d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-78218205-e99f-4f08-b2a9-93751de2c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-15d7075a-3b93-4d47-928e-0d8022829bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-d19c111f-8051-4c42-ab7b-fd601f25dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-2c3c8a98-6cea-4905-8dcf-b892e578548d,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-5725ad30-9116-4a9a-a690-f3388fd18c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432013208-172.17.0.6-1596987072907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36604,DS-a4cc3098-a173-4e4c-ba7d-492247b76813,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-88236fbc-3118-468e-9035-8cb4ab214f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-8c0d4d1e-1477-4272-9488-a422fff26d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-78218205-e99f-4f08-b2a9-93751de2c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-15d7075a-3b93-4d47-928e-0d8022829bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-d19c111f-8051-4c42-ab7b-fd601f25dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-2c3c8a98-6cea-4905-8dcf-b892e578548d,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-5725ad30-9116-4a9a-a690-f3388fd18c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166690282-172.17.0.6-1596987118131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-2710116d-e3fa-43aa-aec5-642df276229f,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-131181d7-6ce4-4e89-98e5-60572f52c783,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-28701a08-9a22-4bbf-96d4-f85836a3bc82,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-f9046200-ba41-402f-84f5-e782d26ee35a,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-c3ce5257-6920-405c-a040-6d380770d20e,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-119e4bd9-3223-4952-80fd-7ffe89fdba42,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-3c256824-f240-475d-94e2-2771b372ebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-00474800-8329-4590-bb18-147257407c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166690282-172.17.0.6-1596987118131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-2710116d-e3fa-43aa-aec5-642df276229f,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-131181d7-6ce4-4e89-98e5-60572f52c783,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-28701a08-9a22-4bbf-96d4-f85836a3bc82,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-f9046200-ba41-402f-84f5-e782d26ee35a,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-c3ce5257-6920-405c-a040-6d380770d20e,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-119e4bd9-3223-4952-80fd-7ffe89fdba42,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-3c256824-f240-475d-94e2-2771b372ebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-00474800-8329-4590-bb18-147257407c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906510583-172.17.0.6-1596987409081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-171a95fa-0fa5-4274-81ac-a92a87d5e87e,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-32b23346-9dab-42f6-8b6d-a1fc2472c893,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-f976f5b2-4251-49dc-8aad-7f27fe899dff,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-8f845c61-bc1d-4237-a6c3-5217856ec729,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-70570a4c-1be1-41db-aac7-835d3a5e98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-9b870d89-a75a-4e50-a6fd-d082c4b2a0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-b67bc76a-fd96-4bb5-943b-ca0597096fae,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-12f0abaf-44c2-4824-a667-86e5eab6131c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906510583-172.17.0.6-1596987409081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-171a95fa-0fa5-4274-81ac-a92a87d5e87e,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-32b23346-9dab-42f6-8b6d-a1fc2472c893,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-f976f5b2-4251-49dc-8aad-7f27fe899dff,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-8f845c61-bc1d-4237-a6c3-5217856ec729,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-70570a4c-1be1-41db-aac7-835d3a5e98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-9b870d89-a75a-4e50-a6fd-d082c4b2a0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-b67bc76a-fd96-4bb5-943b-ca0597096fae,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-12f0abaf-44c2-4824-a667-86e5eab6131c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277334114-172.17.0.6-1596987769228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-8c1f6665-29e8-4498-b595-6a4d51f81db3,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-4d5174ca-3d9c-4530-82fa-ffb8d175041c,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-67015a70-e8f2-45d5-b01a-570baba7a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-c1a25cb2-c721-45d3-bff7-89fa7ca96bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-d28ccc36-926a-4358-9081-9b713d82d962,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-7e34883d-c210-4f66-898d-fd035e7fdc27,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-7682f064-773f-49ef-9d1e-ee6312b64085,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-95e17515-e025-44c8-9b89-5b470e5c3d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277334114-172.17.0.6-1596987769228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-8c1f6665-29e8-4498-b595-6a4d51f81db3,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-4d5174ca-3d9c-4530-82fa-ffb8d175041c,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-67015a70-e8f2-45d5-b01a-570baba7a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-c1a25cb2-c721-45d3-bff7-89fa7ca96bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-d28ccc36-926a-4358-9081-9b713d82d962,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-7e34883d-c210-4f66-898d-fd035e7fdc27,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-7682f064-773f-49ef-9d1e-ee6312b64085,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-95e17515-e025-44c8-9b89-5b470e5c3d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293157008-172.17.0.6-1596987947345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45599,DS-3134079d-2511-4bdd-8c4b-fd0240a1d985,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-776e2e65-8405-4b6c-a245-0c1fa0bbe57c,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-d7111d41-dd9b-431c-9a2e-bde46ce52581,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-0dbebdae-07d7-46c9-9fd9-1ea5f11d082f,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-647b3e1f-21f7-43f9-b9d0-287509c06f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-68e93411-8fbe-4c66-b4aa-3e39ffc514ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-54788942-3a44-4d39-bea6-8b7170ef9610,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-93e4b613-f167-42d0-a7b0-29488d5cd116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293157008-172.17.0.6-1596987947345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45599,DS-3134079d-2511-4bdd-8c4b-fd0240a1d985,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-776e2e65-8405-4b6c-a245-0c1fa0bbe57c,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-d7111d41-dd9b-431c-9a2e-bde46ce52581,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-0dbebdae-07d7-46c9-9fd9-1ea5f11d082f,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-647b3e1f-21f7-43f9-b9d0-287509c06f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-68e93411-8fbe-4c66-b4aa-3e39ffc514ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-54788942-3a44-4d39-bea6-8b7170ef9610,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-93e4b613-f167-42d0-a7b0-29488d5cd116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875174561-172.17.0.6-1596987992097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-9ec5d3ca-ef96-4852-ba4f-b5f52ec2e3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-4bb2f589-5bd0-4d02-890c-08ea9a73f059,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-36aadf64-d3d4-4189-9e1b-bc901cdc6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-824433ac-43a3-4841-bd2c-b34fe1980d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-417ada12-fecb-4a32-b28f-1fd1accc26e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-964ea4df-8f67-4ce2-98e3-5f5e7005b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-e2061570-5fb4-4d49-8ddf-8bd4ad814c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-92ef7ac2-e339-448d-aa7a-90f02157f31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875174561-172.17.0.6-1596987992097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-9ec5d3ca-ef96-4852-ba4f-b5f52ec2e3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-4bb2f589-5bd0-4d02-890c-08ea9a73f059,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-36aadf64-d3d4-4189-9e1b-bc901cdc6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-824433ac-43a3-4841-bd2c-b34fe1980d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-417ada12-fecb-4a32-b28f-1fd1accc26e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-964ea4df-8f67-4ce2-98e3-5f5e7005b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-e2061570-5fb4-4d49-8ddf-8bd4ad814c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-92ef7ac2-e339-448d-aa7a-90f02157f31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772785637-172.17.0.6-1596988123013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-a2803a56-e8be-4d6c-8bdc-0357060cdab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d19ae964-b920-48fd-86b3-951b3ebda73d,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-e44cb41c-fa12-411c-b3e1-f740d03c552a,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-599d1d25-de09-4d1a-9e47-38949a7e3caa,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-8bc563b9-1509-40d5-a483-28da6768ac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-8c129a8b-bd05-4782-8673-ad468efff411,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-980d553e-3f4d-4dce-aae1-8a70f1092bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-23db0c1b-005f-4743-9129-b53571be2671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772785637-172.17.0.6-1596988123013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-a2803a56-e8be-4d6c-8bdc-0357060cdab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d19ae964-b920-48fd-86b3-951b3ebda73d,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-e44cb41c-fa12-411c-b3e1-f740d03c552a,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-599d1d25-de09-4d1a-9e47-38949a7e3caa,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-8bc563b9-1509-40d5-a483-28da6768ac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-8c129a8b-bd05-4782-8673-ad468efff411,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-980d553e-3f4d-4dce-aae1-8a70f1092bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-23db0c1b-005f-4743-9129-b53571be2671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679807972-172.17.0.6-1596988190235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-79da8c2c-89c4-46ef-ad78-1dfdd4f1cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-cb6e8a87-74ec-44b5-8176-2f703a6f93ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8042cb6b-3412-452a-ad01-0f60bf31fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f92ff390-4f33-4fe7-ba8d-5fee5ed121b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-10f46311-1508-43ee-afda-ec17fd285584,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-e62b8981-8d9e-447e-9922-7afbd6e4aace,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-a470d8c8-8292-4f3d-8a55-b38696793578,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-daad841b-6a05-4b5e-86f8-75f9b0008a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679807972-172.17.0.6-1596988190235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-79da8c2c-89c4-46ef-ad78-1dfdd4f1cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-cb6e8a87-74ec-44b5-8176-2f703a6f93ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8042cb6b-3412-452a-ad01-0f60bf31fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f92ff390-4f33-4fe7-ba8d-5fee5ed121b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-10f46311-1508-43ee-afda-ec17fd285584,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-e62b8981-8d9e-447e-9922-7afbd6e4aace,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-a470d8c8-8292-4f3d-8a55-b38696793578,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-daad841b-6a05-4b5e-86f8-75f9b0008a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438203780-172.17.0.6-1596988344760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40212,DS-b1196d21-8434-4869-910a-bd82b6c09aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-f9927d3a-1027-4a51-919a-236bc6993abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-95c97c16-2e83-4438-bb37-41d0a420c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-ba4c33e9-32fb-449c-bbd7-ddae0415d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-98df11a1-15cf-4509-81e6-d24ee6532e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-b81cc2a1-12c0-4aed-b96f-00067306489b,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-1970a138-160b-45bc-90ed-0428d0bcce19,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-55cc5330-59ad-40d0-89ee-4797287dd6ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438203780-172.17.0.6-1596988344760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40212,DS-b1196d21-8434-4869-910a-bd82b6c09aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-f9927d3a-1027-4a51-919a-236bc6993abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-95c97c16-2e83-4438-bb37-41d0a420c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-ba4c33e9-32fb-449c-bbd7-ddae0415d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-98df11a1-15cf-4509-81e6-d24ee6532e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-b81cc2a1-12c0-4aed-b96f-00067306489b,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-1970a138-160b-45bc-90ed-0428d0bcce19,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-55cc5330-59ad-40d0-89ee-4797287dd6ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752384639-172.17.0.6-1596988482411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-e2421428-0581-4fe4-9114-a7388007af53,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-ae086072-1714-4e21-b2c7-f26d6672cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-77c1331c-cb3a-47d4-91de-9b9c6625a885,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-a5571c96-d30b-402b-9828-2e3a678325ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-0436361e-ad3b-440a-96f2-d07be370f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-1201eef0-fa5e-431f-8a4a-d05ddbdfb85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-0660308b-b8b7-4c4e-a28b-79421bba07d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-f3177455-41e3-4094-99f7-6449c3ad242c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752384639-172.17.0.6-1596988482411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-e2421428-0581-4fe4-9114-a7388007af53,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-ae086072-1714-4e21-b2c7-f26d6672cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-77c1331c-cb3a-47d4-91de-9b9c6625a885,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-a5571c96-d30b-402b-9828-2e3a678325ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-0436361e-ad3b-440a-96f2-d07be370f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-1201eef0-fa5e-431f-8a4a-d05ddbdfb85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-0660308b-b8b7-4c4e-a28b-79421bba07d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-f3177455-41e3-4094-99f7-6449c3ad242c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402622075-172.17.0.6-1596988503404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42209,DS-a787698b-b7df-4a8f-a1e8-11948fb226cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-c64aec03-9e3f-47cb-b9fe-795d967d48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-cfc84842-3bbd-4627-8e9a-6e3685df0d56,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-4937f508-8a8f-4b02-8c28-1bcd3cfd0a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-e59c8b84-0410-49c6-ba70-bebb37e9470f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-05196d57-3a94-4991-a39a-945f56563695,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-82376c6e-0629-42c0-9209-6737f0402ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-af01517c-b920-42a8-9514-2604db2d1cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402622075-172.17.0.6-1596988503404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42209,DS-a787698b-b7df-4a8f-a1e8-11948fb226cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-c64aec03-9e3f-47cb-b9fe-795d967d48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-cfc84842-3bbd-4627-8e9a-6e3685df0d56,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-4937f508-8a8f-4b02-8c28-1bcd3cfd0a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-e59c8b84-0410-49c6-ba70-bebb37e9470f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-05196d57-3a94-4991-a39a-945f56563695,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-82376c6e-0629-42c0-9209-6737f0402ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-af01517c-b920-42a8-9514-2604db2d1cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166107509-172.17.0.6-1596988660786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34255,DS-900557eb-a9f8-4d90-ab39-cbfff8fa6fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-fe906999-dc2d-4f09-8592-4a5816c803ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-15b18935-e50f-4b23-97bf-92a656a194d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-c55a784b-0b29-46ae-8f04-c13786b71a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-9886c9c4-825b-453d-8fd6-0a8eee514bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-74a0eb5c-6d2b-4441-a53a-611186518574,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-4b728ed2-b68c-465e-bf6f-7a9b4a6f852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-f2ac27ee-1730-47b5-9dfc-2ba62e5c8d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166107509-172.17.0.6-1596988660786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34255,DS-900557eb-a9f8-4d90-ab39-cbfff8fa6fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-fe906999-dc2d-4f09-8592-4a5816c803ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-15b18935-e50f-4b23-97bf-92a656a194d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-c55a784b-0b29-46ae-8f04-c13786b71a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-9886c9c4-825b-453d-8fd6-0a8eee514bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-74a0eb5c-6d2b-4441-a53a-611186518574,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-4b728ed2-b68c-465e-bf6f-7a9b4a6f852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-f2ac27ee-1730-47b5-9dfc-2ba62e5c8d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283382092-172.17.0.6-1596988704101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-fde499b5-76d8-469c-945d-04878ac0907d,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-568c9867-6291-4d0f-93ae-d68e2b52174c,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b72b0da5-042c-4870-b5dc-38429af0f997,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-408240f3-caf2-4a24-8d8e-8447b397bad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-fb360251-f459-43cb-96e7-02ca14ef7789,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3727e4ba-58ab-4660-9be6-77cc9f75c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-4a3e2162-3123-4798-9c7f-42ffdf741f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-6560afdf-d9a5-4eef-be6e-e0a5e401fd42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283382092-172.17.0.6-1596988704101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-fde499b5-76d8-469c-945d-04878ac0907d,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-568c9867-6291-4d0f-93ae-d68e2b52174c,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b72b0da5-042c-4870-b5dc-38429af0f997,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-408240f3-caf2-4a24-8d8e-8447b397bad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-fb360251-f459-43cb-96e7-02ca14ef7789,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3727e4ba-58ab-4660-9be6-77cc9f75c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-4a3e2162-3123-4798-9c7f-42ffdf741f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-6560afdf-d9a5-4eef-be6e-e0a5e401fd42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609163700-172.17.0.6-1596988789192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-510f68af-d945-4f8f-ab8a-a0c85dc2cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-c1601bd4-7a7c-4519-92fa-b9bb4afcf9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-60116036-bf29-45bd-b7ae-127e219bd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-b7b7f491-4569-4907-9736-aff8fcd320ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-7727b8b5-0f21-4dee-87e2-b8b82340f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-f36e6bc9-1052-4694-a1ba-ff674a76fc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-4c275ad5-7867-423f-8daf-caa1648f5c89,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-b74df916-449a-4e24-bea3-c95b6faef650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609163700-172.17.0.6-1596988789192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-510f68af-d945-4f8f-ab8a-a0c85dc2cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-c1601bd4-7a7c-4519-92fa-b9bb4afcf9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-60116036-bf29-45bd-b7ae-127e219bd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-b7b7f491-4569-4907-9736-aff8fcd320ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-7727b8b5-0f21-4dee-87e2-b8b82340f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-f36e6bc9-1052-4694-a1ba-ff674a76fc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-4c275ad5-7867-423f-8daf-caa1648f5c89,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-b74df916-449a-4e24-bea3-c95b6faef650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669481451-172.17.0.6-1596989056444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45452,DS-4d98444d-43d0-4f9d-a81c-ec77526e0074,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-4be2f588-9ce3-4a68-895c-7c435743a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-10cf2ef7-c88b-4f4b-91b3-f262fe3eb032,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-7d7d92f5-4d09-464d-89d8-f997fde41e22,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-d55ac5a9-a21f-4499-a8d0-884ff1afdb44,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-5c8e48c9-2910-44a6-b01f-40ffe193433f,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-df2a5604-c3cd-4bfc-b7c5-3e28e7a16499,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-b8ff5d35-5d5b-41b6-84c5-7370a329973b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669481451-172.17.0.6-1596989056444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45452,DS-4d98444d-43d0-4f9d-a81c-ec77526e0074,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-4be2f588-9ce3-4a68-895c-7c435743a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-10cf2ef7-c88b-4f4b-91b3-f262fe3eb032,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-7d7d92f5-4d09-464d-89d8-f997fde41e22,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-d55ac5a9-a21f-4499-a8d0-884ff1afdb44,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-5c8e48c9-2910-44a6-b01f-40ffe193433f,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-df2a5604-c3cd-4bfc-b7c5-3e28e7a16499,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-b8ff5d35-5d5b-41b6-84c5-7370a329973b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675468447-172.17.0.6-1596989147068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38803,DS-1ef7b034-20bf-4523-889c-c7301a626fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-dd6c8fb5-9417-4343-9bc0-26e20972f346,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-c3746fb4-3661-4f60-a647-77a5f3846267,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-77b85d48-f4c0-4f6a-838c-d9797c0292a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-7c9f04a1-c12c-4640-b6b5-30e2622d30f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-8ed9225e-8550-4e36-9c3d-2fc9b753c837,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-29a7e8da-94d1-4c35-9424-6e1ac2f1b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-e4e61da2-aa19-4010-8011-1e7a39345d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675468447-172.17.0.6-1596989147068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38803,DS-1ef7b034-20bf-4523-889c-c7301a626fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-dd6c8fb5-9417-4343-9bc0-26e20972f346,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-c3746fb4-3661-4f60-a647-77a5f3846267,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-77b85d48-f4c0-4f6a-838c-d9797c0292a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-7c9f04a1-c12c-4640-b6b5-30e2622d30f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-8ed9225e-8550-4e36-9c3d-2fc9b753c837,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-29a7e8da-94d1-4c35-9424-6e1ac2f1b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-e4e61da2-aa19-4010-8011-1e7a39345d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514209577-172.17.0.6-1596989301938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35098,DS-a86470eb-ae88-465e-be01-9961cce3d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-daf86fab-02ee-4752-8822-2d43bc7eb297,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-5cc9b468-e798-43c3-a04c-ff87aa289945,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-8e8a2184-1c69-42fc-979e-9c1d1775fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-c6c3f2f7-33b9-47cb-a24b-ac126e14f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-969232be-e81c-4c1b-81c8-0dd9507318a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-4f9ab107-3972-4a5b-95e3-96cab463b475,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-83e34f91-32f8-4254-8a9a-82db86a614b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514209577-172.17.0.6-1596989301938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35098,DS-a86470eb-ae88-465e-be01-9961cce3d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-daf86fab-02ee-4752-8822-2d43bc7eb297,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-5cc9b468-e798-43c3-a04c-ff87aa289945,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-8e8a2184-1c69-42fc-979e-9c1d1775fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-c6c3f2f7-33b9-47cb-a24b-ac126e14f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-969232be-e81c-4c1b-81c8-0dd9507318a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-4f9ab107-3972-4a5b-95e3-96cab463b475,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-83e34f91-32f8-4254-8a9a-82db86a614b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100340694-172.17.0.6-1596989413108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-17f8541d-a7e8-4ad5-9a15-557221dd39bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-09121aac-4973-4acf-b842-47d3ebe6b44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-6debb190-a062-48b4-b192-0fa81b4ec5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-2004e841-b2e9-485f-9261-78c38183820c,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-01668472-e346-4565-a760-ef75df753628,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-c3688fc7-55bf-4f67-a467-9cc07b54aabf,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-e119584d-eb7e-4092-aa0d-b8c14b67b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-582b58e2-464d-4849-9e0e-408072cf9d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100340694-172.17.0.6-1596989413108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-17f8541d-a7e8-4ad5-9a15-557221dd39bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-09121aac-4973-4acf-b842-47d3ebe6b44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-6debb190-a062-48b4-b192-0fa81b4ec5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-2004e841-b2e9-485f-9261-78c38183820c,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-01668472-e346-4565-a760-ef75df753628,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-c3688fc7-55bf-4f67-a467-9cc07b54aabf,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-e119584d-eb7e-4092-aa0d-b8c14b67b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-582b58e2-464d-4849-9e0e-408072cf9d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932132226-172.17.0.6-1596989566957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44075,DS-22804fdb-6f51-41bd-8687-a7fa6b9feec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-64d1d268-61c4-4234-8773-5721fa2eb634,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-d2469d41-d468-4ceb-b986-1ca80701681c,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-6fbcc514-f930-411d-a9e8-d9fa275a78bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-3d50322a-5e62-454d-83c8-33c12f3f0640,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-222e18f3-0db5-4888-938a-45e5d4c223d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-f449a926-7fd1-4b12-adae-dfa86ddebbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-85062526-06af-47e4-9cb9-5b4ef684066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932132226-172.17.0.6-1596989566957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44075,DS-22804fdb-6f51-41bd-8687-a7fa6b9feec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-64d1d268-61c4-4234-8773-5721fa2eb634,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-d2469d41-d468-4ceb-b986-1ca80701681c,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-6fbcc514-f930-411d-a9e8-d9fa275a78bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-3d50322a-5e62-454d-83c8-33c12f3f0640,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-222e18f3-0db5-4888-938a-45e5d4c223d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-f449a926-7fd1-4b12-adae-dfa86ddebbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-85062526-06af-47e4-9cb9-5b4ef684066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 3857
