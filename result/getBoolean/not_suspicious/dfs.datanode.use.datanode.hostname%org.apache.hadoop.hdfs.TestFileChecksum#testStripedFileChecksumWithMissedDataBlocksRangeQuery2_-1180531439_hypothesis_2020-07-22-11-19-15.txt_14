reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521109905-172.17.0.13-1595416803395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-dc03205e-efc6-4dd5-8613-ba4091ac16cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-814b211f-6bc3-4de0-a40d-86fa2a4eb98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-320c020d-5336-4fb2-a101-2b5c3a97f8da,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-299644e0-ffbb-413f-93e8-3bd2a2aac611,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-2b264d38-5708-4a90-b66c-6e87ff1e5356,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-c098f910-0a01-43eb-a964-14580f7e3ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-a939c1fd-8f93-4b9a-89bc-2034bfec3fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-8dbcfc7f-10e9-4749-8bd4-e7aa5b54fd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521109905-172.17.0.13-1595416803395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-dc03205e-efc6-4dd5-8613-ba4091ac16cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-814b211f-6bc3-4de0-a40d-86fa2a4eb98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-320c020d-5336-4fb2-a101-2b5c3a97f8da,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-299644e0-ffbb-413f-93e8-3bd2a2aac611,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-2b264d38-5708-4a90-b66c-6e87ff1e5356,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-c098f910-0a01-43eb-a964-14580f7e3ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-a939c1fd-8f93-4b9a-89bc-2034bfec3fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-8dbcfc7f-10e9-4749-8bd4-e7aa5b54fd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347668417-172.17.0.13-1595417888249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-85c8b67b-9819-41ca-b1bf-8f9bba7d3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-a19799a6-84fc-4b87-880a-c0a5b18acc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-22102b34-023e-4778-b2a6-0f7b972f03fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-da29bb07-b1da-416c-8451-c86eb245efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-0bf58a37-4b61-46cd-b669-4483f6119125,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-1364d752-9444-4f91-a2a4-b7a08d2236f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-4707952e-73d8-4653-8e5c-b6e9877fb4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-2cf8e56c-37a1-41ad-9849-59db15bba387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347668417-172.17.0.13-1595417888249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-85c8b67b-9819-41ca-b1bf-8f9bba7d3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-a19799a6-84fc-4b87-880a-c0a5b18acc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-22102b34-023e-4778-b2a6-0f7b972f03fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-da29bb07-b1da-416c-8451-c86eb245efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-0bf58a37-4b61-46cd-b669-4483f6119125,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-1364d752-9444-4f91-a2a4-b7a08d2236f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-4707952e-73d8-4653-8e5c-b6e9877fb4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-2cf8e56c-37a1-41ad-9849-59db15bba387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170057897-172.17.0.13-1595417974321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-bd599cf2-fd45-444b-804f-2a6b44abaf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-ca0e160c-46f0-44a3-9fe2-b90e7f01bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-92eca097-8e55-4c0a-a1bf-03b68ffd1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-51d3a8e9-ab47-4530-80b8-7c1786cac320,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-81a96af2-def9-4374-87df-be95bd007b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-de5216e5-5784-4248-91bf-350c7a523417,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-06d2c23a-5c00-426c-be45-62e55595c9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-43d24e64-139d-4d67-b2ef-6acd64520cad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170057897-172.17.0.13-1595417974321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-bd599cf2-fd45-444b-804f-2a6b44abaf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-ca0e160c-46f0-44a3-9fe2-b90e7f01bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-92eca097-8e55-4c0a-a1bf-03b68ffd1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-51d3a8e9-ab47-4530-80b8-7c1786cac320,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-81a96af2-def9-4374-87df-be95bd007b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-de5216e5-5784-4248-91bf-350c7a523417,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-06d2c23a-5c00-426c-be45-62e55595c9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-43d24e64-139d-4d67-b2ef-6acd64520cad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976449501-172.17.0.13-1595418076879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41169,DS-4f8d5ca3-4f5c-4b94-9f79-8baf73989bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-41333452-0a3e-477f-adc1-62f57a39ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-f27d95ac-7677-4fa1-922a-8a79906b56ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-6b96d2d4-3958-4ea1-a5f2-469289641132,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-ec41759e-34e3-4505-8651-4a2c1fb53048,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-66fe030c-4497-47da-9c31-e0b88eb7df89,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-b7c392a6-3f13-43c9-bd8c-bf6b28375a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-fb65967a-c09b-4ff6-b318-63057ab242bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976449501-172.17.0.13-1595418076879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41169,DS-4f8d5ca3-4f5c-4b94-9f79-8baf73989bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-41333452-0a3e-477f-adc1-62f57a39ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-f27d95ac-7677-4fa1-922a-8a79906b56ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-6b96d2d4-3958-4ea1-a5f2-469289641132,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-ec41759e-34e3-4505-8651-4a2c1fb53048,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-66fe030c-4497-47da-9c31-e0b88eb7df89,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-b7c392a6-3f13-43c9-bd8c-bf6b28375a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-fb65967a-c09b-4ff6-b318-63057ab242bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412592324-172.17.0.13-1595418428286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41281,DS-2301c3e4-e396-4fc2-9c68-4618c4458d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-c9346a5d-ca28-4b9c-b8c3-009599f45c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-a0567721-0244-41e6-8211-324299ef3e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-3f268138-792c-41ab-a365-04d262ebf8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-d6d1df9b-6843-4c9c-bf4c-da32c1d7bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-8a262652-5fb7-4eb4-8e9f-b369d7c5ea00,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-dffb9ece-57f7-4ca4-ae49-63df980a35b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-c9c3fd47-ae37-4d23-9614-a52db3b46477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412592324-172.17.0.13-1595418428286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41281,DS-2301c3e4-e396-4fc2-9c68-4618c4458d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-c9346a5d-ca28-4b9c-b8c3-009599f45c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-a0567721-0244-41e6-8211-324299ef3e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-3f268138-792c-41ab-a365-04d262ebf8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-d6d1df9b-6843-4c9c-bf4c-da32c1d7bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-8a262652-5fb7-4eb4-8e9f-b369d7c5ea00,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-dffb9ece-57f7-4ca4-ae49-63df980a35b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-c9c3fd47-ae37-4d23-9614-a52db3b46477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284673669-172.17.0.13-1595418581152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34372,DS-954a0541-bf31-47ec-88a4-b558f6bc9dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-eee9ea0c-a55b-413a-bc2b-7d41b14d8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-87ad8836-3ae7-4fb2-b325-78daeab6bce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-a1e2b07e-c63e-46c2-bd7e-0b523c6517ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-61818c83-df36-4b37-917b-c9787e8890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-15379c23-8e5c-4072-a906-5777cf6fcaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-1ac4686a-7171-4117-a73d-a988a1018851,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-2c694e28-bc7f-483d-9e49-776c0cd0262b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284673669-172.17.0.13-1595418581152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34372,DS-954a0541-bf31-47ec-88a4-b558f6bc9dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-eee9ea0c-a55b-413a-bc2b-7d41b14d8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-87ad8836-3ae7-4fb2-b325-78daeab6bce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-a1e2b07e-c63e-46c2-bd7e-0b523c6517ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-61818c83-df36-4b37-917b-c9787e8890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-15379c23-8e5c-4072-a906-5777cf6fcaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-1ac4686a-7171-4117-a73d-a988a1018851,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-2c694e28-bc7f-483d-9e49-776c0cd0262b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16932079-172.17.0.13-1595418889835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-337f1179-e24c-40ec-aa4b-e958bf75baa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-8f501d91-c3ef-487a-9b28-9f64a8f60f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-2c31d34c-887a-49f7-9edc-0c9cd4464633,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-bafacbdd-5ad2-4cc1-9c86-a3975834cd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-e0bb82f6-0335-469a-955b-bf9878dccaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-69c97cf3-86f4-4065-8d90-b98fc9093a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-ca065741-ed64-4736-813b-466bf032cf96,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-df61b225-5a45-4006-9fbd-0bf9382c007b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16932079-172.17.0.13-1595418889835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-337f1179-e24c-40ec-aa4b-e958bf75baa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-8f501d91-c3ef-487a-9b28-9f64a8f60f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-2c31d34c-887a-49f7-9edc-0c9cd4464633,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-bafacbdd-5ad2-4cc1-9c86-a3975834cd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-e0bb82f6-0335-469a-955b-bf9878dccaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-69c97cf3-86f4-4065-8d90-b98fc9093a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-ca065741-ed64-4736-813b-466bf032cf96,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-df61b225-5a45-4006-9fbd-0bf9382c007b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441119759-172.17.0.13-1595418957538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-03a80ae6-6149-4d1c-bdc0-72404d2fcec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-3cc48baa-8a83-4441-88ea-c2a5d5ccc6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-2054afae-69bc-464c-97f8-c8dec6042522,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-4f377821-5435-4b87-aec1-f85d00dcfe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-64327008-5b6e-4e04-9e72-b7434ecd18d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-49379213-a8da-4bb7-b821-6c6f895c5107,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-5c6cc3a5-1710-4766-9aaf-560b14dc37fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-5f7c9289-9e07-42b6-9884-13dcec8d2b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441119759-172.17.0.13-1595418957538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-03a80ae6-6149-4d1c-bdc0-72404d2fcec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-3cc48baa-8a83-4441-88ea-c2a5d5ccc6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-2054afae-69bc-464c-97f8-c8dec6042522,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-4f377821-5435-4b87-aec1-f85d00dcfe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-64327008-5b6e-4e04-9e72-b7434ecd18d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-49379213-a8da-4bb7-b821-6c6f895c5107,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-5c6cc3a5-1710-4766-9aaf-560b14dc37fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-5f7c9289-9e07-42b6-9884-13dcec8d2b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694513558-172.17.0.13-1595419023303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-ae5023ab-cbe0-496e-921e-13d3487f80e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-1613445c-aa9e-43c3-9d69-685b7e64bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-b0f73f5b-9f5c-45d5-812f-daf3a9527b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-8b11d23a-929b-408d-b053-bb338f070ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-ba881287-4d4f-48a3-b498-9921480631dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-46626909-c031-46dd-8c7d-2ad5c2642209,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-6b202f9e-2345-4e05-b752-2da8a592b42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-27897102-f1b4-488a-9c72-f0600f47f5f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694513558-172.17.0.13-1595419023303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-ae5023ab-cbe0-496e-921e-13d3487f80e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-1613445c-aa9e-43c3-9d69-685b7e64bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-b0f73f5b-9f5c-45d5-812f-daf3a9527b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-8b11d23a-929b-408d-b053-bb338f070ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-ba881287-4d4f-48a3-b498-9921480631dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-46626909-c031-46dd-8c7d-2ad5c2642209,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-6b202f9e-2345-4e05-b752-2da8a592b42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-27897102-f1b4-488a-9c72-f0600f47f5f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259022282-172.17.0.13-1595419163875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40229,DS-cf3b5710-0dd7-4f5b-90bd-8f7705dcf758,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-88b1303d-2aa2-4c94-bedd-acffe0cce9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-015b10c3-71cb-49c1-9804-fe85cb24eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-74917494-08dd-42b5-90a4-3a5635f495ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-1117361a-30d0-46ed-a9f9-ecd2be2403c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-58aff2cb-f716-490c-a724-46dac485a6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ad832b80-ebae-4f04-8cd8-b0ad9d2cacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-1be38e27-9d12-4e67-9da5-fa38c34459ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259022282-172.17.0.13-1595419163875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40229,DS-cf3b5710-0dd7-4f5b-90bd-8f7705dcf758,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-88b1303d-2aa2-4c94-bedd-acffe0cce9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-015b10c3-71cb-49c1-9804-fe85cb24eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-74917494-08dd-42b5-90a4-3a5635f495ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-1117361a-30d0-46ed-a9f9-ecd2be2403c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-58aff2cb-f716-490c-a724-46dac485a6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ad832b80-ebae-4f04-8cd8-b0ad9d2cacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-1be38e27-9d12-4e67-9da5-fa38c34459ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687787928-172.17.0.13-1595419365190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-fc92b78e-73c3-41d9-996d-da71b2c7bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-c0d03c7b-3ca9-4070-8149-467f19dc5eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-e6ac02ad-9ba4-49f4-91ff-cfd6abc4b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-e3e29a17-43ab-499a-aa1d-b8c6ec284148,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-e2bc1147-379b-48b6-8a5c-eaf6087b44ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-2c100d0a-d7ae-48a5-905e-926724c50e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-39b68233-3637-460f-b3cf-13296ddf66ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-3b600e7d-36c5-464a-ac96-e3146382f17b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687787928-172.17.0.13-1595419365190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-fc92b78e-73c3-41d9-996d-da71b2c7bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-c0d03c7b-3ca9-4070-8149-467f19dc5eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-e6ac02ad-9ba4-49f4-91ff-cfd6abc4b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-e3e29a17-43ab-499a-aa1d-b8c6ec284148,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-e2bc1147-379b-48b6-8a5c-eaf6087b44ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-2c100d0a-d7ae-48a5-905e-926724c50e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-39b68233-3637-460f-b3cf-13296ddf66ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-3b600e7d-36c5-464a-ac96-e3146382f17b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183523081-172.17.0.13-1595419460739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-0382a83f-1e90-47ae-8dc7-64b457ccf40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-b3448b03-d6db-402c-ae98-15aebc748859,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-a5484c88-fcc4-4793-8317-c6aad082677c,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-f535069c-32c6-4dbe-bd98-e2b74346d998,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-7ea9e674-4817-4d8c-b210-99eb516d8b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-da4bdf6a-c3b3-4db6-b4c2-986e9010860a,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-838b16c6-6ab6-4002-a283-939910e02be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-7d333a23-2774-407e-802a-a9bb084137f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183523081-172.17.0.13-1595419460739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-0382a83f-1e90-47ae-8dc7-64b457ccf40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-b3448b03-d6db-402c-ae98-15aebc748859,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-a5484c88-fcc4-4793-8317-c6aad082677c,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-f535069c-32c6-4dbe-bd98-e2b74346d998,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-7ea9e674-4817-4d8c-b210-99eb516d8b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-da4bdf6a-c3b3-4db6-b4c2-986e9010860a,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-838b16c6-6ab6-4002-a283-939910e02be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-7d333a23-2774-407e-802a-a9bb084137f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5635740-172.17.0.13-1595419881990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-180badde-048f-4c3a-82b4-d6990106b4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-2445f7ab-d8a5-4147-bae8-ad159018c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-dc2c972c-ccd7-4443-a462-4a5aac487483,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-dc59a943-12f5-4c03-a57e-c2e8da56b925,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-83a205f0-c2aa-41d8-80f4-3b7d485d4a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-a257b38d-aa79-41f8-b3e9-5c364be232a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-d5318109-a928-470a-8b17-10861f07f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-0af539ce-ad86-42af-8554-3b65f7524a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5635740-172.17.0.13-1595419881990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-180badde-048f-4c3a-82b4-d6990106b4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-2445f7ab-d8a5-4147-bae8-ad159018c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-dc2c972c-ccd7-4443-a462-4a5aac487483,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-dc59a943-12f5-4c03-a57e-c2e8da56b925,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-83a205f0-c2aa-41d8-80f4-3b7d485d4a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-a257b38d-aa79-41f8-b3e9-5c364be232a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-d5318109-a928-470a-8b17-10861f07f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-0af539ce-ad86-42af-8554-3b65f7524a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996843411-172.17.0.13-1595420235756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43338,DS-0e33cb3c-15a4-4205-8df0-fde427ee0209,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-7160a009-be40-4492-a3d1-902f4108b946,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-e7d65dfb-d12e-462e-b33e-583a92435296,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-152e7300-3105-4c22-9c9d-4d8c21bd51e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-fa3c36a5-df7c-4d96-8076-077ff8c7aad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-f4caf31a-0cb3-4bc1-93e1-a4ee4d1dde90,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-a6d253a5-0bac-4f0d-8ce8-7acc17e02468,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-1f6aed28-aaf5-4215-ba7e-5d4109b0a69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996843411-172.17.0.13-1595420235756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43338,DS-0e33cb3c-15a4-4205-8df0-fde427ee0209,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-7160a009-be40-4492-a3d1-902f4108b946,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-e7d65dfb-d12e-462e-b33e-583a92435296,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-152e7300-3105-4c22-9c9d-4d8c21bd51e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-fa3c36a5-df7c-4d96-8076-077ff8c7aad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-f4caf31a-0cb3-4bc1-93e1-a4ee4d1dde90,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-a6d253a5-0bac-4f0d-8ce8-7acc17e02468,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-1f6aed28-aaf5-4215-ba7e-5d4109b0a69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200441540-172.17.0.13-1595420414544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-4d14f822-6c68-436a-925b-deb69c4f7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-2f171f93-3f3e-492d-a0d2-9ef280ca85a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f49bd34a-54be-4dab-8ebf-4d4482e83120,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-951ac811-9582-4402-9d30-e08e19b956ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-663b6346-9e83-414e-8c41-872b3320f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fa972091-5d2f-4309-8756-cc480770dfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-607f618f-2042-4306-8da9-b7af644a9a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-a5e231a6-f07b-447b-b493-a080f3dbe544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200441540-172.17.0.13-1595420414544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-4d14f822-6c68-436a-925b-deb69c4f7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-2f171f93-3f3e-492d-a0d2-9ef280ca85a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f49bd34a-54be-4dab-8ebf-4d4482e83120,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-951ac811-9582-4402-9d30-e08e19b956ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-663b6346-9e83-414e-8c41-872b3320f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fa972091-5d2f-4309-8756-cc480770dfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-607f618f-2042-4306-8da9-b7af644a9a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-a5e231a6-f07b-447b-b493-a080f3dbe544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328599062-172.17.0.13-1595420588125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-b0f8c0fb-b013-4a60-bff7-2cbe349a2837,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1bd01e0f-7875-4c29-a331-e4513bddd022,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-dab23e24-1023-40ea-8f77-bd778a51f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-5d72c6eb-6cb1-42b7-b4bf-c0fe679e639a,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-5ed12284-fec8-4a87-80de-884b8416de48,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-bfa47dde-8147-418e-95bf-292bc2adae97,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-a365dc4e-c768-45e4-bf73-4e282a7ce2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-0de569b4-a7bd-4700-a26c-d184b1dafbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328599062-172.17.0.13-1595420588125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-b0f8c0fb-b013-4a60-bff7-2cbe349a2837,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1bd01e0f-7875-4c29-a331-e4513bddd022,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-dab23e24-1023-40ea-8f77-bd778a51f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-5d72c6eb-6cb1-42b7-b4bf-c0fe679e639a,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-5ed12284-fec8-4a87-80de-884b8416de48,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-bfa47dde-8147-418e-95bf-292bc2adae97,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-a365dc4e-c768-45e4-bf73-4e282a7ce2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-0de569b4-a7bd-4700-a26c-d184b1dafbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579013965-172.17.0.13-1595420697960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-b0c201e4-9bb6-481d-bc4f-9e0c8a6b7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-a4f94b96-053c-4154-84d3-592189ff7d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-c18c2261-4e5d-43cc-89d5-2ed40a30ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-39ee4f94-40c8-4faf-b581-3c0f7fe800ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-3b9a7ebf-07da-45f5-ac39-132e30aa75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-365a7678-54fb-49ba-966d-dc40af0df49d,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-d1fa5ca9-5f66-4aca-91ea-cd5106a785a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-48e45301-ade7-41e0-8797-82e8957c6ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579013965-172.17.0.13-1595420697960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-b0c201e4-9bb6-481d-bc4f-9e0c8a6b7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-a4f94b96-053c-4154-84d3-592189ff7d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-c18c2261-4e5d-43cc-89d5-2ed40a30ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-39ee4f94-40c8-4faf-b581-3c0f7fe800ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-3b9a7ebf-07da-45f5-ac39-132e30aa75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-365a7678-54fb-49ba-966d-dc40af0df49d,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-d1fa5ca9-5f66-4aca-91ea-cd5106a785a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-48e45301-ade7-41e0-8797-82e8957c6ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45702174-172.17.0.13-1595420734723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40924,DS-17b21efe-7c5f-4734-aef9-1e744ca416df,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-d96e67b6-c433-4051-825b-cc478b3086ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-748f015f-ae23-4bf0-9f7f-88227d049d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-e8807340-6176-40e9-bace-a26b3d0bcb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-3f87bf67-5f58-4e0c-bed7-7a203b692265,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-3b70c068-e0ba-4a4f-86b9-525e7afd1c16,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-a1bd2530-92ec-4aba-88db-5dbe776a10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-fe9a7b53-b212-4446-90fb-f8c570076ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45702174-172.17.0.13-1595420734723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40924,DS-17b21efe-7c5f-4734-aef9-1e744ca416df,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-d96e67b6-c433-4051-825b-cc478b3086ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-748f015f-ae23-4bf0-9f7f-88227d049d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-e8807340-6176-40e9-bace-a26b3d0bcb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-3f87bf67-5f58-4e0c-bed7-7a203b692265,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-3b70c068-e0ba-4a4f-86b9-525e7afd1c16,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-a1bd2530-92ec-4aba-88db-5dbe776a10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-fe9a7b53-b212-4446-90fb-f8c570076ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785385479-172.17.0.13-1595420842690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36605,DS-3707c864-c873-4c94-82a3-bf063c192689,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-db19f8b1-ce33-4833-8303-c3636b603a58,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-72de1043-4a25-44be-93f7-f4afa3ec2381,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-771a4628-4fe8-4266-a54c-e08fe8f8550a,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-04fe4d51-9589-485e-8b5f-8014608928e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-5c275e9d-dae3-4eb2-ad91-392d85279844,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-5a5e8e66-bc9f-49a8-b576-b99cbf7070e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-95903091-3950-4c20-b88a-f5faa062d55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785385479-172.17.0.13-1595420842690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36605,DS-3707c864-c873-4c94-82a3-bf063c192689,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-db19f8b1-ce33-4833-8303-c3636b603a58,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-72de1043-4a25-44be-93f7-f4afa3ec2381,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-771a4628-4fe8-4266-a54c-e08fe8f8550a,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-04fe4d51-9589-485e-8b5f-8014608928e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-5c275e9d-dae3-4eb2-ad91-392d85279844,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-5a5e8e66-bc9f-49a8-b576-b99cbf7070e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-95903091-3950-4c20-b88a-f5faa062d55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793152061-172.17.0.13-1595420931266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-a778a7fc-c9c5-42f9-bb69-46890499eefb,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-1f7fe9ac-4466-41e1-a7da-f23a7e5747fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-c0724bad-df23-4d89-b705-d5527d2a490f,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-b4fb6b93-28c9-41c1-8d21-0298f2f03ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-b3d1d053-e648-4b47-8daa-4da98059bf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-0bc05937-c756-4b96-9418-315323b52d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-208fef3b-5bc3-48e6-b054-121406d65049,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-4a2fe26b-9bdf-4cdd-8819-05efdfa670a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793152061-172.17.0.13-1595420931266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-a778a7fc-c9c5-42f9-bb69-46890499eefb,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-1f7fe9ac-4466-41e1-a7da-f23a7e5747fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-c0724bad-df23-4d89-b705-d5527d2a490f,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-b4fb6b93-28c9-41c1-8d21-0298f2f03ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-b3d1d053-e648-4b47-8daa-4da98059bf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-0bc05937-c756-4b96-9418-315323b52d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-208fef3b-5bc3-48e6-b054-121406d65049,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-4a2fe26b-9bdf-4cdd-8819-05efdfa670a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290899903-172.17.0.13-1595421100707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40885,DS-a9a386a1-d8f6-4871-b784-75d37b98e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-3d632115-276a-4a70-83c5-a4794d9720e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-ccbef44e-7d0e-4ec9-ae7c-fd05eea0a433,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-b1e9d8d8-3460-4e6b-be57-48d4d43ebcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-edad83a2-7921-4cee-b87d-6eff74d3464c,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-d0a8d296-1ed0-4eb4-a66f-94a2229d63d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-85156c97-9cb0-4297-8044-6dc475f3a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-c58336af-ef92-4045-8724-e6c21e8546a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290899903-172.17.0.13-1595421100707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40885,DS-a9a386a1-d8f6-4871-b784-75d37b98e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-3d632115-276a-4a70-83c5-a4794d9720e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-ccbef44e-7d0e-4ec9-ae7c-fd05eea0a433,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-b1e9d8d8-3460-4e6b-be57-48d4d43ebcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-edad83a2-7921-4cee-b87d-6eff74d3464c,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-d0a8d296-1ed0-4eb4-a66f-94a2229d63d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-85156c97-9cb0-4297-8044-6dc475f3a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-c58336af-ef92-4045-8724-e6c21e8546a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470837426-172.17.0.13-1595421549636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-25a1d4fa-2a03-4396-81b3-ba98f3979fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-071b5aff-ed83-4df8-be80-419e078f45f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-7a8fe361-9695-4b72-95e0-4fec24bbf57e,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-077b8961-1c36-4470-b3f6-b790654df2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-5b8da36d-2a9d-4a03-ac45-8a492c4a3e03,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-02736e6a-6dd9-4f87-8363-00962d1e908c,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-6386a2a2-dab2-4240-a27e-0489d66e1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-e4092aeb-0b7c-4bb3-9e25-1b3b8532be01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470837426-172.17.0.13-1595421549636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-25a1d4fa-2a03-4396-81b3-ba98f3979fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-071b5aff-ed83-4df8-be80-419e078f45f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-7a8fe361-9695-4b72-95e0-4fec24bbf57e,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-077b8961-1c36-4470-b3f6-b790654df2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-5b8da36d-2a9d-4a03-ac45-8a492c4a3e03,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-02736e6a-6dd9-4f87-8363-00962d1e908c,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-6386a2a2-dab2-4240-a27e-0489d66e1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-e4092aeb-0b7c-4bb3-9e25-1b3b8532be01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826996377-172.17.0.13-1595421713107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44132,DS-b9ebc15e-cbfc-476c-981a-ffc71c1e7fba,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-af6a4972-0ce5-4448-9c85-e7a6c40657d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-c53a09e8-81c1-4186-9b7d-5f253eb167f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-1a55b09e-65c3-433e-92bd-db600245a7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-479e9721-c043-42b5-bcc5-a6fe373352c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-620f1568-46ad-44bf-a146-095f6ead7088,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-40cf4a52-d183-4353-90c5-60d88cd68c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-5bcfc890-650f-415a-be53-1e836c07dd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826996377-172.17.0.13-1595421713107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44132,DS-b9ebc15e-cbfc-476c-981a-ffc71c1e7fba,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-af6a4972-0ce5-4448-9c85-e7a6c40657d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-c53a09e8-81c1-4186-9b7d-5f253eb167f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-1a55b09e-65c3-433e-92bd-db600245a7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-479e9721-c043-42b5-bcc5-a6fe373352c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-620f1568-46ad-44bf-a146-095f6ead7088,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-40cf4a52-d183-4353-90c5-60d88cd68c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-5bcfc890-650f-415a-be53-1e836c07dd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5133
