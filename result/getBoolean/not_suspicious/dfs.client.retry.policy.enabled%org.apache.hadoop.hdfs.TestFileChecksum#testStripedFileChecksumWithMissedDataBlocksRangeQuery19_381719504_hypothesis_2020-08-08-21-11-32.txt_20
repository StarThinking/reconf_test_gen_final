reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525492386-172.17.0.16-1596921784088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39783,DS-cfe9826e-2333-4f01-b11c-412351a81b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-c8c004da-4f4e-4ed6-854f-56b07c12f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-8c555115-45c3-49bb-a6dc-e31c98b55745,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-1608c281-bae5-472e-a118-501b76ce708a,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-9b131d88-1315-4cfc-a8c3-cd57689e9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-b83e2338-63d6-429a-98c9-8df8788a57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-e7db6324-30ed-4da0-b144-dee24695b965,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-bdb9f368-13b3-4357-b6d8-d5e443971caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525492386-172.17.0.16-1596921784088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39783,DS-cfe9826e-2333-4f01-b11c-412351a81b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-c8c004da-4f4e-4ed6-854f-56b07c12f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-8c555115-45c3-49bb-a6dc-e31c98b55745,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-1608c281-bae5-472e-a118-501b76ce708a,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-9b131d88-1315-4cfc-a8c3-cd57689e9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-b83e2338-63d6-429a-98c9-8df8788a57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-e7db6324-30ed-4da0-b144-dee24695b965,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-bdb9f368-13b3-4357-b6d8-d5e443971caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033634599-172.17.0.16-1596921987202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-4e96d551-5d66-439d-b1b7-1f29f4212bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-c059eeb8-561e-48c1-9785-77aae31e49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-983a270d-bc3f-4405-b966-b8d97006302f,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-a3334ccb-cc67-4355-b928-120b1f7d897a,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-02762500-2988-4ba1-bfca-a8cff5b82597,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7a54e35b-560a-49e8-84f3-b427101f459a,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-a3e01145-a800-4f4f-a89a-f5209ed96736,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-79112c60-a7a0-4129-93f7-3bbcd5d65792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033634599-172.17.0.16-1596921987202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-4e96d551-5d66-439d-b1b7-1f29f4212bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-c059eeb8-561e-48c1-9785-77aae31e49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-983a270d-bc3f-4405-b966-b8d97006302f,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-a3334ccb-cc67-4355-b928-120b1f7d897a,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-02762500-2988-4ba1-bfca-a8cff5b82597,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7a54e35b-560a-49e8-84f3-b427101f459a,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-a3e01145-a800-4f4f-a89a-f5209ed96736,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-79112c60-a7a0-4129-93f7-3bbcd5d65792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851812402-172.17.0.16-1596922466999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-797c4b22-050a-4bf6-990d-8001515ccecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-d69c012b-232c-46e1-89f2-b40185128867,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-36099ba0-fe6d-4c41-9046-21788b76e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-85954d7a-c989-4ad3-89e4-5853782d1175,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-a4d9199c-aa23-4802-bbf7-f9ffb7475297,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-39b0c6aa-7427-4ca9-afa2-e133a0072e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-96f85a14-5d95-4101-adf0-2a9db99175b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-d2a0f61a-f374-49ed-98bc-232de6808f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851812402-172.17.0.16-1596922466999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-797c4b22-050a-4bf6-990d-8001515ccecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-d69c012b-232c-46e1-89f2-b40185128867,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-36099ba0-fe6d-4c41-9046-21788b76e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-85954d7a-c989-4ad3-89e4-5853782d1175,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-a4d9199c-aa23-4802-bbf7-f9ffb7475297,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-39b0c6aa-7427-4ca9-afa2-e133a0072e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-96f85a14-5d95-4101-adf0-2a9db99175b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-d2a0f61a-f374-49ed-98bc-232de6808f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056219954-172.17.0.16-1596922884798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-c6ca8b08-266f-4270-a5d4-69725bc62e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-00a60b31-d865-46d8-ae48-66a2a6d7fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-de30c126-ce3e-4e09-a984-3dc37e2efa02,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-59c504db-f96d-4ac9-ac98-d47425a3652e,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-5dff07e3-705d-408e-85d9-ebc9aadb2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-98972173-b993-456e-a8dc-af08f2eb1ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-6ce19d87-b371-42b9-b2a4-5325a09f4a97,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-abfa4250-3353-4433-a3ff-4cf13e9e9e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056219954-172.17.0.16-1596922884798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-c6ca8b08-266f-4270-a5d4-69725bc62e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-00a60b31-d865-46d8-ae48-66a2a6d7fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-de30c126-ce3e-4e09-a984-3dc37e2efa02,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-59c504db-f96d-4ac9-ac98-d47425a3652e,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-5dff07e3-705d-408e-85d9-ebc9aadb2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-98972173-b993-456e-a8dc-af08f2eb1ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-6ce19d87-b371-42b9-b2a4-5325a09f4a97,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-abfa4250-3353-4433-a3ff-4cf13e9e9e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404055823-172.17.0.16-1596922925687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-7a482b49-3c83-4341-9579-15a7d1f1a569,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-364ee61a-0fab-4ed1-a2ea-61f154d14453,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-72845726-9ea1-4de7-91c7-4deb171fc9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-7b08cbb9-e97e-4a70-8d3a-0bd3cce535cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-165d974a-bcc5-4b50-8e97-758b7ed9ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-40df923c-d81d-40be-81e2-35b556793466,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-3a9cc910-1d32-4eb7-a5ac-0f7f87a18ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-aa6547f6-980d-4b3f-854a-adff2181a522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404055823-172.17.0.16-1596922925687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-7a482b49-3c83-4341-9579-15a7d1f1a569,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-364ee61a-0fab-4ed1-a2ea-61f154d14453,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-72845726-9ea1-4de7-91c7-4deb171fc9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-7b08cbb9-e97e-4a70-8d3a-0bd3cce535cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-165d974a-bcc5-4b50-8e97-758b7ed9ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-40df923c-d81d-40be-81e2-35b556793466,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-3a9cc910-1d32-4eb7-a5ac-0f7f87a18ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-aa6547f6-980d-4b3f-854a-adff2181a522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792594624-172.17.0.16-1596923176646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40166,DS-f4b72089-f0bf-4589-8508-bff21af0678a,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-2e7e9418-ad8b-4d50-a1f5-9bd3d66ab2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-c8348aba-c9c4-431a-8687-f5bd9864327b,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-27e1f4a2-ed8b-4094-8abe-d2a53fa52213,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-cf65dfc6-b766-4bdd-afb4-5812c0073374,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-1f19d560-f9e7-4ee8-b10c-fc6053debc20,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-6c2adc3b-0ef3-4c0a-b822-19fb80ac4b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-bc82c2cd-709b-471c-b2c5-e8062d2edb11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792594624-172.17.0.16-1596923176646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40166,DS-f4b72089-f0bf-4589-8508-bff21af0678a,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-2e7e9418-ad8b-4d50-a1f5-9bd3d66ab2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-c8348aba-c9c4-431a-8687-f5bd9864327b,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-27e1f4a2-ed8b-4094-8abe-d2a53fa52213,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-cf65dfc6-b766-4bdd-afb4-5812c0073374,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-1f19d560-f9e7-4ee8-b10c-fc6053debc20,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-6c2adc3b-0ef3-4c0a-b822-19fb80ac4b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-bc82c2cd-709b-471c-b2c5-e8062d2edb11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215866174-172.17.0.16-1596923991422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-817f2af1-0f25-4ab3-8435-95f989e3e595,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-916859f6-2094-46a7-83c0-f7d61ab6c107,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-a16de1dd-b4e6-4dda-962e-b7f0302b1000,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-97039385-807d-4a81-9404-5cf00954b816,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-95c6c18b-3b91-4295-b6ad-9abb011a03ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-0e911afe-ea36-4c61-adb3-eb75bc63d8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-2bdc6c48-6b05-477d-9496-27510c76ea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-b5ee78e0-1d5e-402a-a3a7-37c9c6baadec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215866174-172.17.0.16-1596923991422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-817f2af1-0f25-4ab3-8435-95f989e3e595,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-916859f6-2094-46a7-83c0-f7d61ab6c107,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-a16de1dd-b4e6-4dda-962e-b7f0302b1000,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-97039385-807d-4a81-9404-5cf00954b816,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-95c6c18b-3b91-4295-b6ad-9abb011a03ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-0e911afe-ea36-4c61-adb3-eb75bc63d8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-2bdc6c48-6b05-477d-9496-27510c76ea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-b5ee78e0-1d5e-402a-a3a7-37c9c6baadec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308927204-172.17.0.16-1596924377430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44067,DS-4924a771-b092-41ce-9e0a-77b1ceb06fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-3aef270f-d78b-45d0-8500-1af0aa420350,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-7b2dfcef-b951-466e-9b38-feadeddd7e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-befaa924-bd70-4019-977b-e506cad5f36a,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-caf42ffd-b738-4472-87ae-3c310e8016a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-77775544-bcc5-4310-bdee-d301f794c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-06eb9e55-092e-405d-8b4e-dc67375e4815,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-d9eb8671-da8c-4181-8140-b1c009f9da05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308927204-172.17.0.16-1596924377430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44067,DS-4924a771-b092-41ce-9e0a-77b1ceb06fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-3aef270f-d78b-45d0-8500-1af0aa420350,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-7b2dfcef-b951-466e-9b38-feadeddd7e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-befaa924-bd70-4019-977b-e506cad5f36a,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-caf42ffd-b738-4472-87ae-3c310e8016a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-77775544-bcc5-4310-bdee-d301f794c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-06eb9e55-092e-405d-8b4e-dc67375e4815,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-d9eb8671-da8c-4181-8140-b1c009f9da05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274443108-172.17.0.16-1596924475073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41996,DS-9fef3ddc-71d4-43dc-8462-a1ab416c4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c569a550-ac08-4cc5-a4d5-855fba48d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-bb1873bf-680a-409f-9c9d-e93548930636,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-1fde321a-2bc9-4bbf-a252-2cdb2c457ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-918a7167-0b79-44de-b77a-151ced06936f,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-90dd4aed-c9fc-4b1c-9632-ae448d4f8280,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-794fdabd-107a-496b-abdf-b05d1ae4fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-e4c893ef-fe22-4842-96d1-9c604e6c46ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274443108-172.17.0.16-1596924475073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41996,DS-9fef3ddc-71d4-43dc-8462-a1ab416c4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c569a550-ac08-4cc5-a4d5-855fba48d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-bb1873bf-680a-409f-9c9d-e93548930636,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-1fde321a-2bc9-4bbf-a252-2cdb2c457ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-918a7167-0b79-44de-b77a-151ced06936f,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-90dd4aed-c9fc-4b1c-9632-ae448d4f8280,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-794fdabd-107a-496b-abdf-b05d1ae4fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-e4c893ef-fe22-4842-96d1-9c604e6c46ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703615698-172.17.0.16-1596924573850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-d65cd580-bf08-497a-946d-b4c37eeaef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-5c18a75f-8fae-4457-8968-0b87053129f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-5ff084dd-183b-4d3b-a08d-1607ffca4e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-01b8808b-ee01-4339-882f-28c5d546ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-add40820-bfc9-4a6f-82e2-4899090576d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-2d08c3c6-30ed-4494-9537-4c53d0ebb93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-a8643fa1-44a9-49d8-9da1-022381ddf8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-38745273-18d4-4a55-9486-dc5538a6a3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703615698-172.17.0.16-1596924573850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-d65cd580-bf08-497a-946d-b4c37eeaef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-5c18a75f-8fae-4457-8968-0b87053129f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-5ff084dd-183b-4d3b-a08d-1607ffca4e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-01b8808b-ee01-4339-882f-28c5d546ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-add40820-bfc9-4a6f-82e2-4899090576d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-2d08c3c6-30ed-4494-9537-4c53d0ebb93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-a8643fa1-44a9-49d8-9da1-022381ddf8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-38745273-18d4-4a55-9486-dc5538a6a3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362408531-172.17.0.16-1596924704597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43485,DS-840c5923-43d0-45d1-9f7a-bb03e7f7b412,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-d73bd550-e37f-4825-8167-07288baf0799,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-8f0821bd-53e2-4442-83a6-9ed090ef5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-cc0cbd27-0bb8-46f0-acd5-e81c13199fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-b9fab1fc-58c1-400a-8084-eae9aace8cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-01ac4f7c-3ff4-4d69-ab5b-0ec24fcc7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-f145cf54-dc24-46b7-b031-187208b53c74,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-722d9b32-286a-44ec-a131-37427fa616ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362408531-172.17.0.16-1596924704597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43485,DS-840c5923-43d0-45d1-9f7a-bb03e7f7b412,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-d73bd550-e37f-4825-8167-07288baf0799,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-8f0821bd-53e2-4442-83a6-9ed090ef5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-cc0cbd27-0bb8-46f0-acd5-e81c13199fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-b9fab1fc-58c1-400a-8084-eae9aace8cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-01ac4f7c-3ff4-4d69-ab5b-0ec24fcc7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-f145cf54-dc24-46b7-b031-187208b53c74,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-722d9b32-286a-44ec-a131-37427fa616ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439971246-172.17.0.16-1596924880888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-c86dd63f-019c-4ab0-9682-d5be41b2d458,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-ad43704b-5078-4218-87d8-5eb896848121,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-eb024d24-5069-43b3-a7a9-0d518fbf6143,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-c061d5cd-76fb-4f86-90d5-88c02d113844,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-68cd019d-3161-4d90-9604-fc4a37a7c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-0fd12d37-2085-4eae-9fb7-558ef7a5ee74,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-6fa31598-3d62-4591-a5b5-a52ff74b1f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-a5144248-02c8-46dd-8d73-91c7f9c3369e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439971246-172.17.0.16-1596924880888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-c86dd63f-019c-4ab0-9682-d5be41b2d458,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-ad43704b-5078-4218-87d8-5eb896848121,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-eb024d24-5069-43b3-a7a9-0d518fbf6143,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-c061d5cd-76fb-4f86-90d5-88c02d113844,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-68cd019d-3161-4d90-9604-fc4a37a7c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-0fd12d37-2085-4eae-9fb7-558ef7a5ee74,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-6fa31598-3d62-4591-a5b5-a52ff74b1f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-a5144248-02c8-46dd-8d73-91c7f9c3369e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400526809-172.17.0.16-1596925017607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-4f0cca19-aa7f-4889-a8c5-a831de4d3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-669feb2d-63ad-4820-a3eb-dd778e3537ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-4a444b16-c163-423f-9c7a-cf0a4611b421,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-e3485c64-9e67-4912-a3f1-425cefd07a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-220f1632-f7a8-4566-9249-19f30c0d92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-affe2472-d510-443d-818e-210d68befbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-e3e695a6-c01e-471f-898a-bbe970447d13,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-cc49f78a-1bb3-4377-9531-bdd09319f494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400526809-172.17.0.16-1596925017607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-4f0cca19-aa7f-4889-a8c5-a831de4d3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-669feb2d-63ad-4820-a3eb-dd778e3537ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-4a444b16-c163-423f-9c7a-cf0a4611b421,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-e3485c64-9e67-4912-a3f1-425cefd07a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-220f1632-f7a8-4566-9249-19f30c0d92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-affe2472-d510-443d-818e-210d68befbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-e3e695a6-c01e-471f-898a-bbe970447d13,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-cc49f78a-1bb3-4377-9531-bdd09319f494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4204532-172.17.0.16-1596925352923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-3a1a9ecf-a80d-417a-868c-6b4f9a7457e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-c6f79e8f-7527-4ec7-8281-bf4a8fb4a3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c8000a63-6e0b-4dad-a903-49184a136460,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-6a7f5c63-1798-42b3-92b7-9aea796879f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-80f6391e-59b6-4a15-af44-82ea49f5acf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-79a8ca7c-9d48-40bb-8747-50f830633a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-6028b6d6-e470-4029-bd10-dd7b16e2c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-69c807cb-98fe-457f-a1d9-60c9bce6f269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4204532-172.17.0.16-1596925352923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-3a1a9ecf-a80d-417a-868c-6b4f9a7457e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-c6f79e8f-7527-4ec7-8281-bf4a8fb4a3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c8000a63-6e0b-4dad-a903-49184a136460,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-6a7f5c63-1798-42b3-92b7-9aea796879f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-80f6391e-59b6-4a15-af44-82ea49f5acf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-79a8ca7c-9d48-40bb-8747-50f830633a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-6028b6d6-e470-4029-bd10-dd7b16e2c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-69c807cb-98fe-457f-a1d9-60c9bce6f269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786733202-172.17.0.16-1596925742455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37196,DS-c6c440a9-22ca-412c-8430-841f342464d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-814f27d4-f721-4abd-826e-1df3af3953e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-f972e222-e04c-4556-afec-08e73a9f26f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-578db255-b1a5-490d-908e-e85bd10bbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-abc05a87-3431-4f88-8fc8-d586d0a0be7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-f90e5495-5243-4436-869e-5e59ef7ed688,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-b32cf0dd-80aa-4c1d-bfc5-c78eae6c6b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-505261cc-d360-4b2b-89ce-7a12c1e825f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786733202-172.17.0.16-1596925742455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37196,DS-c6c440a9-22ca-412c-8430-841f342464d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-814f27d4-f721-4abd-826e-1df3af3953e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-f972e222-e04c-4556-afec-08e73a9f26f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-578db255-b1a5-490d-908e-e85bd10bbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-abc05a87-3431-4f88-8fc8-d586d0a0be7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-f90e5495-5243-4436-869e-5e59ef7ed688,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-b32cf0dd-80aa-4c1d-bfc5-c78eae6c6b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-505261cc-d360-4b2b-89ce-7a12c1e825f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392766780-172.17.0.16-1596925822406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41246,DS-260a6df2-c906-4061-a8de-82b918d5ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a2e4f34f-ee53-4798-a320-3ab89c406708,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-b4fb849e-b8a7-4d56-ab89-223a849b506f,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-3acb0f13-06ca-4a83-baba-3604fd29e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-69adc34f-c5b7-4512-8832-287c7185e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-ef380e6b-841f-4b77-8852-1a4ac8df4068,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-96112942-ae90-4e98-a226-226a2d61ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-79f67f2f-aa52-4fa7-ba0d-308bfaba34d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392766780-172.17.0.16-1596925822406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41246,DS-260a6df2-c906-4061-a8de-82b918d5ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a2e4f34f-ee53-4798-a320-3ab89c406708,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-b4fb849e-b8a7-4d56-ab89-223a849b506f,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-3acb0f13-06ca-4a83-baba-3604fd29e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-69adc34f-c5b7-4512-8832-287c7185e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-ef380e6b-841f-4b77-8852-1a4ac8df4068,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-96112942-ae90-4e98-a226-226a2d61ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-79f67f2f-aa52-4fa7-ba0d-308bfaba34d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229106999-172.17.0.16-1596925950448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40532,DS-af6367ae-d671-4e9a-bfb4-17cb01298553,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-a529884e-bb5a-4138-8054-87b229d292fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-43b324c2-cd11-45f6-a84f-2f753b6a43e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-88b845ff-4422-448b-849c-1ae4c7ff5927,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-81c7e59f-fe27-467a-944d-df9903452d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-65efaa67-2465-4e9d-b9e9-71ba064185a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-f6c4c57b-9b32-4c2d-b480-c718ff0327eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-3d9fc817-99a0-4875-a5a3-944735c2ba24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229106999-172.17.0.16-1596925950448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40532,DS-af6367ae-d671-4e9a-bfb4-17cb01298553,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-a529884e-bb5a-4138-8054-87b229d292fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-43b324c2-cd11-45f6-a84f-2f753b6a43e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-88b845ff-4422-448b-849c-1ae4c7ff5927,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-81c7e59f-fe27-467a-944d-df9903452d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-65efaa67-2465-4e9d-b9e9-71ba064185a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-f6c4c57b-9b32-4c2d-b480-c718ff0327eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-3d9fc817-99a0-4875-a5a3-944735c2ba24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22100156-172.17.0.16-1596927428342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42817,DS-c2cd3bb8-76cf-4444-84d4-b154c1c5338a,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-51df3f68-7acd-4b2d-b093-f9cce3c037f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-3a33fce8-7ba9-4e84-a0aa-112faf0ee965,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-255004b2-43b3-4989-a98c-9f30b677155d,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-01f091c9-c65f-4a26-945b-34f7f004b303,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-b5f24d4c-4850-486d-ba12-ed49fa1464f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-e18f7e99-b109-4740-b77e-b0509d1eecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4a38effa-8a04-4306-bfba-5f4ed92419b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22100156-172.17.0.16-1596927428342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42817,DS-c2cd3bb8-76cf-4444-84d4-b154c1c5338a,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-51df3f68-7acd-4b2d-b093-f9cce3c037f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-3a33fce8-7ba9-4e84-a0aa-112faf0ee965,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-255004b2-43b3-4989-a98c-9f30b677155d,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-01f091c9-c65f-4a26-945b-34f7f004b303,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-b5f24d4c-4850-486d-ba12-ed49fa1464f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-e18f7e99-b109-4740-b77e-b0509d1eecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4a38effa-8a04-4306-bfba-5f4ed92419b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403270922-172.17.0.16-1596927578615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-d73e132b-da26-454b-941d-1d3fd07e9754,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-22c0a5eb-a6cf-4399-8fc4-4ec6069fc7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-e8500d3d-3512-4963-81ba-92e8dcdfbcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-09f9eb3a-b2df-4ec3-a6bb-a50af33bcf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-1982da0c-e099-4351-bc90-0be4af7e507d,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-5f3a0d3e-50cb-46ee-b714-5f50619d8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-b00d54c5-98fa-4bb6-8231-ac7e956970ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-ad525cec-b8fc-4033-a862-5187015d7d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403270922-172.17.0.16-1596927578615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-d73e132b-da26-454b-941d-1d3fd07e9754,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-22c0a5eb-a6cf-4399-8fc4-4ec6069fc7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-e8500d3d-3512-4963-81ba-92e8dcdfbcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-09f9eb3a-b2df-4ec3-a6bb-a50af33bcf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-1982da0c-e099-4351-bc90-0be4af7e507d,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-5f3a0d3e-50cb-46ee-b714-5f50619d8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-b00d54c5-98fa-4bb6-8231-ac7e956970ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-ad525cec-b8fc-4033-a862-5187015d7d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6751
