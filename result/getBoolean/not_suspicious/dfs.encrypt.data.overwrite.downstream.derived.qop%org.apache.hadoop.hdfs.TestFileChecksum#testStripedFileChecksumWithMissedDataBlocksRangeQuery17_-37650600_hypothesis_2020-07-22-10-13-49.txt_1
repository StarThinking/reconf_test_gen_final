reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086902802-172.17.0.17-1595412845025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-0ba658bf-fb97-4243-9cd7-affc82a123b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-d988bcea-0320-4ef5-83ca-3198dbb35b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-32c7c67f-f210-4ee7-b6b3-bb215bff78ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-b3cdbd54-0716-49a3-8a70-0ee74f5e3da0,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-d288f10d-2e67-4a5e-8c10-d3e91cc9f02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-4e99c21a-7eda-48c0-958f-0decedad2447,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-52472057-c46d-49f6-8a8c-b30a499c102f,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-a1829f52-1709-4cb3-8c05-8a37b9095cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086902802-172.17.0.17-1595412845025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-0ba658bf-fb97-4243-9cd7-affc82a123b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-d988bcea-0320-4ef5-83ca-3198dbb35b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-32c7c67f-f210-4ee7-b6b3-bb215bff78ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-b3cdbd54-0716-49a3-8a70-0ee74f5e3da0,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-d288f10d-2e67-4a5e-8c10-d3e91cc9f02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-4e99c21a-7eda-48c0-958f-0decedad2447,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-52472057-c46d-49f6-8a8c-b30a499c102f,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-a1829f52-1709-4cb3-8c05-8a37b9095cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137354476-172.17.0.17-1595413220590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-d779f7c2-b186-4165-b84c-a32fd7a3c203,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-93f0600d-a96e-4123-bc4f-d1f1f642ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-bd929da1-a4ba-4117-ae60-4523bc638bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-e77333dd-d35c-4d7e-8929-fc658a8c780b,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-854f15b9-16e6-4584-9e18-95cabdb925e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-5457c6d5-c1b5-46f3-8a65-2a274f496c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-db4e89f6-f1eb-4ea4-9b28-83e9b677cb46,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-4b3162d2-8bf8-4000-8231-db20637ba02b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137354476-172.17.0.17-1595413220590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-d779f7c2-b186-4165-b84c-a32fd7a3c203,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-93f0600d-a96e-4123-bc4f-d1f1f642ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-bd929da1-a4ba-4117-ae60-4523bc638bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-e77333dd-d35c-4d7e-8929-fc658a8c780b,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-854f15b9-16e6-4584-9e18-95cabdb925e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-5457c6d5-c1b5-46f3-8a65-2a274f496c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-db4e89f6-f1eb-4ea4-9b28-83e9b677cb46,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-4b3162d2-8bf8-4000-8231-db20637ba02b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496444406-172.17.0.17-1595413292544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-b3e035ce-7f5e-4368-a946-e304913b8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-2e1386f2-9d5e-4a13-925e-2ac83d723f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-f5013321-d800-4e8a-90e6-e336a204b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-43328e62-d942-4ecf-9f30-f0ec753c2b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-33d8edf6-20e8-40d4-91e4-9a974fdaea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-2dd17bac-01aa-4e6f-bb56-c624600da483,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-24320cd8-5972-45c8-b819-31af316a77c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-605a043c-164c-427d-a8eb-68340217b767,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496444406-172.17.0.17-1595413292544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-b3e035ce-7f5e-4368-a946-e304913b8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-2e1386f2-9d5e-4a13-925e-2ac83d723f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-f5013321-d800-4e8a-90e6-e336a204b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-43328e62-d942-4ecf-9f30-f0ec753c2b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-33d8edf6-20e8-40d4-91e4-9a974fdaea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-2dd17bac-01aa-4e6f-bb56-c624600da483,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-24320cd8-5972-45c8-b819-31af316a77c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-605a043c-164c-427d-a8eb-68340217b767,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134943667-172.17.0.17-1595413812049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-61e79eab-e68d-4993-b19d-66744fc2acf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-76337331-955f-4775-bfb2-70fad2c820ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-f67f1a79-23b1-4dca-bbdb-e12be5894c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-a321db54-21a1-4d92-b43b-e420effb990e,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-47324a4c-2ba4-4fd3-9737-ad90e381d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-bdc55b8c-883d-4d30-8c92-37c8d6b4f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-74636ea3-81ad-4456-89c1-d29a260b01b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-dd30e94e-72e6-41aa-9e91-1d7ba93dc0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134943667-172.17.0.17-1595413812049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-61e79eab-e68d-4993-b19d-66744fc2acf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-76337331-955f-4775-bfb2-70fad2c820ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-f67f1a79-23b1-4dca-bbdb-e12be5894c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-a321db54-21a1-4d92-b43b-e420effb990e,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-47324a4c-2ba4-4fd3-9737-ad90e381d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-bdc55b8c-883d-4d30-8c92-37c8d6b4f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-74636ea3-81ad-4456-89c1-d29a260b01b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-dd30e94e-72e6-41aa-9e91-1d7ba93dc0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421408783-172.17.0.17-1595414202933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-cfffafec-bd83-4f47-a0c6-4d132ad6cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-7f527bc5-985c-46f6-b0cf-bf7ddb4425d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-36b319d9-1972-411e-8987-9673c43ee3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-97644840-bca3-4ee5-b645-57b70b3fb50e,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-3f430268-5af2-468d-833e-c45fc8a638ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-ac603783-e52a-4c02-89b9-48ce00ac6e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-f961a8d9-b17d-4921-abb2-30697ac445d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-78446dba-1cbb-4ceb-a222-079a761a4717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421408783-172.17.0.17-1595414202933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-cfffafec-bd83-4f47-a0c6-4d132ad6cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-7f527bc5-985c-46f6-b0cf-bf7ddb4425d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-36b319d9-1972-411e-8987-9673c43ee3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-97644840-bca3-4ee5-b645-57b70b3fb50e,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-3f430268-5af2-468d-833e-c45fc8a638ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-ac603783-e52a-4c02-89b9-48ce00ac6e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-f961a8d9-b17d-4921-abb2-30697ac445d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-78446dba-1cbb-4ceb-a222-079a761a4717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705391705-172.17.0.17-1595414757650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-5bb2607b-cb54-4b95-9d37-b5e3202c9dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-69eeb576-d95b-4f02-8dff-e94523836bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b3ff3251-9513-4e11-9a9b-9248f3beabb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-e87e26c6-4a55-4d46-84ec-9a4da525b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-1531dd8d-4542-4ff4-831e-cb52c806ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-116bfd42-5db7-41e4-ac33-da363bdc7700,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-2480fb01-95e9-48d5-977e-b1bc6caa0a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-537073fc-3a9f-4ff8-afef-c3611cbc89e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705391705-172.17.0.17-1595414757650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-5bb2607b-cb54-4b95-9d37-b5e3202c9dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-69eeb576-d95b-4f02-8dff-e94523836bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b3ff3251-9513-4e11-9a9b-9248f3beabb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-e87e26c6-4a55-4d46-84ec-9a4da525b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-1531dd8d-4542-4ff4-831e-cb52c806ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-116bfd42-5db7-41e4-ac33-da363bdc7700,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-2480fb01-95e9-48d5-977e-b1bc6caa0a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-537073fc-3a9f-4ff8-afef-c3611cbc89e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324170512-172.17.0.17-1595414826899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-c780e6a3-c599-4870-8993-e0510f09c406,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-8722dc73-c891-446a-a12a-b7b8bd01e772,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-d090f239-eee6-478d-839b-4164f1b36adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-95da1506-b744-437b-9ec0-596d1e5cb96f,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-55c85d42-7149-4da5-b062-6d1dbc49442b,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-dde1a77c-38bb-4015-a75c-f12bb5e7558b,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-528195ee-3761-484f-91e9-0aa5c45b4ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-ac802319-4b3f-4686-a8fc-17888e209a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324170512-172.17.0.17-1595414826899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-c780e6a3-c599-4870-8993-e0510f09c406,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-8722dc73-c891-446a-a12a-b7b8bd01e772,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-d090f239-eee6-478d-839b-4164f1b36adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-95da1506-b744-437b-9ec0-596d1e5cb96f,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-55c85d42-7149-4da5-b062-6d1dbc49442b,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-dde1a77c-38bb-4015-a75c-f12bb5e7558b,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-528195ee-3761-484f-91e9-0aa5c45b4ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-ac802319-4b3f-4686-a8fc-17888e209a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262897057-172.17.0.17-1595414961186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35964,DS-e27d663e-0118-419c-80e2-1ad9ada51503,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-c0654ca4-87da-4a35-93c1-7da00a2b2894,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-aa627381-c81c-4bbe-83ec-4fb581d8446f,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-e5e72184-7c5c-492b-a952-ac5b0001ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-55f07411-0b69-4569-8545-4ac48c1ca2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-6a3f4cc4-cc11-48d0-a879-a356d2c03b84,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-9548cc1c-c99e-49be-a2b4-afc6710e3967,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-f6aaad77-8daa-472c-9a12-23b00a570435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262897057-172.17.0.17-1595414961186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35964,DS-e27d663e-0118-419c-80e2-1ad9ada51503,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-c0654ca4-87da-4a35-93c1-7da00a2b2894,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-aa627381-c81c-4bbe-83ec-4fb581d8446f,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-e5e72184-7c5c-492b-a952-ac5b0001ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-55f07411-0b69-4569-8545-4ac48c1ca2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-6a3f4cc4-cc11-48d0-a879-a356d2c03b84,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-9548cc1c-c99e-49be-a2b4-afc6710e3967,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-f6aaad77-8daa-472c-9a12-23b00a570435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386398917-172.17.0.17-1595414995413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-ddbca21b-00b8-487d-84ff-b0afa3abd31e,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-379e5610-ea0f-4f9b-8e04-dee3f53a427e,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-d72ac890-38a9-4103-9ac3-7d41c13778b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-1586c412-1d0d-4a4d-8cee-aeeada3245ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-bae86598-a8cb-4f0b-adde-2ef2ffcda809,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-4aeee8bd-2b94-4e8e-ac11-dafc91e4a444,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-f494f520-948e-410b-b42b-63bd228315f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-b490fd6c-996b-456e-909a-86f58564f482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386398917-172.17.0.17-1595414995413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-ddbca21b-00b8-487d-84ff-b0afa3abd31e,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-379e5610-ea0f-4f9b-8e04-dee3f53a427e,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-d72ac890-38a9-4103-9ac3-7d41c13778b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-1586c412-1d0d-4a4d-8cee-aeeada3245ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-bae86598-a8cb-4f0b-adde-2ef2ffcda809,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-4aeee8bd-2b94-4e8e-ac11-dafc91e4a444,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-f494f520-948e-410b-b42b-63bd228315f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-b490fd6c-996b-456e-909a-86f58564f482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204402998-172.17.0.17-1595415317878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41394,DS-4a8e3767-34e7-4af1-9074-c2e666a77c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-552294ab-f3d0-45e9-bdaf-ff68c1d827af,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-b320ac39-97df-47e4-a208-57c96b688644,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-04585a00-e95a-43e5-8b3b-f94852e0141a,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-1112b975-e09d-46e9-85d0-92c4e8e688db,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-ab18197c-e396-4b24-aa2d-e4a3695cb54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-579df632-f433-4109-b6c3-d201d0aff221,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-0694fbbc-d74d-45a8-a7ac-32b5e609c573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204402998-172.17.0.17-1595415317878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41394,DS-4a8e3767-34e7-4af1-9074-c2e666a77c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-552294ab-f3d0-45e9-bdaf-ff68c1d827af,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-b320ac39-97df-47e4-a208-57c96b688644,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-04585a00-e95a-43e5-8b3b-f94852e0141a,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-1112b975-e09d-46e9-85d0-92c4e8e688db,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-ab18197c-e396-4b24-aa2d-e4a3695cb54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-579df632-f433-4109-b6c3-d201d0aff221,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-0694fbbc-d74d-45a8-a7ac-32b5e609c573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575635388-172.17.0.17-1595415390751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-7dd90638-84fd-436c-9fb1-a87390fd2d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-0617b9c1-fdf5-4b00-8b34-085240b5bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-0b2a2a1c-ba6a-45ea-a6b8-9ff924ad9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-9afacd0d-50f4-4153-9630-ab0d781390e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-36cd83eb-a277-4edf-9cbc-c35af551a81e,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-33243910-cbe9-4d4a-9fde-76bacb5ecc02,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-29017970-e2ea-445d-bb71-b7aa99a9b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-540b0e51-4a73-4c2d-bdca-c3b344f8f1b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575635388-172.17.0.17-1595415390751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-7dd90638-84fd-436c-9fb1-a87390fd2d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-0617b9c1-fdf5-4b00-8b34-085240b5bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-0b2a2a1c-ba6a-45ea-a6b8-9ff924ad9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-9afacd0d-50f4-4153-9630-ab0d781390e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-36cd83eb-a277-4edf-9cbc-c35af551a81e,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-33243910-cbe9-4d4a-9fde-76bacb5ecc02,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-29017970-e2ea-445d-bb71-b7aa99a9b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-540b0e51-4a73-4c2d-bdca-c3b344f8f1b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658233867-172.17.0.17-1595415710725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40799,DS-da5ec115-bb7a-485a-8c73-8fa3ce5cd0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-3021ada6-8cd8-4225-96b1-a1fa4940212d,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-61ec6493-cb30-44d1-a93b-8f9b198dc53d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-0ebc8003-b71d-4ab4-bac5-980b33620a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-3396e20e-2fb1-42ae-9df7-34f9fe980927,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-eb38bc20-8558-418a-bd7a-9e545d3e84e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-79f6971d-c54a-4d8f-b18e-862a592a0695,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-36c9f4a3-9dbf-4ea6-9bf9-d8b5c19ee810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658233867-172.17.0.17-1595415710725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40799,DS-da5ec115-bb7a-485a-8c73-8fa3ce5cd0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-3021ada6-8cd8-4225-96b1-a1fa4940212d,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-61ec6493-cb30-44d1-a93b-8f9b198dc53d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-0ebc8003-b71d-4ab4-bac5-980b33620a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-3396e20e-2fb1-42ae-9df7-34f9fe980927,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-eb38bc20-8558-418a-bd7a-9e545d3e84e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-79f6971d-c54a-4d8f-b18e-862a592a0695,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-36c9f4a3-9dbf-4ea6-9bf9-d8b5c19ee810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511925989-172.17.0.17-1595415750073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-9eb17f37-92b3-4a29-b3f1-d324463a4f23,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-2f85aa49-f3c9-4d6a-bd3e-d82c8e4dad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-4ab78a0e-4408-436c-9b73-5310fc688f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-77fa0ebe-4dd3-4ac1-9b21-f7fbe3c38c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-6f466f65-60e7-4402-bae8-b1fb66f89766,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-dcdc2a26-3132-46e6-9fb1-9b1cef1add78,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-269de7c0-a887-4284-b9af-80212d6b37c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-2bcc0ce2-2b1b-4e69-82e9-b065f9d66ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511925989-172.17.0.17-1595415750073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-9eb17f37-92b3-4a29-b3f1-d324463a4f23,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-2f85aa49-f3c9-4d6a-bd3e-d82c8e4dad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-4ab78a0e-4408-436c-9b73-5310fc688f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-77fa0ebe-4dd3-4ac1-9b21-f7fbe3c38c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-6f466f65-60e7-4402-bae8-b1fb66f89766,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-dcdc2a26-3132-46e6-9fb1-9b1cef1add78,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-269de7c0-a887-4284-b9af-80212d6b37c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-2bcc0ce2-2b1b-4e69-82e9-b065f9d66ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572096774-172.17.0.17-1595415816268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-e886581d-f545-40f7-b524-76498c43cb31,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-ba1aeb18-19d0-4487-a8b4-c1b224616ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-d8ebf5f5-f0a0-41e2-b9ef-ff9bc7eb1c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-a39b4ca3-d2aa-4024-b29b-ec6369e48105,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-c367f79a-c7d5-45d0-8b4c-389ff2051824,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-a988002f-3323-4de2-b7e9-b35b35575912,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-018b8342-3bb3-4f40-bcf8-66b676e5ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-74a65991-755a-487d-a326-8ba99ec1a51c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572096774-172.17.0.17-1595415816268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-e886581d-f545-40f7-b524-76498c43cb31,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-ba1aeb18-19d0-4487-a8b4-c1b224616ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-d8ebf5f5-f0a0-41e2-b9ef-ff9bc7eb1c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-a39b4ca3-d2aa-4024-b29b-ec6369e48105,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-c367f79a-c7d5-45d0-8b4c-389ff2051824,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-a988002f-3323-4de2-b7e9-b35b35575912,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-018b8342-3bb3-4f40-bcf8-66b676e5ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-74a65991-755a-487d-a326-8ba99ec1a51c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456634032-172.17.0.17-1595415855730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44606,DS-f904f062-3e81-4f99-acf7-4d50be34e648,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-f6238e32-6036-4487-b188-82f5384cc578,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-625f331d-08d4-4004-b008-b51f60c13bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-edfec44b-e3dc-4b94-bb77-f99195275bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-f0327d6c-ff21-4dda-b8c2-7c73dca43eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-e568710c-3d83-42ae-bd99-b3363dd763bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-3a75edda-7b75-4ec8-bd92-686853d15ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-70a7d7d8-cd20-4878-be83-c53121361056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456634032-172.17.0.17-1595415855730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44606,DS-f904f062-3e81-4f99-acf7-4d50be34e648,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-f6238e32-6036-4487-b188-82f5384cc578,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-625f331d-08d4-4004-b008-b51f60c13bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-edfec44b-e3dc-4b94-bb77-f99195275bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-f0327d6c-ff21-4dda-b8c2-7c73dca43eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-e568710c-3d83-42ae-bd99-b3363dd763bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-3a75edda-7b75-4ec8-bd92-686853d15ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-70a7d7d8-cd20-4878-be83-c53121361056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053372657-172.17.0.17-1595415891049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43462,DS-6729809b-c853-4b37-98cf-0195f6c42a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-d41bdfd9-2c85-4b8d-9fbb-fac7177849e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-357836df-a726-4c2e-b702-20a69921850c,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-48ce1d16-5452-42ea-aef9-9ba089e50890,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8eb7bfe2-0911-4f28-b17e-c9c8c5bd1e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-ace4a517-58d1-45b2-b078-3aade56b0f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-74208eb8-30fe-4d3c-941a-4869c386557c,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-cd95b406-57b3-40d5-a784-e90dd372f55e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053372657-172.17.0.17-1595415891049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43462,DS-6729809b-c853-4b37-98cf-0195f6c42a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-d41bdfd9-2c85-4b8d-9fbb-fac7177849e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-357836df-a726-4c2e-b702-20a69921850c,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-48ce1d16-5452-42ea-aef9-9ba089e50890,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8eb7bfe2-0911-4f28-b17e-c9c8c5bd1e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-ace4a517-58d1-45b2-b078-3aade56b0f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-74208eb8-30fe-4d3c-941a-4869c386557c,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-cd95b406-57b3-40d5-a784-e90dd372f55e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1276748959-172.17.0.17-1595416092608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35311,DS-8068e130-80b3-4b90-8f8e-58ce6c8d5a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-28a738ec-475a-4353-a61d-e1b6b70b5668,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-d7d0bab2-c218-4dd5-b5ed-3097027273a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-56dadfcc-e000-482d-ad69-dab81db33f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-324b763b-be44-4981-885a-8910901f1556,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-d6542221-663d-4654-a8cb-83ca3aca9534,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-d713e121-2edc-4bfb-8f94-d2c5e914e563,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-312502c9-b41f-49a2-bf08-39c36a41094a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1276748959-172.17.0.17-1595416092608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35311,DS-8068e130-80b3-4b90-8f8e-58ce6c8d5a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-28a738ec-475a-4353-a61d-e1b6b70b5668,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-d7d0bab2-c218-4dd5-b5ed-3097027273a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-56dadfcc-e000-482d-ad69-dab81db33f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-324b763b-be44-4981-885a-8910901f1556,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-d6542221-663d-4654-a8cb-83ca3aca9534,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-d713e121-2edc-4bfb-8f94-d2c5e914e563,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-312502c9-b41f-49a2-bf08-39c36a41094a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380212741-172.17.0.17-1595416210165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-d75244a7-8234-4ce8-b4cc-8e58a7875809,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-ba55cb6d-e970-4e14-95f7-888832b72531,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-746a3abd-bbc7-4bdf-842e-5d14a5753e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-d6dccc37-1f4b-466f-b7b8-7a28c9d188a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-b93a310f-fd43-47ca-a78b-6a5671b8bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-b9305e6c-fa8b-4165-9782-0e0cbce55f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-ddd63564-f9f7-45b7-a5b1-24749ada5d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-4c1a420f-dde6-488d-a0b6-63291ff488b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380212741-172.17.0.17-1595416210165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-d75244a7-8234-4ce8-b4cc-8e58a7875809,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-ba55cb6d-e970-4e14-95f7-888832b72531,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-746a3abd-bbc7-4bdf-842e-5d14a5753e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-d6dccc37-1f4b-466f-b7b8-7a28c9d188a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-b93a310f-fd43-47ca-a78b-6a5671b8bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-b9305e6c-fa8b-4165-9782-0e0cbce55f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-ddd63564-f9f7-45b7-a5b1-24749ada5d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-4c1a420f-dde6-488d-a0b6-63291ff488b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069354279-172.17.0.17-1595416295441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-3c358209-7e86-4c16-930b-2011a5eed96f,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-6e526a0f-2794-464c-b6da-60fc6a7c0649,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-a13ff712-1f3d-489c-972f-42ca7353d377,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-b1ca8d22-595d-4d13-9e99-c02d05bc73c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-ed964503-8e72-42b1-964b-d02b425a9f53,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-1e0f1b14-8aa9-47c4-9292-c65f3184099d,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-a3369d55-3c56-443a-aae2-45ab055882a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-ff3cd09b-2b9f-4622-b5f2-2b4ac37d0d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069354279-172.17.0.17-1595416295441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-3c358209-7e86-4c16-930b-2011a5eed96f,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-6e526a0f-2794-464c-b6da-60fc6a7c0649,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-a13ff712-1f3d-489c-972f-42ca7353d377,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-b1ca8d22-595d-4d13-9e99-c02d05bc73c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-ed964503-8e72-42b1-964b-d02b425a9f53,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-1e0f1b14-8aa9-47c4-9292-c65f3184099d,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-a3369d55-3c56-443a-aae2-45ab055882a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-ff3cd09b-2b9f-4622-b5f2-2b4ac37d0d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670373381-172.17.0.17-1595416449954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-acb8e917-30bb-4c7b-aaa4-359cde7d18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-e35a6410-6617-4bc4-952b-46e64a3c93c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-5abf95bb-0832-42e6-97c3-1886b0b049d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-7303055d-198d-4f3e-9d13-5ad38b513966,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-edaf2b9d-24eb-4881-8a17-f359c6cbe551,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-4f67203e-1150-49c3-8423-0154dcfed7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-d3333978-1393-4a91-8b5d-76f402ab1c09,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-4fa5716a-57b7-46a7-b556-1715107b6916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670373381-172.17.0.17-1595416449954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-acb8e917-30bb-4c7b-aaa4-359cde7d18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-e35a6410-6617-4bc4-952b-46e64a3c93c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-5abf95bb-0832-42e6-97c3-1886b0b049d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-7303055d-198d-4f3e-9d13-5ad38b513966,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-edaf2b9d-24eb-4881-8a17-f359c6cbe551,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-4f67203e-1150-49c3-8423-0154dcfed7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-d3333978-1393-4a91-8b5d-76f402ab1c09,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-4fa5716a-57b7-46a7-b556-1715107b6916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072974157-172.17.0.17-1595416552315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-921c0798-4e33-4b25-8989-7f739cfbafa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-4d94be25-c543-4dab-a34d-09338dca821d,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-900b5857-8ca3-4ddb-a560-b0e19b512dee,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-5f357756-a860-451e-b145-9004699fc949,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-fd1cac34-77e3-4958-b7a8-7ffdaab0f7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-c19f5925-483f-4dfc-a193-7141a4080290,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-7447d5ca-4735-4d40-967f-5d99828c08af,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-01e733e3-3149-488e-b1ad-6bd4c7bd2572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072974157-172.17.0.17-1595416552315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-921c0798-4e33-4b25-8989-7f739cfbafa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-4d94be25-c543-4dab-a34d-09338dca821d,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-900b5857-8ca3-4ddb-a560-b0e19b512dee,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-5f357756-a860-451e-b145-9004699fc949,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-fd1cac34-77e3-4958-b7a8-7ffdaab0f7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-c19f5925-483f-4dfc-a193-7141a4080290,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-7447d5ca-4735-4d40-967f-5d99828c08af,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-01e733e3-3149-488e-b1ad-6bd4c7bd2572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347675693-172.17.0.17-1595416805482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-955acd3c-0a8d-4cfd-9269-32c8200f799c,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-783b49d0-ddf1-443f-953a-124f8f0e7177,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-388e24e6-c9b4-4cc4-ba27-d7813a3ac5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-4bcf3f88-e597-432a-af16-3d880165b814,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-8bbb0ced-fdb7-4881-9dab-cbe3accbb716,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-bba177bf-a6cd-432c-afbe-1af4af51cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-86070a5c-063f-4aef-980a-80d8afed89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-45d41ec7-890f-47f2-b817-c3c950c37e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347675693-172.17.0.17-1595416805482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-955acd3c-0a8d-4cfd-9269-32c8200f799c,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-783b49d0-ddf1-443f-953a-124f8f0e7177,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-388e24e6-c9b4-4cc4-ba27-d7813a3ac5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-4bcf3f88-e597-432a-af16-3d880165b814,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-8bbb0ced-fdb7-4881-9dab-cbe3accbb716,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-bba177bf-a6cd-432c-afbe-1af4af51cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-86070a5c-063f-4aef-980a-80d8afed89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-45d41ec7-890f-47f2-b817-c3c950c37e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016320528-172.17.0.17-1595416889335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-dbd8de73-12bc-4936-b9b6-117ae59d78f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-455e28c4-6587-42ec-9196-21be1e3cbf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-8dde4e73-ed60-42eb-b1c5-ca1a3f00c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-1bd832e6-5502-4814-9492-1f9473bdbaad,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-08f423a4-1cf3-4b8d-b151-7cdc7dc44233,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-28d1988d-bc11-4f61-b25a-113e1c9d8614,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-a263f295-c27c-48d8-bd55-188f072050a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-1cc2d5b6-fcd5-4550-8230-88df7d974617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016320528-172.17.0.17-1595416889335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-dbd8de73-12bc-4936-b9b6-117ae59d78f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-455e28c4-6587-42ec-9196-21be1e3cbf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-8dde4e73-ed60-42eb-b1c5-ca1a3f00c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-1bd832e6-5502-4814-9492-1f9473bdbaad,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-08f423a4-1cf3-4b8d-b151-7cdc7dc44233,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-28d1988d-bc11-4f61-b25a-113e1c9d8614,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-a263f295-c27c-48d8-bd55-188f072050a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-1cc2d5b6-fcd5-4550-8230-88df7d974617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4070
