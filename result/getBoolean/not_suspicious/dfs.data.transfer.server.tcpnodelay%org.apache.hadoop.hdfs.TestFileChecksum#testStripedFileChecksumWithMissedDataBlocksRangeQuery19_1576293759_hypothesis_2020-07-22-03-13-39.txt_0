reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954233466-172.17.0.15-1595387730853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-98d39c55-1859-41d0-bf29-76324c7651df,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-075b0000-162a-4cf2-bad9-d1bd6521f688,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-82aea8a9-86f5-41e7-b8b3-6b8e2a9f3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-4b318b24-6e5a-4b70-af4c-976fd813d1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-14168d2c-6153-47ba-ace8-03caef2e0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-11f557c1-8bc1-4f0c-abb7-76682d7b3803,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-78f8028b-dc3c-4868-b1ee-7ae64f566da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-c430195c-f1a2-4b35-a102-a4e443ff2d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954233466-172.17.0.15-1595387730853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-98d39c55-1859-41d0-bf29-76324c7651df,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-075b0000-162a-4cf2-bad9-d1bd6521f688,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-82aea8a9-86f5-41e7-b8b3-6b8e2a9f3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-4b318b24-6e5a-4b70-af4c-976fd813d1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-14168d2c-6153-47ba-ace8-03caef2e0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-11f557c1-8bc1-4f0c-abb7-76682d7b3803,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-78f8028b-dc3c-4868-b1ee-7ae64f566da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-c430195c-f1a2-4b35-a102-a4e443ff2d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612327590-172.17.0.15-1595387869592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-d9c3880a-3e9b-493c-a4f8-002ef7913fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-fbe4fea1-912b-4113-8ba0-0cae76fed7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-a0b4836d-d82d-452b-b6b9-000aee9b062a,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-16cd52f4-488d-4d44-8404-29cb4dee2581,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-151dcbbb-45ed-4001-aac3-42902cbd3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-e7c439a1-7e6c-4c05-ab15-572571476e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-323164bb-c2ee-4cde-8c11-ae1edb274b65,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-a1dd9958-4753-426b-ad32-209f657c1b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612327590-172.17.0.15-1595387869592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-d9c3880a-3e9b-493c-a4f8-002ef7913fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-fbe4fea1-912b-4113-8ba0-0cae76fed7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-a0b4836d-d82d-452b-b6b9-000aee9b062a,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-16cd52f4-488d-4d44-8404-29cb4dee2581,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-151dcbbb-45ed-4001-aac3-42902cbd3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-e7c439a1-7e6c-4c05-ab15-572571476e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-323164bb-c2ee-4cde-8c11-ae1edb274b65,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-a1dd9958-4753-426b-ad32-209f657c1b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929077562-172.17.0.15-1595388272058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-a932a174-2098-4c19-9e9d-a90bcd1afa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-713e6b7e-ef71-49b9-acb5-f87692a568e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-5a4d67c1-e136-48d1-91ed-d480ebe2a038,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-c8d8cd18-2863-472a-bd7d-07a5e9ba4ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-9fc5f30a-ab81-4c34-9884-6b310413d93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-fecc022a-a4af-4e77-8907-1e0b803c6c21,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-e6048161-daa2-4812-bebc-d79500be5bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-ebf6849e-d118-4621-a8b8-a72628436f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929077562-172.17.0.15-1595388272058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-a932a174-2098-4c19-9e9d-a90bcd1afa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-713e6b7e-ef71-49b9-acb5-f87692a568e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-5a4d67c1-e136-48d1-91ed-d480ebe2a038,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-c8d8cd18-2863-472a-bd7d-07a5e9ba4ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-9fc5f30a-ab81-4c34-9884-6b310413d93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-fecc022a-a4af-4e77-8907-1e0b803c6c21,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-e6048161-daa2-4812-bebc-d79500be5bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-ebf6849e-d118-4621-a8b8-a72628436f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125338953-172.17.0.15-1595388380662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-464837f6-1f6c-4b35-bacf-08414814dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-85be0952-f34f-4c07-8095-c03e6d591fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-8502101e-90f4-4966-8ce5-5dd330b9060c,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-566edac7-4215-48d6-9ed6-e3f48d4b8985,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-a50e33c6-3baa-4f7e-974d-8550962f1190,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-128d56f8-3e1c-47f3-bc0d-7e406840b312,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-6d29270f-e8f6-4251-aa37-138ec67d5eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-ce565366-3399-4e3b-80f8-ac5a704b342d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125338953-172.17.0.15-1595388380662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-464837f6-1f6c-4b35-bacf-08414814dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-85be0952-f34f-4c07-8095-c03e6d591fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-8502101e-90f4-4966-8ce5-5dd330b9060c,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-566edac7-4215-48d6-9ed6-e3f48d4b8985,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-a50e33c6-3baa-4f7e-974d-8550962f1190,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-128d56f8-3e1c-47f3-bc0d-7e406840b312,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-6d29270f-e8f6-4251-aa37-138ec67d5eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-ce565366-3399-4e3b-80f8-ac5a704b342d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289123075-172.17.0.15-1595388417224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45909,DS-004d30fc-b0e6-46d7-9446-250904bc6745,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-84ae3e94-d061-4795-932d-9615880c3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-06660b7a-258d-4f4d-850a-bc210ba1d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-3f6d1851-011b-49fe-b849-0f5ebf39088b,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-0d17c57c-9a0d-44fe-bcbf-d7766452fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-da60b98d-9216-4876-bbcd-19901cb94a21,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-70e83668-451d-4ed8-a818-13e5ca4eee1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-a98c4f0f-407a-401c-a007-11cf8143325a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289123075-172.17.0.15-1595388417224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45909,DS-004d30fc-b0e6-46d7-9446-250904bc6745,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-84ae3e94-d061-4795-932d-9615880c3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-06660b7a-258d-4f4d-850a-bc210ba1d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-3f6d1851-011b-49fe-b849-0f5ebf39088b,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-0d17c57c-9a0d-44fe-bcbf-d7766452fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-da60b98d-9216-4876-bbcd-19901cb94a21,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-70e83668-451d-4ed8-a818-13e5ca4eee1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-a98c4f0f-407a-401c-a007-11cf8143325a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369590473-172.17.0.15-1595388646232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35213,DS-ed600c53-b3ff-4e2f-a90d-ad4e7e3f4322,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-2f8ec097-2139-4850-af1c-eecab58ca804,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-4cd272bd-2ff7-476a-bd2c-50e247dd3a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-40ab6e51-510d-4acf-8074-c13c073c6302,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-6607b549-1329-4c21-91f4-00e8d24941a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d3c4cb66-e0bb-4466-92d7-179173221847,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-bb6d7bbf-a60d-4726-9780-6695094eace6,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-2c38b0c9-3825-4d78-8b4b-8d7f5fff0704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369590473-172.17.0.15-1595388646232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35213,DS-ed600c53-b3ff-4e2f-a90d-ad4e7e3f4322,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-2f8ec097-2139-4850-af1c-eecab58ca804,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-4cd272bd-2ff7-476a-bd2c-50e247dd3a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-40ab6e51-510d-4acf-8074-c13c073c6302,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-6607b549-1329-4c21-91f4-00e8d24941a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d3c4cb66-e0bb-4466-92d7-179173221847,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-bb6d7bbf-a60d-4726-9780-6695094eace6,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-2c38b0c9-3825-4d78-8b4b-8d7f5fff0704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530176673-172.17.0.15-1595389221879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-83030a91-1772-463e-8cc5-8c1d99b30c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-aeab9813-4d07-4150-8eaf-7e48f07daae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-6e1f70ce-849c-4ed5-b4de-d17b018d99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-1ef83e2b-5156-45ef-9927-2dc19c5ecd41,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-79e09a64-be99-47ce-8d59-6cde536c9843,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-7b0348bd-7cb9-4721-9a1f-0243b3c5cdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-1c18e537-f4f9-44e1-903c-bf8e1bbb3e85,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-a156b898-ebdc-4360-8429-c972a4c197fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530176673-172.17.0.15-1595389221879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-83030a91-1772-463e-8cc5-8c1d99b30c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-aeab9813-4d07-4150-8eaf-7e48f07daae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-6e1f70ce-849c-4ed5-b4de-d17b018d99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-1ef83e2b-5156-45ef-9927-2dc19c5ecd41,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-79e09a64-be99-47ce-8d59-6cde536c9843,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-7b0348bd-7cb9-4721-9a1f-0243b3c5cdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-1c18e537-f4f9-44e1-903c-bf8e1bbb3e85,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-a156b898-ebdc-4360-8429-c972a4c197fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648482009-172.17.0.15-1595389541149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42467,DS-3d1d1f9f-ec5a-4209-94c2-1f7ffaf0759c,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-6b0f5d1f-93b7-4592-8af9-4f0f24384964,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-60992c4f-e994-4370-be4d-dd893aa3be16,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-c468a076-3a33-4441-90dd-618657d27870,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-0bb143cc-10ba-4676-bf67-93fc1ff8f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-532b2e6e-1895-4be3-a20d-186206730c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-cfcceb3c-06ab-436a-b7f1-624bad518461,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-e00226f1-d223-4ddf-8eb7-f028fc03bd4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648482009-172.17.0.15-1595389541149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42467,DS-3d1d1f9f-ec5a-4209-94c2-1f7ffaf0759c,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-6b0f5d1f-93b7-4592-8af9-4f0f24384964,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-60992c4f-e994-4370-be4d-dd893aa3be16,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-c468a076-3a33-4441-90dd-618657d27870,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-0bb143cc-10ba-4676-bf67-93fc1ff8f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-532b2e6e-1895-4be3-a20d-186206730c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-cfcceb3c-06ab-436a-b7f1-624bad518461,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-e00226f1-d223-4ddf-8eb7-f028fc03bd4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106868706-172.17.0.15-1595389707726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-e7328eaf-63a0-4f6f-9749-7647cc935b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-726567f6-7ea3-4c55-9f06-dda2726838c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-56c6f223-560f-4669-a0d6-2412039eaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-35b51bc5-e1ee-46dd-9727-1aab943ecc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-0cc44a4e-8f0c-4555-b2b7-195cb132cf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-8ae56d64-8ea7-4835-a0af-827287e5d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-8354bd0c-dee8-481f-8b0e-f4c31bd120f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-e7ee2852-5f7f-46df-88e5-ef8a98b5a22c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106868706-172.17.0.15-1595389707726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-e7328eaf-63a0-4f6f-9749-7647cc935b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-726567f6-7ea3-4c55-9f06-dda2726838c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-56c6f223-560f-4669-a0d6-2412039eaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-35b51bc5-e1ee-46dd-9727-1aab943ecc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-0cc44a4e-8f0c-4555-b2b7-195cb132cf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-8ae56d64-8ea7-4835-a0af-827287e5d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-8354bd0c-dee8-481f-8b0e-f4c31bd120f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-e7ee2852-5f7f-46df-88e5-ef8a98b5a22c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323962740-172.17.0.15-1595389783846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39508,DS-d8d059ec-30b9-4b06-882d-3ff270cde89f,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-73e3acf8-b3f9-4f85-96ff-7ac0f7867338,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-3640962c-ea67-49e9-8cd2-68435c582eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-97545728-359e-407d-8d1c-2ff4115032e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-88cbce88-5df4-424e-8c9d-79b94b3b7c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e8713803-9313-47cc-9f82-878652f9723c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-734d3edd-02bc-404e-be64-15ad578d5f43,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-0cc50e27-3f64-4f3f-b5ad-836927d6e7be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323962740-172.17.0.15-1595389783846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39508,DS-d8d059ec-30b9-4b06-882d-3ff270cde89f,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-73e3acf8-b3f9-4f85-96ff-7ac0f7867338,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-3640962c-ea67-49e9-8cd2-68435c582eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-97545728-359e-407d-8d1c-2ff4115032e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-88cbce88-5df4-424e-8c9d-79b94b3b7c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e8713803-9313-47cc-9f82-878652f9723c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-734d3edd-02bc-404e-be64-15ad578d5f43,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-0cc50e27-3f64-4f3f-b5ad-836927d6e7be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478851376-172.17.0.15-1595390302566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44486,DS-b4877f3f-2611-4cf4-8c16-400866f5f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-f01b39ef-6f42-40ef-8c21-9a1c42e560fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-f235f731-0f82-4c2d-a005-5ed74920abe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-d34407a1-2e6e-4689-83b7-eea20ab704b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-cfbaea55-b32a-41b5-a750-45cb989b8ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-dab90ead-ad14-42ca-b996-441a3816e538,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-b2e625c7-686b-4650-8717-df007c2539ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-49abbe7c-f7ff-4aa9-ad64-4280f4b057c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478851376-172.17.0.15-1595390302566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44486,DS-b4877f3f-2611-4cf4-8c16-400866f5f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-f01b39ef-6f42-40ef-8c21-9a1c42e560fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-f235f731-0f82-4c2d-a005-5ed74920abe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-d34407a1-2e6e-4689-83b7-eea20ab704b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-cfbaea55-b32a-41b5-a750-45cb989b8ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-dab90ead-ad14-42ca-b996-441a3816e538,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-b2e625c7-686b-4650-8717-df007c2539ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-49abbe7c-f7ff-4aa9-ad64-4280f4b057c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92360660-172.17.0.15-1595390518419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34387,DS-87bd8044-337d-412c-9787-576ddf68bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-2d724027-d8cf-4047-a9d6-9105a552dcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-4cdef3be-66dd-493f-a289-af5ff6a6a804,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-c89c3065-f9f6-43d8-96e2-d70509e3d371,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-84e9ee41-b3d1-467f-a80c-42c902c393bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-5c84b34a-0797-4620-bec6-f186997c2477,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-1000b75b-39e0-4da3-aa35-169533be73b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-779be263-a99d-4faf-b2b4-8a14371441e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92360660-172.17.0.15-1595390518419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34387,DS-87bd8044-337d-412c-9787-576ddf68bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-2d724027-d8cf-4047-a9d6-9105a552dcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-4cdef3be-66dd-493f-a289-af5ff6a6a804,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-c89c3065-f9f6-43d8-96e2-d70509e3d371,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-84e9ee41-b3d1-467f-a80c-42c902c393bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-5c84b34a-0797-4620-bec6-f186997c2477,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-1000b75b-39e0-4da3-aa35-169533be73b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-779be263-a99d-4faf-b2b4-8a14371441e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301277052-172.17.0.15-1595390685938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33901,DS-83820c1f-bc5f-4e96-8f02-f5b24c3c15d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-996591d7-f1fa-4d66-88fb-c9978b377d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-a5451353-b178-4265-a2c8-613b09104d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-8bbd69ba-aab6-40b8-b2cd-5baf197e374c,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-5bc34db4-0a1e-4d3b-9ce5-2ae41f582567,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-71e0d261-13e1-4e8d-ab9c-894f28dde808,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-789ec137-cdec-4fb1-af65-bfeb8609c553,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-6101b4b4-84ad-431f-8e9d-14b3fa75bb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301277052-172.17.0.15-1595390685938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33901,DS-83820c1f-bc5f-4e96-8f02-f5b24c3c15d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-996591d7-f1fa-4d66-88fb-c9978b377d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-a5451353-b178-4265-a2c8-613b09104d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-8bbd69ba-aab6-40b8-b2cd-5baf197e374c,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-5bc34db4-0a1e-4d3b-9ce5-2ae41f582567,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-71e0d261-13e1-4e8d-ab9c-894f28dde808,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-789ec137-cdec-4fb1-af65-bfeb8609c553,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-6101b4b4-84ad-431f-8e9d-14b3fa75bb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010496665-172.17.0.15-1595390722368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-c380b7d9-c28c-40cd-9782-20f1cee75c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-e5d6d1de-a69c-438b-88c2-0a9e21ef085e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6915f3ed-e8a8-45b1-baf4-70d8a3dd75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-15ccf4bb-562e-4b42-94d6-30367304eb22,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-3a378f5b-2f3a-44c6-9b1b-f8b0a24985f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-2e4d4622-0c6c-498e-b21e-536918da1363,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-925ee2b3-efa1-4ca1-beed-1339f16709a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-74f37250-a281-4ed3-9454-bdd2c05f23b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010496665-172.17.0.15-1595390722368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-c380b7d9-c28c-40cd-9782-20f1cee75c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-e5d6d1de-a69c-438b-88c2-0a9e21ef085e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6915f3ed-e8a8-45b1-baf4-70d8a3dd75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-15ccf4bb-562e-4b42-94d6-30367304eb22,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-3a378f5b-2f3a-44c6-9b1b-f8b0a24985f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-2e4d4622-0c6c-498e-b21e-536918da1363,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-925ee2b3-efa1-4ca1-beed-1339f16709a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-74f37250-a281-4ed3-9454-bdd2c05f23b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671049072-172.17.0.15-1595390950782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-f03e626d-96e3-45a7-8fba-ce0d50d147ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-dc096eaa-c4fb-4c46-8c3a-bf59b896940f,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-3aefc70f-a36f-4798-9038-cbcc7544b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-416dc31b-8b51-4506-8037-04a7b60c8317,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a52f29a2-75ba-4b19-80f8-26828a0d76d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8e8c1ad1-eb50-4c08-8c0a-1ed16c82fbce,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-13b22301-544a-4f1e-a6a9-c39fd151a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-47c48ecf-1bbd-41b9-acb1-d13338bfafca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671049072-172.17.0.15-1595390950782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-f03e626d-96e3-45a7-8fba-ce0d50d147ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-dc096eaa-c4fb-4c46-8c3a-bf59b896940f,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-3aefc70f-a36f-4798-9038-cbcc7544b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-416dc31b-8b51-4506-8037-04a7b60c8317,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a52f29a2-75ba-4b19-80f8-26828a0d76d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8e8c1ad1-eb50-4c08-8c0a-1ed16c82fbce,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-13b22301-544a-4f1e-a6a9-c39fd151a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-47c48ecf-1bbd-41b9-acb1-d13338bfafca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754202331-172.17.0.15-1595391081442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-dc897375-118f-4364-9579-105e0d257834,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-961bcd6b-22cb-4de9-a9c6-cb75e692b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-2b5f9438-620d-4e4b-93e4-031e1ef30e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-63af7b26-3864-4c1e-857f-75263679e6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-56c581d3-cc5f-41bd-ba5b-16e4d3ab8828,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-aa8f79aa-ac54-4b10-9831-aa485ec0cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-ab4d060c-425c-475c-bcf7-3269fc7ba294,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-eafb8d6d-5a69-420f-898f-0562fbdb26fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754202331-172.17.0.15-1595391081442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-dc897375-118f-4364-9579-105e0d257834,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-961bcd6b-22cb-4de9-a9c6-cb75e692b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-2b5f9438-620d-4e4b-93e4-031e1ef30e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-63af7b26-3864-4c1e-857f-75263679e6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-56c581d3-cc5f-41bd-ba5b-16e4d3ab8828,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-aa8f79aa-ac54-4b10-9831-aa485ec0cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-ab4d060c-425c-475c-bcf7-3269fc7ba294,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-eafb8d6d-5a69-420f-898f-0562fbdb26fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604312789-172.17.0.15-1595391850779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-b047d733-d278-455e-af90-9c53e54cd658,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-bb51774d-0abd-49d5-8e01-8d44d01f94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-3eaf9ade-41dd-4ec2-8649-ae10b2511cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-565d7404-5cd1-4970-9554-d1c906d216aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-20d25ee7-899c-4d46-b287-a67bd919e442,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-05cefdc1-3cad-4d7c-855d-6e4b6fcdca66,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-c8d84c79-118d-4feb-8476-2a0672763cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-a8e0573f-2827-4519-9882-b2eeb64bfe25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604312789-172.17.0.15-1595391850779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-b047d733-d278-455e-af90-9c53e54cd658,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-bb51774d-0abd-49d5-8e01-8d44d01f94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-3eaf9ade-41dd-4ec2-8649-ae10b2511cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-565d7404-5cd1-4970-9554-d1c906d216aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-20d25ee7-899c-4d46-b287-a67bd919e442,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-05cefdc1-3cad-4d7c-855d-6e4b6fcdca66,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-c8d84c79-118d-4feb-8476-2a0672763cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-a8e0573f-2827-4519-9882-b2eeb64bfe25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778930755-172.17.0.15-1595392040760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-0ae54847-4ca2-4819-8c9e-bbe13c386c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-079188c5-f0d1-441c-886a-438564b1d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-67487b13-7188-4912-937a-22c9c941c420,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-d9099ad6-210a-4a78-ae47-f2a9ddd3c988,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-ba21bf40-64af-4f2c-9539-7865fa7954e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-6b814071-bfff-479d-bc75-4638ec3503f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a58db6a1-d294-4118-94ad-9f367327b179,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-8d3476bb-215e-465a-9fb7-3749da75c26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778930755-172.17.0.15-1595392040760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-0ae54847-4ca2-4819-8c9e-bbe13c386c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-079188c5-f0d1-441c-886a-438564b1d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-67487b13-7188-4912-937a-22c9c941c420,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-d9099ad6-210a-4a78-ae47-f2a9ddd3c988,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-ba21bf40-64af-4f2c-9539-7865fa7954e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-6b814071-bfff-479d-bc75-4638ec3503f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a58db6a1-d294-4118-94ad-9f367327b179,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-8d3476bb-215e-465a-9fb7-3749da75c26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637293304-172.17.0.15-1595392421198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38630,DS-b44b67ff-d61d-4b9f-9cd8-6054367362ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-826314af-7785-40fa-8d65-43de894777e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-297121e5-2d9a-4fcd-aa82-75e6cd786726,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-3a4fe2e6-4244-4e8c-a921-76def749e9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-d9345171-fcf1-46cf-8102-b40555b3318d,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-55f12558-e53a-475a-93e6-223aa4f06bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-5b8f0f93-6a33-4857-8e9b-9cc9450ad2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-6409efad-16e0-4bcf-a58c-6fce983ba34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637293304-172.17.0.15-1595392421198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38630,DS-b44b67ff-d61d-4b9f-9cd8-6054367362ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-826314af-7785-40fa-8d65-43de894777e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-297121e5-2d9a-4fcd-aa82-75e6cd786726,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-3a4fe2e6-4244-4e8c-a921-76def749e9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-d9345171-fcf1-46cf-8102-b40555b3318d,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-55f12558-e53a-475a-93e6-223aa4f06bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-5b8f0f93-6a33-4857-8e9b-9cc9450ad2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-6409efad-16e0-4bcf-a58c-6fce983ba34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5050
