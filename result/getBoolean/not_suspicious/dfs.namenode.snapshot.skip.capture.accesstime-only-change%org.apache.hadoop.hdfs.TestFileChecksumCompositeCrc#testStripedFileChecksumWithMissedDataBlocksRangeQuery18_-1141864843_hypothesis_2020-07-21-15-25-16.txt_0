reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875061887-172.17.0.6-1595345698625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-5ccf13e8-2a76-4d11-b1f0-bbefb69b518f,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-8f2bb2b5-dc67-4597-bb26-1beca674b029,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-713b9d78-2b9d-4c1d-b73c-f111d835b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-633a26ae-bec9-4da0-a6fb-a2ad93ba780b,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-26d4b5fc-6d85-48a2-9c76-8ff313507c29,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-7bf46b12-0e98-466e-9bff-bcee7fa7cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-fb776d51-7428-4d47-8685-f1206d54f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-7967f56f-8600-4551-9171-0c64586841f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875061887-172.17.0.6-1595345698625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-5ccf13e8-2a76-4d11-b1f0-bbefb69b518f,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-8f2bb2b5-dc67-4597-bb26-1beca674b029,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-713b9d78-2b9d-4c1d-b73c-f111d835b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-633a26ae-bec9-4da0-a6fb-a2ad93ba780b,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-26d4b5fc-6d85-48a2-9c76-8ff313507c29,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-7bf46b12-0e98-466e-9bff-bcee7fa7cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-fb776d51-7428-4d47-8685-f1206d54f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-7967f56f-8600-4551-9171-0c64586841f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941086464-172.17.0.6-1595346133084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-73f835ae-22ef-4e70-b61b-2a8258961820,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6adc34f4-d956-4b7a-aff5-261d97303b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-0b3f4391-e575-48a6-ad8f-0c5fb0c28087,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-ad21e65c-00a6-43ae-8323-b917092f91e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-7c4a567b-c575-4389-9452-022cefc53da9,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-31b6ea09-35e9-4586-973a-1c56f60de576,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-47250b46-399f-4d89-a5f0-353aa420d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-c9d7d01b-3589-4607-a2bf-4d8066b3f1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941086464-172.17.0.6-1595346133084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-73f835ae-22ef-4e70-b61b-2a8258961820,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6adc34f4-d956-4b7a-aff5-261d97303b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-0b3f4391-e575-48a6-ad8f-0c5fb0c28087,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-ad21e65c-00a6-43ae-8323-b917092f91e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-7c4a567b-c575-4389-9452-022cefc53da9,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-31b6ea09-35e9-4586-973a-1c56f60de576,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-47250b46-399f-4d89-a5f0-353aa420d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-c9d7d01b-3589-4607-a2bf-4d8066b3f1c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005891783-172.17.0.6-1595346762282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-6ed25ebf-f77d-41c0-85c9-fa2c447cd4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-a22adc5f-27b6-4cd8-a45c-c2308519c5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-4c05e0c4-5abc-4bdb-a3b0-a71593260aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-deab3dfc-48f4-4f35-9723-f05960018841,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-e38b5f69-47f2-4ac6-ad1a-75cfec35794d,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-5ece9a4f-0f0e-48a4-bd6f-e63c68f2f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-488c38ea-7b6e-454c-8091-f29272a173e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-6654d388-c750-46d5-b1aa-bcd269374c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005891783-172.17.0.6-1595346762282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-6ed25ebf-f77d-41c0-85c9-fa2c447cd4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-a22adc5f-27b6-4cd8-a45c-c2308519c5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-4c05e0c4-5abc-4bdb-a3b0-a71593260aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-deab3dfc-48f4-4f35-9723-f05960018841,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-e38b5f69-47f2-4ac6-ad1a-75cfec35794d,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-5ece9a4f-0f0e-48a4-bd6f-e63c68f2f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-488c38ea-7b6e-454c-8091-f29272a173e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-6654d388-c750-46d5-b1aa-bcd269374c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220427043-172.17.0.6-1595347268618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-1467172d-bd0b-44fe-985d-a05e71ec82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-5bff085e-0212-4aa5-986f-b766ff229dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-b75d5340-733a-45c2-82ab-15170712a730,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-9d0a8da0-9af5-44e4-982f-696f117f330b,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-d05484da-25b0-479f-9cc0-db5838d4bede,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-3c7c026c-09f3-4501-9f9c-d9cce2b68459,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-95a19d8d-8917-4096-9628-3effcf93e634,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-baffa048-9ca2-470b-a6ce-d478ac8d4a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220427043-172.17.0.6-1595347268618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-1467172d-bd0b-44fe-985d-a05e71ec82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-5bff085e-0212-4aa5-986f-b766ff229dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-b75d5340-733a-45c2-82ab-15170712a730,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-9d0a8da0-9af5-44e4-982f-696f117f330b,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-d05484da-25b0-479f-9cc0-db5838d4bede,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-3c7c026c-09f3-4501-9f9c-d9cce2b68459,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-95a19d8d-8917-4096-9628-3effcf93e634,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-baffa048-9ca2-470b-a6ce-d478ac8d4a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529407330-172.17.0.6-1595347372141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46779,DS-a4138453-b525-45f3-882e-c62adcc92af1,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-cc838764-3a8c-4e0b-b157-6f1345e03443,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-081f81fd-c1b3-4657-a09f-e83eef27748a,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-dfe2ebf6-d812-4a3f-b22c-e52a99601b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-108ac2d9-373f-476f-bda0-535eb0c9e012,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-2206369f-36e0-47ee-bb48-207e546c3667,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-4c1b11c4-a61c-448b-80dd-3ffe3a6d852d,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a6eca6ae-07ae-4302-bd61-36e9aca71202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529407330-172.17.0.6-1595347372141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46779,DS-a4138453-b525-45f3-882e-c62adcc92af1,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-cc838764-3a8c-4e0b-b157-6f1345e03443,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-081f81fd-c1b3-4657-a09f-e83eef27748a,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-dfe2ebf6-d812-4a3f-b22c-e52a99601b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-108ac2d9-373f-476f-bda0-535eb0c9e012,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-2206369f-36e0-47ee-bb48-207e546c3667,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-4c1b11c4-a61c-448b-80dd-3ffe3a6d852d,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a6eca6ae-07ae-4302-bd61-36e9aca71202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676549050-172.17.0.6-1595347518281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-5f2dd783-525f-4131-8dbc-a102980c1843,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-cedd0906-8c81-4429-82aa-5983f8893364,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-9d9c54ef-0026-40d1-95a7-22554d057377,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-9ec86e16-cd41-4907-9725-be81663895d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-fd9001b7-1701-4852-966e-c9534e7efe42,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-8cb8120b-b44f-4ab1-a8b5-3b8662762af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-1475b33a-892c-401e-95a8-7a2e680b7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-59b90cf4-edeb-435e-bb26-89d1a0b56a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676549050-172.17.0.6-1595347518281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-5f2dd783-525f-4131-8dbc-a102980c1843,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-cedd0906-8c81-4429-82aa-5983f8893364,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-9d9c54ef-0026-40d1-95a7-22554d057377,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-9ec86e16-cd41-4907-9725-be81663895d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-fd9001b7-1701-4852-966e-c9534e7efe42,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-8cb8120b-b44f-4ab1-a8b5-3b8662762af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-1475b33a-892c-401e-95a8-7a2e680b7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-59b90cf4-edeb-435e-bb26-89d1a0b56a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882805241-172.17.0.6-1595347641374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-f81cbabc-7614-4368-b88a-6e66698d0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-b485b73a-09c4-4d8f-9bba-c7e7e17d870c,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-3514927e-4e9b-4ce8-95cd-f1b1e2ca7322,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-1936e396-3781-42a3-88b0-eab90b8d6e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-35e0a50f-3a0a-4b3e-8eb1-792a3c8d7fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-4c967869-631c-4e0d-874a-0ebfacb0a240,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-950434bf-eca5-4835-81a9-9259796e4a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-8cca8d92-1f75-402e-99eb-e3eef4071b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882805241-172.17.0.6-1595347641374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-f81cbabc-7614-4368-b88a-6e66698d0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-b485b73a-09c4-4d8f-9bba-c7e7e17d870c,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-3514927e-4e9b-4ce8-95cd-f1b1e2ca7322,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-1936e396-3781-42a3-88b0-eab90b8d6e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-35e0a50f-3a0a-4b3e-8eb1-792a3c8d7fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-4c967869-631c-4e0d-874a-0ebfacb0a240,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-950434bf-eca5-4835-81a9-9259796e4a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-8cca8d92-1f75-402e-99eb-e3eef4071b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715264380-172.17.0.6-1595347867296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-7ab7cb33-4d91-4721-8942-cd36db565408,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-3e806939-afcb-4722-b0fc-2dcc41d4ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-fa03388c-f308-472e-85fa-ea4e8be634bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-6c3ccfd1-62aa-408d-86d2-244f06523457,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-b63942ad-2dd8-455a-b163-99867fc6f4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-50228b8c-97ba-4c01-9881-02865a48aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-5ba05592-a6be-427c-98d0-e2939b16121a,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-f938428b-0514-4550-984e-bf658d0f6025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715264380-172.17.0.6-1595347867296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-7ab7cb33-4d91-4721-8942-cd36db565408,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-3e806939-afcb-4722-b0fc-2dcc41d4ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-fa03388c-f308-472e-85fa-ea4e8be634bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-6c3ccfd1-62aa-408d-86d2-244f06523457,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-b63942ad-2dd8-455a-b163-99867fc6f4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-50228b8c-97ba-4c01-9881-02865a48aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-5ba05592-a6be-427c-98d0-e2939b16121a,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-f938428b-0514-4550-984e-bf658d0f6025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621322258-172.17.0.6-1595347971146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-e0b47630-dae2-4ba9-9940-f5c8c5edfbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-ce6cae93-ea4d-4809-a8e7-79bbcb97d943,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-0e9ec598-1d56-49f8-a75d-fb39e7a006d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-80e7158d-5cd4-4cb9-814b-4f921b25aabc,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-4bad5d41-564e-4562-9efc-734a31d603bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-f8a15ccc-204a-4168-ba61-f471b3eb0d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6bb098e2-18dd-481e-9ea4-9f2dae7f02c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d9ff94c8-df1a-43cb-bf66-549d611a26d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621322258-172.17.0.6-1595347971146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-e0b47630-dae2-4ba9-9940-f5c8c5edfbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-ce6cae93-ea4d-4809-a8e7-79bbcb97d943,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-0e9ec598-1d56-49f8-a75d-fb39e7a006d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-80e7158d-5cd4-4cb9-814b-4f921b25aabc,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-4bad5d41-564e-4562-9efc-734a31d603bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-f8a15ccc-204a-4168-ba61-f471b3eb0d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6bb098e2-18dd-481e-9ea4-9f2dae7f02c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d9ff94c8-df1a-43cb-bf66-549d611a26d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424996999-172.17.0.6-1595348423572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-03bdb155-9f72-416c-ba4a-c256786ae7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-606c570f-309e-441c-89be-79b6702e6a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-544818cf-2fab-4b4d-93b1-c052f243260e,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-009735b9-8a8a-4315-ae92-68766d79167c,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-813e2b7f-9838-42f0-a53e-c426aa9c5fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-47429415-0b0d-4de6-98fa-d06879449704,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-f9c9857f-892d-4959-af08-0580f534360e,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-efa1aef1-6f55-4f7c-91ad-bccdec2d989c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424996999-172.17.0.6-1595348423572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-03bdb155-9f72-416c-ba4a-c256786ae7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-606c570f-309e-441c-89be-79b6702e6a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-544818cf-2fab-4b4d-93b1-c052f243260e,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-009735b9-8a8a-4315-ae92-68766d79167c,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-813e2b7f-9838-42f0-a53e-c426aa9c5fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-47429415-0b0d-4de6-98fa-d06879449704,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-f9c9857f-892d-4959-af08-0580f534360e,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-efa1aef1-6f55-4f7c-91ad-bccdec2d989c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974099367-172.17.0.6-1595348610238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44433,DS-0748f441-48ad-4f1c-b4e1-4957c41393d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-457d1160-e004-4169-bcf5-4167c6239044,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-e9c6a466-6928-4658-aef4-c17622093310,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-cf7300eb-a504-49ab-a292-b713a52ea6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-286328e4-f7d9-4f89-a625-708553ac058c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-af159b8e-a12b-4193-b6bf-f72f21af2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-fea2827c-b5ce-4f6c-bd7c-a151488b1a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-c353fe84-603a-448c-9bca-fcdba69b0215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974099367-172.17.0.6-1595348610238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44433,DS-0748f441-48ad-4f1c-b4e1-4957c41393d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-457d1160-e004-4169-bcf5-4167c6239044,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-e9c6a466-6928-4658-aef4-c17622093310,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-cf7300eb-a504-49ab-a292-b713a52ea6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-286328e4-f7d9-4f89-a625-708553ac058c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-af159b8e-a12b-4193-b6bf-f72f21af2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-fea2827c-b5ce-4f6c-bd7c-a151488b1a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-c353fe84-603a-448c-9bca-fcdba69b0215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424313178-172.17.0.6-1595349469569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33510,DS-c0d867fa-f38e-4bc2-94a5-5ae650690b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-2a4053b7-e879-45fd-a508-cfc1b223682f,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-ea4cd317-a840-42f6-9242-a53d7eb603a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-6da9c20b-904d-4b18-ae29-1a69e8cbdb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-f7505905-bf6b-43f1-a689-c5518c4f25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-66688d32-489b-42d1-9f03-ce5c6163c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-de04faac-b355-4366-8d9f-55dd4ffa6d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-ae5b3b33-8f63-49a6-85fd-5f5430e07758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424313178-172.17.0.6-1595349469569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33510,DS-c0d867fa-f38e-4bc2-94a5-5ae650690b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-2a4053b7-e879-45fd-a508-cfc1b223682f,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-ea4cd317-a840-42f6-9242-a53d7eb603a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-6da9c20b-904d-4b18-ae29-1a69e8cbdb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-f7505905-bf6b-43f1-a689-c5518c4f25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-66688d32-489b-42d1-9f03-ce5c6163c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-de04faac-b355-4366-8d9f-55dd4ffa6d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-ae5b3b33-8f63-49a6-85fd-5f5430e07758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691385811-172.17.0.6-1595349687440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-308cac9b-0d31-477e-9593-3799087f048c,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-8976ae01-f040-48c6-92ab-d7c4ca59ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-0f7ce944-a9e5-4bf0-bf32-dc65ba9e6332,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-f466018f-ca53-48bc-a5fa-38f44320d26f,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-4810f1d6-dd80-47c3-bcfd-56f21dcc9142,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-7e988121-ba56-4490-afbe-410e39c6813c,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-011b3a15-519d-48a0-b001-e3a733924e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-edbe2796-5381-48ac-b8b5-342d1e45d106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691385811-172.17.0.6-1595349687440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-308cac9b-0d31-477e-9593-3799087f048c,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-8976ae01-f040-48c6-92ab-d7c4ca59ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-0f7ce944-a9e5-4bf0-bf32-dc65ba9e6332,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-f466018f-ca53-48bc-a5fa-38f44320d26f,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-4810f1d6-dd80-47c3-bcfd-56f21dcc9142,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-7e988121-ba56-4490-afbe-410e39c6813c,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-011b3a15-519d-48a0-b001-e3a733924e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-edbe2796-5381-48ac-b8b5-342d1e45d106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5446
