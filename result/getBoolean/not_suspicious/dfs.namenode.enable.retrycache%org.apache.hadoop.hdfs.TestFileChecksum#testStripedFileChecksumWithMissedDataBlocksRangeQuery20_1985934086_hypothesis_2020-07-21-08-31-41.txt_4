reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628280462-172.17.0.4-1595320720072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-7c66f42e-3d07-40b6-92b8-289f15c0f8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-e9fee5cf-a4f9-457b-8cb6-511d3d04e672,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-a67a47f3-5783-48db-9865-565fae598856,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-f170bdb2-e245-4705-8b5d-dec64657b558,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-8b49257f-fb33-4869-8c75-88f958d1f34c,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4b775443-4061-4669-9ef5-eb044dfc1597,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-8ac273de-b588-4a62-8057-976b8371710f,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-057b1a7e-f5d2-4286-8878-e53a1b6ef6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628280462-172.17.0.4-1595320720072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-7c66f42e-3d07-40b6-92b8-289f15c0f8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-e9fee5cf-a4f9-457b-8cb6-511d3d04e672,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-a67a47f3-5783-48db-9865-565fae598856,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-f170bdb2-e245-4705-8b5d-dec64657b558,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-8b49257f-fb33-4869-8c75-88f958d1f34c,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4b775443-4061-4669-9ef5-eb044dfc1597,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-8ac273de-b588-4a62-8057-976b8371710f,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-057b1a7e-f5d2-4286-8878-e53a1b6ef6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941613826-172.17.0.4-1595321042506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-6cd120af-9bab-44f6-8e12-163764b703e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-1fd90d88-3a1e-4904-8fc9-c91e31c501f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-df8c4a5b-b84f-49b1-885d-dc3ab185bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-77ddd3f8-3b9e-4f56-9c03-ec9c637af892,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-fac75143-23f9-4a1e-9789-d83eaf329670,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-05798e75-961a-4eb2-b91d-7a55ebe91298,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-53221012-5a3c-49de-8058-3a5eb22d3b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-e85ebfa5-a585-49d7-9a89-4052126a476d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941613826-172.17.0.4-1595321042506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-6cd120af-9bab-44f6-8e12-163764b703e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-1fd90d88-3a1e-4904-8fc9-c91e31c501f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-df8c4a5b-b84f-49b1-885d-dc3ab185bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-77ddd3f8-3b9e-4f56-9c03-ec9c637af892,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-fac75143-23f9-4a1e-9789-d83eaf329670,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-05798e75-961a-4eb2-b91d-7a55ebe91298,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-53221012-5a3c-49de-8058-3a5eb22d3b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-e85ebfa5-a585-49d7-9a89-4052126a476d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416316993-172.17.0.4-1595321513253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-cbe2a722-f14e-4ff4-aaca-abe621f7b245,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-b08e1ef7-06e5-40b6-91d0-f6bfa5d8a710,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-86e1e975-0055-4a97-af45-98279f94ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-2f287128-ee67-4595-a702-147a77b4501b,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-fa5da4df-8359-41ec-96e6-eda071bcfa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-c6376397-5c94-4c09-aa69-d7f1bc346608,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-8688b8f8-900b-40d8-85e0-f231f2135682,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-fa5049f8-83a2-4e94-888d-351ca4bedb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416316993-172.17.0.4-1595321513253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-cbe2a722-f14e-4ff4-aaca-abe621f7b245,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-b08e1ef7-06e5-40b6-91d0-f6bfa5d8a710,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-86e1e975-0055-4a97-af45-98279f94ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-2f287128-ee67-4595-a702-147a77b4501b,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-fa5da4df-8359-41ec-96e6-eda071bcfa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-c6376397-5c94-4c09-aa69-d7f1bc346608,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-8688b8f8-900b-40d8-85e0-f231f2135682,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-fa5049f8-83a2-4e94-888d-351ca4bedb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303651209-172.17.0.4-1595321619646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39572,DS-7bef4da8-da7c-4477-9796-f96f65011df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-c36a3216-c284-4d64-94a6-ae2f0ef057c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-1fd67888-bd6e-43cb-b42a-716002e80104,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-1d0b134d-8118-4ba7-bb5c-172ae3d737f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-0efc2d2d-186c-4c07-8671-b85ce272ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-dcf1a3aa-27a1-4d41-8c96-4fc9c9733a82,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-64d245ab-e5e9-424b-bc90-983b703c9c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-a7682cc3-8a4b-496b-bbd7-1cf9974849b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303651209-172.17.0.4-1595321619646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39572,DS-7bef4da8-da7c-4477-9796-f96f65011df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-c36a3216-c284-4d64-94a6-ae2f0ef057c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-1fd67888-bd6e-43cb-b42a-716002e80104,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-1d0b134d-8118-4ba7-bb5c-172ae3d737f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-0efc2d2d-186c-4c07-8671-b85ce272ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-dcf1a3aa-27a1-4d41-8c96-4fc9c9733a82,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-64d245ab-e5e9-424b-bc90-983b703c9c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-a7682cc3-8a4b-496b-bbd7-1cf9974849b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494861317-172.17.0.4-1595321689410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33942,DS-e1a39085-2a41-43e3-8cb9-380a7aa2cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-23ab74f7-1656-49e0-986d-c1ea0e2e6b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ed486b33-be08-431f-b1b2-68ff114f5734,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-6e35045e-b852-4217-af09-81cc9cba6878,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-6fa03c81-8500-449e-9971-af14ae9e2742,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-9d198224-c56c-4b9f-9b43-1c22aaaf7ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-9e2531f6-b335-454b-9466-91f67197a5be,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-cd3ff8da-7d70-45ba-9f7a-e1c7937d7b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494861317-172.17.0.4-1595321689410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33942,DS-e1a39085-2a41-43e3-8cb9-380a7aa2cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-23ab74f7-1656-49e0-986d-c1ea0e2e6b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ed486b33-be08-431f-b1b2-68ff114f5734,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-6e35045e-b852-4217-af09-81cc9cba6878,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-6fa03c81-8500-449e-9971-af14ae9e2742,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-9d198224-c56c-4b9f-9b43-1c22aaaf7ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-9e2531f6-b335-454b-9466-91f67197a5be,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-cd3ff8da-7d70-45ba-9f7a-e1c7937d7b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807559304-172.17.0.4-1595322274498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-7cfe5dd8-5677-4b3c-bab3-a89d6a7ff3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-784daced-137c-434a-9b5b-ac136b092aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-80a26eaa-6fce-48ee-8125-10e8e1ed0fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-7dced651-1192-4715-8245-245fd818c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-af238db7-63ac-4229-948f-49ead72e8c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-4d2df77a-2013-4471-adde-03943fd1d827,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-c414d479-91ed-41f6-9538-0a2ed8747707,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-8051b694-4ecf-418c-8679-c4c22bd47ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807559304-172.17.0.4-1595322274498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-7cfe5dd8-5677-4b3c-bab3-a89d6a7ff3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-784daced-137c-434a-9b5b-ac136b092aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-80a26eaa-6fce-48ee-8125-10e8e1ed0fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-7dced651-1192-4715-8245-245fd818c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-af238db7-63ac-4229-948f-49ead72e8c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-4d2df77a-2013-4471-adde-03943fd1d827,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-c414d479-91ed-41f6-9538-0a2ed8747707,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-8051b694-4ecf-418c-8679-c4c22bd47ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907384582-172.17.0.4-1595322382129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-adf4a37d-3370-4a4f-b0e2-5a20c14c1a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-cf33a700-d1a3-4585-9f13-9b22aa5c37b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-566adb88-54ba-45e4-a996-940d6ee6d716,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-0191ce15-60e0-4368-b397-206ac38003e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-0fe2adda-4e84-4027-bf6b-6a74fb5b3f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-23288bab-0553-4942-aff5-cdeec1a34569,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7d650644-701c-49f0-913a-e4b7c4d55736,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-8ee825c9-873d-4a60-a556-9d445aa0d7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907384582-172.17.0.4-1595322382129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-adf4a37d-3370-4a4f-b0e2-5a20c14c1a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-cf33a700-d1a3-4585-9f13-9b22aa5c37b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-566adb88-54ba-45e4-a996-940d6ee6d716,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-0191ce15-60e0-4368-b397-206ac38003e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-0fe2adda-4e84-4027-bf6b-6a74fb5b3f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-23288bab-0553-4942-aff5-cdeec1a34569,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7d650644-701c-49f0-913a-e4b7c4d55736,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-8ee825c9-873d-4a60-a556-9d445aa0d7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257817553-172.17.0.4-1595322443208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45205,DS-c0795b91-00a8-4053-bcbc-ad732b3e0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-a473017b-0bcb-4278-9ed8-e63810a26a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-49e5249d-8167-4786-a6d4-8fe48183d280,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-97a33bd5-af1f-49c5-83b2-811b71157ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-7851a14b-c580-4464-b3e1-6b2f9fa2a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-20f00abc-1f90-4310-9994-418442b4b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-354f43d3-961a-490c-b853-e3ecd2f19934,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-900bcbf2-e61a-4ec3-9976-7d006bb95264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257817553-172.17.0.4-1595322443208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45205,DS-c0795b91-00a8-4053-bcbc-ad732b3e0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-a473017b-0bcb-4278-9ed8-e63810a26a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-49e5249d-8167-4786-a6d4-8fe48183d280,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-97a33bd5-af1f-49c5-83b2-811b71157ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-7851a14b-c580-4464-b3e1-6b2f9fa2a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-20f00abc-1f90-4310-9994-418442b4b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-354f43d3-961a-490c-b853-e3ecd2f19934,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-900bcbf2-e61a-4ec3-9976-7d006bb95264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812521462-172.17.0.4-1595322506995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-2d5810ec-3def-48e3-826d-64b8e0b144ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-be0cf807-bf8e-4e55-86e1-5e6071c354d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-199838db-05f2-433d-a030-eaf4ba4217b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-1185c903-40db-405a-9ac7-ddc4f9e07a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-118640b2-9002-41e2-9d10-c00becb651f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-2248532b-fac2-4728-b64f-ca30d49c50db,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-377e89e4-1777-4c61-8ddd-b838b05c54aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-95f2d750-dca3-474b-8959-dad79a539d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812521462-172.17.0.4-1595322506995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-2d5810ec-3def-48e3-826d-64b8e0b144ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-be0cf807-bf8e-4e55-86e1-5e6071c354d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-199838db-05f2-433d-a030-eaf4ba4217b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-1185c903-40db-405a-9ac7-ddc4f9e07a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-118640b2-9002-41e2-9d10-c00becb651f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-2248532b-fac2-4728-b64f-ca30d49c50db,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-377e89e4-1777-4c61-8ddd-b838b05c54aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-95f2d750-dca3-474b-8959-dad79a539d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372079691-172.17.0.4-1595322542243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-f7a8760a-a47c-403d-a1de-9ffb5e163a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-8a97140b-8d33-44e0-b573-7a0aab35148a,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-1b1bde8b-a22e-4cad-810a-3a08035e0969,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a0c0c657-ce7c-452f-8ad8-e3c7c4bb155b,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-f782de09-e1df-4e64-99a3-d8f9fb7aa4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-1b3fd674-b6d3-4388-816f-aa27bf4a3f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-223b6a36-f877-4def-a7dd-cbcbea953757,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-914c36fd-4c63-4b50-83a5-cf9cd108fc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372079691-172.17.0.4-1595322542243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-f7a8760a-a47c-403d-a1de-9ffb5e163a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-8a97140b-8d33-44e0-b573-7a0aab35148a,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-1b1bde8b-a22e-4cad-810a-3a08035e0969,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a0c0c657-ce7c-452f-8ad8-e3c7c4bb155b,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-f782de09-e1df-4e64-99a3-d8f9fb7aa4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-1b3fd674-b6d3-4388-816f-aa27bf4a3f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-223b6a36-f877-4def-a7dd-cbcbea953757,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-914c36fd-4c63-4b50-83a5-cf9cd108fc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69189593-172.17.0.4-1595322581552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-08e3df19-d1b4-476a-8308-d95db314ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-630e53e3-c023-43d2-b1b7-eb22b6af2ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-a8b9fa3f-435d-4192-9130-9f045f38f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-029eb686-26fa-420f-aec1-276b4baff2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-8df79740-1189-401a-949f-3197af89a522,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-557b51f4-7b15-494d-b6c1-b25394501295,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-09717170-282d-4b1e-bec0-353c56e7f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-0f19f152-66ed-4785-94df-37c89145454d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69189593-172.17.0.4-1595322581552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-08e3df19-d1b4-476a-8308-d95db314ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-630e53e3-c023-43d2-b1b7-eb22b6af2ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-a8b9fa3f-435d-4192-9130-9f045f38f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-029eb686-26fa-420f-aec1-276b4baff2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-8df79740-1189-401a-949f-3197af89a522,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-557b51f4-7b15-494d-b6c1-b25394501295,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-09717170-282d-4b1e-bec0-353c56e7f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-0f19f152-66ed-4785-94df-37c89145454d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939736583-172.17.0.4-1595322812504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-af47348c-564a-4f93-8e16-4bee8475ff2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-530f4211-c74a-4f9d-803f-e2b2ffad9e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-8a043bf2-d9fb-477f-b347-f87809514a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-68c2bf19-9177-4330-951b-8746d8427b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-be03b0ef-d7b0-4a03-88b4-dd70454e09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-dd6c30d8-7ddc-4785-bd5e-b2e3affe472c,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f8bef972-d37e-4650-b7df-bd0fad25a40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-9d2c833e-7d6b-4652-8784-b6c622668693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939736583-172.17.0.4-1595322812504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-af47348c-564a-4f93-8e16-4bee8475ff2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-530f4211-c74a-4f9d-803f-e2b2ffad9e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-8a043bf2-d9fb-477f-b347-f87809514a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-68c2bf19-9177-4330-951b-8746d8427b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-be03b0ef-d7b0-4a03-88b4-dd70454e09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-dd6c30d8-7ddc-4785-bd5e-b2e3affe472c,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f8bef972-d37e-4650-b7df-bd0fad25a40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-9d2c833e-7d6b-4652-8784-b6c622668693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687622578-172.17.0.4-1595322913956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-f34aaaef-f517-4827-876e-92fe1b7e520f,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-8b54876c-fffd-4be0-b6ae-afc48c5fe3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-28c981a3-1bad-48bd-aa82-0874ba349b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-1b432ce0-1600-46f8-a093-0877d80a156c,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-45beab37-25fa-45dc-8dcf-b9d1cee6ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-bf846731-72a5-4b20-8303-0ea64a7d8b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-d0e8e017-0a7b-4098-897e-02cae5e45eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-0b95b091-eb31-4246-a5af-4805b2929bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687622578-172.17.0.4-1595322913956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-f34aaaef-f517-4827-876e-92fe1b7e520f,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-8b54876c-fffd-4be0-b6ae-afc48c5fe3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-28c981a3-1bad-48bd-aa82-0874ba349b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-1b432ce0-1600-46f8-a093-0877d80a156c,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-45beab37-25fa-45dc-8dcf-b9d1cee6ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-bf846731-72a5-4b20-8303-0ea64a7d8b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-d0e8e017-0a7b-4098-897e-02cae5e45eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-0b95b091-eb31-4246-a5af-4805b2929bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512251528-172.17.0.4-1595322979464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-daed416f-a9a7-4b61-bf28-b54c1914fe27,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-9e7d5884-6402-4af7-87a3-cebd628207dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-91e81728-4078-4333-8276-b87a798452f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-7602e957-87f9-4a9d-96af-07612c449067,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-7006292d-2000-4301-8cb1-4a1bc34b8548,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-839de2b7-c924-407e-98ac-e992aef635f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-2aec87a6-153f-4bc6-ac2e-af9c315ed3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-53b60c22-6b12-4fa6-872a-fd785b9bea70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512251528-172.17.0.4-1595322979464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-daed416f-a9a7-4b61-bf28-b54c1914fe27,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-9e7d5884-6402-4af7-87a3-cebd628207dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-91e81728-4078-4333-8276-b87a798452f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-7602e957-87f9-4a9d-96af-07612c449067,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-7006292d-2000-4301-8cb1-4a1bc34b8548,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-839de2b7-c924-407e-98ac-e992aef635f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-2aec87a6-153f-4bc6-ac2e-af9c315ed3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-53b60c22-6b12-4fa6-872a-fd785b9bea70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630964433-172.17.0.4-1595323333482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38611,DS-425c0990-0a4e-42ea-a708-c447a7496da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-29c47eb3-2b9f-444e-af91-a047d91e9842,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-b60e538f-c1f9-4899-ba28-8f6ac434d645,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-e6c7d7db-cd64-4bad-a936-d33fe9cc33ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-58a905e8-d636-47d9-acee-7413e8f06122,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-cf988ead-4b88-484f-9aa7-d29aa5234439,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-2437479b-219a-4b44-a007-e1e386695915,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-2118ecc9-9142-45ff-a73c-b5ed8b5cf7a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630964433-172.17.0.4-1595323333482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38611,DS-425c0990-0a4e-42ea-a708-c447a7496da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-29c47eb3-2b9f-444e-af91-a047d91e9842,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-b60e538f-c1f9-4899-ba28-8f6ac434d645,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-e6c7d7db-cd64-4bad-a936-d33fe9cc33ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-58a905e8-d636-47d9-acee-7413e8f06122,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-cf988ead-4b88-484f-9aa7-d29aa5234439,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-2437479b-219a-4b44-a007-e1e386695915,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-2118ecc9-9142-45ff-a73c-b5ed8b5cf7a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003711833-172.17.0.4-1595323368639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-b6501958-b460-4f7d-b990-e0dda3055805,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-c6638e32-1d2d-4463-905b-b7e70f8ebd87,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-2c2e7c6b-b325-4d6f-a96e-d83925ad59c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-dcc2a61f-73c1-49a1-acbc-f18409715cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-4f8b7e2a-c16e-4b3a-8b45-c7dab13060d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-6dc6f147-f328-4fda-9dad-0f0b79f0c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-5fe28473-d46c-4a8c-82cb-132c9d4493a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8efb7ccf-d5d8-447c-b27e-4c7321e40ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003711833-172.17.0.4-1595323368639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-b6501958-b460-4f7d-b990-e0dda3055805,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-c6638e32-1d2d-4463-905b-b7e70f8ebd87,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-2c2e7c6b-b325-4d6f-a96e-d83925ad59c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-dcc2a61f-73c1-49a1-acbc-f18409715cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-4f8b7e2a-c16e-4b3a-8b45-c7dab13060d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-6dc6f147-f328-4fda-9dad-0f0b79f0c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-5fe28473-d46c-4a8c-82cb-132c9d4493a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8efb7ccf-d5d8-447c-b27e-4c7321e40ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394597807-172.17.0.4-1595323504709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39432,DS-06059e0c-4695-4543-9809-a50311efca77,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-6c3114dd-2eba-48e1-ae22-7e7647c64763,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-a104d03e-aafc-44d9-9e7c-76726629cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-530ee9bc-ba25-4dc3-b55f-9a44f86b4c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-fa88f2dc-fb21-435d-81c6-19013bf9ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-7c1819ea-c751-4150-a83f-e50a7fcc062f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-eaf659ca-5930-4916-a023-bf8e8b92d720,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-2e8a0930-a635-4b7b-94e9-673b36207ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394597807-172.17.0.4-1595323504709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39432,DS-06059e0c-4695-4543-9809-a50311efca77,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-6c3114dd-2eba-48e1-ae22-7e7647c64763,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-a104d03e-aafc-44d9-9e7c-76726629cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-530ee9bc-ba25-4dc3-b55f-9a44f86b4c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-fa88f2dc-fb21-435d-81c6-19013bf9ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-7c1819ea-c751-4150-a83f-e50a7fcc062f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-eaf659ca-5930-4916-a023-bf8e8b92d720,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-2e8a0930-a635-4b7b-94e9-673b36207ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488326353-172.17.0.4-1595323671226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-456add7a-1988-42bc-b18d-86a0bf69139e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-61cd94b2-a239-4770-830b-9fcda789a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-7514bee7-bdce-4773-a001-a37d9a251ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-afbaea1c-d462-4be6-9a0c-89d9dcc1cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-a0b6d56a-05f3-47dd-95fb-1a746fa7fdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-ad115430-6a32-42f7-bfdd-d493bd838ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-d2586585-2f98-4d59-b655-6d75cea03348,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-f1aea887-6ab1-4c33-81e3-9166976ee603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488326353-172.17.0.4-1595323671226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-456add7a-1988-42bc-b18d-86a0bf69139e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-61cd94b2-a239-4770-830b-9fcda789a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-7514bee7-bdce-4773-a001-a37d9a251ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-afbaea1c-d462-4be6-9a0c-89d9dcc1cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-a0b6d56a-05f3-47dd-95fb-1a746fa7fdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-ad115430-6a32-42f7-bfdd-d493bd838ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-d2586585-2f98-4d59-b655-6d75cea03348,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-f1aea887-6ab1-4c33-81e3-9166976ee603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324383957-172.17.0.4-1595324117228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-3c258c1b-5010-4715-b09c-b58b5b198395,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-beb32047-17f0-41fa-a8ea-351c8c8f93b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-fe4a6739-cf4e-405f-a154-000e74d5917d,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-e7bf88ed-ba52-4dcd-8c00-bcde2d17e098,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-e917d629-9b14-48cd-95fb-f8434b81b885,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9d313d25-a376-41b9-bb8a-7cce340beee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-333e541f-2334-4921-8555-74cb1d8206c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-f725d78e-02b0-4670-96ed-99b1e95832c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324383957-172.17.0.4-1595324117228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-3c258c1b-5010-4715-b09c-b58b5b198395,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-beb32047-17f0-41fa-a8ea-351c8c8f93b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-fe4a6739-cf4e-405f-a154-000e74d5917d,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-e7bf88ed-ba52-4dcd-8c00-bcde2d17e098,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-e917d629-9b14-48cd-95fb-f8434b81b885,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9d313d25-a376-41b9-bb8a-7cce340beee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-333e541f-2334-4921-8555-74cb1d8206c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-f725d78e-02b0-4670-96ed-99b1e95832c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999564102-172.17.0.4-1595324191221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37656,DS-974bb3a8-5497-414f-8900-e5f62c2cece8,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-d7366302-404d-4f4f-be1f-21cc31244a47,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-e95ef92f-0608-4b36-b862-b8f2a48d09a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-401ef419-e8b5-4cf4-8315-f550bd113e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-fecff849-2ea2-4203-bb2d-b5fa4058d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-6073fbcd-c6f6-417b-b498-9902b664fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-be47cacf-d31f-4922-8ea6-387b8bbefb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-566aaa2b-906c-40b9-b93c-8eabbce67b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999564102-172.17.0.4-1595324191221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37656,DS-974bb3a8-5497-414f-8900-e5f62c2cece8,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-d7366302-404d-4f4f-be1f-21cc31244a47,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-e95ef92f-0608-4b36-b862-b8f2a48d09a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-401ef419-e8b5-4cf4-8315-f550bd113e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-fecff849-2ea2-4203-bb2d-b5fa4058d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-6073fbcd-c6f6-417b-b498-9902b664fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-be47cacf-d31f-4922-8ea6-387b8bbefb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-566aaa2b-906c-40b9-b93c-8eabbce67b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158767858-172.17.0.4-1595324224241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-4aedb219-25fe-4155-9e50-c30b881035ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-01e01e71-bf8d-4229-a19b-71076bc129cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-d229b6f4-5492-4e81-b1d1-9f2d5f32bfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-fe1866e4-bbce-421a-b986-def8965b182d,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-de684a74-4a7a-4cf3-aada-bff566044063,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-06c61930-82be-476b-9a53-13e122f78d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-bd0f6352-48c7-4117-889f-7818fabdc6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-0318cd64-4833-4ec6-b731-8c27df7d5bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158767858-172.17.0.4-1595324224241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-4aedb219-25fe-4155-9e50-c30b881035ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-01e01e71-bf8d-4229-a19b-71076bc129cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-d229b6f4-5492-4e81-b1d1-9f2d5f32bfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-fe1866e4-bbce-421a-b986-def8965b182d,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-de684a74-4a7a-4cf3-aada-bff566044063,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-06c61930-82be-476b-9a53-13e122f78d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-bd0f6352-48c7-4117-889f-7818fabdc6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-0318cd64-4833-4ec6-b731-8c27df7d5bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243591258-172.17.0.4-1595324655411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-9657ff6d-e138-4a12-b3ba-98d6c8da5358,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-f6d9aeee-b6ed-42f3-8956-2cbd1dafc345,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-d88bef29-e788-492c-a09c-abc78dd0bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-7b8d3a15-c026-4f24-b118-0b75a355b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-beb4b7dd-72af-4915-b659-fd248162edb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-fe043a17-5f25-4ce2-bdea-48e919798d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-42f5c62c-4d3e-4463-a366-f63fc73ab485,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-44471262-7a8c-4830-ad54-c20801722d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243591258-172.17.0.4-1595324655411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-9657ff6d-e138-4a12-b3ba-98d6c8da5358,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-f6d9aeee-b6ed-42f3-8956-2cbd1dafc345,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-d88bef29-e788-492c-a09c-abc78dd0bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-7b8d3a15-c026-4f24-b118-0b75a355b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-beb4b7dd-72af-4915-b659-fd248162edb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-fe043a17-5f25-4ce2-bdea-48e919798d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-42f5c62c-4d3e-4463-a366-f63fc73ab485,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-44471262-7a8c-4830-ad54-c20801722d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4888
