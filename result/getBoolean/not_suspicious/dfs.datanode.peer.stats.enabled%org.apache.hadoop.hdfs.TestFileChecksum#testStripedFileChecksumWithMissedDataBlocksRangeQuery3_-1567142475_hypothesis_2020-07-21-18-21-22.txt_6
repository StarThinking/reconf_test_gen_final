reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846960686-172.17.0.10-1595355770498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-471204df-7c3a-493d-b256-c2df4a12ea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-c039144c-4a90-44dc-88ce-f8e2efa98d66,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-d9cf2dd8-b9bd-4bad-ad0f-5abd1f151360,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-70e49824-e4f6-4052-97da-42d8fdecf272,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-e424171c-3262-4392-9fea-95fe7b652d21,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-4b7174c8-de07-4963-98c6-a1c76d26bb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-0d25ca1a-1f73-4e0c-88eb-eff9f45d05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-3f85f182-1964-43e4-959e-21f0a92f9c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846960686-172.17.0.10-1595355770498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-471204df-7c3a-493d-b256-c2df4a12ea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-c039144c-4a90-44dc-88ce-f8e2efa98d66,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-d9cf2dd8-b9bd-4bad-ad0f-5abd1f151360,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-70e49824-e4f6-4052-97da-42d8fdecf272,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-e424171c-3262-4392-9fea-95fe7b652d21,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-4b7174c8-de07-4963-98c6-a1c76d26bb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-0d25ca1a-1f73-4e0c-88eb-eff9f45d05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-3f85f182-1964-43e4-959e-21f0a92f9c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860994733-172.17.0.10-1595356022867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36273,DS-e32b9fa7-d30d-4de3-a083-95c493571f18,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-843467b2-047b-4624-b1c1-5226e527005c,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-eb03658c-8f92-457d-8e39-91c19ce003a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-abc481fd-b002-4aaa-8846-e018b675789b,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-3334079b-57aa-4d03-b183-02d5efabc13e,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-8bdd01cd-420b-4d18-96a6-4f27b3d85317,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-1077bdb9-64f0-415a-ba27-504295b1dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-8ace44ac-b1a5-441a-8065-67a769808f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860994733-172.17.0.10-1595356022867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36273,DS-e32b9fa7-d30d-4de3-a083-95c493571f18,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-843467b2-047b-4624-b1c1-5226e527005c,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-eb03658c-8f92-457d-8e39-91c19ce003a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-abc481fd-b002-4aaa-8846-e018b675789b,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-3334079b-57aa-4d03-b183-02d5efabc13e,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-8bdd01cd-420b-4d18-96a6-4f27b3d85317,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-1077bdb9-64f0-415a-ba27-504295b1dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-8ace44ac-b1a5-441a-8065-67a769808f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690242662-172.17.0.10-1595356342254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-d76220cc-e5a8-4f9d-92a0-2926d7acb5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-202033c7-668b-4f4a-af12-f8198da631d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-7f491516-5652-448e-b160-3d2f8e9609b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-021a8eec-af68-48be-906d-89200d31e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-71b51f38-4e76-4a2f-889b-698c442bc8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-e8a49917-ee10-4492-a97e-d93eaafb2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-7b06a0ad-b368-41be-abd0-bd9a82395d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-be7bcad6-83fb-4c1c-a025-01d9e70ac7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690242662-172.17.0.10-1595356342254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-d76220cc-e5a8-4f9d-92a0-2926d7acb5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-202033c7-668b-4f4a-af12-f8198da631d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-7f491516-5652-448e-b160-3d2f8e9609b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-021a8eec-af68-48be-906d-89200d31e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-71b51f38-4e76-4a2f-889b-698c442bc8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-e8a49917-ee10-4492-a97e-d93eaafb2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-7b06a0ad-b368-41be-abd0-bd9a82395d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-be7bcad6-83fb-4c1c-a025-01d9e70ac7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487425676-172.17.0.10-1595356713318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-16395459-8152-4772-b1dc-9cb4012aac06,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-b9013f33-48df-48f4-8b8e-7f8eec1e3ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-0ada88e8-303f-4488-8def-8155e8576839,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-c7f85ef3-9b0b-433e-a3ee-0ca5249dfeea,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-66203699-a4b1-40bb-9ff5-ad551293072c,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-541e638e-0e72-46a4-aa57-a8c18ff0dbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-eb48582f-8e63-4c7c-9f0f-02289c9941e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-1347a3a6-5666-47dc-9e4e-6afe79f5781c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487425676-172.17.0.10-1595356713318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-16395459-8152-4772-b1dc-9cb4012aac06,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-b9013f33-48df-48f4-8b8e-7f8eec1e3ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-0ada88e8-303f-4488-8def-8155e8576839,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-c7f85ef3-9b0b-433e-a3ee-0ca5249dfeea,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-66203699-a4b1-40bb-9ff5-ad551293072c,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-541e638e-0e72-46a4-aa57-a8c18ff0dbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-eb48582f-8e63-4c7c-9f0f-02289c9941e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-1347a3a6-5666-47dc-9e4e-6afe79f5781c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743274144-172.17.0.10-1595357552820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-71eae316-ea51-4d8f-93d0-083fc99291e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-07b26917-a279-4d65-b059-fb6963ac82aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-b0f0d63b-79c8-4166-a33f-53be4e608642,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-3c712cdd-f55e-46e0-bf36-206a5bde13ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-d8259212-ea16-4ed8-a31f-91d211c033a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-433f8b2d-75d8-459b-b4e9-47a2d4951748,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-2281921a-9c5a-4297-b063-df45419eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-8896caca-b250-40d9-b5c2-705dccf0aac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743274144-172.17.0.10-1595357552820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-71eae316-ea51-4d8f-93d0-083fc99291e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-07b26917-a279-4d65-b059-fb6963ac82aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-b0f0d63b-79c8-4166-a33f-53be4e608642,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-3c712cdd-f55e-46e0-bf36-206a5bde13ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-d8259212-ea16-4ed8-a31f-91d211c033a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-433f8b2d-75d8-459b-b4e9-47a2d4951748,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-2281921a-9c5a-4297-b063-df45419eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-8896caca-b250-40d9-b5c2-705dccf0aac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905527210-172.17.0.10-1595357704623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-3e4564b6-b6e4-49fa-a25b-3ece28dc6f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-cedc64df-6290-447d-800c-b9ac91b388dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-2eca79be-5a2b-46a6-8821-37adfa39f601,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-62192d2d-6022-4426-80de-e487b43b4ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-9cbbcc90-91fb-483a-8f69-e01423839454,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-54deb2b6-0eb6-4d66-bc94-b9b3d7f4ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-674e8076-6473-440d-ab8f-9614466df144,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-f13ffc21-7bfa-4c99-bccc-3a5c726be1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905527210-172.17.0.10-1595357704623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-3e4564b6-b6e4-49fa-a25b-3ece28dc6f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-cedc64df-6290-447d-800c-b9ac91b388dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-2eca79be-5a2b-46a6-8821-37adfa39f601,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-62192d2d-6022-4426-80de-e487b43b4ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-9cbbcc90-91fb-483a-8f69-e01423839454,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-54deb2b6-0eb6-4d66-bc94-b9b3d7f4ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-674e8076-6473-440d-ab8f-9614466df144,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-f13ffc21-7bfa-4c99-bccc-3a5c726be1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997132529-172.17.0.10-1595357980286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-fabe0f65-6c1a-426b-9a48-7fa19105bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-790e3f37-8c48-4f87-ae09-706c54e3f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-a42bf327-882c-4954-8bb5-9ff9f8dfd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-bfdbc9f9-9615-4f40-a3a9-ab2b105e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-fb29f4fd-fb4c-4b64-8c4d-5d11f8c9f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-ae2152c2-ab07-4b20-a3d0-1aa86ea4f2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-7691dfb2-b1dd-44f6-98ac-762f7fc91004,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-15a30eb7-9ccb-49cb-80e8-1ade6f01e6b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997132529-172.17.0.10-1595357980286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-fabe0f65-6c1a-426b-9a48-7fa19105bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-790e3f37-8c48-4f87-ae09-706c54e3f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-a42bf327-882c-4954-8bb5-9ff9f8dfd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-bfdbc9f9-9615-4f40-a3a9-ab2b105e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-fb29f4fd-fb4c-4b64-8c4d-5d11f8c9f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-ae2152c2-ab07-4b20-a3d0-1aa86ea4f2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-7691dfb2-b1dd-44f6-98ac-762f7fc91004,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-15a30eb7-9ccb-49cb-80e8-1ade6f01e6b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24448495-172.17.0.10-1595358247979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41214,DS-743d165d-1346-4c2a-b908-002f43d4ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-10ab63af-dbe6-4318-9ca6-6635954d2992,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e87de51a-fea8-443f-8185-47151682c514,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-b4e75638-7c7f-47b3-a7a8-14959d06ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-6f9dfa5f-1f62-4b07-aba0-fdb19a23bc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-e3859b86-b6c1-4a5f-925f-3968da65adae,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-222fc31c-33f7-4557-9cf9-53b59b843863,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-3492368b-f44e-4772-bf03-ee88b42a329a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24448495-172.17.0.10-1595358247979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41214,DS-743d165d-1346-4c2a-b908-002f43d4ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-10ab63af-dbe6-4318-9ca6-6635954d2992,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e87de51a-fea8-443f-8185-47151682c514,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-b4e75638-7c7f-47b3-a7a8-14959d06ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-6f9dfa5f-1f62-4b07-aba0-fdb19a23bc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-e3859b86-b6c1-4a5f-925f-3968da65adae,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-222fc31c-33f7-4557-9cf9-53b59b843863,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-3492368b-f44e-4772-bf03-ee88b42a329a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117535931-172.17.0.10-1595358403294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-a2187d5f-d194-4234-811b-ed6ca306d6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-c667b163-83bc-4f97-ae97-fd6c9bc46ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-7a1c807b-43f2-4ced-bbf4-370d93817c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-8fc10915-7a69-4332-a889-7f4861ba045b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-747272c8-6d38-4568-8789-0334fe5f59df,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-2220f1d0-df40-47b3-9508-254643167bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-880ba74f-f030-492c-83b7-3946a05d7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-5f4dcf59-d9c3-41db-a258-27a631d6d4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117535931-172.17.0.10-1595358403294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-a2187d5f-d194-4234-811b-ed6ca306d6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-c667b163-83bc-4f97-ae97-fd6c9bc46ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-7a1c807b-43f2-4ced-bbf4-370d93817c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-8fc10915-7a69-4332-a889-7f4861ba045b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-747272c8-6d38-4568-8789-0334fe5f59df,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-2220f1d0-df40-47b3-9508-254643167bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-880ba74f-f030-492c-83b7-3946a05d7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-5f4dcf59-d9c3-41db-a258-27a631d6d4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012956315-172.17.0.10-1595358441061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-394ad854-adea-4cf7-8aff-021743f5ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-a36dbc33-bae9-4a89-8087-d76dab5cd50e,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-c3090def-e0c9-4308-b815-7d2aaeae850d,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-5527e607-be2a-42c9-9b26-886e6fca9d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-5ca75c9b-95d6-43bc-b26f-3074c07e03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-8b1a4c6a-5a22-4a93-8f7d-3cb221625229,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-93c724d7-861b-4dba-9660-f98e1476b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-e97d4499-53b5-4160-a6ad-f64f07723e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012956315-172.17.0.10-1595358441061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-394ad854-adea-4cf7-8aff-021743f5ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-a36dbc33-bae9-4a89-8087-d76dab5cd50e,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-c3090def-e0c9-4308-b815-7d2aaeae850d,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-5527e607-be2a-42c9-9b26-886e6fca9d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-5ca75c9b-95d6-43bc-b26f-3074c07e03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-8b1a4c6a-5a22-4a93-8f7d-3cb221625229,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-93c724d7-861b-4dba-9660-f98e1476b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-e97d4499-53b5-4160-a6ad-f64f07723e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382010726-172.17.0.10-1595358607974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-ded49000-47db-4378-9892-a023b6fb0773,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-496b0015-42e1-4bc5-a5bf-2e1826b9a5df,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-3697275f-dfd9-4c40-bd30-5fcc7c7cc816,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-97015fcf-3832-4cbd-9111-70665f2cc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-9fa04389-1ccf-4167-93fe-5d1e1fb32f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-bc289b22-2b48-49b9-bfe2-bb4590f5c834,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-644a4628-7787-4b66-b50c-ec0c15e20629,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-137e8ac4-df34-4338-bcb2-8f0f7aa4b16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382010726-172.17.0.10-1595358607974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-ded49000-47db-4378-9892-a023b6fb0773,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-496b0015-42e1-4bc5-a5bf-2e1826b9a5df,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-3697275f-dfd9-4c40-bd30-5fcc7c7cc816,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-97015fcf-3832-4cbd-9111-70665f2cc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-9fa04389-1ccf-4167-93fe-5d1e1fb32f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-bc289b22-2b48-49b9-bfe2-bb4590f5c834,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-644a4628-7787-4b66-b50c-ec0c15e20629,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-137e8ac4-df34-4338-bcb2-8f0f7aa4b16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788707899-172.17.0.10-1595359023996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-f0c19532-2ad5-46de-9865-0fb1b353632d,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-a7053ea3-3488-4220-a4f0-4f26686ebcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-99b8858d-cb3e-403c-b47e-88bb621f3496,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-f217c216-a9f4-44a0-8d57-b78736e731c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-b7053d18-efab-4066-85ac-bc478e47f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-48b8acc5-0564-481a-97f8-7728e37839e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-dffb2404-ddf9-40e9-9412-63ca35bfbfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-5038ff8d-bdaf-4bf2-81cf-c6144c53a5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788707899-172.17.0.10-1595359023996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-f0c19532-2ad5-46de-9865-0fb1b353632d,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-a7053ea3-3488-4220-a4f0-4f26686ebcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-99b8858d-cb3e-403c-b47e-88bb621f3496,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-f217c216-a9f4-44a0-8d57-b78736e731c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-b7053d18-efab-4066-85ac-bc478e47f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-48b8acc5-0564-481a-97f8-7728e37839e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-dffb2404-ddf9-40e9-9412-63ca35bfbfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-5038ff8d-bdaf-4bf2-81cf-c6144c53a5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702992073-172.17.0.10-1595359277250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-ca5047d0-665f-4aa6-a7e3-d8ca56a57af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-e5834a5e-5242-4493-b34d-13e901b8cc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-de36bf68-36a4-4599-8074-da01ea723563,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-59a76cb3-8fd7-4f63-a973-9415a1a48781,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-6a90931b-d8cf-4c82-ada1-d41ad1bf4398,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-46222516-3696-45d7-b843-e9f4b71dc0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-8d6c90a7-8b8d-4112-83b6-e821457b34d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-de5c6e4d-e0f2-4a29-8c1b-a7e20cfcf4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702992073-172.17.0.10-1595359277250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-ca5047d0-665f-4aa6-a7e3-d8ca56a57af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-e5834a5e-5242-4493-b34d-13e901b8cc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-de36bf68-36a4-4599-8074-da01ea723563,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-59a76cb3-8fd7-4f63-a973-9415a1a48781,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-6a90931b-d8cf-4c82-ada1-d41ad1bf4398,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-46222516-3696-45d7-b843-e9f4b71dc0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-8d6c90a7-8b8d-4112-83b6-e821457b34d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-de5c6e4d-e0f2-4a29-8c1b-a7e20cfcf4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750076622-172.17.0.10-1595359376095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36237,DS-3fe31d67-21fa-4b8a-80fc-0963849a83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-06012c59-48f0-4c5d-829d-d3a55b9a3361,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-164e0e72-ab75-43e2-8ee9-49dac4a7641d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-907e41d3-20b6-4cb9-b4d4-1d28596b9725,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-b8f76072-e737-4378-89a9-c8f86c3d5573,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-484ccb84-35db-4d38-b3ff-8a09f2f47879,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-6815fecc-16cf-4a37-a782-cc38c2a0a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-a8305aff-f1fe-4b50-8629-7a63cd0ff52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750076622-172.17.0.10-1595359376095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36237,DS-3fe31d67-21fa-4b8a-80fc-0963849a83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-06012c59-48f0-4c5d-829d-d3a55b9a3361,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-164e0e72-ab75-43e2-8ee9-49dac4a7641d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-907e41d3-20b6-4cb9-b4d4-1d28596b9725,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-b8f76072-e737-4378-89a9-c8f86c3d5573,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-484ccb84-35db-4d38-b3ff-8a09f2f47879,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-6815fecc-16cf-4a37-a782-cc38c2a0a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-a8305aff-f1fe-4b50-8629-7a63cd0ff52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328739009-172.17.0.10-1595359439902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-d37591dc-7c4d-437b-9997-e9e35d351ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-2da19d9c-1134-44d6-bbdf-9dd4be4b4559,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-e4afb009-a172-4797-9afe-caee882ceeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-4865db94-1c21-4a02-8d39-80d7d5bbcbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-b4022661-e14c-4b41-b198-c7898fa02240,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-a209b2ad-2aa5-4c00-89e3-a4508ba47342,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-58a5aaed-6ad3-4228-a469-40443654ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2eded0a8-6721-4b05-a3a5-f0d91489a94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328739009-172.17.0.10-1595359439902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-d37591dc-7c4d-437b-9997-e9e35d351ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-2da19d9c-1134-44d6-bbdf-9dd4be4b4559,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-e4afb009-a172-4797-9afe-caee882ceeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-4865db94-1c21-4a02-8d39-80d7d5bbcbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-b4022661-e14c-4b41-b198-c7898fa02240,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-a209b2ad-2aa5-4c00-89e3-a4508ba47342,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-58a5aaed-6ad3-4228-a469-40443654ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2eded0a8-6721-4b05-a3a5-f0d91489a94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136443402-172.17.0.10-1595359631638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-ed77c929-0cd4-4e92-be97-97e1e90b615d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-68b469da-a1de-465f-aa0b-854c8bcf7357,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bffd8705-5527-40f3-b31c-22340295b355,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-1ef2332a-6604-4126-9bd6-eebe4a63f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-1c5613ce-9000-45b4-b081-e28dd3a78591,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-286a39d1-a7c0-4c7d-b4dc-7656d0f820b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-c77345d2-a110-4e58-adb0-0e13f14b3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-edd3a28c-e794-4b0c-854f-45b0ade3d2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136443402-172.17.0.10-1595359631638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-ed77c929-0cd4-4e92-be97-97e1e90b615d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-68b469da-a1de-465f-aa0b-854c8bcf7357,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bffd8705-5527-40f3-b31c-22340295b355,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-1ef2332a-6604-4126-9bd6-eebe4a63f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-1c5613ce-9000-45b4-b081-e28dd3a78591,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-286a39d1-a7c0-4c7d-b4dc-7656d0f820b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-c77345d2-a110-4e58-adb0-0e13f14b3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-edd3a28c-e794-4b0c-854f-45b0ade3d2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124988966-172.17.0.10-1595360070022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-49aee8bf-72a7-4992-a7ef-37f8483b617e,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-af24fe1c-041c-4065-9d88-308d2e35e147,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-7224e347-4e69-4567-8b80-2a85ed006333,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-edb51c01-cc38-4a45-a951-d875edc1e49a,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-0eb67221-9453-4288-ae3e-5a83e194ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-eb221500-33b3-4402-a8c6-462816ff4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-f168da19-f09a-436c-bd06-68608d2e7e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-8a129bcb-c17f-468c-83d0-7e6d8086e1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124988966-172.17.0.10-1595360070022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-49aee8bf-72a7-4992-a7ef-37f8483b617e,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-af24fe1c-041c-4065-9d88-308d2e35e147,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-7224e347-4e69-4567-8b80-2a85ed006333,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-edb51c01-cc38-4a45-a951-d875edc1e49a,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-0eb67221-9453-4288-ae3e-5a83e194ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-eb221500-33b3-4402-a8c6-462816ff4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-f168da19-f09a-436c-bd06-68608d2e7e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-8a129bcb-c17f-468c-83d0-7e6d8086e1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83936180-172.17.0.10-1595360215423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-a7f4c004-f287-4093-9d7d-37b527bd1f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-26721a27-921b-4a28-8c7c-de0d4517dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-8f4141d2-5fb7-4d53-a261-79b45337619c,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-43f43626-29f8-4958-9aa6-2ef393a27ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-ac8b955e-30ea-4000-9e55-9fee6c6c28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-23321aa0-f466-4558-b6b0-cd235ffefb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-99924245-487c-4a65-9ff4-2e194216b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-35fbd409-b94f-4f54-b240-b1888b4b007c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83936180-172.17.0.10-1595360215423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-a7f4c004-f287-4093-9d7d-37b527bd1f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-26721a27-921b-4a28-8c7c-de0d4517dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-8f4141d2-5fb7-4d53-a261-79b45337619c,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-43f43626-29f8-4958-9aa6-2ef393a27ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-ac8b955e-30ea-4000-9e55-9fee6c6c28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-23321aa0-f466-4558-b6b0-cd235ffefb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-99924245-487c-4a65-9ff4-2e194216b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-35fbd409-b94f-4f54-b240-b1888b4b007c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954545404-172.17.0.10-1595360655207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-ef2561b2-5ddc-424d-831b-8039816f3168,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-08821a88-6a27-448c-ac5b-0b2d7d4eae76,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-624c499a-fd0b-4da8-a0b6-9de607eae7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-289a2fba-0941-4f24-b2fe-4900f8b4d013,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-cf2874df-b152-4d57-9ce3-bfa8cc442f41,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-6d96c7e0-b611-41f6-ad85-9e89c7dc3b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-d0744745-6ee6-4f62-967b-0bf65d63cf61,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-f00110d5-a9ec-4392-85a5-c82d353133f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954545404-172.17.0.10-1595360655207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-ef2561b2-5ddc-424d-831b-8039816f3168,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-08821a88-6a27-448c-ac5b-0b2d7d4eae76,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-624c499a-fd0b-4da8-a0b6-9de607eae7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-289a2fba-0941-4f24-b2fe-4900f8b4d013,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-cf2874df-b152-4d57-9ce3-bfa8cc442f41,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-6d96c7e0-b611-41f6-ad85-9e89c7dc3b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-d0744745-6ee6-4f62-967b-0bf65d63cf61,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-f00110d5-a9ec-4392-85a5-c82d353133f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679485678-172.17.0.10-1595360934449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-5f482685-57a3-4ed5-8930-5324f1933096,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-b1b8046a-099a-4f56-b4bd-a625b54313da,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-36de0ba0-c3e9-4446-b990-300115e4ce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-8a55df82-5cfc-415e-a8aa-e9de4f192580,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-bc3c2251-426d-4536-b6f7-367d984dd700,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-f7e289e1-e9c7-4eaa-8a89-070a90938697,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-f4b63bb4-f7cc-405e-b9de-ec988b09b867,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-e61b4588-4424-4525-a7f6-f6851e8286e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679485678-172.17.0.10-1595360934449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-5f482685-57a3-4ed5-8930-5324f1933096,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-b1b8046a-099a-4f56-b4bd-a625b54313da,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-36de0ba0-c3e9-4446-b990-300115e4ce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-8a55df82-5cfc-415e-a8aa-e9de4f192580,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-bc3c2251-426d-4536-b6f7-367d984dd700,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-f7e289e1-e9c7-4eaa-8a89-070a90938697,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-f4b63bb4-f7cc-405e-b9de-ec988b09b867,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-e61b4588-4424-4525-a7f6-f6851e8286e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5299
