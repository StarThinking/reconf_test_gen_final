reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855592842-172.17.0.21-1596942789021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-12f31ae1-5df2-4802-8773-5ee2896e66c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-b9758b39-ae99-4490-bf39-592a2e5281bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-1017833e-b9bc-4ea8-89db-c3c9efd70ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-2b8e867a-e4bf-474d-9d7b-5b2ab7345d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-6edfbb38-17dd-4eb1-8719-11a4a82167c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-c41e0467-3e67-4ddc-825f-d2a9d46c2ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-2bf07b1a-254e-45af-9d1b-721b8ffdfac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-a033273b-fb6a-4391-b763-b0b95925fe7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855592842-172.17.0.21-1596942789021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-12f31ae1-5df2-4802-8773-5ee2896e66c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-b9758b39-ae99-4490-bf39-592a2e5281bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-1017833e-b9bc-4ea8-89db-c3c9efd70ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-2b8e867a-e4bf-474d-9d7b-5b2ab7345d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-6edfbb38-17dd-4eb1-8719-11a4a82167c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-c41e0467-3e67-4ddc-825f-d2a9d46c2ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-2bf07b1a-254e-45af-9d1b-721b8ffdfac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-a033273b-fb6a-4391-b763-b0b95925fe7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943896825-172.17.0.21-1596942820523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-66678e28-4e57-4dce-abc5-93aec132979e,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-d2f7da2d-faa2-4877-91ef-31dc2c9bd9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-3fbf7ed0-6e27-4750-8f4c-b3ec2dd52eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-99226105-8d5a-4ce7-a052-c35a2484cdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-59b2e4b5-2b60-4810-838e-e936827f3d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-0580e42e-f2c2-44d0-9b93-9c0d1a06042e,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-c4d1727a-ea31-4c57-8aa8-e48e3f9f6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-98a5f951-7050-4cb2-ac9c-f71cafbfdd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943896825-172.17.0.21-1596942820523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-66678e28-4e57-4dce-abc5-93aec132979e,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-d2f7da2d-faa2-4877-91ef-31dc2c9bd9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-3fbf7ed0-6e27-4750-8f4c-b3ec2dd52eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-99226105-8d5a-4ce7-a052-c35a2484cdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-59b2e4b5-2b60-4810-838e-e936827f3d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-0580e42e-f2c2-44d0-9b93-9c0d1a06042e,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-c4d1727a-ea31-4c57-8aa8-e48e3f9f6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-98a5f951-7050-4cb2-ac9c-f71cafbfdd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244029433-172.17.0.21-1596942854680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-14616dbd-f120-483d-8356-a3b0dfdf2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-8302a669-4880-43a7-bd55-2f11eab4516c,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-01adb72a-31c9-4318-b626-a56e43760b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-90d03a80-e7d1-426d-b713-2a9ae094a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-2d51c498-a5b5-4d30-b95b-3e06490b0499,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-fd018104-4642-4876-b605-298a00b98c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-ba595262-908e-4937-9a25-33663ec4e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-835a0e00-d7e3-4a33-9898-8d75e913b849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244029433-172.17.0.21-1596942854680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-14616dbd-f120-483d-8356-a3b0dfdf2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-8302a669-4880-43a7-bd55-2f11eab4516c,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-01adb72a-31c9-4318-b626-a56e43760b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-90d03a80-e7d1-426d-b713-2a9ae094a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-2d51c498-a5b5-4d30-b95b-3e06490b0499,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-fd018104-4642-4876-b605-298a00b98c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-ba595262-908e-4937-9a25-33663ec4e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-835a0e00-d7e3-4a33-9898-8d75e913b849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133881616-172.17.0.21-1596943230939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44198,DS-9594aff2-fa31-4814-a59e-b30611143054,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-24ebc2f0-974c-4e36-8588-2f689fae07ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-96081987-ea62-46b4-a61e-a710f0b505c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c7a83758-4a32-43a4-b0de-ba79f047be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-d9467f24-f1fb-40e5-a42d-5ef3bf2a889d,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-a112be37-9f9e-41a7-89b9-7d5d1c5778fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-7dc769f1-f7f6-420a-91a5-a87dc8680d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-f50ea700-eccb-41e8-a580-dd7fd6233b55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133881616-172.17.0.21-1596943230939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44198,DS-9594aff2-fa31-4814-a59e-b30611143054,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-24ebc2f0-974c-4e36-8588-2f689fae07ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-96081987-ea62-46b4-a61e-a710f0b505c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c7a83758-4a32-43a4-b0de-ba79f047be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-d9467f24-f1fb-40e5-a42d-5ef3bf2a889d,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-a112be37-9f9e-41a7-89b9-7d5d1c5778fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-7dc769f1-f7f6-420a-91a5-a87dc8680d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-f50ea700-eccb-41e8-a580-dd7fd6233b55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740884695-172.17.0.21-1596943542671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-4eda319f-b07e-43b9-b054-3a7aeb4e8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-1cdadeff-3a2b-4144-a2ff-1c876c2a8c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-ff33da57-d6a1-47fd-8113-829916e3daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-a682cfb9-0038-49cf-be5a-eb8124a2591c,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-85bd5a45-c0fe-473a-8100-e91817b37ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b96dd747-8914-4353-ab4a-b495192de1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-e6d5109b-eed3-4762-88a9-c787cb149678,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-16747355-f2aa-4a9c-a4a0-b1f400290e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740884695-172.17.0.21-1596943542671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-4eda319f-b07e-43b9-b054-3a7aeb4e8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-1cdadeff-3a2b-4144-a2ff-1c876c2a8c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-ff33da57-d6a1-47fd-8113-829916e3daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-a682cfb9-0038-49cf-be5a-eb8124a2591c,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-85bd5a45-c0fe-473a-8100-e91817b37ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b96dd747-8914-4353-ab4a-b495192de1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-e6d5109b-eed3-4762-88a9-c787cb149678,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-16747355-f2aa-4a9c-a4a0-b1f400290e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112242688-172.17.0.21-1596943726875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-2ea20c1a-ec3a-40cb-942b-fca8b48ee7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-50c0b704-8d54-4672-a3ca-f671dcb16c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-d88fd6f0-767f-47df-9800-dd728d78c375,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-54e54a27-90a8-429f-ba75-54b9e53eb175,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-9a26ebba-8a42-4380-88b4-e239701f1445,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-7cdf7f62-26fb-4eda-8c3a-639e705251d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-99a44b1d-8575-4033-8fc3-a4199d6fd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-1fa57489-7fdc-4b77-8bd3-c4195a7d5c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112242688-172.17.0.21-1596943726875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-2ea20c1a-ec3a-40cb-942b-fca8b48ee7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-50c0b704-8d54-4672-a3ca-f671dcb16c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-d88fd6f0-767f-47df-9800-dd728d78c375,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-54e54a27-90a8-429f-ba75-54b9e53eb175,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-9a26ebba-8a42-4380-88b4-e239701f1445,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-7cdf7f62-26fb-4eda-8c3a-639e705251d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-99a44b1d-8575-4033-8fc3-a4199d6fd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-1fa57489-7fdc-4b77-8bd3-c4195a7d5c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90195505-172.17.0.21-1596943938414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-944befc5-e225-40a9-ba05-ae9540538b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-741f1603-0dc8-49bc-a7a5-4d0291d75bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-d04999a9-779a-4c4c-9b74-8dd803e7f22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-64200edd-417e-4378-82ff-883138376fde,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-b585a188-c4dd-4436-a290-e8d3ce0f7bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-a9bc819b-adfb-42d4-935c-f835830aa9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-80a3ce59-4a72-4156-a9ac-b98a26852b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-69dadda3-b45d-4045-a8ce-0d5a672a73ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90195505-172.17.0.21-1596943938414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-944befc5-e225-40a9-ba05-ae9540538b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-741f1603-0dc8-49bc-a7a5-4d0291d75bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-d04999a9-779a-4c4c-9b74-8dd803e7f22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-64200edd-417e-4378-82ff-883138376fde,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-b585a188-c4dd-4436-a290-e8d3ce0f7bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-a9bc819b-adfb-42d4-935c-f835830aa9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-80a3ce59-4a72-4156-a9ac-b98a26852b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-69dadda3-b45d-4045-a8ce-0d5a672a73ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917625754-172.17.0.21-1596944110146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-c32d177a-5dda-498b-9f74-ba326dcee506,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-646b8bcc-0e53-4536-8cc9-09901b683286,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-f737193c-6819-4378-8eef-34d22864a35b,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-e1c4f70b-537b-4a39-b832-2ad6584b8fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-87c9c820-2c8c-4daa-bdc5-8106c5813639,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-02aff6c3-3eb1-4967-ab4e-b15db28bdfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-0fb20709-b882-444d-ba35-282bb38f1b23,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-b84a5612-274f-4291-b040-86e29eefa808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917625754-172.17.0.21-1596944110146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-c32d177a-5dda-498b-9f74-ba326dcee506,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-646b8bcc-0e53-4536-8cc9-09901b683286,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-f737193c-6819-4378-8eef-34d22864a35b,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-e1c4f70b-537b-4a39-b832-2ad6584b8fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-87c9c820-2c8c-4daa-bdc5-8106c5813639,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-02aff6c3-3eb1-4967-ab4e-b15db28bdfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-0fb20709-b882-444d-ba35-282bb38f1b23,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-b84a5612-274f-4291-b040-86e29eefa808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343870354-172.17.0.21-1596944340028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-ef8921ae-d538-4f6a-a18b-a9c6de51883d,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-dcf1476a-2169-4916-ac74-f1e1fa95fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-21cd3bf9-250b-406d-a1a8-4f20c4db1490,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-1c560c5b-1289-467c-adcd-060f624d6590,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-1d709142-91ae-40b9-bad7-acee764d1132,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-ebca7356-3e23-4072-82d1-149a3a05f048,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-d7d4a5f6-72ec-43d4-bc14-b49d90880a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-1c69136b-0eb1-4bb3-aac2-61d2dbb8adb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343870354-172.17.0.21-1596944340028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-ef8921ae-d538-4f6a-a18b-a9c6de51883d,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-dcf1476a-2169-4916-ac74-f1e1fa95fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-21cd3bf9-250b-406d-a1a8-4f20c4db1490,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-1c560c5b-1289-467c-adcd-060f624d6590,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-1d709142-91ae-40b9-bad7-acee764d1132,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-ebca7356-3e23-4072-82d1-149a3a05f048,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-d7d4a5f6-72ec-43d4-bc14-b49d90880a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-1c69136b-0eb1-4bb3-aac2-61d2dbb8adb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451985298-172.17.0.21-1596944558394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33967,DS-15ce4f79-ff40-4717-b658-f10c063db3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-2c24bf95-ca09-4104-ac9f-3e3de7997a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-8c707a3c-8950-43e8-b6a2-3e8d467134b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-740205e9-e429-46b0-8e94-f07f72600343,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-cd21f3d3-edba-4bf2-bc2e-cffbede64d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-9c0e606a-b922-4366-a08e-cbbd30a283b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-cf8ac74b-cfd1-4e0e-97b4-92e13c8db227,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-4ae0e33f-8bb7-4af3-a571-1b57c0facf68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451985298-172.17.0.21-1596944558394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33967,DS-15ce4f79-ff40-4717-b658-f10c063db3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-2c24bf95-ca09-4104-ac9f-3e3de7997a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-8c707a3c-8950-43e8-b6a2-3e8d467134b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-740205e9-e429-46b0-8e94-f07f72600343,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-cd21f3d3-edba-4bf2-bc2e-cffbede64d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-9c0e606a-b922-4366-a08e-cbbd30a283b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-cf8ac74b-cfd1-4e0e-97b4-92e13c8db227,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-4ae0e33f-8bb7-4af3-a571-1b57c0facf68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767870151-172.17.0.21-1596944761223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43427,DS-18b77958-40fc-4d15-867a-91a6088b4ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-10d68183-7fe2-441e-a6a8-80d46e66d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-d38104ec-1a0e-49c1-9aa7-958e128b3f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-6ca9538a-e9b0-4e2a-a9a1-51ca71c18019,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-d7799041-4964-41de-b742-88c87d18e542,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-f164e08e-16c4-4329-8969-26d716dcd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-a051b6eb-c56f-4d9b-ade7-46af2e155eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-260aaf98-3e2f-446f-8f2e-0d3421f5d94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767870151-172.17.0.21-1596944761223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43427,DS-18b77958-40fc-4d15-867a-91a6088b4ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-10d68183-7fe2-441e-a6a8-80d46e66d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-d38104ec-1a0e-49c1-9aa7-958e128b3f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-6ca9538a-e9b0-4e2a-a9a1-51ca71c18019,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-d7799041-4964-41de-b742-88c87d18e542,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-f164e08e-16c4-4329-8969-26d716dcd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-a051b6eb-c56f-4d9b-ade7-46af2e155eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-260aaf98-3e2f-446f-8f2e-0d3421f5d94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067424869-172.17.0.21-1596945043203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42279,DS-3f47eba2-2b1c-4bce-90de-167979997bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-5348420b-41b0-482e-93bf-8198f2a43fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-d085b3f1-3fe6-4229-90d7-9e60a01fbfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-84f80ebb-0df0-4a21-8d56-5557df2ae301,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-959e5ef8-3c8b-4554-89c9-e440e94c68f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-7fbd0414-460b-4bef-aa3c-c6dc548136b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-b4acdbdd-e344-4eee-b9f1-34fa519b86e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-74a90ae6-d3c1-4585-b37a-9f5f991aae6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067424869-172.17.0.21-1596945043203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42279,DS-3f47eba2-2b1c-4bce-90de-167979997bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-5348420b-41b0-482e-93bf-8198f2a43fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-d085b3f1-3fe6-4229-90d7-9e60a01fbfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-84f80ebb-0df0-4a21-8d56-5557df2ae301,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-959e5ef8-3c8b-4554-89c9-e440e94c68f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-7fbd0414-460b-4bef-aa3c-c6dc548136b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-b4acdbdd-e344-4eee-b9f1-34fa519b86e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-74a90ae6-d3c1-4585-b37a-9f5f991aae6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762363225-172.17.0.21-1596945082146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-80e191a2-9be2-4727-a833-bc8bffcb627d,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-ca5c51ae-cc89-4332-91e9-2070b5c843f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-246e1970-f8d1-49f1-82de-226cd7caea90,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-4390e682-119c-461b-933c-70b38565b7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-0859e096-3097-428c-b43e-e90ad8c91161,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-95687349-e54a-42d5-818a-b80c5809df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-81a2ae46-c447-4308-80ba-a44860988366,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-1925e660-94fe-4c57-bdc2-04dbdb417ef8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762363225-172.17.0.21-1596945082146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-80e191a2-9be2-4727-a833-bc8bffcb627d,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-ca5c51ae-cc89-4332-91e9-2070b5c843f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-246e1970-f8d1-49f1-82de-226cd7caea90,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-4390e682-119c-461b-933c-70b38565b7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-0859e096-3097-428c-b43e-e90ad8c91161,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-95687349-e54a-42d5-818a-b80c5809df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-81a2ae46-c447-4308-80ba-a44860988366,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-1925e660-94fe-4c57-bdc2-04dbdb417ef8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124248530-172.17.0.21-1596945159480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-f0fcaa34-43ef-46ff-bca6-f01721d074c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-902f2960-a78a-4d63-b019-97697e920687,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-ef9ea119-7af2-4d3e-93d0-da6d58e062a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-b7325945-f8d4-4ce2-b674-6f7d4cdf8cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-7c56ca87-bc89-4e16-af53-db6089b61d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-3a824f3a-c6bf-4dd9-80b1-c690610ed100,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-0d7fbf89-1ba9-4a8b-8d09-07a5c18f95d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-583b61a4-bf29-422a-a5e9-440aca625ce3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124248530-172.17.0.21-1596945159480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-f0fcaa34-43ef-46ff-bca6-f01721d074c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-902f2960-a78a-4d63-b019-97697e920687,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-ef9ea119-7af2-4d3e-93d0-da6d58e062a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-b7325945-f8d4-4ce2-b674-6f7d4cdf8cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-7c56ca87-bc89-4e16-af53-db6089b61d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-3a824f3a-c6bf-4dd9-80b1-c690610ed100,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-0d7fbf89-1ba9-4a8b-8d09-07a5c18f95d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-583b61a4-bf29-422a-a5e9-440aca625ce3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012180661-172.17.0.21-1596945231637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-975653b1-61cf-469b-adbf-010e50d1f995,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-3f486c8f-c547-4f72-a0ad-b0e1787265d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-be216539-a023-4199-a699-1052fc19f1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-e336bee3-3f40-4bbd-b4bd-7b557fccfb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-ff5539ff-8968-4c82-9548-2a26b81283d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-fd3fe8f9-94c3-477e-8a53-8494e3498f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-5ff2ea04-f260-485d-be70-2c15530f4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-59744b4d-ed87-469c-b9d9-f6f1424bab40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012180661-172.17.0.21-1596945231637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-975653b1-61cf-469b-adbf-010e50d1f995,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-3f486c8f-c547-4f72-a0ad-b0e1787265d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-be216539-a023-4199-a699-1052fc19f1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-e336bee3-3f40-4bbd-b4bd-7b557fccfb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-ff5539ff-8968-4c82-9548-2a26b81283d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-fd3fe8f9-94c3-477e-8a53-8494e3498f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-5ff2ea04-f260-485d-be70-2c15530f4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-59744b4d-ed87-469c-b9d9-f6f1424bab40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117753604-172.17.0.21-1596945261566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41632,DS-058af1f8-4451-4103-91e6-4c65756fc2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-5db60a68-8655-458e-a19a-b5bcb97629f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-06bda403-d8e8-4aed-8177-f0b792ea5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-510d1c60-67ae-4b76-a67f-f6790c5e85d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-ecd01e7e-095d-4377-b5a2-65f613deade4,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-896c02e6-f5aa-43d2-85c8-c386a01104a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-95a672b7-bd60-4640-bfc9-c17bbf1bdbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-e586216a-2553-4e1e-a099-025ad74731a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117753604-172.17.0.21-1596945261566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41632,DS-058af1f8-4451-4103-91e6-4c65756fc2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-5db60a68-8655-458e-a19a-b5bcb97629f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-06bda403-d8e8-4aed-8177-f0b792ea5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-510d1c60-67ae-4b76-a67f-f6790c5e85d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-ecd01e7e-095d-4377-b5a2-65f613deade4,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-896c02e6-f5aa-43d2-85c8-c386a01104a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-95a672b7-bd60-4640-bfc9-c17bbf1bdbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-e586216a-2553-4e1e-a099-025ad74731a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486850942-172.17.0.21-1596945320174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-1acd48d7-8024-4a5d-b98e-9eae4b83f423,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-ef604106-3354-400c-a644-9dc196422d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-661a72d5-ddea-4b56-8c96-ae1117a07b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-4cfe24ee-ba12-4d65-be3b-b0ef31333416,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-600c89c8-081e-40a2-b305-59ccb8334836,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-766ff413-6b24-4c32-92aa-541e4ea0caf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-b99e42e3-434c-4df0-9d93-301f07232948,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-61faaad2-10ec-4b34-bf5f-53ad7ab3a59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486850942-172.17.0.21-1596945320174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-1acd48d7-8024-4a5d-b98e-9eae4b83f423,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-ef604106-3354-400c-a644-9dc196422d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-661a72d5-ddea-4b56-8c96-ae1117a07b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-4cfe24ee-ba12-4d65-be3b-b0ef31333416,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-600c89c8-081e-40a2-b305-59ccb8334836,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-766ff413-6b24-4c32-92aa-541e4ea0caf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-b99e42e3-434c-4df0-9d93-301f07232948,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-61faaad2-10ec-4b34-bf5f-53ad7ab3a59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444652122-172.17.0.21-1596945505115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42862,DS-ab10cbd9-80e7-45da-83e3-0a5b24ae6aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-2d8b83fc-db5f-4ea5-a73b-4126d1c7ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-58a0b6b5-a287-4d9e-a193-dba526212cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-35a85e8b-52b4-4228-8613-2a256b71d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-bd1c8e2e-2b4f-4522-99c8-5017fd52687e,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-cbfbbff9-b36c-47eb-9671-5219876665f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-9b8cf009-98de-42fd-92cc-d25c32e1d202,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-c5599b6a-04d4-450b-a54a-46a957f900ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444652122-172.17.0.21-1596945505115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42862,DS-ab10cbd9-80e7-45da-83e3-0a5b24ae6aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-2d8b83fc-db5f-4ea5-a73b-4126d1c7ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-58a0b6b5-a287-4d9e-a193-dba526212cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-35a85e8b-52b4-4228-8613-2a256b71d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-bd1c8e2e-2b4f-4522-99c8-5017fd52687e,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-cbfbbff9-b36c-47eb-9671-5219876665f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-9b8cf009-98de-42fd-92cc-d25c32e1d202,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-c5599b6a-04d4-450b-a54a-46a957f900ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675352502-172.17.0.21-1596945608076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-e745e152-0b03-4820-b412-9ffdd4304d34,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-b820bdda-b763-435c-b510-9b46e50dfb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-b0261fe8-1ccf-4726-a315-3fbbf8c2c858,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-24886f99-1de1-47a5-8612-617b3e33d819,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-d29e23f3-eddc-4b3a-ac8c-68d515a6b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-ab314860-28b4-4b8a-9cd4-b96d93255d82,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-2d603634-4dde-4d5f-b2fa-98eefcb7fd69,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-b0f1d49a-8659-40a7-889b-9626b8613047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675352502-172.17.0.21-1596945608076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-e745e152-0b03-4820-b412-9ffdd4304d34,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-b820bdda-b763-435c-b510-9b46e50dfb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-b0261fe8-1ccf-4726-a315-3fbbf8c2c858,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-24886f99-1de1-47a5-8612-617b3e33d819,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-d29e23f3-eddc-4b3a-ac8c-68d515a6b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-ab314860-28b4-4b8a-9cd4-b96d93255d82,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-2d603634-4dde-4d5f-b2fa-98eefcb7fd69,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-b0f1d49a-8659-40a7-889b-9626b8613047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85795126-172.17.0.21-1596945778400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41502,DS-ea361f6d-f45b-4a20-b546-84c39aecf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-db4401af-28c4-4a0b-80ce-2728cb1220f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-72b90b10-3251-4fb2-ae72-a45960f23340,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-c2bd3b3a-73a2-49b7-8e53-44ee4026b292,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-ba57e836-c6fa-456b-b533-1c7faf33f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-4871aafc-75f5-49fa-b7ae-2e970480adbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-14c0edb0-1200-4244-a32e-1477cf045729,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-cfb197c8-f5e1-4f0b-b366-bde11cb9e409,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85795126-172.17.0.21-1596945778400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41502,DS-ea361f6d-f45b-4a20-b546-84c39aecf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-db4401af-28c4-4a0b-80ce-2728cb1220f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-72b90b10-3251-4fb2-ae72-a45960f23340,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-c2bd3b3a-73a2-49b7-8e53-44ee4026b292,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-ba57e836-c6fa-456b-b533-1c7faf33f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-4871aafc-75f5-49fa-b7ae-2e970480adbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-14c0edb0-1200-4244-a32e-1477cf045729,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-cfb197c8-f5e1-4f0b-b366-bde11cb9e409,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772037204-172.17.0.21-1596945942025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-fc6e10e9-0296-415e-9244-37bbd6f2a9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-01b14aa1-4642-4cd2-9d7e-cb20f0b7f960,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-fbc3c597-9518-433a-bbf9-af81cda1fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-03a86427-ffd1-4812-9370-659b3b8f2c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-e04cc251-47a0-4405-b0ed-0f7262dffdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-fc16527b-aa45-48e5-9ed3-2f08ed486d03,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-df59b13d-5e6d-403d-a031-1bfc6f40fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-7b924dd4-f7e8-44e9-8d1f-f76a15d544ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772037204-172.17.0.21-1596945942025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-fc6e10e9-0296-415e-9244-37bbd6f2a9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-01b14aa1-4642-4cd2-9d7e-cb20f0b7f960,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-fbc3c597-9518-433a-bbf9-af81cda1fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-03a86427-ffd1-4812-9370-659b3b8f2c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-e04cc251-47a0-4405-b0ed-0f7262dffdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-fc16527b-aa45-48e5-9ed3-2f08ed486d03,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-df59b13d-5e6d-403d-a031-1bfc6f40fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-7b924dd4-f7e8-44e9-8d1f-f76a15d544ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197666706-172.17.0.21-1596946265216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-3b0f36b2-76e2-465f-ba1d-0989450c7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-01d04531-c505-4212-a887-e50c008c694e,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-c2457b7c-43d2-4aee-8719-6e533c6900c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-fe7ff199-c108-4b0e-bad7-cadc45a0b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-16fee5a2-eca2-427b-8ea4-db931bb96182,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-482841f1-dfa6-4fca-8c56-8892dffa882a,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-23f8299f-4846-46c1-aecc-c15b15a8b6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-47bbb6d6-0c15-4dad-ad60-0cab73bf8912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197666706-172.17.0.21-1596946265216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-3b0f36b2-76e2-465f-ba1d-0989450c7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-01d04531-c505-4212-a887-e50c008c694e,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-c2457b7c-43d2-4aee-8719-6e533c6900c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-fe7ff199-c108-4b0e-bad7-cadc45a0b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-16fee5a2-eca2-427b-8ea4-db931bb96182,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-482841f1-dfa6-4fca-8c56-8892dffa882a,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-23f8299f-4846-46c1-aecc-c15b15a8b6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-47bbb6d6-0c15-4dad-ad60-0cab73bf8912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568200624-172.17.0.21-1596946368105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-58b75507-63a4-44e5-b6b7-6bce4f5d4137,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-b5b89d2f-1a2d-4f2a-90c9-48f5ebeb6de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-238bdb6b-d809-4015-9f64-bffdd79957b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-5168ab19-3c46-48dc-8fc0-c426256e8738,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-62b6faa5-b205-4cb2-b8e4-d67807deedbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-c3028894-9d2e-4d68-9e17-fe0d3a18be76,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-c904bc09-872f-4da2-b002-8bf5a0771971,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-f07d23be-6f58-4f19-a8e3-39d7a9e42339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568200624-172.17.0.21-1596946368105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-58b75507-63a4-44e5-b6b7-6bce4f5d4137,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-b5b89d2f-1a2d-4f2a-90c9-48f5ebeb6de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-238bdb6b-d809-4015-9f64-bffdd79957b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-5168ab19-3c46-48dc-8fc0-c426256e8738,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-62b6faa5-b205-4cb2-b8e4-d67807deedbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-c3028894-9d2e-4d68-9e17-fe0d3a18be76,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-c904bc09-872f-4da2-b002-8bf5a0771971,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-f07d23be-6f58-4f19-a8e3-39d7a9e42339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936664140-172.17.0.21-1596946467576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-878c902e-2283-4677-a6d2-46f7f0eb4419,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-e4b173f2-b388-4a91-a46c-7eaee49a80ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-17cd883e-46f2-4f29-b896-9b941dbd217d,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-1df43885-1b08-4f6d-bfda-d1c3b4dd852a,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-6efca5ec-dbd3-42cb-ba33-d0138e996523,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-f5786c49-e350-4a91-a4bc-f8347266cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-5386b574-62b2-4f14-bb87-f224c0329688,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-046de6f3-9dfb-442b-a199-7e98334c3ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936664140-172.17.0.21-1596946467576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-878c902e-2283-4677-a6d2-46f7f0eb4419,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-e4b173f2-b388-4a91-a46c-7eaee49a80ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-17cd883e-46f2-4f29-b896-9b941dbd217d,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-1df43885-1b08-4f6d-bfda-d1c3b4dd852a,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-6efca5ec-dbd3-42cb-ba33-d0138e996523,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-f5786c49-e350-4a91-a4bc-f8347266cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-5386b574-62b2-4f14-bb87-f224c0329688,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-046de6f3-9dfb-442b-a199-7e98334c3ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196099326-172.17.0.21-1596946640940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-56f4422b-24b9-4921-91fb-b83a99f5f1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-24743415-b257-4e27-a13a-79c9cdcd78db,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-3761a095-fc71-4264-8a2d-d57ba812c338,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-90ae031b-f57c-4299-8b04-2fff18a09d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-c9cba2e5-2625-4ccb-8730-86d8d601055d,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-76ee2346-9585-4b2f-87c0-2aa95555b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-2cc5436a-374e-41b2-9679-bdf424cce78f,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-7f08b1b1-2c58-45db-bbfe-cd100db4ef99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196099326-172.17.0.21-1596946640940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-56f4422b-24b9-4921-91fb-b83a99f5f1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-24743415-b257-4e27-a13a-79c9cdcd78db,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-3761a095-fc71-4264-8a2d-d57ba812c338,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-90ae031b-f57c-4299-8b04-2fff18a09d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-c9cba2e5-2625-4ccb-8730-86d8d601055d,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-76ee2346-9585-4b2f-87c0-2aa95555b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-2cc5436a-374e-41b2-9679-bdf424cce78f,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-7f08b1b1-2c58-45db-bbfe-cd100db4ef99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770471685-172.17.0.21-1596946681352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40731,DS-4ed7d702-7b77-4d62-89b7-4763823f4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-28f4a603-77f1-443c-89cd-21d9a448bbec,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-ff09f216-ee28-4862-a34f-4c0021f6d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-df6f0501-55e0-43f0-99f1-25ad2c813661,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-a2632f47-355c-43bf-bb19-ba63d8126e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-4fbe52ea-df9a-4c5c-9715-31307e41ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-b1ed8f51-5cf1-4abf-83de-941d3cf547ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-5cb09f5e-ecf2-48ef-9f2c-63161f9b3aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770471685-172.17.0.21-1596946681352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40731,DS-4ed7d702-7b77-4d62-89b7-4763823f4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-28f4a603-77f1-443c-89cd-21d9a448bbec,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-ff09f216-ee28-4862-a34f-4c0021f6d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-df6f0501-55e0-43f0-99f1-25ad2c813661,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-a2632f47-355c-43bf-bb19-ba63d8126e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-4fbe52ea-df9a-4c5c-9715-31307e41ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-b1ed8f51-5cf1-4abf-83de-941d3cf547ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-5cb09f5e-ecf2-48ef-9f2c-63161f9b3aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794130621-172.17.0.21-1596946779488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-8bcae648-a6b0-4015-9c2d-68d5dba36535,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-1f9f86c3-6c74-4016-8012-3e9833d03a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-5b6a55ce-335c-46d7-b6dd-bb379da8a4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-cc67ccc4-25ec-4d48-bf5e-2c6c404d6410,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-c594943e-683c-463d-876c-4a0b9694e4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-ba0c8762-846b-42a1-b25b-336961d00f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-3018032a-30f3-4ee1-9929-956cf78f8aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-af51fd25-38a8-4653-8c63-67fd0f32f1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794130621-172.17.0.21-1596946779488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-8bcae648-a6b0-4015-9c2d-68d5dba36535,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-1f9f86c3-6c74-4016-8012-3e9833d03a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-5b6a55ce-335c-46d7-b6dd-bb379da8a4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-cc67ccc4-25ec-4d48-bf5e-2c6c404d6410,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-c594943e-683c-463d-876c-4a0b9694e4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-ba0c8762-846b-42a1-b25b-336961d00f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-3018032a-30f3-4ee1-9929-956cf78f8aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-af51fd25-38a8-4653-8c63-67fd0f32f1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467800154-172.17.0.21-1596947580585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36262,DS-3c0ef03d-6ab0-4377-91f2-7df41e73574c,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-48fe494d-9cab-49b5-8469-501f79db25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-728e4536-ced4-46c9-9ed1-d74b659aec23,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-68f6a1ec-42f8-4485-b5cb-dcdcd58ea738,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-0516ce42-afc2-48a9-b33a-6904dffa6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-d406b55b-6c32-4538-9741-a64fd9aa1329,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-805fed6b-27b2-4425-b01c-34ee6102b308,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-be2053ee-6088-4028-b1b2-b7d39ea6d616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467800154-172.17.0.21-1596947580585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36262,DS-3c0ef03d-6ab0-4377-91f2-7df41e73574c,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-48fe494d-9cab-49b5-8469-501f79db25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-728e4536-ced4-46c9-9ed1-d74b659aec23,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-68f6a1ec-42f8-4485-b5cb-dcdcd58ea738,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-0516ce42-afc2-48a9-b33a-6904dffa6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-d406b55b-6c32-4538-9741-a64fd9aa1329,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-805fed6b-27b2-4425-b01c-34ee6102b308,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-be2053ee-6088-4028-b1b2-b7d39ea6d616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5310
