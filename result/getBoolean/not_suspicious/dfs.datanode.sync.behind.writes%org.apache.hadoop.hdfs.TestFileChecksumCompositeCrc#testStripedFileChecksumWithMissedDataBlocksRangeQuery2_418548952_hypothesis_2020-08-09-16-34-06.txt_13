reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741866252-172.17.0.16-1596990857112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-9c3e3ee2-b19d-4ad1-9886-98252307bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-329ec5e0-ae95-432f-af6e-79ece0016e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-6647fcba-637c-4266-b621-15a2bc9c9ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-01e6a294-6c9d-4975-a24e-3e8d8a93aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-8a8f138f-bf4a-49f8-9ef6-4dc2929d63a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-bb438003-e117-4a46-847e-41454a9cb4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-60e01b97-9115-421d-a295-72f84180405f,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-46dbf59c-c960-42f9-a9d3-c236aa35926a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741866252-172.17.0.16-1596990857112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-9c3e3ee2-b19d-4ad1-9886-98252307bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-329ec5e0-ae95-432f-af6e-79ece0016e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-6647fcba-637c-4266-b621-15a2bc9c9ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-01e6a294-6c9d-4975-a24e-3e8d8a93aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-8a8f138f-bf4a-49f8-9ef6-4dc2929d63a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-bb438003-e117-4a46-847e-41454a9cb4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-60e01b97-9115-421d-a295-72f84180405f,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-46dbf59c-c960-42f9-a9d3-c236aa35926a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998318940-172.17.0.16-1596990897655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-c353e053-d1ca-4e0f-aa98-e82568d7b7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-a7ba4240-782e-43c4-aabd-44a0346b5390,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-1b9f58a9-4d73-4995-9f7c-d219d5e99340,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-fac2a83c-924d-4096-84be-b7cba36ad8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-da787a69-acb3-4f6b-a701-610edd58032f,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-c691b4d5-697e-4a8d-85f6-877897892ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-a27cfdd1-07dc-4698-aa7a-4176608f78f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-365065ca-6953-4434-a668-59289eacc966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998318940-172.17.0.16-1596990897655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-c353e053-d1ca-4e0f-aa98-e82568d7b7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-a7ba4240-782e-43c4-aabd-44a0346b5390,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-1b9f58a9-4d73-4995-9f7c-d219d5e99340,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-fac2a83c-924d-4096-84be-b7cba36ad8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-da787a69-acb3-4f6b-a701-610edd58032f,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-c691b4d5-697e-4a8d-85f6-877897892ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-a27cfdd1-07dc-4698-aa7a-4176608f78f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-365065ca-6953-4434-a668-59289eacc966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140054845-172.17.0.16-1596992201275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-f99bab98-6892-44fd-be57-8f86dcdc8071,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2b019736-fbc9-4a40-94d5-b055ff02f247,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-56b640ab-dd5a-4750-affb-09833156d6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-192be252-c6ec-4f77-9eed-b090966e8210,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-546a97aa-34c0-45a6-abea-e1934a8fec56,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-76b3de11-5ee3-478c-8e10-5bd2eefca37e,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-b215feb2-5d15-4fa7-9f6e-9546df57032a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-086b38bb-4c5c-47c7-a0b5-779fba501120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140054845-172.17.0.16-1596992201275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-f99bab98-6892-44fd-be57-8f86dcdc8071,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2b019736-fbc9-4a40-94d5-b055ff02f247,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-56b640ab-dd5a-4750-affb-09833156d6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-192be252-c6ec-4f77-9eed-b090966e8210,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-546a97aa-34c0-45a6-abea-e1934a8fec56,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-76b3de11-5ee3-478c-8e10-5bd2eefca37e,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-b215feb2-5d15-4fa7-9f6e-9546df57032a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-086b38bb-4c5c-47c7-a0b5-779fba501120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017374885-172.17.0.16-1596992330010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-97446eb7-1f29-4bd4-afda-ff9a117df299,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-b4fc5cf7-85f0-4aa2-a816-573bf588f582,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-b8884374-fd47-4d8c-a906-d261c407dbad,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-56dc257a-975b-4c85-9f2e-85c257f252e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-af073f18-ff66-4da2-87b9-3ba3609beb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-53ffa287-c572-4679-bfec-629f4186fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-3ae3136f-783f-474e-9723-45c216df7ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-9fc215fe-c1e4-42db-a8cd-f1310a4dc76c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017374885-172.17.0.16-1596992330010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-97446eb7-1f29-4bd4-afda-ff9a117df299,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-b4fc5cf7-85f0-4aa2-a816-573bf588f582,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-b8884374-fd47-4d8c-a906-d261c407dbad,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-56dc257a-975b-4c85-9f2e-85c257f252e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-af073f18-ff66-4da2-87b9-3ba3609beb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-53ffa287-c572-4679-bfec-629f4186fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-3ae3136f-783f-474e-9723-45c216df7ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-9fc215fe-c1e4-42db-a8cd-f1310a4dc76c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784146398-172.17.0.16-1596992417444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46476,DS-2a3b26be-6b8e-427b-bb31-df6ad8cc0969,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-2e4db3b7-20ef-4f37-9adc-e9160859a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-e77dc98d-6bff-4563-a580-aca7202b7b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-839aaaee-3712-4df8-8af6-b0c6cd516233,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-6fb62eb1-9802-425c-917d-5f242368cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-bae3370c-3c85-4a18-b664-05a5c09d19b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-60d06236-900d-4816-a6c6-0db4478490e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-bfed4b44-7cef-49c8-9fdd-ccde0d4f3dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784146398-172.17.0.16-1596992417444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46476,DS-2a3b26be-6b8e-427b-bb31-df6ad8cc0969,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-2e4db3b7-20ef-4f37-9adc-e9160859a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-e77dc98d-6bff-4563-a580-aca7202b7b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-839aaaee-3712-4df8-8af6-b0c6cd516233,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-6fb62eb1-9802-425c-917d-5f242368cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-bae3370c-3c85-4a18-b664-05a5c09d19b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-60d06236-900d-4816-a6c6-0db4478490e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-bfed4b44-7cef-49c8-9fdd-ccde0d4f3dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568878824-172.17.0.16-1596992451785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-4b704331-880b-4861-bdcc-aaf62812939c,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-0cfdbade-fb16-45af-8958-cf3f3ee24396,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-7186bd17-3138-4984-8e5c-c02b50ab58ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-8ff352d4-e187-47b3-ac8c-5003bd4a21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-7529c943-92a0-4025-abc6-8816a2067be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-5457e15f-8ac0-4b7d-8115-765ab93c0a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-8ffbec2c-5fa5-49b1-abf9-d6a70d6d60a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-cdd96d12-01cd-4837-9135-e8c94a28d43d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568878824-172.17.0.16-1596992451785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-4b704331-880b-4861-bdcc-aaf62812939c,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-0cfdbade-fb16-45af-8958-cf3f3ee24396,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-7186bd17-3138-4984-8e5c-c02b50ab58ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-8ff352d4-e187-47b3-ac8c-5003bd4a21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-7529c943-92a0-4025-abc6-8816a2067be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-5457e15f-8ac0-4b7d-8115-765ab93c0a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-8ffbec2c-5fa5-49b1-abf9-d6a70d6d60a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-cdd96d12-01cd-4837-9135-e8c94a28d43d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449784757-172.17.0.16-1596992703047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-8b224d98-3e11-47e2-9d00-be90e7c86085,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-98dd8ba4-2498-46f2-b4c1-de03d266e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-b0a1368c-46c6-4d01-a37b-178837a61763,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-b45d22e1-bf96-43ae-8653-516181c396b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-7468bc41-1330-4288-8dbd-eb86cd0d8b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-0766eb76-cf87-4742-a54e-0685616389a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-0cce0686-afed-4669-951c-d153b9c3035a,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-ef59d8c9-c032-46cb-b05c-fba58aa9e7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449784757-172.17.0.16-1596992703047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-8b224d98-3e11-47e2-9d00-be90e7c86085,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-98dd8ba4-2498-46f2-b4c1-de03d266e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-b0a1368c-46c6-4d01-a37b-178837a61763,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-b45d22e1-bf96-43ae-8653-516181c396b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-7468bc41-1330-4288-8dbd-eb86cd0d8b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-0766eb76-cf87-4742-a54e-0685616389a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-0cce0686-afed-4669-951c-d153b9c3035a,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-ef59d8c9-c032-46cb-b05c-fba58aa9e7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088587187-172.17.0.16-1596992804556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-01971a46-7248-43d7-8c40-0f19eb97a630,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-b8763603-0365-4c4c-b15f-e0049f7286d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-19a76306-365f-4c33-934e-1ffdd3971c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-5edb4e0d-eb0e-47fa-9ad6-ba276bc7f501,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-18be8bb8-ec7f-4a1a-a25b-6b7ec84e874e,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-48ba45d8-9ce2-4dd2-a497-a07df5631963,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-c4025ed4-4c0c-4f9d-b145-e1dd36739110,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-d8179a5c-fcce-4441-8c3e-0c411aee4362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088587187-172.17.0.16-1596992804556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-01971a46-7248-43d7-8c40-0f19eb97a630,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-b8763603-0365-4c4c-b15f-e0049f7286d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-19a76306-365f-4c33-934e-1ffdd3971c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-5edb4e0d-eb0e-47fa-9ad6-ba276bc7f501,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-18be8bb8-ec7f-4a1a-a25b-6b7ec84e874e,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-48ba45d8-9ce2-4dd2-a497-a07df5631963,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-c4025ed4-4c0c-4f9d-b145-e1dd36739110,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-d8179a5c-fcce-4441-8c3e-0c411aee4362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367290414-172.17.0.16-1596993021776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44501,DS-486b7f03-e478-44ba-b3f7-d0de5d7bfccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-7cd1b387-e729-43c8-8c9a-3952d3ddf430,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-3489760e-0296-4695-8272-a63112a386a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-9b3ddde3-7cf5-44b0-a0f7-69bdb58515c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-6d1cdc2f-5eca-4c7a-98f8-f6f98280f526,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-2254770c-4604-4dd3-a5fd-f841bafc61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-fd429daf-0531-4593-b2a9-70a4b6cb1837,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-52847b48-4201-47e3-8b58-6f758a53ae3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367290414-172.17.0.16-1596993021776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44501,DS-486b7f03-e478-44ba-b3f7-d0de5d7bfccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-7cd1b387-e729-43c8-8c9a-3952d3ddf430,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-3489760e-0296-4695-8272-a63112a386a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-9b3ddde3-7cf5-44b0-a0f7-69bdb58515c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-6d1cdc2f-5eca-4c7a-98f8-f6f98280f526,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-2254770c-4604-4dd3-a5fd-f841bafc61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-fd429daf-0531-4593-b2a9-70a4b6cb1837,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-52847b48-4201-47e3-8b58-6f758a53ae3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331842854-172.17.0.16-1596993037627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-6b94ded3-5794-49ef-83eb-e8a38f34ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-5d452ed4-de18-4ffb-927e-8250ec70ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-d2f0c702-f0c7-426a-b747-f046dbf85334,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-8d78e63a-96c6-4d53-b805-a2933bdee87e,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-84d2d6f8-da7c-4037-9079-25151bec1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-36227b3f-8582-4e53-af3a-4f701c83b193,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-e273c3e1-2186-46cd-ae6d-bc17d2afb076,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-ae776e5c-40ee-446c-b0ec-08a6269f253d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331842854-172.17.0.16-1596993037627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-6b94ded3-5794-49ef-83eb-e8a38f34ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-5d452ed4-de18-4ffb-927e-8250ec70ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-d2f0c702-f0c7-426a-b747-f046dbf85334,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-8d78e63a-96c6-4d53-b805-a2933bdee87e,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-84d2d6f8-da7c-4037-9079-25151bec1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-36227b3f-8582-4e53-af3a-4f701c83b193,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-e273c3e1-2186-46cd-ae6d-bc17d2afb076,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-ae776e5c-40ee-446c-b0ec-08a6269f253d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003796704-172.17.0.16-1596993069318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46319,DS-f0af838c-6049-4e05-8b74-4f0c2fc75b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-d9a841fc-1034-462b-9a72-0b8f25aacf88,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-19084186-2679-4bf2-81a1-dc339c5d4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-efff932d-2640-4884-9f3e-a17840e75f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-d497df34-11c7-41ee-91cb-a345f6d54f30,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-ee1a32b1-04db-4126-8af5-6021f971ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-e1d124a1-2ab6-42e6-a2e4-953cd4025d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-08e2f5f8-8b2f-4355-8578-3b4fd65d0ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003796704-172.17.0.16-1596993069318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46319,DS-f0af838c-6049-4e05-8b74-4f0c2fc75b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-d9a841fc-1034-462b-9a72-0b8f25aacf88,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-19084186-2679-4bf2-81a1-dc339c5d4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-efff932d-2640-4884-9f3e-a17840e75f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-d497df34-11c7-41ee-91cb-a345f6d54f30,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-ee1a32b1-04db-4126-8af5-6021f971ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-e1d124a1-2ab6-42e6-a2e4-953cd4025d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-08e2f5f8-8b2f-4355-8578-3b4fd65d0ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157040121-172.17.0.16-1596993195849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38612,DS-7ca949cf-f626-4b85-b56f-36efda8bcaae,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-85023849-f02f-4fe0-838d-2252dd56ba31,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-64848c08-a0f1-483e-90de-37226be60c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-13fb8340-dbd7-40e6-a658-866fef9fb3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-45f0c3b2-84d1-46dc-bc0a-fe3f94287b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-7053ec3f-78ea-4f07-9eeb-d5f6835288fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-a8566526-13c3-4923-80df-10f4e2bcbc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-3c223631-9b9d-4424-a435-2d8fae981a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157040121-172.17.0.16-1596993195849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38612,DS-7ca949cf-f626-4b85-b56f-36efda8bcaae,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-85023849-f02f-4fe0-838d-2252dd56ba31,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-64848c08-a0f1-483e-90de-37226be60c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-13fb8340-dbd7-40e6-a658-866fef9fb3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-45f0c3b2-84d1-46dc-bc0a-fe3f94287b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-7053ec3f-78ea-4f07-9eeb-d5f6835288fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-a8566526-13c3-4923-80df-10f4e2bcbc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-3c223631-9b9d-4424-a435-2d8fae981a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202044523-172.17.0.16-1596993242763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-2c3eb7ce-30da-4a03-a4cc-78694309f066,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8a652236-2cc4-47d4-b5cb-1138d0a33568,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-78a49699-8a20-4b73-9bca-1c2581d6b557,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-9572bffc-e728-4011-bb33-b31659edf152,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-fbc404d1-181b-4f75-a65d-efd3c6cd9dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-007f9d9b-8833-49df-88a2-a45e32dce21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-c1416f9d-7d6e-4c49-a3af-7abd41081346,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-cd78c78f-13c3-4c02-87e8-b2fab24f5807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202044523-172.17.0.16-1596993242763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-2c3eb7ce-30da-4a03-a4cc-78694309f066,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8a652236-2cc4-47d4-b5cb-1138d0a33568,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-78a49699-8a20-4b73-9bca-1c2581d6b557,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-9572bffc-e728-4011-bb33-b31659edf152,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-fbc404d1-181b-4f75-a65d-efd3c6cd9dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-007f9d9b-8833-49df-88a2-a45e32dce21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-c1416f9d-7d6e-4c49-a3af-7abd41081346,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-cd78c78f-13c3-4c02-87e8-b2fab24f5807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673941720-172.17.0.16-1596993889445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-6b58ab0c-f920-4435-8d85-622dd981f456,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-143b88d4-6fc7-49f5-ac7f-d9b813bb2327,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-4e78a6e8-1ce0-415a-a3aa-f2c762b73d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-0122254b-f5eb-44b7-afb7-1f094a480f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-5b746722-6f3b-4296-a38f-516e10bb9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-1571cf01-a681-4534-91ff-05ae7c203864,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-d21c8caf-97ce-4cd3-9545-eb3b93ed653d,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-845eb9bd-e145-43ad-83cb-78f7ed63c5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673941720-172.17.0.16-1596993889445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-6b58ab0c-f920-4435-8d85-622dd981f456,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-143b88d4-6fc7-49f5-ac7f-d9b813bb2327,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-4e78a6e8-1ce0-415a-a3aa-f2c762b73d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-0122254b-f5eb-44b7-afb7-1f094a480f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-5b746722-6f3b-4296-a38f-516e10bb9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-1571cf01-a681-4534-91ff-05ae7c203864,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-d21c8caf-97ce-4cd3-9545-eb3b93ed653d,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-845eb9bd-e145-43ad-83cb-78f7ed63c5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 3147
