reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800733388-172.17.0.4-1595363623687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-fa9b8830-b67f-45cc-8420-1ae32a0c9104,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-2696b5c2-68fe-4c22-98b5-9506bec0342f,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6d5241cc-27f5-4712-8462-773836c7d915,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-a98411c3-5927-4db2-8528-99113558596f,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-5526e09f-43f9-487a-ab5e-aabe08f9def5,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-9ae12ce2-b1bf-4c88-a60a-456483d510d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-4c5d0a4b-6589-42e4-935f-790fdcff3c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-a9fa82a4-b24e-4697-8b3e-7fec056b0095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800733388-172.17.0.4-1595363623687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-fa9b8830-b67f-45cc-8420-1ae32a0c9104,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-2696b5c2-68fe-4c22-98b5-9506bec0342f,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6d5241cc-27f5-4712-8462-773836c7d915,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-a98411c3-5927-4db2-8528-99113558596f,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-5526e09f-43f9-487a-ab5e-aabe08f9def5,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-9ae12ce2-b1bf-4c88-a60a-456483d510d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-4c5d0a4b-6589-42e4-935f-790fdcff3c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-a9fa82a4-b24e-4697-8b3e-7fec056b0095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138377702-172.17.0.4-1595364068991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42060,DS-4c065aa4-3114-492a-bc92-6b1658eb778e,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-5efd3981-f17f-4a60-a2a4-3038bab58279,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-89970042-2fd1-495e-ac81-7596931823b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-f3923b41-796c-4f21-829d-c10d0b5df3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-8277ce67-62ea-4586-b836-c8600725a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-ee260cef-7526-499d-8977-a4bcfa96a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-f0df952f-b56c-4d63-83e6-c925714efcae,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-81da9fa5-38c2-457d-aa88-9e9b2e8483d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138377702-172.17.0.4-1595364068991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42060,DS-4c065aa4-3114-492a-bc92-6b1658eb778e,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-5efd3981-f17f-4a60-a2a4-3038bab58279,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-89970042-2fd1-495e-ac81-7596931823b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-f3923b41-796c-4f21-829d-c10d0b5df3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-8277ce67-62ea-4586-b836-c8600725a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-ee260cef-7526-499d-8977-a4bcfa96a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-f0df952f-b56c-4d63-83e6-c925714efcae,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-81da9fa5-38c2-457d-aa88-9e9b2e8483d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689298737-172.17.0.4-1595364227984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41864,DS-4f911b0d-44bf-4757-ab51-23c9254d445b,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-98735f11-9016-45ee-9361-2f4a15627251,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-06449074-078d-43ac-8fa3-03948cbd30a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-e77d2371-60be-48ff-888d-291c52ef8ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4e049df6-c9d1-49ad-9df6-e2328250aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-2e55589b-a3fb-4c23-8ac0-cb8a9d40b090,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-c453586e-88e0-497e-b96c-fd280d287db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-127a905a-7571-4ca6-9da7-e17a7af57559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689298737-172.17.0.4-1595364227984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41864,DS-4f911b0d-44bf-4757-ab51-23c9254d445b,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-98735f11-9016-45ee-9361-2f4a15627251,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-06449074-078d-43ac-8fa3-03948cbd30a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-e77d2371-60be-48ff-888d-291c52ef8ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4e049df6-c9d1-49ad-9df6-e2328250aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-2e55589b-a3fb-4c23-8ac0-cb8a9d40b090,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-c453586e-88e0-497e-b96c-fd280d287db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-127a905a-7571-4ca6-9da7-e17a7af57559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349503080-172.17.0.4-1595364535182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38832,DS-bf7952ae-8a26-42f2-a4a6-411e99d34cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-25dc2955-38c7-45b9-97fe-cc19641c8eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9de24150-6de4-4d7c-953d-b0cd15164c26,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-873304c2-e6bd-4527-a60a-15f5833f177d,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-382464fe-b3e7-465a-885f-ee0dfa76bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-2e99793f-3cb3-44f6-9dff-1a7ca2367625,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-1da80e41-3d7b-4ba6-938a-572c12a0592e,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-4f468a01-c992-4b44-8cd5-b9d0c1df1c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349503080-172.17.0.4-1595364535182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38832,DS-bf7952ae-8a26-42f2-a4a6-411e99d34cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-25dc2955-38c7-45b9-97fe-cc19641c8eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9de24150-6de4-4d7c-953d-b0cd15164c26,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-873304c2-e6bd-4527-a60a-15f5833f177d,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-382464fe-b3e7-465a-885f-ee0dfa76bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-2e99793f-3cb3-44f6-9dff-1a7ca2367625,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-1da80e41-3d7b-4ba6-938a-572c12a0592e,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-4f468a01-c992-4b44-8cd5-b9d0c1df1c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073435090-172.17.0.4-1595364798897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41832,DS-8d5e5d2c-e7b5-47bb-9457-7d6e5d9b0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-e4862526-04df-4110-9ebb-26c48e396972,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-404fb03a-8190-4d7a-ad77-b91f229bf9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-f99e78b2-cc18-4346-abf3-8c805a6b8ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-3c98df23-1c01-4e4f-beb7-83cb3905fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-a2d8b908-4d5d-41bb-ac20-9d3c36440b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-09df0d5c-f684-47e3-9440-228026b4adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-905e7762-c6aa-439c-9026-4fe00e5a56a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073435090-172.17.0.4-1595364798897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41832,DS-8d5e5d2c-e7b5-47bb-9457-7d6e5d9b0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-e4862526-04df-4110-9ebb-26c48e396972,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-404fb03a-8190-4d7a-ad77-b91f229bf9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-f99e78b2-cc18-4346-abf3-8c805a6b8ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-3c98df23-1c01-4e4f-beb7-83cb3905fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-a2d8b908-4d5d-41bb-ac20-9d3c36440b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-09df0d5c-f684-47e3-9440-228026b4adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-905e7762-c6aa-439c-9026-4fe00e5a56a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966496752-172.17.0.4-1595365408020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34597,DS-31718771-c14f-4832-bf08-dfdff8685266,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-cd9c2d0f-2c90-4722-9e06-a708630441d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-6b2685cd-9712-4513-8df1-0591e14fb21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-cdc23703-7f5a-437f-a31f-d038a6017deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-5f7a3779-9b31-40d2-86b6-f0f3f56841ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-cc5fabe3-06cb-4e2c-a791-04d047c1b684,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-7b0fcdf3-e3ae-4c32-8681-b753715478f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-83f5d338-8282-417a-aaaf-bdd4751d480a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966496752-172.17.0.4-1595365408020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34597,DS-31718771-c14f-4832-bf08-dfdff8685266,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-cd9c2d0f-2c90-4722-9e06-a708630441d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-6b2685cd-9712-4513-8df1-0591e14fb21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-cdc23703-7f5a-437f-a31f-d038a6017deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-5f7a3779-9b31-40d2-86b6-f0f3f56841ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-cc5fabe3-06cb-4e2c-a791-04d047c1b684,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-7b0fcdf3-e3ae-4c32-8681-b753715478f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-83f5d338-8282-417a-aaaf-bdd4751d480a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807148440-172.17.0.4-1595366150062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-0a59fe36-4b35-496f-bc5e-17b0d820b487,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-575b3dda-dda6-4abf-bd07-e5bf90e0e077,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-63e9b670-9e79-4b36-845d-8d6d7cbe2a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-2f3081e2-616b-4c10-a5a2-1fa8d5ffc748,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-e0ce96b6-3a52-476e-91d1-a47e83599b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-296523be-ef5d-4546-9944-64ca7788be4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-b8ae9944-fbb9-40b1-b491-9e220a6e067f,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-2946a0eb-b006-44cc-9973-dd20c1da9b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807148440-172.17.0.4-1595366150062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-0a59fe36-4b35-496f-bc5e-17b0d820b487,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-575b3dda-dda6-4abf-bd07-e5bf90e0e077,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-63e9b670-9e79-4b36-845d-8d6d7cbe2a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-2f3081e2-616b-4c10-a5a2-1fa8d5ffc748,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-e0ce96b6-3a52-476e-91d1-a47e83599b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-296523be-ef5d-4546-9944-64ca7788be4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-b8ae9944-fbb9-40b1-b491-9e220a6e067f,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-2946a0eb-b006-44cc-9973-dd20c1da9b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293205423-172.17.0.4-1595366250382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40594,DS-0be281b6-4a42-4e84-801e-7a62af3fa284,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-d35d4efa-ac2b-4fdf-aacf-82e25b321e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-8b5a10f5-1b2c-45ca-b1e6-7b765de31f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-0bbea65c-6ef9-450c-ad2f-6998aa5d466f,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-2674a5f6-c31b-4440-987e-53f51b27b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-14259714-d2cc-4eec-ac74-6d8d2364bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-91f00c14-8e7c-4d4a-b7b2-2e965869e029,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-1225faa4-50ff-426a-9277-fdde8cf9a30a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293205423-172.17.0.4-1595366250382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40594,DS-0be281b6-4a42-4e84-801e-7a62af3fa284,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-d35d4efa-ac2b-4fdf-aacf-82e25b321e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-8b5a10f5-1b2c-45ca-b1e6-7b765de31f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-0bbea65c-6ef9-450c-ad2f-6998aa5d466f,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-2674a5f6-c31b-4440-987e-53f51b27b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-14259714-d2cc-4eec-ac74-6d8d2364bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-91f00c14-8e7c-4d4a-b7b2-2e965869e029,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-1225faa4-50ff-426a-9277-fdde8cf9a30a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509615149-172.17.0.4-1595366916758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-79698716-5105-4fed-95d9-2ee6b5dae6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-793a4557-9c95-4dfa-9c4d-721f1f4e4173,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-79b50189-5d53-41b2-aa5f-3254a198adaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-ba0ad0fb-cc9c-41a9-971f-028853e6c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-be20b3e2-79fe-436b-9064-35b9365030b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-92ea9a4c-0c48-40e8-959d-e4a2603bf476,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-cf387cb1-aef2-437c-aec2-6fe20a008b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-7f8147a7-bbf4-4172-87b6-524106cf0bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509615149-172.17.0.4-1595366916758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-79698716-5105-4fed-95d9-2ee6b5dae6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-793a4557-9c95-4dfa-9c4d-721f1f4e4173,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-79b50189-5d53-41b2-aa5f-3254a198adaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-ba0ad0fb-cc9c-41a9-971f-028853e6c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-be20b3e2-79fe-436b-9064-35b9365030b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-92ea9a4c-0c48-40e8-959d-e4a2603bf476,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-cf387cb1-aef2-437c-aec2-6fe20a008b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-7f8147a7-bbf4-4172-87b6-524106cf0bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419814756-172.17.0.4-1595367149399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-ff8dfc15-a907-4f8a-a881-94fa1b614260,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-70e935db-f5fa-4577-ac8a-ab97e0756e86,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-796948f8-52c5-4559-84c7-f004833f338e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-9b9b56d7-70d0-42af-9df9-7029f8b5c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-9e8057c9-9a80-4fcc-8d8e-55a6f67eccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-99c7705c-6765-47f3-acbb-2b6a76a7eaff,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-ec815963-3435-4daf-897c-f57075d34e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-423c0485-ddcb-4650-a5ed-6a626601b9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419814756-172.17.0.4-1595367149399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-ff8dfc15-a907-4f8a-a881-94fa1b614260,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-70e935db-f5fa-4577-ac8a-ab97e0756e86,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-796948f8-52c5-4559-84c7-f004833f338e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-9b9b56d7-70d0-42af-9df9-7029f8b5c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-9e8057c9-9a80-4fcc-8d8e-55a6f67eccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-99c7705c-6765-47f3-acbb-2b6a76a7eaff,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-ec815963-3435-4daf-897c-f57075d34e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-423c0485-ddcb-4650-a5ed-6a626601b9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742737988-172.17.0.4-1595367414751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-01f556bc-336a-4fca-af3d-943b22ecc173,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-bbbd96d6-f4a1-49ca-9bf2-c762d5296fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-b798d5ba-9a5e-4158-9394-8f0589186bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-47913b31-6e18-4320-bb02-aa1d6efa0dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-1dd89e2a-3324-4149-bb2d-8518830e3830,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-906fccce-8bdd-4867-8adc-4818a7e306a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-164a6c49-14cc-4a05-822f-02f65d08afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-376238cf-c846-4145-b224-5bf15e55b40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742737988-172.17.0.4-1595367414751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-01f556bc-336a-4fca-af3d-943b22ecc173,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-bbbd96d6-f4a1-49ca-9bf2-c762d5296fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-b798d5ba-9a5e-4158-9394-8f0589186bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-47913b31-6e18-4320-bb02-aa1d6efa0dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-1dd89e2a-3324-4149-bb2d-8518830e3830,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-906fccce-8bdd-4867-8adc-4818a7e306a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-164a6c49-14cc-4a05-822f-02f65d08afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-376238cf-c846-4145-b224-5bf15e55b40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853654897-172.17.0.4-1595367537990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-3e029faa-b850-4fab-86c2-f91f751f31fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-babb61d4-5898-4ad2-9e1f-57eedc8ef40a,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-8c4b4d2b-c485-400e-b99e-4e33d0c719f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-66ef503a-d9b4-4dc5-853f-e377f7187449,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-17f3c594-3a48-4490-b645-78859124fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-b07d7520-78ad-428f-b3d8-c51b8461c21c,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-759d05e0-4a58-46d1-9f34-71da832e93a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-e4e768a9-daa1-4c7f-bb3c-c3930bc62ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853654897-172.17.0.4-1595367537990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-3e029faa-b850-4fab-86c2-f91f751f31fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-babb61d4-5898-4ad2-9e1f-57eedc8ef40a,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-8c4b4d2b-c485-400e-b99e-4e33d0c719f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-66ef503a-d9b4-4dc5-853f-e377f7187449,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-17f3c594-3a48-4490-b645-78859124fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-b07d7520-78ad-428f-b3d8-c51b8461c21c,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-759d05e0-4a58-46d1-9f34-71da832e93a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-e4e768a9-daa1-4c7f-bb3c-c3930bc62ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172334015-172.17.0.4-1595367754209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-5f195474-b15d-43ce-b03c-a0878cb660ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-e4c2b104-609d-4ec1-a4d9-768fdee27c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-56c94452-06da-4f9b-8fb6-239e73975bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-96b990c8-cd63-4773-8734-103c63b4ea54,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-76ab76d6-afc9-44e6-93a9-9d54520aa511,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-b1163ee7-ba8a-4227-ab95-74a352072a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0e3151a0-614f-49aa-8e5a-28a6a1bdd6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-f0f56cd1-adf7-4aad-81c9-4d50958e0239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172334015-172.17.0.4-1595367754209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-5f195474-b15d-43ce-b03c-a0878cb660ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-e4c2b104-609d-4ec1-a4d9-768fdee27c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-56c94452-06da-4f9b-8fb6-239e73975bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-96b990c8-cd63-4773-8734-103c63b4ea54,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-76ab76d6-afc9-44e6-93a9-9d54520aa511,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-b1163ee7-ba8a-4227-ab95-74a352072a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0e3151a0-614f-49aa-8e5a-28a6a1bdd6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-f0f56cd1-adf7-4aad-81c9-4d50958e0239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163582126-172.17.0.4-1595367878757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-aa81f4c9-6f01-4334-b15e-ae1aff4e586c,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-114e4e6d-efd4-4c7d-a193-18c5ad32ddf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-d60948b4-e259-4fd1-9246-d5b0a86d966a,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a994545f-b82f-4f4f-a404-b07b4038145f,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-7b37cc6c-bfeb-4d74-ab4c-e4f5385231ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-1ad624ba-5ea9-471f-be7e-097aebd9dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-26cc87eb-49a9-438f-a3d1-906ac8003dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-d8a2a19c-3af8-455a-a9d9-ab9443a89e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163582126-172.17.0.4-1595367878757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-aa81f4c9-6f01-4334-b15e-ae1aff4e586c,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-114e4e6d-efd4-4c7d-a193-18c5ad32ddf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-d60948b4-e259-4fd1-9246-d5b0a86d966a,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a994545f-b82f-4f4f-a404-b07b4038145f,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-7b37cc6c-bfeb-4d74-ab4c-e4f5385231ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-1ad624ba-5ea9-471f-be7e-097aebd9dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-26cc87eb-49a9-438f-a3d1-906ac8003dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-d8a2a19c-3af8-455a-a9d9-ab9443a89e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580053391-172.17.0.4-1595368250038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-68e416d4-7936-41be-ae49-a13b92729f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-966a0f26-c25f-4ce5-a206-08408f03770d,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-a9a4519a-f793-4e2f-b131-03900985c157,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-e8625651-2e17-4f4e-ae48-283524401607,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-03a77245-a07d-419c-8957-7f01ef1b8a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-17e355ba-9cf3-41b2-a3d6-8c423c8d0fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-49390736-52f4-4da3-8f13-8f6e168fe966,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-41586926-b42d-4db1-ae31-5da1266d968d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580053391-172.17.0.4-1595368250038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-68e416d4-7936-41be-ae49-a13b92729f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-966a0f26-c25f-4ce5-a206-08408f03770d,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-a9a4519a-f793-4e2f-b131-03900985c157,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-e8625651-2e17-4f4e-ae48-283524401607,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-03a77245-a07d-419c-8957-7f01ef1b8a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-17e355ba-9cf3-41b2-a3d6-8c423c8d0fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-49390736-52f4-4da3-8f13-8f6e168fe966,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-41586926-b42d-4db1-ae31-5da1266d968d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436369704-172.17.0.4-1595368361627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38047,DS-93ced35f-c70e-44e0-9509-53e2eabb2408,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-2c652103-1d0b-475d-8787-fa16215ec9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-3c81f0ca-f7c4-48db-982e-66c43cb7f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-03bcc2d0-f7b0-4dd2-b0b1-3e686de3d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-f61feabc-2d44-4542-8089-264cba107d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-8324884b-a420-4dcd-99ee-e1f7bd90c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-85df3fc7-6e93-4524-847e-a6afc4ab851c,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-cc119e8f-52ee-4ac5-9b8d-339d38f42c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436369704-172.17.0.4-1595368361627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38047,DS-93ced35f-c70e-44e0-9509-53e2eabb2408,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-2c652103-1d0b-475d-8787-fa16215ec9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-3c81f0ca-f7c4-48db-982e-66c43cb7f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-03bcc2d0-f7b0-4dd2-b0b1-3e686de3d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-f61feabc-2d44-4542-8089-264cba107d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-8324884b-a420-4dcd-99ee-e1f7bd90c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-85df3fc7-6e93-4524-847e-a6afc4ab851c,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-cc119e8f-52ee-4ac5-9b8d-339d38f42c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278652288-172.17.0.4-1595368639444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-7e55e63a-1291-4c03-8edb-971521752733,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-062cfbaf-a6fd-4b6e-b18b-cc0fe4a73244,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-8ea80cbe-6af7-486f-a564-9003b1db1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-162b8569-b7e5-4210-a7cc-b73cbad62e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-ca8d82aa-22a9-436e-ba68-f04b3a727429,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-af3125b8-a678-4556-b6c1-ee21c160377c,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-5e06b524-a3e1-4621-b77c-dcb1966dc301,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-d93a7c09-761a-4e30-a007-45511e5ba483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278652288-172.17.0.4-1595368639444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-7e55e63a-1291-4c03-8edb-971521752733,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-062cfbaf-a6fd-4b6e-b18b-cc0fe4a73244,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-8ea80cbe-6af7-486f-a564-9003b1db1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-162b8569-b7e5-4210-a7cc-b73cbad62e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-ca8d82aa-22a9-436e-ba68-f04b3a727429,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-af3125b8-a678-4556-b6c1-ee21c160377c,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-5e06b524-a3e1-4621-b77c-dcb1966dc301,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-d93a7c09-761a-4e30-a007-45511e5ba483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5647
