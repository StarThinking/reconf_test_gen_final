reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25686841-172.17.0.18-1595361731754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40726,DS-6b834a77-138e-43db-9381-dcfc81d42228,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-848692bb-c99d-456d-bf4a-8ebc49ec8578,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-541f4c0b-ffee-4f0a-be3a-a83dca1d721e,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-03e06618-52fa-4e59-b259-0561417dcabf,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-c58b87eb-ec44-4d67-af0d-8bd3ee320d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-fa8e44c3-09ce-46ba-a579-d627ae10aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-2705c7d9-91df-4335-bb1e-2cf2caa83204,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-9e597235-f52b-4501-b568-b95d1c6f43c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25686841-172.17.0.18-1595361731754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40726,DS-6b834a77-138e-43db-9381-dcfc81d42228,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-848692bb-c99d-456d-bf4a-8ebc49ec8578,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-541f4c0b-ffee-4f0a-be3a-a83dca1d721e,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-03e06618-52fa-4e59-b259-0561417dcabf,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-c58b87eb-ec44-4d67-af0d-8bd3ee320d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-fa8e44c3-09ce-46ba-a579-d627ae10aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-2705c7d9-91df-4335-bb1e-2cf2caa83204,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-9e597235-f52b-4501-b568-b95d1c6f43c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975150131-172.17.0.18-1595362368485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39075,DS-fb28de91-8532-459b-a111-17cfd152509a,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-2c36e7d1-e1e7-4f81-8415-2dec58f88edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-be2dc494-0880-4864-a762-1d97526b4064,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-7dbae1f4-1137-43e8-a11d-c6f932ad48e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-91be835a-9c3f-4e47-ba1f-3f2214c11c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-2950a258-a7ff-4279-ada3-531a02b75ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-6f98a48c-0bac-4c43-8f51-852ad1292af6,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-b721b19b-4efb-4377-9d5a-70f05672ce00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975150131-172.17.0.18-1595362368485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39075,DS-fb28de91-8532-459b-a111-17cfd152509a,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-2c36e7d1-e1e7-4f81-8415-2dec58f88edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-be2dc494-0880-4864-a762-1d97526b4064,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-7dbae1f4-1137-43e8-a11d-c6f932ad48e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-91be835a-9c3f-4e47-ba1f-3f2214c11c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-2950a258-a7ff-4279-ada3-531a02b75ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-6f98a48c-0bac-4c43-8f51-852ad1292af6,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-b721b19b-4efb-4377-9d5a-70f05672ce00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632145537-172.17.0.18-1595362404034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42974,DS-3e124463-4d9d-4747-ba29-21a88feeaca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-7b927cbd-1265-4b12-8d4f-a10f097726dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-432b9a4e-a031-44e8-9d01-bf6df667e88f,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-fe8de91b-43f4-474b-a698-06cd0130f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-3543ab8b-bca5-4e17-a978-8eb85deffdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-ad7faf0c-ff42-444f-a040-752d53e19110,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-c19dc072-7ce0-4aad-9123-1695cb998b81,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-bc4397c6-e499-4199-8741-7663c99ba436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632145537-172.17.0.18-1595362404034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42974,DS-3e124463-4d9d-4747-ba29-21a88feeaca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-7b927cbd-1265-4b12-8d4f-a10f097726dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-432b9a4e-a031-44e8-9d01-bf6df667e88f,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-fe8de91b-43f4-474b-a698-06cd0130f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-3543ab8b-bca5-4e17-a978-8eb85deffdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-ad7faf0c-ff42-444f-a040-752d53e19110,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-c19dc072-7ce0-4aad-9123-1695cb998b81,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-bc4397c6-e499-4199-8741-7663c99ba436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956711112-172.17.0.18-1595362474267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-f844b39f-86e0-4a08-a7de-a1fbae49a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-226c5870-7748-431e-9a52-eb1d99c319cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-7040d03e-e1bc-4fbc-94a6-f2df9b820f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-59711e7d-8f8f-4e8f-998b-341c82c674dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-53fa5dd8-7052-44d0-af70-bdd6a0c207c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-d08fcb2a-fead-44a9-8a29-e8e69734343f,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-0c7f0bec-e72a-4b3f-8a0e-97733bfe8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-c7d9f26b-b964-4b6e-b65b-788990c12880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956711112-172.17.0.18-1595362474267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-f844b39f-86e0-4a08-a7de-a1fbae49a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-226c5870-7748-431e-9a52-eb1d99c319cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-7040d03e-e1bc-4fbc-94a6-f2df9b820f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-59711e7d-8f8f-4e8f-998b-341c82c674dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-53fa5dd8-7052-44d0-af70-bdd6a0c207c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-d08fcb2a-fead-44a9-8a29-e8e69734343f,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-0c7f0bec-e72a-4b3f-8a0e-97733bfe8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-c7d9f26b-b964-4b6e-b65b-788990c12880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811491694-172.17.0.18-1595362819568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-6fcadcdc-bf62-4397-8d16-c10450a6e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-ce9fb410-521a-4897-a033-dfb6cdc31d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-33a5062f-4de2-43b4-92f3-7c4f7fe6af31,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-d5e55221-0410-4e99-9404-1b113492a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-43d2abe0-d5a2-4585-b445-18011f878a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-93e763b5-fa64-48df-aafd-60760d1ce3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-2a093c49-3b54-4553-9e38-4263f9c900c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-a349f627-9ad5-4a2a-bd82-02c0639c40ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811491694-172.17.0.18-1595362819568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-6fcadcdc-bf62-4397-8d16-c10450a6e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-ce9fb410-521a-4897-a033-dfb6cdc31d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-33a5062f-4de2-43b4-92f3-7c4f7fe6af31,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-d5e55221-0410-4e99-9404-1b113492a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-43d2abe0-d5a2-4585-b445-18011f878a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-93e763b5-fa64-48df-aafd-60760d1ce3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-2a093c49-3b54-4553-9e38-4263f9c900c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-a349f627-9ad5-4a2a-bd82-02c0639c40ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143521423-172.17.0.18-1595362920460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44457,DS-717e1ee6-4233-43f7-8c05-45008fcc8691,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-5ff01160-d728-4a1f-b0b4-90e120d44c31,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-28cc42aa-70c8-4427-8c98-386584ed9186,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-a9f82663-e9d8-4c40-b071-f48aac84271b,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-2bcb96e1-e8c7-4aa9-9d7d-91ac42b5ef0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-dab2a5f8-4684-431f-9cf5-8936659a2f60,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-8b09a962-24f6-42e8-9a18-2939ecf3fb59,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f9f61075-dd1d-4093-8e53-d865ec0ac7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143521423-172.17.0.18-1595362920460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44457,DS-717e1ee6-4233-43f7-8c05-45008fcc8691,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-5ff01160-d728-4a1f-b0b4-90e120d44c31,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-28cc42aa-70c8-4427-8c98-386584ed9186,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-a9f82663-e9d8-4c40-b071-f48aac84271b,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-2bcb96e1-e8c7-4aa9-9d7d-91ac42b5ef0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-dab2a5f8-4684-431f-9cf5-8936659a2f60,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-8b09a962-24f6-42e8-9a18-2939ecf3fb59,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f9f61075-dd1d-4093-8e53-d865ec0ac7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207076262-172.17.0.18-1595364254332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42178,DS-15e0be74-ae2b-4085-91df-c79d5ec02865,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-3e42098b-6808-431a-bc65-6b60e3dad182,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-31e92c34-f5ab-4a50-a3d3-2f561d6a30cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-0d0da702-ee51-4cbd-863c-38d900e7edae,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-f986c46d-6822-4e3d-b94f-1bb3907ce689,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-c814b236-d048-401d-8396-795e3caf4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-4baeb41f-04ef-4bec-a37a-7f9c8a823e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-8548564f-528b-4e09-8ff9-0360e8de78bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207076262-172.17.0.18-1595364254332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42178,DS-15e0be74-ae2b-4085-91df-c79d5ec02865,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-3e42098b-6808-431a-bc65-6b60e3dad182,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-31e92c34-f5ab-4a50-a3d3-2f561d6a30cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-0d0da702-ee51-4cbd-863c-38d900e7edae,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-f986c46d-6822-4e3d-b94f-1bb3907ce689,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-c814b236-d048-401d-8396-795e3caf4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-4baeb41f-04ef-4bec-a37a-7f9c8a823e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-8548564f-528b-4e09-8ff9-0360e8de78bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493522502-172.17.0.18-1595364327440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-84139635-ff2f-471b-bd4f-c5fc1d5761f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-8a4384fb-6ec8-44a0-b000-75fdeee57235,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-f3e1733c-54e4-45bc-a331-e37c81b582a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f03ad758-2a6b-43b5-aa08-cc28b8a0f725,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-1e4095f2-0be7-4387-a19c-8bfc203e103e,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-7ee1aa84-1a83-4a7a-a8f0-b707114e3160,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-6a2f770f-ca87-4e75-941b-91a1fb84d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-d61f161b-5b0c-4f87-92c3-fdb2993f2d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493522502-172.17.0.18-1595364327440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-84139635-ff2f-471b-bd4f-c5fc1d5761f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-8a4384fb-6ec8-44a0-b000-75fdeee57235,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-f3e1733c-54e4-45bc-a331-e37c81b582a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f03ad758-2a6b-43b5-aa08-cc28b8a0f725,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-1e4095f2-0be7-4387-a19c-8bfc203e103e,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-7ee1aa84-1a83-4a7a-a8f0-b707114e3160,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-6a2f770f-ca87-4e75-941b-91a1fb84d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-d61f161b-5b0c-4f87-92c3-fdb2993f2d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700687208-172.17.0.18-1595364398580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-7b91a665-fe2f-4387-98ec-d6de74a887b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-7aa63e23-0a70-48e7-8bb1-b4060f01fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-8cc20b6d-7ba2-4d9a-bdd2-cb08603bbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-915636aa-58f1-4bf7-9d78-1dc9f078aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-3bf92152-a5e9-4b73-a232-26704a5ddf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-4f3d7e1c-b83e-4379-833f-a47738c396ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-36984cd9-2a04-4d5a-9e93-8f1f33a19cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-d736abb9-3efe-4b5b-bd71-921d1c485bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700687208-172.17.0.18-1595364398580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-7b91a665-fe2f-4387-98ec-d6de74a887b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-7aa63e23-0a70-48e7-8bb1-b4060f01fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-8cc20b6d-7ba2-4d9a-bdd2-cb08603bbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-915636aa-58f1-4bf7-9d78-1dc9f078aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-3bf92152-a5e9-4b73-a232-26704a5ddf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-4f3d7e1c-b83e-4379-833f-a47738c396ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-36984cd9-2a04-4d5a-9e93-8f1f33a19cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-d736abb9-3efe-4b5b-bd71-921d1c485bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605293447-172.17.0.18-1595364428498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-8da7ffcd-a6b0-40a6-ba13-364f874ea44f,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-a4a1d76a-f03e-4284-b478-15d5788f9711,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-a0347904-1958-4de1-a899-7cc41f75adbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-2234f567-0872-4021-b8e1-b325a85d14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-f917e108-9717-4d3d-af41-f122c9c38525,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-8def6735-d0c5-4eae-b4d7-8360c8e72b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-4e788efc-e385-4156-b1a3-2131a64e3768,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-5d38e210-bea1-4543-b240-a4c146f535f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605293447-172.17.0.18-1595364428498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-8da7ffcd-a6b0-40a6-ba13-364f874ea44f,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-a4a1d76a-f03e-4284-b478-15d5788f9711,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-a0347904-1958-4de1-a899-7cc41f75adbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-2234f567-0872-4021-b8e1-b325a85d14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-f917e108-9717-4d3d-af41-f122c9c38525,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-8def6735-d0c5-4eae-b4d7-8360c8e72b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-4e788efc-e385-4156-b1a3-2131a64e3768,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-5d38e210-bea1-4543-b240-a4c146f535f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262492199-172.17.0.18-1595364982557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-8289b943-7a9d-4f65-9395-22659c58b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-5ab6b4fd-a729-412c-8d90-263f6fdecc70,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-c7df422b-55d7-422a-8a67-98e8586d4ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b56089ba-707f-48b4-bd9d-6706305a5006,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-4cd6e2fb-bcb0-47d1-b813-a821fb688230,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-51ea0eb1-7965-4d3c-bef5-3f5eb08b615e,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-0c707c91-78ee-4b43-b6c6-1b7c42f34425,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-ddb66e45-a926-47fd-9d35-cae69b18eefe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262492199-172.17.0.18-1595364982557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-8289b943-7a9d-4f65-9395-22659c58b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-5ab6b4fd-a729-412c-8d90-263f6fdecc70,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-c7df422b-55d7-422a-8a67-98e8586d4ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b56089ba-707f-48b4-bd9d-6706305a5006,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-4cd6e2fb-bcb0-47d1-b813-a821fb688230,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-51ea0eb1-7965-4d3c-bef5-3f5eb08b615e,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-0c707c91-78ee-4b43-b6c6-1b7c42f34425,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-ddb66e45-a926-47fd-9d35-cae69b18eefe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310349955-172.17.0.18-1595365307541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43740,DS-2ac437c7-159a-41f3-bf4e-1fbb99fd21d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-47a5b4db-28c0-4d4e-8b81-506be6cc4acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-fff4c7a6-9f2b-4416-bfa8-fda76a50d73d,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-5a6869a1-89b7-4600-9c52-33311d627549,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-0f22be36-f1c1-4b3d-9388-6a8d39667bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-03a63fbc-938f-47ab-a645-3c438fa28795,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-0015e5a7-8623-489a-8236-7abc29dbaeae,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-6096640a-f135-4164-8eae-c4a0f0550262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310349955-172.17.0.18-1595365307541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43740,DS-2ac437c7-159a-41f3-bf4e-1fbb99fd21d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-47a5b4db-28c0-4d4e-8b81-506be6cc4acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-fff4c7a6-9f2b-4416-bfa8-fda76a50d73d,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-5a6869a1-89b7-4600-9c52-33311d627549,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-0f22be36-f1c1-4b3d-9388-6a8d39667bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-03a63fbc-938f-47ab-a645-3c438fa28795,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-0015e5a7-8623-489a-8236-7abc29dbaeae,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-6096640a-f135-4164-8eae-c4a0f0550262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212773665-172.17.0.18-1595365375756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-ddd11775-78b8-42e0-9a18-25f72c3fa055,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-4b3bb690-5385-4ea9-84dd-e74e429725f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-3cc45263-7ad6-4348-b345-f113450bbfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-1ea274ec-d46b-4d6c-a0c2-1faddcffe808,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-4a6bd667-96c2-42fb-9bd3-669fd0d48d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-a754267c-7c62-404a-be53-83792c78ecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-bcf7a985-c29b-49f6-9f49-a85221464830,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-51c5defb-78cd-4cd2-9ce4-198374ac3308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212773665-172.17.0.18-1595365375756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-ddd11775-78b8-42e0-9a18-25f72c3fa055,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-4b3bb690-5385-4ea9-84dd-e74e429725f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-3cc45263-7ad6-4348-b345-f113450bbfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-1ea274ec-d46b-4d6c-a0c2-1faddcffe808,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-4a6bd667-96c2-42fb-9bd3-669fd0d48d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-a754267c-7c62-404a-be53-83792c78ecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-bcf7a985-c29b-49f6-9f49-a85221464830,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-51c5defb-78cd-4cd2-9ce4-198374ac3308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591958407-172.17.0.18-1595365460216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-5412df22-fc23-4e6f-9e1c-d34a1a404d15,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-132b7588-9e51-4e27-ae7d-b8525021b638,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-260532d4-fa6c-479e-854e-0012c71baaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-ea114438-ecdb-4008-b5c5-29765cf32f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-3e64379b-910e-4b4f-8785-d75f21a7268f,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-c1f8ddf2-85b4-408a-ba76-657096ec758a,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-28c0bf28-7761-434a-bd30-2e5a3e82bd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-a38d3f47-a6c6-4029-9d53-c276e756d7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591958407-172.17.0.18-1595365460216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-5412df22-fc23-4e6f-9e1c-d34a1a404d15,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-132b7588-9e51-4e27-ae7d-b8525021b638,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-260532d4-fa6c-479e-854e-0012c71baaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-ea114438-ecdb-4008-b5c5-29765cf32f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-3e64379b-910e-4b4f-8785-d75f21a7268f,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-c1f8ddf2-85b4-408a-ba76-657096ec758a,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-28c0bf28-7761-434a-bd30-2e5a3e82bd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-a38d3f47-a6c6-4029-9d53-c276e756d7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5464
