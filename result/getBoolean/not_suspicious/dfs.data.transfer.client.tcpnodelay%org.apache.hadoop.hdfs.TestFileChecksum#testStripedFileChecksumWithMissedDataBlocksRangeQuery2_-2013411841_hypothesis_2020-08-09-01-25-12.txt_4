reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582969380-172.17.0.12-1596936358019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-660a9a08-5a3f-4b8f-a8bd-21b88e08df24,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-9b8137a7-642d-4911-8632-e2a2e18261d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-9d570720-351f-4554-9e08-83c5c10f6798,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-12352b98-0353-49af-8997-611b062a0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-ee327948-b7af-458c-826a-df928863a341,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-f13f8702-db49-4793-b9d0-e73f62628a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-87296fec-5f8c-444e-8eb9-2387258c842f,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-b7e9f82a-8742-434b-962c-62281e35455d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582969380-172.17.0.12-1596936358019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-660a9a08-5a3f-4b8f-a8bd-21b88e08df24,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-9b8137a7-642d-4911-8632-e2a2e18261d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-9d570720-351f-4554-9e08-83c5c10f6798,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-12352b98-0353-49af-8997-611b062a0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-ee327948-b7af-458c-826a-df928863a341,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-f13f8702-db49-4793-b9d0-e73f62628a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-87296fec-5f8c-444e-8eb9-2387258c842f,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-b7e9f82a-8742-434b-962c-62281e35455d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631571252-172.17.0.12-1596936452825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-f389aacd-636d-454b-82b7-77e52bd1f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-04ef0c41-e7ef-42e6-80f9-3f9755cd2587,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-8bac31fb-5cba-4880-acf8-2da354933a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-39e3d11a-4519-44c3-aba4-76a6612c24ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c5d11fd5-fe14-478c-a015-b6ac78832dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-933eaa2f-c998-460f-95dc-f887a10c1c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-e20e3792-3abf-41de-97c7-95074a2ac8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-a8e5c793-f296-4233-a309-90bfd1317e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631571252-172.17.0.12-1596936452825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-f389aacd-636d-454b-82b7-77e52bd1f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-04ef0c41-e7ef-42e6-80f9-3f9755cd2587,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-8bac31fb-5cba-4880-acf8-2da354933a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-39e3d11a-4519-44c3-aba4-76a6612c24ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c5d11fd5-fe14-478c-a015-b6ac78832dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-933eaa2f-c998-460f-95dc-f887a10c1c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-e20e3792-3abf-41de-97c7-95074a2ac8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-a8e5c793-f296-4233-a309-90bfd1317e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129460629-172.17.0.12-1596936555646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-b3e273e8-b7b8-40c1-870f-92ee8f90422c,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-487f4672-8dc6-4ef4-80ea-35c1facefaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-8e0e8cb4-31f3-4335-9944-411f77055e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-c25ce9e7-65fe-4b95-965d-11da5b4aeeee,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-7b23cffc-092c-402f-86f2-aa20ee21f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-183b181e-639e-4269-9e05-5dae463b865f,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-c7fb5ee9-35f3-419c-9a9e-6e712e3d1227,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-6d6baa1c-3b84-4689-9666-69f84904d9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129460629-172.17.0.12-1596936555646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-b3e273e8-b7b8-40c1-870f-92ee8f90422c,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-487f4672-8dc6-4ef4-80ea-35c1facefaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-8e0e8cb4-31f3-4335-9944-411f77055e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-c25ce9e7-65fe-4b95-965d-11da5b4aeeee,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-7b23cffc-092c-402f-86f2-aa20ee21f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-183b181e-639e-4269-9e05-5dae463b865f,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-c7fb5ee9-35f3-419c-9a9e-6e712e3d1227,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-6d6baa1c-3b84-4689-9666-69f84904d9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873832966-172.17.0.12-1596936590992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41764,DS-24524776-1c58-491e-9a91-4717df07da80,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-611c9bf9-1d43-4f27-b837-d9f3619d5a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-aaf24591-6282-49fd-8406-263c81e05ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-3c46ba49-2f18-4ffc-ba8c-9a846714fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-56ddc75a-997f-4716-957e-2f6c5eb6f1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-6385c552-66f5-4747-85de-bc275803ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-dc243da5-8805-4dea-b5f6-6e14d68ccb86,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-31d719a1-8319-45ae-91b8-accb14c88e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873832966-172.17.0.12-1596936590992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41764,DS-24524776-1c58-491e-9a91-4717df07da80,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-611c9bf9-1d43-4f27-b837-d9f3619d5a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-aaf24591-6282-49fd-8406-263c81e05ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-3c46ba49-2f18-4ffc-ba8c-9a846714fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-56ddc75a-997f-4716-957e-2f6c5eb6f1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-6385c552-66f5-4747-85de-bc275803ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-dc243da5-8805-4dea-b5f6-6e14d68ccb86,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-31d719a1-8319-45ae-91b8-accb14c88e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511215958-172.17.0.12-1596936751447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39694,DS-278dd502-6d32-4e21-acbd-edb2c190d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-2468ce9a-b4a3-413b-b184-20ab457ece4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-ea50ab8d-a7c5-47eb-b4e3-626fd7accd64,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-414b3bdb-8650-487c-84a3-2d85a4735034,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-1f7a72d8-85cb-4098-8336-351280a31e33,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-dbf304e8-5361-4520-8b6d-683a23528a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-ddb4e1a4-c40d-4619-af91-e354a76042a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-96a09795-08d9-4d30-a478-22833a0ca48f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511215958-172.17.0.12-1596936751447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39694,DS-278dd502-6d32-4e21-acbd-edb2c190d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-2468ce9a-b4a3-413b-b184-20ab457ece4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-ea50ab8d-a7c5-47eb-b4e3-626fd7accd64,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-414b3bdb-8650-487c-84a3-2d85a4735034,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-1f7a72d8-85cb-4098-8336-351280a31e33,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-dbf304e8-5361-4520-8b6d-683a23528a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-ddb4e1a4-c40d-4619-af91-e354a76042a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-96a09795-08d9-4d30-a478-22833a0ca48f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138208172-172.17.0.12-1596937091562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-854a88ad-cb4a-42a9-9fca-4f92c8de01a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-13fd9158-be45-418f-bf9f-c09291ddb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-9bffbfae-531e-420e-9600-7f868a24e317,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-6d5e1aa9-c44f-49c6-9b62-9ca8a483a982,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-27722ac5-19ad-4f66-a656-765872a03a08,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ff6cf5b8-1f7c-44a5-ac1c-faac4b485ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-3c370401-b400-45cc-bc15-23a294ef861d,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-ba5b96da-2525-4e2b-88a5-e4e4271b66d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138208172-172.17.0.12-1596937091562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-854a88ad-cb4a-42a9-9fca-4f92c8de01a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-13fd9158-be45-418f-bf9f-c09291ddb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-9bffbfae-531e-420e-9600-7f868a24e317,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-6d5e1aa9-c44f-49c6-9b62-9ca8a483a982,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-27722ac5-19ad-4f66-a656-765872a03a08,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ff6cf5b8-1f7c-44a5-ac1c-faac4b485ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-3c370401-b400-45cc-bc15-23a294ef861d,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-ba5b96da-2525-4e2b-88a5-e4e4271b66d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548917090-172.17.0.12-1596937159938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-17d0b799-00f7-4565-ac9c-36ed4d3be81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-49861648-3457-49f6-a277-c55aad7ff544,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-ef5ac65a-b575-4185-b4ef-b1264c1d62ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-b3482681-2acd-4766-9c92-f0d72c313bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-21880c0b-f138-4fd4-b542-9db5786fa0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-aa05593a-d532-4460-8315-9838d9f8bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-67371d4a-789d-46f8-a75f-c764d0a58ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-ba1cc42c-bd40-47e4-bf41-c3ebbefc971f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548917090-172.17.0.12-1596937159938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-17d0b799-00f7-4565-ac9c-36ed4d3be81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-49861648-3457-49f6-a277-c55aad7ff544,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-ef5ac65a-b575-4185-b4ef-b1264c1d62ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-b3482681-2acd-4766-9c92-f0d72c313bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-21880c0b-f138-4fd4-b542-9db5786fa0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-aa05593a-d532-4460-8315-9838d9f8bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-67371d4a-789d-46f8-a75f-c764d0a58ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-ba1cc42c-bd40-47e4-bf41-c3ebbefc971f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154571791-172.17.0.12-1596937511126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-d82fcb4a-1a61-451e-a6eb-dab497ebbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-a2ec25cd-c1f6-4f08-87e1-d867f0c93db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-b16a0fdb-ed1d-45f6-949b-ebde17313f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-83dedaa2-1ace-4195-a3fc-014311d96d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-a3c17ee6-44bb-4833-b4ed-ac98b2f710a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-77bafd87-9130-482e-8d8e-2c918370cc72,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-1e6510cd-af32-44c9-a87c-8ac88f665a93,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-4470ec08-e2f0-4b58-9893-468a68b3e02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154571791-172.17.0.12-1596937511126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-d82fcb4a-1a61-451e-a6eb-dab497ebbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-a2ec25cd-c1f6-4f08-87e1-d867f0c93db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-b16a0fdb-ed1d-45f6-949b-ebde17313f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-83dedaa2-1ace-4195-a3fc-014311d96d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-a3c17ee6-44bb-4833-b4ed-ac98b2f710a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-77bafd87-9130-482e-8d8e-2c918370cc72,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-1e6510cd-af32-44c9-a87c-8ac88f665a93,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-4470ec08-e2f0-4b58-9893-468a68b3e02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336685408-172.17.0.12-1596937573625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45047,DS-ccdca961-656e-4ab0-8f0a-bbf538302b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-d21380a0-7635-458d-93b7-616671565887,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-bc065965-89d4-4b04-b113-eb6e8e72ce72,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-731d3b34-c0a9-4a66-9073-fbae0731df69,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-545cb88f-ec4b-4bba-b7b1-6300873d2254,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-2690aaa3-2b84-4119-a046-a80f3dd597e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-2fa3a9bf-8b67-4629-8e68-329ed299e7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-8186e9e4-3736-4a72-8f03-634b27a568e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336685408-172.17.0.12-1596937573625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45047,DS-ccdca961-656e-4ab0-8f0a-bbf538302b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-d21380a0-7635-458d-93b7-616671565887,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-bc065965-89d4-4b04-b113-eb6e8e72ce72,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-731d3b34-c0a9-4a66-9073-fbae0731df69,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-545cb88f-ec4b-4bba-b7b1-6300873d2254,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-2690aaa3-2b84-4119-a046-a80f3dd597e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-2fa3a9bf-8b67-4629-8e68-329ed299e7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-8186e9e4-3736-4a72-8f03-634b27a568e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054378593-172.17.0.12-1596938186401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37963,DS-f41a773f-d1c0-43e0-9409-c4cc10f6a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-e60edf87-0fcf-4821-8cac-77ea17e11c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-7405fdeb-20fe-4a2e-9a2a-cb5248ca37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-36e13175-bc31-4d78-adae-69d0621a1106,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-28965403-2c08-40e5-a2df-3625a8f35be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-67c8a06d-6895-47a3-9641-60f09a4533d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-33cad1d8-9b1f-44dd-88b2-ac3e192ee697,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-a7f746ca-efb4-46ea-a8b3-49c24e7aa53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054378593-172.17.0.12-1596938186401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37963,DS-f41a773f-d1c0-43e0-9409-c4cc10f6a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-e60edf87-0fcf-4821-8cac-77ea17e11c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-7405fdeb-20fe-4a2e-9a2a-cb5248ca37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-36e13175-bc31-4d78-adae-69d0621a1106,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-28965403-2c08-40e5-a2df-3625a8f35be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-67c8a06d-6895-47a3-9641-60f09a4533d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-33cad1d8-9b1f-44dd-88b2-ac3e192ee697,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-a7f746ca-efb4-46ea-a8b3-49c24e7aa53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986205479-172.17.0.12-1596938310936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44234,DS-14eae27b-0167-455b-bcd9-3221701c8ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-d614047c-a3d4-4c5d-bdcf-4838cba4caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-e112bf26-4919-477f-97d7-b0c946be1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-96b9613b-c5a0-4f02-9c9a-ae21bac7f5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-916b95a5-7dd3-4630-bd6b-8a942567e1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-6aea3f03-ef69-4977-a269-1453e845aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-68816c68-fcd4-4f55-a51d-3571e326ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7c2ddd6e-830d-4ede-9bd1-4c1794ea83a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986205479-172.17.0.12-1596938310936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44234,DS-14eae27b-0167-455b-bcd9-3221701c8ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-d614047c-a3d4-4c5d-bdcf-4838cba4caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-e112bf26-4919-477f-97d7-b0c946be1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-96b9613b-c5a0-4f02-9c9a-ae21bac7f5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-916b95a5-7dd3-4630-bd6b-8a942567e1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-6aea3f03-ef69-4977-a269-1453e845aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-68816c68-fcd4-4f55-a51d-3571e326ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7c2ddd6e-830d-4ede-9bd1-4c1794ea83a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48159404-172.17.0.12-1596938340375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33424,DS-da670de2-206e-4128-af17-d0af23de2368,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-601648cd-456a-494d-a5d5-bb7d4936bb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-af99411f-3ce7-437b-a41b-9e6fadae4a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-3d56f88f-b013-40d8-8716-f30be9275b13,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-87a4d326-cdb5-4245-90c6-947b2271cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-9a9ec413-8ea3-4461-a9d6-98e89ae4550f,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-6d569006-8fa3-494d-8c5d-ecce63043c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-014215e5-648e-4004-ac81-183236336d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48159404-172.17.0.12-1596938340375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33424,DS-da670de2-206e-4128-af17-d0af23de2368,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-601648cd-456a-494d-a5d5-bb7d4936bb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-af99411f-3ce7-437b-a41b-9e6fadae4a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-3d56f88f-b013-40d8-8716-f30be9275b13,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-87a4d326-cdb5-4245-90c6-947b2271cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-9a9ec413-8ea3-4461-a9d6-98e89ae4550f,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-6d569006-8fa3-494d-8c5d-ecce63043c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-014215e5-648e-4004-ac81-183236336d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251721693-172.17.0.12-1596938701374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46695,DS-d0398d8f-6bdd-4ea2-8643-7f7d1735beed,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-ca27830d-8f88-4b27-9884-81435f30415c,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-d33bf867-4239-4ceb-a406-4506d986816c,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-e77c7232-c128-49e0-bce9-441221d8bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-e7c3a936-864d-4d57-ad83-b38980d411bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-b66c6675-654a-45aa-9661-c1f91988959a,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-9250431f-6cd7-46c0-a2fd-5d30d9d5c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-b1aafcec-ba67-4678-a04b-aa322ef8466f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251721693-172.17.0.12-1596938701374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46695,DS-d0398d8f-6bdd-4ea2-8643-7f7d1735beed,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-ca27830d-8f88-4b27-9884-81435f30415c,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-d33bf867-4239-4ceb-a406-4506d986816c,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-e77c7232-c128-49e0-bce9-441221d8bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-e7c3a936-864d-4d57-ad83-b38980d411bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-b66c6675-654a-45aa-9661-c1f91988959a,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-9250431f-6cd7-46c0-a2fd-5d30d9d5c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-b1aafcec-ba67-4678-a04b-aa322ef8466f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774773526-172.17.0.12-1596938844342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-2068733d-fd27-42f0-b263-8300638162ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-9a30ec65-2e35-4282-bb4a-004eb3ce8497,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-0c6fb094-5b68-429d-a68e-2d59c7789b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-d0fea6d4-5fe4-4dcb-bdaf-014b02322b75,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-55c93a6d-d803-40c7-9fb8-76e43c30ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-a9f2260a-e615-4122-bcf0-3427401943cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-a2e9fc48-3a8d-45a8-9210-05a05e10af50,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-53585740-b184-4a72-ac7d-bdc506d98e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774773526-172.17.0.12-1596938844342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-2068733d-fd27-42f0-b263-8300638162ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-9a30ec65-2e35-4282-bb4a-004eb3ce8497,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-0c6fb094-5b68-429d-a68e-2d59c7789b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-d0fea6d4-5fe4-4dcb-bdaf-014b02322b75,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-55c93a6d-d803-40c7-9fb8-76e43c30ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-a9f2260a-e615-4122-bcf0-3427401943cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-a2e9fc48-3a8d-45a8-9210-05a05e10af50,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-53585740-b184-4a72-ac7d-bdc506d98e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921287091-172.17.0.12-1596938916796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-404036db-0d0c-426e-9bf7-7cc6163f78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-141820f3-301f-494f-b58a-fab6b06310e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-08ecf10b-0909-42c1-91ae-5573db638fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-04004346-c38f-42f5-b797-b4a60f84a657,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-77488620-6f95-4125-8187-bc7258bfd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-c44dc85f-188a-4a94-8209-98823f40e0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-fab1321d-0af4-4bbc-9075-92fbea58ef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-5d4a9618-4868-44f9-88fd-8c55c3a684fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921287091-172.17.0.12-1596938916796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-404036db-0d0c-426e-9bf7-7cc6163f78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-141820f3-301f-494f-b58a-fab6b06310e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-08ecf10b-0909-42c1-91ae-5573db638fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-04004346-c38f-42f5-b797-b4a60f84a657,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-77488620-6f95-4125-8187-bc7258bfd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-c44dc85f-188a-4a94-8209-98823f40e0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-fab1321d-0af4-4bbc-9075-92fbea58ef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-5d4a9618-4868-44f9-88fd-8c55c3a684fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323685036-172.17.0.12-1596939239213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-c0714587-4ffc-493a-b64c-055c776c1bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-00538656-3825-492a-b29d-7897e407d745,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-4aab87e2-15e3-429f-8d80-5563051d9200,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-dc254d8c-8e04-43a8-8eb0-45d157ced668,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-172ff75b-5607-4da0-bece-00b186cb1671,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5a673ba2-bedf-4b68-aba5-78c157419288,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-512382cb-7a09-43a0-9446-9624413cd0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-4afb211d-647d-4590-9c12-1ec187ed8e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323685036-172.17.0.12-1596939239213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-c0714587-4ffc-493a-b64c-055c776c1bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-00538656-3825-492a-b29d-7897e407d745,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-4aab87e2-15e3-429f-8d80-5563051d9200,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-dc254d8c-8e04-43a8-8eb0-45d157ced668,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-172ff75b-5607-4da0-bece-00b186cb1671,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5a673ba2-bedf-4b68-aba5-78c157419288,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-512382cb-7a09-43a0-9446-9624413cd0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-4afb211d-647d-4590-9c12-1ec187ed8e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302884157-172.17.0.12-1596939280413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-04d26ccd-a8d2-4b8c-934d-957c37f9eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-d4e9955d-b8d7-4d0e-a35e-5d4fba349afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-290ad9b6-46f4-4828-bda5-a9512ccc35f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-886ecd1c-be6a-4e6a-94f3-7f95a9ee25f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-7baf3d78-3a2c-466c-bb24-d846f2e8cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-c13d40ee-4354-4951-bb19-106e07180230,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-5bed22a7-ca55-4418-ab36-fd59f3d86aed,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d29d6187-173c-4902-8761-c1dfbc88a986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302884157-172.17.0.12-1596939280413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-04d26ccd-a8d2-4b8c-934d-957c37f9eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-d4e9955d-b8d7-4d0e-a35e-5d4fba349afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-290ad9b6-46f4-4828-bda5-a9512ccc35f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-886ecd1c-be6a-4e6a-94f3-7f95a9ee25f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-7baf3d78-3a2c-466c-bb24-d846f2e8cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-c13d40ee-4354-4951-bb19-106e07180230,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-5bed22a7-ca55-4418-ab36-fd59f3d86aed,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d29d6187-173c-4902-8761-c1dfbc88a986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126731998-172.17.0.12-1596939527618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-26931ed6-6e82-49ba-8039-958152018e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-ef93ae2b-b746-4e0f-8d1d-f00b4bf6e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-ddeca095-f426-4edf-8a99-d31f6ed8e784,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-d87fbd00-d140-4705-b816-9f2652ba5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-d985aa51-2d09-4c99-9b45-603bc729f806,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-4990bd79-8e4b-4e86-bad0-c0860c118879,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-5fb973b4-c3df-4af9-9c0a-02532001d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-834aec94-f208-4f52-9b5f-8f0ca4248d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126731998-172.17.0.12-1596939527618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-26931ed6-6e82-49ba-8039-958152018e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-ef93ae2b-b746-4e0f-8d1d-f00b4bf6e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-ddeca095-f426-4edf-8a99-d31f6ed8e784,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-d87fbd00-d140-4705-b816-9f2652ba5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-d985aa51-2d09-4c99-9b45-603bc729f806,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-4990bd79-8e4b-4e86-bad0-c0860c118879,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-5fb973b4-c3df-4af9-9c0a-02532001d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-834aec94-f208-4f52-9b5f-8f0ca4248d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810497776-172.17.0.12-1596939563837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-c6ce42a8-d607-4797-a0a9-cf0e19da4b87,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-f0f205d6-6186-49fe-9cfb-58004f7c1c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-2a0d84f3-c8f2-4e91-8bf0-a3d67aa76925,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-fce699f3-e77e-43eb-9bc4-77bfde53428b,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-b22df825-47ff-4e11-bfe8-61860d3f9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-f8723190-1655-4bdc-bf34-3a550c2fb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-3c97457f-7fe1-438e-85f7-01f0ce08d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-d7683ba5-5842-4daa-8377-40d347c287a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810497776-172.17.0.12-1596939563837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-c6ce42a8-d607-4797-a0a9-cf0e19da4b87,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-f0f205d6-6186-49fe-9cfb-58004f7c1c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-2a0d84f3-c8f2-4e91-8bf0-a3d67aa76925,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-fce699f3-e77e-43eb-9bc4-77bfde53428b,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-b22df825-47ff-4e11-bfe8-61860d3f9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-f8723190-1655-4bdc-bf34-3a550c2fb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-3c97457f-7fe1-438e-85f7-01f0ce08d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-d7683ba5-5842-4daa-8377-40d347c287a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737820587-172.17.0.12-1596939626745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43609,DS-a97f9225-2315-437a-87ba-c70952b165d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-3b84641d-098d-419d-a5a6-400527795582,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-54a9a13e-35b6-46c6-aa1e-c0621bf0a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6b328d99-af8c-426f-ab4e-6d29259f1881,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-7c6f57a6-d30e-44be-92f3-7d72c9db3584,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-fa5856d3-efdd-4e3f-b17f-26f6c23bd9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-38024601-f4f5-443a-9570-dd0cd7550c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-42a72652-2c93-47ee-aac2-9b0957ab50a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737820587-172.17.0.12-1596939626745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43609,DS-a97f9225-2315-437a-87ba-c70952b165d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-3b84641d-098d-419d-a5a6-400527795582,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-54a9a13e-35b6-46c6-aa1e-c0621bf0a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6b328d99-af8c-426f-ab4e-6d29259f1881,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-7c6f57a6-d30e-44be-92f3-7d72c9db3584,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-fa5856d3-efdd-4e3f-b17f-26f6c23bd9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-38024601-f4f5-443a-9570-dd0cd7550c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-42a72652-2c93-47ee-aac2-9b0957ab50a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270843990-172.17.0.12-1596939762758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35964,DS-2b671e5d-05f2-4a96-b0f0-c25dce43c428,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-c6b35b2b-4a57-4cea-9a37-7acd07325cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-eb0bd255-4c47-4b91-b0a6-fd905f59337d,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-6b3a7dfc-bb76-4f5e-ac0f-280d741ce523,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-6a310e45-b0fb-45ea-80c1-9a99170b06d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-9f78935e-3ccd-4051-85d0-2962011eb2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-dc2cf324-da95-4cf1-b25d-84156289413f,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-a65ab021-fe3e-46cd-8ffb-f66c9f80bf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270843990-172.17.0.12-1596939762758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35964,DS-2b671e5d-05f2-4a96-b0f0-c25dce43c428,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-c6b35b2b-4a57-4cea-9a37-7acd07325cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-eb0bd255-4c47-4b91-b0a6-fd905f59337d,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-6b3a7dfc-bb76-4f5e-ac0f-280d741ce523,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-6a310e45-b0fb-45ea-80c1-9a99170b06d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-9f78935e-3ccd-4051-85d0-2962011eb2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-dc2cf324-da95-4cf1-b25d-84156289413f,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-a65ab021-fe3e-46cd-8ffb-f66c9f80bf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000548119-172.17.0.12-1596940220384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-5b4c20fc-1950-41e0-860d-91a8f6340d06,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-04e56283-e561-4cfa-93c2-6b0c670a510b,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-dbb3725a-cabf-4283-af37-2be077355036,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-9138c3db-4e7a-456c-a3b8-1ab5e00ae492,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-fd0d19f7-089f-4698-93e5-c779813df561,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-a4842d8a-9599-4e73-beeb-cf144bcd80a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-af8a28f8-af8c-41ef-88fa-adb5a9d487da,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-0c717b28-8d74-4a47-b1b5-ab53492f0527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2000548119-172.17.0.12-1596940220384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-5b4c20fc-1950-41e0-860d-91a8f6340d06,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-04e56283-e561-4cfa-93c2-6b0c670a510b,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-dbb3725a-cabf-4283-af37-2be077355036,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-9138c3db-4e7a-456c-a3b8-1ab5e00ae492,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-fd0d19f7-089f-4698-93e5-c779813df561,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-a4842d8a-9599-4e73-beeb-cf144bcd80a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-af8a28f8-af8c-41ef-88fa-adb5a9d487da,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-0c717b28-8d74-4a47-b1b5-ab53492f0527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204461932-172.17.0.12-1596940717069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-70adc784-391a-437a-85cd-2140d4b01431,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-3315508b-4e83-43ef-b79e-59306e3be946,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-9d6fd1ea-f150-4661-a32a-467fcfe6455e,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-6ec974de-2900-49e8-961e-11dd729e5edc,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-6dceba18-d1b4-42b5-b767-a3c9df8567c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-91b4787c-de9a-49f2-9397-b8460bc50566,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-79762dc8-30c1-4b31-a823-737cd04bd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-042d441a-d475-478d-9a2d-4faa44cbd7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204461932-172.17.0.12-1596940717069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-70adc784-391a-437a-85cd-2140d4b01431,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-3315508b-4e83-43ef-b79e-59306e3be946,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-9d6fd1ea-f150-4661-a32a-467fcfe6455e,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-6ec974de-2900-49e8-961e-11dd729e5edc,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-6dceba18-d1b4-42b5-b767-a3c9df8567c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-91b4787c-de9a-49f2-9397-b8460bc50566,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-79762dc8-30c1-4b31-a823-737cd04bd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-042d441a-d475-478d-9a2d-4faa44cbd7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308263658-172.17.0.12-1596941189632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-0b39f3fc-a660-489d-9d63-061ca06fed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-af624ec4-edf4-4d0c-89c8-7cdf6e2704bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-90e16a83-1d29-4cfb-a2a2-4720766fa515,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-e18ecf73-7a71-4a3d-9a4f-7eda368c1c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-189fa941-a73d-46b0-8e1e-3125474593de,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-bfdb9f49-40b1-463b-b50e-74ff5a7d22fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-ef10346c-f0a7-4898-8a95-23383876bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-f583114d-9714-4e23-aff7-a9ee60129e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308263658-172.17.0.12-1596941189632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-0b39f3fc-a660-489d-9d63-061ca06fed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-af624ec4-edf4-4d0c-89c8-7cdf6e2704bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-90e16a83-1d29-4cfb-a2a2-4720766fa515,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-e18ecf73-7a71-4a3d-9a4f-7eda368c1c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-189fa941-a73d-46b0-8e1e-3125474593de,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-bfdb9f49-40b1-463b-b50e-74ff5a7d22fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-ef10346c-f0a7-4898-8a95-23383876bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-f583114d-9714-4e23-aff7-a9ee60129e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472642684-172.17.0.12-1596941546960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-a573a7b3-f1ca-41c5-9630-862b93631dec,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-bd5d0619-97a6-42c9-bb83-dc99131c21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-9908e18a-16e1-4e9a-9dea-c20b5371e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-e5414868-f993-46e4-923c-6d58dae6c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-356de786-b54a-4986-87d0-c8059ace2b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-7c16ee2a-cc70-4558-b86e-f55d66072e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-24ab815e-71ac-4c59-b41d-26d02afbcb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-cc3feba4-f49f-4c32-b7ca-a3022a221aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472642684-172.17.0.12-1596941546960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-a573a7b3-f1ca-41c5-9630-862b93631dec,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-bd5d0619-97a6-42c9-bb83-dc99131c21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-9908e18a-16e1-4e9a-9dea-c20b5371e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-e5414868-f993-46e4-923c-6d58dae6c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-356de786-b54a-4986-87d0-c8059ace2b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-7c16ee2a-cc70-4558-b86e-f55d66072e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-24ab815e-71ac-4c59-b41d-26d02afbcb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-cc3feba4-f49f-4c32-b7ca-a3022a221aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051081352-172.17.0.12-1596941580962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34132,DS-2a7ada24-b576-4fd7-bbd5-b4ca073ae1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-7c93991c-0a16-486e-8644-2ae1b778c69a,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-5c4bbd38-b2ac-4c53-aec1-6bb767a7a511,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-ce0a902e-d866-469d-9fdb-018b42eec744,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-ac3d91d1-946d-4b84-8bc7-84422281b146,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-7b8e371a-32f8-41f3-91bd-baf7162bb9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-cfee24f9-7560-4669-b007-72fb284f98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-30e43cc5-69be-4887-82de-926f653c1b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051081352-172.17.0.12-1596941580962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34132,DS-2a7ada24-b576-4fd7-bbd5-b4ca073ae1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-7c93991c-0a16-486e-8644-2ae1b778c69a,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-5c4bbd38-b2ac-4c53-aec1-6bb767a7a511,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-ce0a902e-d866-469d-9fdb-018b42eec744,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-ac3d91d1-946d-4b84-8bc7-84422281b146,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-7b8e371a-32f8-41f3-91bd-baf7162bb9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-cfee24f9-7560-4669-b007-72fb284f98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-30e43cc5-69be-4887-82de-926f653c1b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5291
