reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080997698-172.17.0.9-1595330355897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46575,DS-066aeb3c-1c84-46f5-8283-5a0ecb214caa,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-5b64151c-c27f-4db4-8aec-48fa08e25e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-5c0b4e87-6ac1-4ebd-8b15-85ce31ce038e,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-29cbf777-7196-4f96-a2c7-bc0a973d1003,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-40fe38c7-6adf-4712-b38f-c6961db16b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-d76cc89d-bbb4-4ea1-acee-c12a2270ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-7c187f98-d223-45a4-bd0e-5db6c00fdd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-6cee446d-7d80-4c4a-9745-19971570664b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080997698-172.17.0.9-1595330355897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46575,DS-066aeb3c-1c84-46f5-8283-5a0ecb214caa,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-5b64151c-c27f-4db4-8aec-48fa08e25e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-5c0b4e87-6ac1-4ebd-8b15-85ce31ce038e,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-29cbf777-7196-4f96-a2c7-bc0a973d1003,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-40fe38c7-6adf-4712-b38f-c6961db16b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-d76cc89d-bbb4-4ea1-acee-c12a2270ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-7c187f98-d223-45a4-bd0e-5db6c00fdd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-6cee446d-7d80-4c4a-9745-19971570664b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737415376-172.17.0.9-1595330403003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-9443b43d-75fa-4567-bee7-4c9e3f4a5e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-0ec59c46-9aab-45fe-b689-4eab5e25825d,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-71be7e39-1e9b-43d9-a1d9-05a0a3803cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-abca6a25-eff5-464c-b39e-bcf0ccb26421,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-919fceff-aa49-49c9-9e94-3e36628d6345,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-7e81bd75-3f08-4a78-9e0a-3071a79dd2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-5c93f1a2-c9e6-4bb0-8a30-5295c7659338,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-ed3955c4-cb5b-4143-b847-bd6d168f71df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737415376-172.17.0.9-1595330403003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-9443b43d-75fa-4567-bee7-4c9e3f4a5e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-0ec59c46-9aab-45fe-b689-4eab5e25825d,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-71be7e39-1e9b-43d9-a1d9-05a0a3803cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-abca6a25-eff5-464c-b39e-bcf0ccb26421,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-919fceff-aa49-49c9-9e94-3e36628d6345,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-7e81bd75-3f08-4a78-9e0a-3071a79dd2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-5c93f1a2-c9e6-4bb0-8a30-5295c7659338,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-ed3955c4-cb5b-4143-b847-bd6d168f71df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652827514-172.17.0.9-1595331118205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-0053c57e-bdd7-4160-867d-56340b0fb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-24b2af1f-0cbe-4f64-acf2-5715cff85a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-2aa4d729-bd9b-4b1c-91b6-c8dd267e1014,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-48d69d9d-6008-476a-b018-eced3e092881,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-bc487157-ba2d-4d41-84f0-086f5f2d441c,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-a32ec930-a884-438a-a5a1-6cc211928a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-d954978a-64c0-43db-8e22-dcb3d4acdece,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d31f8438-b42b-4232-baa3-6a9fcb17f2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652827514-172.17.0.9-1595331118205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-0053c57e-bdd7-4160-867d-56340b0fb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-24b2af1f-0cbe-4f64-acf2-5715cff85a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-2aa4d729-bd9b-4b1c-91b6-c8dd267e1014,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-48d69d9d-6008-476a-b018-eced3e092881,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-bc487157-ba2d-4d41-84f0-086f5f2d441c,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-a32ec930-a884-438a-a5a1-6cc211928a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-d954978a-64c0-43db-8e22-dcb3d4acdece,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d31f8438-b42b-4232-baa3-6a9fcb17f2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19466313-172.17.0.9-1595331162764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-4c0ca457-4f38-478c-974a-70f1d03cae39,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-0e6928aa-90b2-429d-b5ff-f8f72eafed69,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-40d739bb-51fa-4998-afa8-57805bd7b507,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-1ce4efad-1236-4d6a-89b2-5e8f6e4e744f,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-b7244864-0121-431c-abb3-9f4eafb0ca9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f64241ec-00bd-432d-b8ca-a1e8b14c91c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-a1c15f77-9438-4241-bb16-2d3dba0d1cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-74f4ce7f-51f8-4dec-9bcc-986204a8eb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19466313-172.17.0.9-1595331162764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-4c0ca457-4f38-478c-974a-70f1d03cae39,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-0e6928aa-90b2-429d-b5ff-f8f72eafed69,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-40d739bb-51fa-4998-afa8-57805bd7b507,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-1ce4efad-1236-4d6a-89b2-5e8f6e4e744f,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-b7244864-0121-431c-abb3-9f4eafb0ca9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f64241ec-00bd-432d-b8ca-a1e8b14c91c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-a1c15f77-9438-4241-bb16-2d3dba0d1cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-74f4ce7f-51f8-4dec-9bcc-986204a8eb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466979671-172.17.0.9-1595331324669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-07c14713-7e70-48a2-9713-cee2ef336a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-0e74c6a1-5351-4bc9-9abb-83e725706d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-33aa83a5-b32b-431b-99aa-41affea25c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-fb3afeb5-7def-41fa-b0a4-b73c1ef93e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-af394c51-b772-4844-9fe4-bad6653714c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-4c91d3d6-77f8-4b74-9311-5df6450bb902,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-0c8ecb2d-f677-40a1-98df-5acb180b0e01,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-3dac52c0-9d32-4f5e-bcb7-0336df44c67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466979671-172.17.0.9-1595331324669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-07c14713-7e70-48a2-9713-cee2ef336a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-0e74c6a1-5351-4bc9-9abb-83e725706d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-33aa83a5-b32b-431b-99aa-41affea25c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-fb3afeb5-7def-41fa-b0a4-b73c1ef93e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-af394c51-b772-4844-9fe4-bad6653714c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-4c91d3d6-77f8-4b74-9311-5df6450bb902,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-0c8ecb2d-f677-40a1-98df-5acb180b0e01,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-3dac52c0-9d32-4f5e-bcb7-0336df44c67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531812246-172.17.0.9-1595331452769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-7a8f3216-f295-40af-a0cd-d316cd476a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-9d73141e-e921-4811-adea-47bba45cf360,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-82b39a14-b87f-4b18-9025-52ce22edcd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-d62c6730-10bb-4b18-9758-f0f5dcd76a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-b6a77e04-dc71-4c31-b07a-5befabfc8415,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-b83b363e-4262-42e8-87f9-313223dac950,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-afc26c7b-7d28-4485-9b5b-feb2490a51ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-9348a7c3-c5a2-47b9-b99e-c809d85d0fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531812246-172.17.0.9-1595331452769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-7a8f3216-f295-40af-a0cd-d316cd476a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-9d73141e-e921-4811-adea-47bba45cf360,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-82b39a14-b87f-4b18-9025-52ce22edcd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-d62c6730-10bb-4b18-9758-f0f5dcd76a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-b6a77e04-dc71-4c31-b07a-5befabfc8415,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-b83b363e-4262-42e8-87f9-313223dac950,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-afc26c7b-7d28-4485-9b5b-feb2490a51ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-9348a7c3-c5a2-47b9-b99e-c809d85d0fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534200844-172.17.0.9-1595331630100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38896,DS-b13b9c40-7b9b-4f0b-8bd3-64ddc9a6b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-ba04b54a-0164-464d-a8c3-d4af64f8b0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-aafab9d2-c663-43a8-8775-8c2305eb6efd,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-2336fddf-02ba-46cc-9cbf-1104505f19e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-3f51e17e-cd6f-41eb-8f82-30307cb932a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-b91af59f-30ff-4397-a180-56d21c3ca9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-abfb4455-6d8f-41c2-9e83-9d722db0dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-86184ae6-29d0-4b04-8b6f-36909c5abb70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534200844-172.17.0.9-1595331630100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38896,DS-b13b9c40-7b9b-4f0b-8bd3-64ddc9a6b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-ba04b54a-0164-464d-a8c3-d4af64f8b0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-aafab9d2-c663-43a8-8775-8c2305eb6efd,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-2336fddf-02ba-46cc-9cbf-1104505f19e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-3f51e17e-cd6f-41eb-8f82-30307cb932a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-b91af59f-30ff-4397-a180-56d21c3ca9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-abfb4455-6d8f-41c2-9e83-9d722db0dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-86184ae6-29d0-4b04-8b6f-36909c5abb70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403369925-172.17.0.9-1595332221775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33092,DS-c7c3264a-ce5b-4d7a-a5f8-0e4527b84f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-29655712-ed07-425b-be73-485db30d5ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-687b3b68-984d-4fe7-a95b-2b5f11cb4411,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-cc20d127-ab5e-48e2-becf-2f8d4b2e85f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-36885510-240f-4206-8645-947742c9c257,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-85f59ec4-efb9-4859-917c-557f980182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-471a9bdf-1878-4fb2-acdb-cf1171abd0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-07606a2c-18c9-494c-ba4e-e216a8778011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403369925-172.17.0.9-1595332221775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33092,DS-c7c3264a-ce5b-4d7a-a5f8-0e4527b84f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-29655712-ed07-425b-be73-485db30d5ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-687b3b68-984d-4fe7-a95b-2b5f11cb4411,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-cc20d127-ab5e-48e2-becf-2f8d4b2e85f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-36885510-240f-4206-8645-947742c9c257,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-85f59ec4-efb9-4859-917c-557f980182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-471a9bdf-1878-4fb2-acdb-cf1171abd0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-07606a2c-18c9-494c-ba4e-e216a8778011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334410903-172.17.0.9-1595332551887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46156,DS-9f48f6e4-a35a-4057-9bec-7d5215215ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-adeb0815-0e19-4d87-b3c1-1330145cea28,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-957a08ff-e88f-438f-900f-c1fa832aaf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-1c82c36c-e209-4bc2-bbcc-211992e14add,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-482173cf-8493-41b0-9a83-16c791611cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-1d13531a-b5e9-41b3-bece-d49266f049bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-d8894757-a033-408b-b755-6ae1290b3796,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-14680d06-a2da-4330-a2a7-d87cf92bd3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334410903-172.17.0.9-1595332551887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46156,DS-9f48f6e4-a35a-4057-9bec-7d5215215ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-adeb0815-0e19-4d87-b3c1-1330145cea28,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-957a08ff-e88f-438f-900f-c1fa832aaf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-1c82c36c-e209-4bc2-bbcc-211992e14add,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-482173cf-8493-41b0-9a83-16c791611cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-1d13531a-b5e9-41b3-bece-d49266f049bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-d8894757-a033-408b-b755-6ae1290b3796,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-14680d06-a2da-4330-a2a7-d87cf92bd3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943472884-172.17.0.9-1595332735508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-0c53c014-7979-442c-a966-9475dd0a877a,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-72fbf106-9130-4706-9dc6-1af8bcd9789b,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-835d295f-11c7-4d1e-8fc9-54063b3fe39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-4494db8e-2295-47dd-99c5-473c7e156ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-a91a8414-57ca-496d-82d9-9666974658a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-835d9a1b-3354-4c50-bee2-919eb48194cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a951c4d8-eb3f-4ca7-b3f9-b6b0473a682d,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-1049b55b-b87b-4a12-8a87-32034d34a642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943472884-172.17.0.9-1595332735508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-0c53c014-7979-442c-a966-9475dd0a877a,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-72fbf106-9130-4706-9dc6-1af8bcd9789b,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-835d295f-11c7-4d1e-8fc9-54063b3fe39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-4494db8e-2295-47dd-99c5-473c7e156ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-a91a8414-57ca-496d-82d9-9666974658a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-835d9a1b-3354-4c50-bee2-919eb48194cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a951c4d8-eb3f-4ca7-b3f9-b6b0473a682d,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-1049b55b-b87b-4a12-8a87-32034d34a642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668058599-172.17.0.9-1595332921646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-4562dce4-c622-439a-a50b-b176353a93da,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-78d5f8ec-fe20-4c6e-a78c-036e14b83a68,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-8db00c75-369d-41be-a7a4-d6fc840ee5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-a6fb0012-118c-4a68-b896-42ea65fd6ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-057fcda1-93b7-4883-b112-6abc5fa65bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-891d856a-4e84-4bcf-84ce-214a0aebb324,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-dd65c391-8a95-4878-b52e-bd17cc27832b,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-6bf98c85-3bd4-48a4-a2ad-df86fabee324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668058599-172.17.0.9-1595332921646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-4562dce4-c622-439a-a50b-b176353a93da,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-78d5f8ec-fe20-4c6e-a78c-036e14b83a68,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-8db00c75-369d-41be-a7a4-d6fc840ee5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-a6fb0012-118c-4a68-b896-42ea65fd6ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-057fcda1-93b7-4883-b112-6abc5fa65bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-891d856a-4e84-4bcf-84ce-214a0aebb324,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-dd65c391-8a95-4878-b52e-bd17cc27832b,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-6bf98c85-3bd4-48a4-a2ad-df86fabee324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690597107-172.17.0.9-1595333483558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-a282078a-8211-442f-93e5-c1948d959e55,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-ac40a483-1d99-402a-8acb-d27a94dd0ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-b8dec96f-9f4a-43ca-8d51-ee8a96770b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-286a4bc2-91c4-43be-8425-8a51dc814e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-916ed13a-68f8-469e-b1eb-c05613febc52,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-8fa883d5-5473-4831-85b5-e1edb163ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-bb21c6c5-1beb-4aef-ace3-25c7f747aa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-e116013d-48df-4fee-a74d-d135fb47a864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690597107-172.17.0.9-1595333483558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-a282078a-8211-442f-93e5-c1948d959e55,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-ac40a483-1d99-402a-8acb-d27a94dd0ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-b8dec96f-9f4a-43ca-8d51-ee8a96770b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-286a4bc2-91c4-43be-8425-8a51dc814e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-916ed13a-68f8-469e-b1eb-c05613febc52,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-8fa883d5-5473-4831-85b5-e1edb163ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-bb21c6c5-1beb-4aef-ace3-25c7f747aa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-e116013d-48df-4fee-a74d-d135fb47a864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516831074-172.17.0.9-1595333521837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-85f75b1b-a998-44d0-91ec-bdd07b057a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-26ee9ca8-f697-407c-a72e-3304fe4bb9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-75af5716-b111-440e-8cfe-580972deeb98,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-3df090aa-82be-4ca7-9cac-ef0f15244090,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-0497d44d-4dbe-41ee-8552-18d635176ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-511d5f28-8a57-4838-b145-0682376da584,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-6d394e24-4590-468a-80ff-8f0a16cb656c,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-2f7fbba1-3dce-4fd8-b3b1-052d6129ddb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516831074-172.17.0.9-1595333521837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-85f75b1b-a998-44d0-91ec-bdd07b057a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-26ee9ca8-f697-407c-a72e-3304fe4bb9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-75af5716-b111-440e-8cfe-580972deeb98,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-3df090aa-82be-4ca7-9cac-ef0f15244090,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-0497d44d-4dbe-41ee-8552-18d635176ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-511d5f28-8a57-4838-b145-0682376da584,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-6d394e24-4590-468a-80ff-8f0a16cb656c,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-2f7fbba1-3dce-4fd8-b3b1-052d6129ddb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337850692-172.17.0.9-1595333607161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-b31adf3e-9067-4106-96dc-00585ab1a759,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-d29b0b3f-676f-4009-9213-6e6ae6952c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-96d6720a-9fe0-40cf-95b4-8c32a21d8251,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a21aa4e0-5030-4fdf-af7b-aaa5ab198c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-bc28370c-25bb-4d92-ba02-9b576777a110,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-1fc7b4b8-ef6d-4870-bdd7-f7920201cbad,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-c2b09fc2-6cfa-4726-a869-7d2fb37f3f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a55c0ac3-a81f-4a0c-a22f-0111ffb2e950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337850692-172.17.0.9-1595333607161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-b31adf3e-9067-4106-96dc-00585ab1a759,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-d29b0b3f-676f-4009-9213-6e6ae6952c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-96d6720a-9fe0-40cf-95b4-8c32a21d8251,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a21aa4e0-5030-4fdf-af7b-aaa5ab198c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-bc28370c-25bb-4d92-ba02-9b576777a110,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-1fc7b4b8-ef6d-4870-bdd7-f7920201cbad,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-c2b09fc2-6cfa-4726-a869-7d2fb37f3f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a55c0ac3-a81f-4a0c-a22f-0111ffb2e950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636639716-172.17.0.9-1595334673265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-0599bfc2-0043-4f95-826a-ea369c71d153,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-46aec969-cf71-498f-8d2d-f526cfc479d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-8d0d4262-05eb-464a-9bca-f8a5d51c73df,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-92fcc838-f45c-4230-9577-258e79df06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-31a7c62b-486f-4aa3-a421-db6f16d7d0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ec54557b-76c4-442e-9ec0-0025e5b24841,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-9d128366-62b6-490f-bb50-0126fde5f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-bb4d4c4a-d7db-4242-b3fb-897b5307491e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636639716-172.17.0.9-1595334673265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-0599bfc2-0043-4f95-826a-ea369c71d153,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-46aec969-cf71-498f-8d2d-f526cfc479d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-8d0d4262-05eb-464a-9bca-f8a5d51c73df,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-92fcc838-f45c-4230-9577-258e79df06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-31a7c62b-486f-4aa3-a421-db6f16d7d0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ec54557b-76c4-442e-9ec0-0025e5b24841,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-9d128366-62b6-490f-bb50-0126fde5f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-bb4d4c4a-d7db-4242-b3fb-897b5307491e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185213924-172.17.0.9-1595334789698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-caa5d36b-8a5b-46b3-aac4-abf87e703271,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-c46201ff-f370-4831-9ed1-1f07d50af6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-104acfb9-2543-4df1-a55b-b73ddfd62de7,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-565a8992-ce4c-431e-9e55-f56c707ff933,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-26fe3c85-d297-422d-b150-dea6699b9017,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-4ed3fa03-2a5d-440f-af9a-26315efd9e33,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-aff858b4-95bc-4357-980e-4d57a4889bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-27eb06f4-6743-471f-aeb8-8471000ee301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185213924-172.17.0.9-1595334789698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-caa5d36b-8a5b-46b3-aac4-abf87e703271,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-c46201ff-f370-4831-9ed1-1f07d50af6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-104acfb9-2543-4df1-a55b-b73ddfd62de7,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-565a8992-ce4c-431e-9e55-f56c707ff933,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-26fe3c85-d297-422d-b150-dea6699b9017,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-4ed3fa03-2a5d-440f-af9a-26315efd9e33,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-aff858b4-95bc-4357-980e-4d57a4889bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-27eb06f4-6743-471f-aeb8-8471000ee301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133710989-172.17.0.9-1595334832719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-d1e383a1-0fc6-4380-ad1c-a8eb8900e9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-387a0591-6e37-44d7-a15f-a9a649e17305,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-9541f911-20d8-4b23-96d9-4631cdb35179,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-7a7b38cf-395a-421a-93d3-d100cacd9d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-f7f58060-203d-4c37-873b-1516ec36f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-3f2a26a1-1b79-469a-8e7a-bec73923e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-0feab719-fea1-41ee-a59d-add0375cde1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-9dd29598-829f-4c77-9ebb-3865873bf1df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133710989-172.17.0.9-1595334832719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-d1e383a1-0fc6-4380-ad1c-a8eb8900e9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-387a0591-6e37-44d7-a15f-a9a649e17305,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-9541f911-20d8-4b23-96d9-4631cdb35179,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-7a7b38cf-395a-421a-93d3-d100cacd9d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-f7f58060-203d-4c37-873b-1516ec36f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-3f2a26a1-1b79-469a-8e7a-bec73923e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-0feab719-fea1-41ee-a59d-add0375cde1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-9dd29598-829f-4c77-9ebb-3865873bf1df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479942668-172.17.0.9-1595335068282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-ed49d368-aa00-43f4-9b49-df540a1a25ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-43e69cbc-fadd-4fcc-8358-d3631892acb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-80beda4b-f3b6-48a1-a441-2f6eaa896f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-a98bbeb5-c9e3-4675-877d-8c9e1c40ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-6f253dae-1392-498c-bc3d-e37895f0fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-87483bd2-8206-440f-9adf-90611bfb2cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-a8028b07-eef9-4cf3-a299-c68940e26495,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-71208948-f482-4c10-b6bd-6db3f4db0253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479942668-172.17.0.9-1595335068282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-ed49d368-aa00-43f4-9b49-df540a1a25ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-43e69cbc-fadd-4fcc-8358-d3631892acb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-80beda4b-f3b6-48a1-a441-2f6eaa896f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-a98bbeb5-c9e3-4675-877d-8c9e1c40ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-6f253dae-1392-498c-bc3d-e37895f0fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-87483bd2-8206-440f-9adf-90611bfb2cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-a8028b07-eef9-4cf3-a299-c68940e26495,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-71208948-f482-4c10-b6bd-6db3f4db0253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157878838-172.17.0.9-1595335108822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46388,DS-8381849d-d8be-4333-8a74-b36630592394,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-492efcdf-25c9-4117-92c3-111893714770,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-5d23db49-13a2-4fde-952b-e9ad4cb878fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-4a3b05b6-6d76-46be-8aa8-486f75eeebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-a61db9e6-28da-48ce-93d9-c927d0bbc29f,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-bfeea6af-962a-46b9-99e5-49dfaec2021a,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-0a0f0d54-a226-487c-bd83-8029a9f5ff16,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-d1d44ba8-5bc5-4a23-929a-0e0867c15ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157878838-172.17.0.9-1595335108822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46388,DS-8381849d-d8be-4333-8a74-b36630592394,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-492efcdf-25c9-4117-92c3-111893714770,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-5d23db49-13a2-4fde-952b-e9ad4cb878fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-4a3b05b6-6d76-46be-8aa8-486f75eeebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-a61db9e6-28da-48ce-93d9-c927d0bbc29f,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-bfeea6af-962a-46b9-99e5-49dfaec2021a,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-0a0f0d54-a226-487c-bd83-8029a9f5ff16,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-d1d44ba8-5bc5-4a23-929a-0e0867c15ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987959145-172.17.0.9-1595335234666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-a3a72ccd-90b3-470a-8c6e-d748b5f85a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-3cba3e0a-095d-4cb1-b6d3-352bb55e2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-3cd642dd-6157-4cc0-a3ff-c943ed66255a,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-7689d006-ca12-4d0b-9dcd-ccdb5f0d2301,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-d34df306-1533-4a4e-a7d6-cdc1dab71676,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-406f6183-8474-49e8-b9b2-6a6286883f20,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-6bae5e99-a0a0-49ca-bbb1-1da421b5e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-95b021ef-e5c2-4c25-8f08-f85800a45353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987959145-172.17.0.9-1595335234666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-a3a72ccd-90b3-470a-8c6e-d748b5f85a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-3cba3e0a-095d-4cb1-b6d3-352bb55e2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-3cd642dd-6157-4cc0-a3ff-c943ed66255a,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-7689d006-ca12-4d0b-9dcd-ccdb5f0d2301,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-d34df306-1533-4a4e-a7d6-cdc1dab71676,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-406f6183-8474-49e8-b9b2-6a6286883f20,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-6bae5e99-a0a0-49ca-bbb1-1da421b5e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-95b021ef-e5c2-4c25-8f08-f85800a45353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141767458-172.17.0.9-1595335798713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-c4c7d18c-ddcc-4f47-8c35-3f4fa80896a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-8ebda3d6-c125-460f-91d1-76b234dd9b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-bdd52c46-27f0-4fb5-bd2f-48d1e3b264ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-0e2996b3-32aa-40d9-bc14-2c4852a03d54,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-8df64528-7d64-45f9-a54a-c3197a3cf8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-3547f601-b221-4b2c-b0d4-8a4921e98d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-f40b272a-5b0f-4546-a8a3-fcefdbcd9411,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-6ec048c6-8525-4747-9ebd-53d1dda75844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141767458-172.17.0.9-1595335798713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-c4c7d18c-ddcc-4f47-8c35-3f4fa80896a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-8ebda3d6-c125-460f-91d1-76b234dd9b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-bdd52c46-27f0-4fb5-bd2f-48d1e3b264ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-0e2996b3-32aa-40d9-bc14-2c4852a03d54,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-8df64528-7d64-45f9-a54a-c3197a3cf8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-3547f601-b221-4b2c-b0d4-8a4921e98d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-f40b272a-5b0f-4546-a8a3-fcefdbcd9411,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-6ec048c6-8525-4747-9ebd-53d1dda75844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367004698-172.17.0.9-1595335884112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-6b4b57a2-abf3-435b-a844-a4ad99070ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-a7470272-23b6-483d-a85f-5b69d95e41de,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-17162232-0811-4b93-aaaf-11c7a52d2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-26c2d569-8bc1-42f7-bc2c-5158e58c4257,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-c8a5892d-a6b7-400e-98c6-21c27f229988,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-b0a6a9f4-679e-412a-b1bb-9a21d584e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-a041ee9b-4d31-4d1a-a47d-08651a8210a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-b80b1bef-83d6-461b-9cfe-34b64f0bd18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367004698-172.17.0.9-1595335884112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-6b4b57a2-abf3-435b-a844-a4ad99070ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-a7470272-23b6-483d-a85f-5b69d95e41de,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-17162232-0811-4b93-aaaf-11c7a52d2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-26c2d569-8bc1-42f7-bc2c-5158e58c4257,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-c8a5892d-a6b7-400e-98c6-21c27f229988,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-b0a6a9f4-679e-412a-b1bb-9a21d584e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-a041ee9b-4d31-4d1a-a47d-08651a8210a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-b80b1bef-83d6-461b-9cfe-34b64f0bd18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283854773-172.17.0.9-1595336240821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40174,DS-d79c449c-fdf8-4c49-a238-1dac42f022e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-bd48bb92-1551-4f9a-94ea-f7fecb5c5d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-b19b60ca-7471-419f-a06b-50a4d13d4487,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-be7d8530-8c28-434d-9b79-2d40614205be,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-683071d0-74c9-4fcd-ba30-e67002c8218a,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-aad2e540-e4e1-4800-8bf4-2237355cbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-aa9d097b-698d-4186-b9d5-4d58b74565cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-8230a222-45d0-4a76-9063-dd2081d0ef2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283854773-172.17.0.9-1595336240821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40174,DS-d79c449c-fdf8-4c49-a238-1dac42f022e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-bd48bb92-1551-4f9a-94ea-f7fecb5c5d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-b19b60ca-7471-419f-a06b-50a4d13d4487,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-be7d8530-8c28-434d-9b79-2d40614205be,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-683071d0-74c9-4fcd-ba30-e67002c8218a,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-aad2e540-e4e1-4800-8bf4-2237355cbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-aa9d097b-698d-4186-b9d5-4d58b74565cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-8230a222-45d0-4a76-9063-dd2081d0ef2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028961918-172.17.0.9-1595336282977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-feeeb6de-0708-4dae-98f7-976bd35d9059,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-36477770-e735-489e-be13-a893a2f6c820,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-996ae6c2-c8e7-46b8-a5f3-1d12087415a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-5696efc2-c8c7-4b98-8695-21b3fdb7e484,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-5fb52ee8-7f10-42e8-9807-e85d620cddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-f27a2d36-4e12-40d8-9551-46a9abb306e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-2f00b921-ad19-461d-accc-2990ce218249,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-9287da03-1fc4-4a8b-9982-91b7a5800a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028961918-172.17.0.9-1595336282977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-feeeb6de-0708-4dae-98f7-976bd35d9059,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-36477770-e735-489e-be13-a893a2f6c820,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-996ae6c2-c8e7-46b8-a5f3-1d12087415a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-5696efc2-c8c7-4b98-8695-21b3fdb7e484,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-5fb52ee8-7f10-42e8-9807-e85d620cddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-f27a2d36-4e12-40d8-9551-46a9abb306e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-2f00b921-ad19-461d-accc-2990ce218249,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-9287da03-1fc4-4a8b-9982-91b7a5800a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6273
