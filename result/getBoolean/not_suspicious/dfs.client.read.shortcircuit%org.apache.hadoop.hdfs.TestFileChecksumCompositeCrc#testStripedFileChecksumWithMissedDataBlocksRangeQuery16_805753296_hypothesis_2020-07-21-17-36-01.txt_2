reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241594877-172.17.0.2-1595353068360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-a3950a71-faab-4a95-a546-e45e40f728a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-216c0613-10f6-4af3-9e22-f54764aaaffa,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-aa04e7fe-1de0-4615-a886-2f39c27542a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-b3efc66c-6d55-442e-aa6e-19f129d316fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-e8c04988-f941-4651-ade8-e88ce7c5d63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-c05f208c-11b8-4da9-ba9c-ed1fe9238439,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-3a681a78-b901-4d2c-90ee-34f1f914cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-738a0edb-6fd0-4465-ac28-9c2ae5c16c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241594877-172.17.0.2-1595353068360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-a3950a71-faab-4a95-a546-e45e40f728a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-216c0613-10f6-4af3-9e22-f54764aaaffa,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-aa04e7fe-1de0-4615-a886-2f39c27542a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-b3efc66c-6d55-442e-aa6e-19f129d316fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-e8c04988-f941-4651-ade8-e88ce7c5d63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-c05f208c-11b8-4da9-ba9c-ed1fe9238439,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-3a681a78-b901-4d2c-90ee-34f1f914cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-738a0edb-6fd0-4465-ac28-9c2ae5c16c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082720771-172.17.0.2-1595353151374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36823,DS-7a3ce267-9f45-4281-ad25-a017326591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-2001fdf4-da8f-4362-b046-7e551c910aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-99c9fb52-1439-49c4-966d-4b0b4beed343,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-eab3861d-4157-4f5c-b167-710c17b90cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-bfa9d43c-6b8c-420c-87b4-c150a9da7773,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-4706f7fb-cbff-4740-a206-e821a04b0b58,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0062037a-e712-4f12-a1e6-2ed68423e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-30263cdb-ac45-4da0-b9a5-9d1c2848764f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082720771-172.17.0.2-1595353151374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36823,DS-7a3ce267-9f45-4281-ad25-a017326591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-2001fdf4-da8f-4362-b046-7e551c910aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-99c9fb52-1439-49c4-966d-4b0b4beed343,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-eab3861d-4157-4f5c-b167-710c17b90cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-bfa9d43c-6b8c-420c-87b4-c150a9da7773,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-4706f7fb-cbff-4740-a206-e821a04b0b58,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0062037a-e712-4f12-a1e6-2ed68423e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-30263cdb-ac45-4da0-b9a5-9d1c2848764f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255057520-172.17.0.2-1595353414588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-295480fd-7bc1-4a8d-952f-45d86dc3ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-fce425c4-ec8b-471f-a2d5-b9d0f0528251,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-bc018faa-5e07-4c0b-ade4-665d26bfdb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-e6b5c291-4eaf-4bcc-9c23-bea4326c70d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-832b170d-160c-4704-8a40-e9607193d8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-aeb620df-b0d2-401d-ae15-a9b557cfd575,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-c0cc1a50-92bc-4177-ba21-cbef2eb0dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-a917a6be-cfb5-4ad0-bfbd-5c55af81bfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255057520-172.17.0.2-1595353414588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-295480fd-7bc1-4a8d-952f-45d86dc3ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-fce425c4-ec8b-471f-a2d5-b9d0f0528251,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-bc018faa-5e07-4c0b-ade4-665d26bfdb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-e6b5c291-4eaf-4bcc-9c23-bea4326c70d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-832b170d-160c-4704-8a40-e9607193d8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-aeb620df-b0d2-401d-ae15-a9b557cfd575,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-c0cc1a50-92bc-4177-ba21-cbef2eb0dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-a917a6be-cfb5-4ad0-bfbd-5c55af81bfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124739755-172.17.0.2-1595354260627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-0cda1311-761d-4d7a-bc2c-a2785ddc8171,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-617ba3ed-1648-4b2a-a057-62c23b5f196d,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-e872da30-7c0b-4091-88f0-c9f7e5b3270b,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-8e56fc72-7dd0-432d-988a-ceead002835b,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-722e8204-af81-4d41-bb81-130fb7adf35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-6bdd35fe-955e-41ee-bf48-6a93890403c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-12ebeaa6-e180-4ce1-98b1-df733335cceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-a5ec9e0a-52ac-496d-947a-2c9e342a0be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124739755-172.17.0.2-1595354260627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-0cda1311-761d-4d7a-bc2c-a2785ddc8171,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-617ba3ed-1648-4b2a-a057-62c23b5f196d,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-e872da30-7c0b-4091-88f0-c9f7e5b3270b,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-8e56fc72-7dd0-432d-988a-ceead002835b,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-722e8204-af81-4d41-bb81-130fb7adf35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-6bdd35fe-955e-41ee-bf48-6a93890403c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-12ebeaa6-e180-4ce1-98b1-df733335cceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-a5ec9e0a-52ac-496d-947a-2c9e342a0be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643432480-172.17.0.2-1595355026068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43761,DS-869ad7a1-206e-4307-92f8-a802a1594877,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-a981a7ea-593f-4dfa-8084-8e9a19528863,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-f1ecc398-e047-4e1a-9726-1222b005699a,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-63a83ca4-ff92-4720-945c-ca694b0d5868,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-be95bb2c-c94e-4514-959f-58591bf9b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-5911f481-177a-46e8-83a6-569574538f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-a499e4a2-5089-4b3c-b929-8684780c36b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4067ddbc-0728-4256-9bd7-4a4b37e490e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643432480-172.17.0.2-1595355026068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43761,DS-869ad7a1-206e-4307-92f8-a802a1594877,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-a981a7ea-593f-4dfa-8084-8e9a19528863,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-f1ecc398-e047-4e1a-9726-1222b005699a,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-63a83ca4-ff92-4720-945c-ca694b0d5868,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-be95bb2c-c94e-4514-959f-58591bf9b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-5911f481-177a-46e8-83a6-569574538f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-a499e4a2-5089-4b3c-b929-8684780c36b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4067ddbc-0728-4256-9bd7-4a4b37e490e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761083591-172.17.0.2-1595355434396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-c2499f83-a56f-4658-9e8d-b500a1c0e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-ea5d1078-e97f-4810-adac-2d0264a4d641,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-869e3c55-f669-4a88-bc61-06500356699d,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-03193bd0-e5b6-473f-826c-f45fdead1d82,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-6ef739b6-f753-45c7-b2dc-e054de887f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-f629ec8e-351e-4b91-b497-3d7501eb52fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-60d7fc49-5e5f-4060-9338-a0eabcf2864f,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-5666510a-79d7-42d4-95a5-1023e43e3840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761083591-172.17.0.2-1595355434396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-c2499f83-a56f-4658-9e8d-b500a1c0e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-ea5d1078-e97f-4810-adac-2d0264a4d641,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-869e3c55-f669-4a88-bc61-06500356699d,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-03193bd0-e5b6-473f-826c-f45fdead1d82,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-6ef739b6-f753-45c7-b2dc-e054de887f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-f629ec8e-351e-4b91-b497-3d7501eb52fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-60d7fc49-5e5f-4060-9338-a0eabcf2864f,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-5666510a-79d7-42d4-95a5-1023e43e3840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727718779-172.17.0.2-1595356490616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38147,DS-fff2f696-fb8d-4cf9-b729-ee93582f395a,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-92e56d04-76de-4a65-9025-6c138829c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-24549885-9e49-44ab-904d-262a82a6bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-cea7410d-4990-4891-8590-ef9cd47c0556,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-2c7f61ea-f48c-49f9-abf0-d7c0072e6bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-3383f138-99b6-4e4c-8880-93f91d796dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-938cd4ca-7a86-4726-9b60-d8eb1c62b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-9f23115e-c9c7-40fe-be64-1d4f3af3ae00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727718779-172.17.0.2-1595356490616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38147,DS-fff2f696-fb8d-4cf9-b729-ee93582f395a,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-92e56d04-76de-4a65-9025-6c138829c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-24549885-9e49-44ab-904d-262a82a6bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-cea7410d-4990-4891-8590-ef9cd47c0556,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-2c7f61ea-f48c-49f9-abf0-d7c0072e6bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-3383f138-99b6-4e4c-8880-93f91d796dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-938cd4ca-7a86-4726-9b60-d8eb1c62b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-9f23115e-c9c7-40fe-be64-1d4f3af3ae00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881838822-172.17.0.2-1595356827147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36749,DS-e10e41c8-0e5d-4464-b160-7a7836e8d003,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-7d00c9fe-d67a-4b2c-b26e-bf4c383b5349,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-3225fc1e-8b62-43ce-a532-6a0b7492f85b,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-cff0ea8e-b0b2-410e-9b04-8e81e514551c,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cd0bb556-c17e-4d6b-8bf9-7066048494ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-6f00e7b4-675d-4fd3-beac-005082aaff98,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-2532f8d6-d9ce-445f-8b14-325df235d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-9cf1170b-10ff-4dc4-aa57-e90d87284446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881838822-172.17.0.2-1595356827147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36749,DS-e10e41c8-0e5d-4464-b160-7a7836e8d003,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-7d00c9fe-d67a-4b2c-b26e-bf4c383b5349,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-3225fc1e-8b62-43ce-a532-6a0b7492f85b,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-cff0ea8e-b0b2-410e-9b04-8e81e514551c,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cd0bb556-c17e-4d6b-8bf9-7066048494ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-6f00e7b4-675d-4fd3-beac-005082aaff98,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-2532f8d6-d9ce-445f-8b14-325df235d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-9cf1170b-10ff-4dc4-aa57-e90d87284446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492518765-172.17.0.2-1595357165407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-c5bf8aeb-58ca-4700-882f-9cd182aaa9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-5674da47-04b5-4177-a882-98d5798156c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-e41c4c09-666e-42cb-a9c0-794fd977b9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-963d4f93-b746-484d-8fac-0fef2a495198,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-fa0818a8-e5eb-457f-b4e2-e131876cc42f,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-65d119c4-330d-474e-9348-0cd98d89df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-7955e56b-ad5c-4c2c-8e05-c9614025ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-9e3f91bb-9589-44a2-acc4-8b5d0abc36f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492518765-172.17.0.2-1595357165407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-c5bf8aeb-58ca-4700-882f-9cd182aaa9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-5674da47-04b5-4177-a882-98d5798156c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-e41c4c09-666e-42cb-a9c0-794fd977b9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-963d4f93-b746-484d-8fac-0fef2a495198,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-fa0818a8-e5eb-457f-b4e2-e131876cc42f,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-65d119c4-330d-474e-9348-0cd98d89df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-7955e56b-ad5c-4c2c-8e05-c9614025ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-9e3f91bb-9589-44a2-acc4-8b5d0abc36f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10370030-172.17.0.2-1595357579014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32894,DS-9fa8df57-3d36-4c0d-b1cf-50ed2356a44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-5e16880b-646b-4939-9af4-0c78b51180bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b919c026-7dfb-4d3d-b6d1-126fce9988f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-81e06551-ac29-4e37-b295-ec78f455e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-7df211b4-2875-473a-8119-46372a4ee596,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-8c7a2b96-1cb2-4664-8f50-c23ce2d506cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-d67bf255-5837-4e58-a783-c0aac9e8bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-5ab7955f-6b4c-4ba3-9859-b92b7778f94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10370030-172.17.0.2-1595357579014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32894,DS-9fa8df57-3d36-4c0d-b1cf-50ed2356a44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-5e16880b-646b-4939-9af4-0c78b51180bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b919c026-7dfb-4d3d-b6d1-126fce9988f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-81e06551-ac29-4e37-b295-ec78f455e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-7df211b4-2875-473a-8119-46372a4ee596,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-8c7a2b96-1cb2-4664-8f50-c23ce2d506cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-d67bf255-5837-4e58-a783-c0aac9e8bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-5ab7955f-6b4c-4ba3-9859-b92b7778f94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17057971-172.17.0.2-1595358578774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-ad43977f-8587-44c4-a3af-b8ee9c554d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-ab9ca630-9ca3-4046-85a9-66414d936b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-2f7321b2-c16c-4c64-b701-15b123ea194c,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-a3ec703d-b42b-4f10-8ddb-91d62d92f501,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-27216536-cf5c-40a3-9518-07ff833b936e,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-e8662f61-911f-4ff4-984c-c7f4cbc1e946,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-215f82d2-3cd6-4f8d-b2f5-89e4fed5698c,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-080d2e48-e8b2-48cc-8ade-5af58ec551d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17057971-172.17.0.2-1595358578774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-ad43977f-8587-44c4-a3af-b8ee9c554d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-ab9ca630-9ca3-4046-85a9-66414d936b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-2f7321b2-c16c-4c64-b701-15b123ea194c,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-a3ec703d-b42b-4f10-8ddb-91d62d92f501,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-27216536-cf5c-40a3-9518-07ff833b936e,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-e8662f61-911f-4ff4-984c-c7f4cbc1e946,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-215f82d2-3cd6-4f8d-b2f5-89e4fed5698c,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-080d2e48-e8b2-48cc-8ade-5af58ec551d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439251068-172.17.0.2-1595359549055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40165,DS-51c2e780-842a-4d2e-9e2e-abda14b3c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-6b9fea5d-0100-4821-aeb7-147321c65c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-8f4440d4-9d13-49e6-bf77-9d277d8bfb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-5ceb3709-f3b3-47b0-9fc9-0dfcf7a818b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-0c15de0f-4993-49b5-8c21-92a139e64d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-b8cc50a8-87bd-4915-9fed-e8cf21dae820,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-aebc62fe-80d7-4993-9e8a-c9b2d15c2d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ffee0cac-5388-4435-88d7-23c0bffc17c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439251068-172.17.0.2-1595359549055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40165,DS-51c2e780-842a-4d2e-9e2e-abda14b3c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-6b9fea5d-0100-4821-aeb7-147321c65c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-8f4440d4-9d13-49e6-bf77-9d277d8bfb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-5ceb3709-f3b3-47b0-9fc9-0dfcf7a818b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-0c15de0f-4993-49b5-8c21-92a139e64d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-b8cc50a8-87bd-4915-9fed-e8cf21dae820,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-aebc62fe-80d7-4993-9e8a-c9b2d15c2d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ffee0cac-5388-4435-88d7-23c0bffc17c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6652
