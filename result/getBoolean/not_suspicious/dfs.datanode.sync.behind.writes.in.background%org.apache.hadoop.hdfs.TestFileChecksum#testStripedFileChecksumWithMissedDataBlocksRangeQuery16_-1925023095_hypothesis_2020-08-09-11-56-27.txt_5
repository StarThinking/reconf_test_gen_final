reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049272954-172.17.0.16-1596974363230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41402,DS-4e217ee7-f007-410a-86e9-af98cb358029,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-7f5ae5e4-8778-464d-88ca-3923c6bf4edc,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-9f11f072-c31c-489b-9095-084ec0cb9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-0d2faca0-a017-4f45-bbeb-51ee08489d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-878f686d-cea9-4ea2-8186-1b82c497d058,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5fb5ff51-dfb2-48ab-9b58-66368ca7c183,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-c2bf8a28-7c09-41fc-a523-85ec53238709,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-2502bd0d-2860-4587-80a8-86c8ef330282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049272954-172.17.0.16-1596974363230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41402,DS-4e217ee7-f007-410a-86e9-af98cb358029,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-7f5ae5e4-8778-464d-88ca-3923c6bf4edc,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-9f11f072-c31c-489b-9095-084ec0cb9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-0d2faca0-a017-4f45-bbeb-51ee08489d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-878f686d-cea9-4ea2-8186-1b82c497d058,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5fb5ff51-dfb2-48ab-9b58-66368ca7c183,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-c2bf8a28-7c09-41fc-a523-85ec53238709,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-2502bd0d-2860-4587-80a8-86c8ef330282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986882250-172.17.0.16-1596974421080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-fc742557-3157-4013-abbe-c5cad6fd9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-85ba5bd2-1dca-412b-adf0-3d438cb9f21b,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-1a1ffc22-737b-4a06-b578-91b04db6d056,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-25da891a-70ff-4679-8fad-6943a49a7d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-06ecebd5-ff6f-48ee-80d4-c18b778b973a,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-21be64c3-e4b2-4fb5-8024-6fadf05ef714,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-e7546192-fb51-43f6-84bb-a039e4d9bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-cbf1963e-212b-4db2-a241-691b60e4512c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986882250-172.17.0.16-1596974421080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-fc742557-3157-4013-abbe-c5cad6fd9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-85ba5bd2-1dca-412b-adf0-3d438cb9f21b,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-1a1ffc22-737b-4a06-b578-91b04db6d056,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-25da891a-70ff-4679-8fad-6943a49a7d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-06ecebd5-ff6f-48ee-80d4-c18b778b973a,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-21be64c3-e4b2-4fb5-8024-6fadf05ef714,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-e7546192-fb51-43f6-84bb-a039e4d9bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-cbf1963e-212b-4db2-a241-691b60e4512c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273164188-172.17.0.16-1596974526900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37249,DS-ed53b6fc-83bd-45ba-b812-fd47ede31865,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-a59de9ea-f1da-4769-9d41-8d76b106ec18,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-4d44b919-7f80-4b3d-83fe-945e4d2609a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-d43f8c6e-e871-4166-b751-c5671bbc4115,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-61dd84d1-def5-4efa-819c-965809f0bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-8f74d3e4-e061-4b6e-9b3b-0970e0e61ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-7c2ce3b7-084c-49f5-bff6-85705fe1acff,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-0069c99d-fb6b-4b41-804a-87b72a3aebfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273164188-172.17.0.16-1596974526900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37249,DS-ed53b6fc-83bd-45ba-b812-fd47ede31865,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-a59de9ea-f1da-4769-9d41-8d76b106ec18,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-4d44b919-7f80-4b3d-83fe-945e4d2609a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-d43f8c6e-e871-4166-b751-c5671bbc4115,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-61dd84d1-def5-4efa-819c-965809f0bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-8f74d3e4-e061-4b6e-9b3b-0970e0e61ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-7c2ce3b7-084c-49f5-bff6-85705fe1acff,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-0069c99d-fb6b-4b41-804a-87b72a3aebfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69117209-172.17.0.16-1596974556998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-98fd2c68-0507-4f88-a9fa-c02592135198,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-e7294a77-5d74-4e70-8f30-83d566196be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-dfb2be7b-3069-4a6c-b78b-55fe928d9863,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-5097127e-d167-41b4-b783-8bc747a0e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-4196c7ce-9ec7-4e2f-9e1d-cccc398df815,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-c515b4ae-ce4c-4930-8177-cdce00a6e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-696378b8-c6ec-425a-b018-8991aa2d3e75,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-c23396e9-1620-44b1-8aac-d6010094e2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69117209-172.17.0.16-1596974556998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-98fd2c68-0507-4f88-a9fa-c02592135198,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-e7294a77-5d74-4e70-8f30-83d566196be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-dfb2be7b-3069-4a6c-b78b-55fe928d9863,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-5097127e-d167-41b4-b783-8bc747a0e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-4196c7ce-9ec7-4e2f-9e1d-cccc398df815,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-c515b4ae-ce4c-4930-8177-cdce00a6e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-696378b8-c6ec-425a-b018-8991aa2d3e75,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-c23396e9-1620-44b1-8aac-d6010094e2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282920538-172.17.0.16-1596974585325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33260,DS-588b4bd9-9eac-4c93-971c-c830ee9966d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-b5a4bb39-f414-4e1c-95f1-b84d81338804,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-4cf2d5c9-eb7d-4a02-bc3d-a6b4d1c76f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-df46b624-c347-4933-a753-0d37d40de8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-78078fe9-4c6b-4924-9c94-1cb75e652164,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-832ec4f6-cfe1-4445-9a1e-3902e4f55885,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-afc74d72-2d77-447d-9d66-0ca2fc921bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-c5e45fb8-819a-49a0-b341-b28ad651c080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282920538-172.17.0.16-1596974585325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33260,DS-588b4bd9-9eac-4c93-971c-c830ee9966d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-b5a4bb39-f414-4e1c-95f1-b84d81338804,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-4cf2d5c9-eb7d-4a02-bc3d-a6b4d1c76f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-df46b624-c347-4933-a753-0d37d40de8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-78078fe9-4c6b-4924-9c94-1cb75e652164,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-832ec4f6-cfe1-4445-9a1e-3902e4f55885,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-afc74d72-2d77-447d-9d66-0ca2fc921bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-c5e45fb8-819a-49a0-b341-b28ad651c080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331827369-172.17.0.16-1596975163452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45901,DS-9c503906-60c4-4492-8562-f1d040f68bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-bd2326a4-e8e4-4ca8-9e69-3666dcd8e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-6b3b3282-6b01-4226-a3b9-f2b69d539b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-50c6325f-ccc6-43b4-b4d9-5124a9242d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-a8f5410b-5301-46f8-a4ec-4b6fbaa781a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-e805c016-edb4-4ba0-b874-5a9a2b9c1b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-9585ecf8-a3cf-47ea-aaee-d3e722ec8f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-af8ab24b-569e-4446-9fc9-c6ca96272ddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331827369-172.17.0.16-1596975163452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45901,DS-9c503906-60c4-4492-8562-f1d040f68bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-bd2326a4-e8e4-4ca8-9e69-3666dcd8e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-6b3b3282-6b01-4226-a3b9-f2b69d539b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-50c6325f-ccc6-43b4-b4d9-5124a9242d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-a8f5410b-5301-46f8-a4ec-4b6fbaa781a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-e805c016-edb4-4ba0-b874-5a9a2b9c1b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-9585ecf8-a3cf-47ea-aaee-d3e722ec8f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-af8ab24b-569e-4446-9fc9-c6ca96272ddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407553854-172.17.0.16-1596975260596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45476,DS-0a960f6f-ad58-47d2-aa07-7b4887bffeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-d7659cb7-cf35-4fdd-80c9-0278914011a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-fb8c579a-8d06-4855-8b75-8ff0299b3b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-0c2362a7-5186-405c-9507-2a1b177633ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-cfaa0998-643e-498c-b432-23c224ac776a,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-801a75db-d197-49bc-8801-12fc2059d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-8bdc1728-f5e1-43d2-9c0f-a36c93df5296,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-fd5fccbc-1919-47c9-aa0b-3bd8955143c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407553854-172.17.0.16-1596975260596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45476,DS-0a960f6f-ad58-47d2-aa07-7b4887bffeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-d7659cb7-cf35-4fdd-80c9-0278914011a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-fb8c579a-8d06-4855-8b75-8ff0299b3b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-0c2362a7-5186-405c-9507-2a1b177633ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-cfaa0998-643e-498c-b432-23c224ac776a,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-801a75db-d197-49bc-8801-12fc2059d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-8bdc1728-f5e1-43d2-9c0f-a36c93df5296,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-fd5fccbc-1919-47c9-aa0b-3bd8955143c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624200807-172.17.0.16-1596975297868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-99b1ce32-1aaa-416e-8204-0f267cf9bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-3ad8fe24-fa18-4262-b8ef-1a152d863859,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-66a8d318-57ff-44fd-a050-dccc03a1ece2,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-80e371ff-4936-4421-8c20-af323adf7a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-90268b3f-89ec-44ba-ab7d-4ddddb8126b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-c0db7eee-fb37-45a5-977f-095ceb88dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-44425ae2-ec9a-49d1-b6a8-21b57e8522f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-8a9ddc8f-0dee-4948-9da2-7ad6f21403d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624200807-172.17.0.16-1596975297868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-99b1ce32-1aaa-416e-8204-0f267cf9bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-3ad8fe24-fa18-4262-b8ef-1a152d863859,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-66a8d318-57ff-44fd-a050-dccc03a1ece2,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-80e371ff-4936-4421-8c20-af323adf7a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-90268b3f-89ec-44ba-ab7d-4ddddb8126b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-c0db7eee-fb37-45a5-977f-095ceb88dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-44425ae2-ec9a-49d1-b6a8-21b57e8522f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-8a9ddc8f-0dee-4948-9da2-7ad6f21403d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154871191-172.17.0.16-1596975782399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-819bb4e6-cc1b-4cec-a99a-6e9714995e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-eee782b1-df78-4a2d-9e5a-58a6737903f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-31cfe3d6-917c-4a0b-844d-aef9c7ae2a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-d654b3f0-02f0-4238-9eea-9ac6434a9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-c4d13c99-4b0d-4a01-a0c4-4ff92a77565b,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-101ded16-b102-4fa2-ab95-beadbb24c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-07ec8bb4-e907-4cf0-9bd3-690daf490d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-dc33e0f4-191a-4787-b12d-fdece3f5604d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154871191-172.17.0.16-1596975782399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-819bb4e6-cc1b-4cec-a99a-6e9714995e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-eee782b1-df78-4a2d-9e5a-58a6737903f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-31cfe3d6-917c-4a0b-844d-aef9c7ae2a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-d654b3f0-02f0-4238-9eea-9ac6434a9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-c4d13c99-4b0d-4a01-a0c4-4ff92a77565b,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-101ded16-b102-4fa2-ab95-beadbb24c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-07ec8bb4-e907-4cf0-9bd3-690daf490d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-dc33e0f4-191a-4787-b12d-fdece3f5604d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591510688-172.17.0.16-1596975918386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-27bac62c-065b-4b4d-8af1-40dc95d6d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-92723c21-3c75-4817-ae38-25ed59648bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-e3c1ba7c-4d2a-4ab4-b1b9-20beb4692a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-257a1810-3395-43ae-ae51-f6c2c6586a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-da9c22f6-17f8-4a77-941e-a020e17e9caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-519b8200-04ec-4f60-aaba-001337d12c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-71476a3c-f983-4152-a859-1e000d961d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-fe586b3c-5542-426f-84b4-e9970041a223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591510688-172.17.0.16-1596975918386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-27bac62c-065b-4b4d-8af1-40dc95d6d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-92723c21-3c75-4817-ae38-25ed59648bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-e3c1ba7c-4d2a-4ab4-b1b9-20beb4692a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-257a1810-3395-43ae-ae51-f6c2c6586a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-da9c22f6-17f8-4a77-941e-a020e17e9caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-519b8200-04ec-4f60-aaba-001337d12c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-71476a3c-f983-4152-a859-1e000d961d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-fe586b3c-5542-426f-84b4-e9970041a223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476907516-172.17.0.16-1596976082520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-d8b1989b-768f-4278-af01-0ecb82fd9173,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-d1e85eae-4d68-4ef9-8ca0-e51064b09edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-c92731ea-5a3d-4cf2-8479-0e9e26e2a973,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-784ca166-4359-4062-9a85-7b1d086523c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-58cdcdb7-eb4a-4971-9e36-96e65b0a4e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-79b286c2-68d0-45f6-972c-c70dfcf67160,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-28c423b1-c342-4fbc-bb0f-f872a62cd373,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-2f85e682-cb6f-4bf4-a5ae-5611abc2cb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476907516-172.17.0.16-1596976082520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-d8b1989b-768f-4278-af01-0ecb82fd9173,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-d1e85eae-4d68-4ef9-8ca0-e51064b09edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-c92731ea-5a3d-4cf2-8479-0e9e26e2a973,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-784ca166-4359-4062-9a85-7b1d086523c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-58cdcdb7-eb4a-4971-9e36-96e65b0a4e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-79b286c2-68d0-45f6-972c-c70dfcf67160,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-28c423b1-c342-4fbc-bb0f-f872a62cd373,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-2f85e682-cb6f-4bf4-a5ae-5611abc2cb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194038346-172.17.0.16-1596976110951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-fa7d4b65-2c54-4af4-8c1c-b0b781b3236c,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-cbfba625-12eb-467e-8439-5fb15b94481f,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-ab1fb3bc-3c58-410f-98ba-be4771e3fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-b47ae9eb-230f-417f-b73a-fa38dbb4dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-7f3aa2ce-2490-493f-9103-e8e8fb88f17b,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-57428f94-61a3-4e33-9ec8-22daadcc154a,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-db5faaac-f7a3-46a5-a260-6be3713df897,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-1e0fc4ce-1f0f-4506-8659-43883d1d661e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194038346-172.17.0.16-1596976110951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-fa7d4b65-2c54-4af4-8c1c-b0b781b3236c,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-cbfba625-12eb-467e-8439-5fb15b94481f,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-ab1fb3bc-3c58-410f-98ba-be4771e3fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-b47ae9eb-230f-417f-b73a-fa38dbb4dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-7f3aa2ce-2490-493f-9103-e8e8fb88f17b,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-57428f94-61a3-4e33-9ec8-22daadcc154a,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-db5faaac-f7a3-46a5-a260-6be3713df897,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-1e0fc4ce-1f0f-4506-8659-43883d1d661e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442130456-172.17.0.16-1596976216814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-dd5f1682-f407-4123-8c90-d7f7ee890700,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-baf36dad-c19f-42c3-a3b0-6f4f336a756b,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-31352bd2-e6b2-4042-9db8-e36a5a3f9105,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-83e85414-0b68-4ddf-b7bb-b13b902b75d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-40a090de-7fd3-4db6-94fa-5c482bc1c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-c81690e4-d7ba-4e61-a7e7-6fd295195609,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-5ab349ff-317d-4888-b76e-a96632b9cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-7738d4ab-95f2-42ea-a493-83613e1d4fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442130456-172.17.0.16-1596976216814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-dd5f1682-f407-4123-8c90-d7f7ee890700,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-baf36dad-c19f-42c3-a3b0-6f4f336a756b,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-31352bd2-e6b2-4042-9db8-e36a5a3f9105,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-83e85414-0b68-4ddf-b7bb-b13b902b75d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-40a090de-7fd3-4db6-94fa-5c482bc1c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-c81690e4-d7ba-4e61-a7e7-6fd295195609,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-5ab349ff-317d-4888-b76e-a96632b9cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-7738d4ab-95f2-42ea-a493-83613e1d4fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938065132-172.17.0.16-1596976408809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-36f03132-18fb-4a37-a9e3-609716fee7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-75d99255-e22c-41e0-94eb-4f7d8c032b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-6e2f44a0-764b-4eb7-9695-d58a48bedfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-5e66e4eb-2060-48e0-9a31-f1ef3d492fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-0d0d7335-617d-461e-b19e-812820996bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-06f05823-ea30-4ab9-8ad9-19c70e3fb53c,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-2e658b40-bd0f-4bc1-919f-7b4b5883a6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-74bb20e8-1790-4cc5-aa71-4f49459da9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938065132-172.17.0.16-1596976408809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-36f03132-18fb-4a37-a9e3-609716fee7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-75d99255-e22c-41e0-94eb-4f7d8c032b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-6e2f44a0-764b-4eb7-9695-d58a48bedfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-5e66e4eb-2060-48e0-9a31-f1ef3d492fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-0d0d7335-617d-461e-b19e-812820996bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-06f05823-ea30-4ab9-8ad9-19c70e3fb53c,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-2e658b40-bd0f-4bc1-919f-7b4b5883a6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-74bb20e8-1790-4cc5-aa71-4f49459da9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058117816-172.17.0.16-1596976605880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-f7bbee8c-6525-49fd-a6d1-4f3f691631df,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-85832056-1b44-41cd-9f03-4ea4a5832e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-41dcc1df-160f-4e12-8156-7c8da92cf9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-43a0d637-2591-4cf0-bb36-e8d89643765f,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-555db2c7-983c-4539-93ea-c72a32e89fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-59f6982a-601b-4034-9266-f3d2b87303ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-d52c84e6-4fcd-49a5-bb3d-2691736c4f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-78cd2ef9-8738-4524-91f3-f43314c76f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058117816-172.17.0.16-1596976605880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-f7bbee8c-6525-49fd-a6d1-4f3f691631df,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-85832056-1b44-41cd-9f03-4ea4a5832e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-41dcc1df-160f-4e12-8156-7c8da92cf9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-43a0d637-2591-4cf0-bb36-e8d89643765f,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-555db2c7-983c-4539-93ea-c72a32e89fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-59f6982a-601b-4034-9266-f3d2b87303ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-d52c84e6-4fcd-49a5-bb3d-2691736c4f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-78cd2ef9-8738-4524-91f3-f43314c76f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600943549-172.17.0.16-1596977122705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-d1127d68-1250-4ddf-8d74-b441330ba351,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-57f2dafe-8754-49d9-bd92-3ff9416e7980,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-2321eeed-b4e3-4e2b-9dca-0a9c41d552d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-3275ce35-ec2c-4d92-b18a-c23383a77611,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-5e15b414-da20-4b28-9814-553fc90f80f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-106bc04a-4bf8-4c39-987d-adc9baee1a30,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-dabcb87c-e64c-446c-aa69-fa4c33e8816c,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-8364472a-075b-458f-a38b-889a18f88d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600943549-172.17.0.16-1596977122705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-d1127d68-1250-4ddf-8d74-b441330ba351,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-57f2dafe-8754-49d9-bd92-3ff9416e7980,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-2321eeed-b4e3-4e2b-9dca-0a9c41d552d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-3275ce35-ec2c-4d92-b18a-c23383a77611,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-5e15b414-da20-4b28-9814-553fc90f80f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-106bc04a-4bf8-4c39-987d-adc9baee1a30,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-dabcb87c-e64c-446c-aa69-fa4c33e8816c,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-8364472a-075b-458f-a38b-889a18f88d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674027722-172.17.0.16-1596977349919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-9357b6a5-657f-4157-82db-f8f89f3d1c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-a0effd3c-5bf7-4ae4-9043-c94d83936544,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-8be7fa08-69aa-4b4c-81e8-d775ed01c035,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-b8def90b-8150-4202-b1c6-3453f25941fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-b9a9739d-ccae-4f6b-b997-c4aa75f78eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-053aba31-0c6a-4df7-a7dd-dbf6555458a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-ae92fb75-e271-43a9-a455-bd99ce708521,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-bd65d2c9-87d3-4032-9700-ba7b421a27ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674027722-172.17.0.16-1596977349919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-9357b6a5-657f-4157-82db-f8f89f3d1c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-a0effd3c-5bf7-4ae4-9043-c94d83936544,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-8be7fa08-69aa-4b4c-81e8-d775ed01c035,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-b8def90b-8150-4202-b1c6-3453f25941fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-b9a9739d-ccae-4f6b-b997-c4aa75f78eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-053aba31-0c6a-4df7-a7dd-dbf6555458a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-ae92fb75-e271-43a9-a455-bd99ce708521,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-bd65d2c9-87d3-4032-9700-ba7b421a27ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22212099-172.17.0.16-1596978058611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-0a4c4f2b-be9a-4fed-99e2-174336dcde38,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-1e3d3dbd-7882-4e03-b28f-84f4478fcc30,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-53cb5509-1c7d-4143-a4ce-8d5c49f78fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-33b0dc41-3da4-45fc-9356-f319e4878de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-ffd6af8b-e8fd-4e6d-9580-c137684d6d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-c8366ebd-7952-457c-9d64-28364b020a32,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-e95b8105-5363-484a-8dd8-2d0be389f534,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-666e6cd5-701f-4edf-8bb6-a2b4ea25a131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22212099-172.17.0.16-1596978058611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-0a4c4f2b-be9a-4fed-99e2-174336dcde38,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-1e3d3dbd-7882-4e03-b28f-84f4478fcc30,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-53cb5509-1c7d-4143-a4ce-8d5c49f78fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-33b0dc41-3da4-45fc-9356-f319e4878de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-ffd6af8b-e8fd-4e6d-9580-c137684d6d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-c8366ebd-7952-457c-9d64-28364b020a32,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-e95b8105-5363-484a-8dd8-2d0be389f534,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-666e6cd5-701f-4edf-8bb6-a2b4ea25a131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652813345-172.17.0.16-1596978189360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-f89c17dd-03c4-4224-8952-f7140901ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-b0264f72-61d8-4203-b6f5-6ef7b0084280,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-839bf171-8e70-41ac-9232-1eb7a7df6397,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-b6c46ecc-7584-4645-b039-4fc59071b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-111a8543-6887-4361-9319-d20a8f384b81,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-5e374f06-0e4a-416f-8b03-60c0101c8567,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-48b56017-20ba-4ce7-a9e2-3ebb8dd0c52e,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-bd887cdd-d79b-4be5-b7ca-79ca586e5328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652813345-172.17.0.16-1596978189360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-f89c17dd-03c4-4224-8952-f7140901ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-b0264f72-61d8-4203-b6f5-6ef7b0084280,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-839bf171-8e70-41ac-9232-1eb7a7df6397,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-b6c46ecc-7584-4645-b039-4fc59071b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-111a8543-6887-4361-9319-d20a8f384b81,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-5e374f06-0e4a-416f-8b03-60c0101c8567,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-48b56017-20ba-4ce7-a9e2-3ebb8dd0c52e,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-bd887cdd-d79b-4be5-b7ca-79ca586e5328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562647110-172.17.0.16-1596978224139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-f8a3d904-d639-4a03-8237-7888ff5a14aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-44a2b53a-c0f2-4f9e-a757-7aadbd1006fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-22963e05-b4cf-4a29-abde-40b6828e2078,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-c93f3cdf-0421-4210-b10f-922a975c2e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-c53b8951-354c-4def-9f1a-0128ba1f50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-a7d862f9-b24d-40c4-a940-e1426dd851ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-ca7c19e1-f9c1-42bc-90b4-d58cd6ba3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-370fb094-485b-4f5c-ad86-6b3d135d8f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562647110-172.17.0.16-1596978224139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-f8a3d904-d639-4a03-8237-7888ff5a14aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-44a2b53a-c0f2-4f9e-a757-7aadbd1006fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-22963e05-b4cf-4a29-abde-40b6828e2078,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-c93f3cdf-0421-4210-b10f-922a975c2e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-c53b8951-354c-4def-9f1a-0128ba1f50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-a7d862f9-b24d-40c4-a940-e1426dd851ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-ca7c19e1-f9c1-42bc-90b4-d58cd6ba3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-370fb094-485b-4f5c-ad86-6b3d135d8f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534440038-172.17.0.16-1596978427198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-a7c97d0b-19ec-4bbe-bdba-573a2839e598,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-6fcf0060-9929-4007-9374-121b5140ece2,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-cf35e63a-bc4e-4c37-ae8d-5ed1ce11ab48,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-496c06a3-674d-4a28-964f-fabafc892dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-933595fc-0974-43d8-b46c-452e8b0d5e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-f353669e-92b8-41cf-aeba-60ce0df87b23,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-d6382644-db4d-4842-881e-8d8ef115569a,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-ca1646ef-e425-4159-9ce7-9404c99af4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534440038-172.17.0.16-1596978427198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-a7c97d0b-19ec-4bbe-bdba-573a2839e598,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-6fcf0060-9929-4007-9374-121b5140ece2,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-cf35e63a-bc4e-4c37-ae8d-5ed1ce11ab48,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-496c06a3-674d-4a28-964f-fabafc892dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-933595fc-0974-43d8-b46c-452e8b0d5e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-f353669e-92b8-41cf-aeba-60ce0df87b23,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-d6382644-db4d-4842-881e-8d8ef115569a,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-ca1646ef-e425-4159-9ce7-9404c99af4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206888650-172.17.0.16-1596978460838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34405,DS-131c495b-ca68-41a8-98ab-da402881acb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-c58f5a48-4815-4839-a546-418242996360,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-8cfe05de-5786-46d4-9e67-f3951880b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-ecc7dfca-3671-4d57-9d68-d59857876518,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-af38b47c-a600-4a66-b887-2d9a64df9d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-146a62ab-b097-4106-bde3-8e08047ac35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-b5a0950d-e841-48b5-bf2b-0aedf4518f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-67d2cef7-6b81-4c67-9788-3adf2ac406cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206888650-172.17.0.16-1596978460838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34405,DS-131c495b-ca68-41a8-98ab-da402881acb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-c58f5a48-4815-4839-a546-418242996360,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-8cfe05de-5786-46d4-9e67-f3951880b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-ecc7dfca-3671-4d57-9d68-d59857876518,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-af38b47c-a600-4a66-b887-2d9a64df9d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-146a62ab-b097-4106-bde3-8e08047ac35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-b5a0950d-e841-48b5-bf2b-0aedf4518f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-67d2cef7-6b81-4c67-9788-3adf2ac406cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4826
