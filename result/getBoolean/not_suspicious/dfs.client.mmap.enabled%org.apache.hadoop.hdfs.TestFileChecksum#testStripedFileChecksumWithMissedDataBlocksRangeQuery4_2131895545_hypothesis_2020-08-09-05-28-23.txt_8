reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381345353-172.17.0.4-1596950918525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37516,DS-3fbe3241-7998-4867-9fc8-13185f72ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-3103e523-8376-4b38-b930-574cf29de7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-cf8643a6-365e-4b0c-af7e-c277a7a3976e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-d3c4c980-388a-4259-9613-ed18c0306708,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-2c2d8334-d26d-447b-8d50-9ad702844081,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-bdfe1cbd-62c6-4446-bb31-611767379de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-0af2a451-b245-465d-816d-235d2c156f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-7db6c35c-46e4-4d13-86cb-afc4e9b5ab30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381345353-172.17.0.4-1596950918525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37516,DS-3fbe3241-7998-4867-9fc8-13185f72ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-3103e523-8376-4b38-b930-574cf29de7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-cf8643a6-365e-4b0c-af7e-c277a7a3976e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-d3c4c980-388a-4259-9613-ed18c0306708,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-2c2d8334-d26d-447b-8d50-9ad702844081,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-bdfe1cbd-62c6-4446-bb31-611767379de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-0af2a451-b245-465d-816d-235d2c156f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-7db6c35c-46e4-4d13-86cb-afc4e9b5ab30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970096638-172.17.0.4-1596951085717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45815,DS-f49182e7-a6bb-47d5-81f2-ef11bfc4d5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-e8845e97-e1fb-4215-bc7d-21a956e1b0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-0f50f68c-8514-4d95-a49e-909044e366de,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-19d34188-8b44-43eb-b15a-6a4e29a66756,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-a83b37bd-b496-45b0-9d69-3d11346f0882,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-7059843c-19e9-4d9c-acab-fcfe1f1e9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-f247b2cb-ef64-4f99-8047-dfcba53c1e83,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-fef47aac-7733-4622-940b-d96939f62128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970096638-172.17.0.4-1596951085717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45815,DS-f49182e7-a6bb-47d5-81f2-ef11bfc4d5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-e8845e97-e1fb-4215-bc7d-21a956e1b0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-0f50f68c-8514-4d95-a49e-909044e366de,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-19d34188-8b44-43eb-b15a-6a4e29a66756,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-a83b37bd-b496-45b0-9d69-3d11346f0882,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-7059843c-19e9-4d9c-acab-fcfe1f1e9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-f247b2cb-ef64-4f99-8047-dfcba53c1e83,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-fef47aac-7733-4622-940b-d96939f62128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799858521-172.17.0.4-1596951163301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-780b70e2-372c-4746-b44b-621ef952c878,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-99f2ec2a-ae00-4386-bb52-5b2997784011,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-969000aa-5b72-4f29-9a70-f715f818bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-ab023413-ccb8-4114-aec5-8ee1677f434e,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-fc93c6ac-ec4f-4030-80fb-2ae14f90e798,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-09620e94-cfb3-4f2b-827a-2413f81cbc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-44b691a4-6788-434d-82df-44ca7a5f630a,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-2c33cc1d-f054-430e-9969-09c7a3688b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799858521-172.17.0.4-1596951163301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-780b70e2-372c-4746-b44b-621ef952c878,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-99f2ec2a-ae00-4386-bb52-5b2997784011,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-969000aa-5b72-4f29-9a70-f715f818bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-ab023413-ccb8-4114-aec5-8ee1677f434e,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-fc93c6ac-ec4f-4030-80fb-2ae14f90e798,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-09620e94-cfb3-4f2b-827a-2413f81cbc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-44b691a4-6788-434d-82df-44ca7a5f630a,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-2c33cc1d-f054-430e-9969-09c7a3688b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037286541-172.17.0.4-1596952171339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36009,DS-60b0448d-daf7-4448-b8e5-9f1f214cf116,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-e4aaecc3-ccc6-4452-bb35-1e6922729e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-f9b3ed8e-c2eb-4a05-ad2a-4b0458b1d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-77cace7a-d770-4a14-8a08-ecc98b8c8cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-16d27c80-1892-407e-a9c4-7666d991d689,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b18718d2-1a9b-407a-9be7-31ed409fc654,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-fb8f32db-161a-447d-950c-7501422aebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-67d9bc99-af55-4e54-9827-f65899f1d420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037286541-172.17.0.4-1596952171339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36009,DS-60b0448d-daf7-4448-b8e5-9f1f214cf116,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-e4aaecc3-ccc6-4452-bb35-1e6922729e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-f9b3ed8e-c2eb-4a05-ad2a-4b0458b1d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-77cace7a-d770-4a14-8a08-ecc98b8c8cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-16d27c80-1892-407e-a9c4-7666d991d689,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b18718d2-1a9b-407a-9be7-31ed409fc654,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-fb8f32db-161a-447d-950c-7501422aebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-67d9bc99-af55-4e54-9827-f65899f1d420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189078935-172.17.0.4-1596952347980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-0d550910-9ee5-41e4-813d-452b7ac83e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-8c36abca-1beb-451c-95ce-a5ff6e251021,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-cd2f57ba-1db2-4833-9655-743ca7507f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-bbb7f061-9b5d-462a-8b0a-3cce5b463762,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-2a8b26df-8b41-47da-82bf-7bf48868366d,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-2699973e-bf4a-479d-9d1c-2f83b8da20a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-ec764b54-bbbf-436e-be66-588472d623dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-3967a288-d527-4779-9538-0045d3f6fe3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189078935-172.17.0.4-1596952347980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-0d550910-9ee5-41e4-813d-452b7ac83e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-8c36abca-1beb-451c-95ce-a5ff6e251021,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-cd2f57ba-1db2-4833-9655-743ca7507f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-bbb7f061-9b5d-462a-8b0a-3cce5b463762,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-2a8b26df-8b41-47da-82bf-7bf48868366d,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-2699973e-bf4a-479d-9d1c-2f83b8da20a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-ec764b54-bbbf-436e-be66-588472d623dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-3967a288-d527-4779-9538-0045d3f6fe3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980776771-172.17.0.4-1596952596399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-0c50d0e9-72c8-459e-aff2-d0c9ee5859b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-c83ef9c0-d4d7-499e-8d89-6c4b10876ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-e61bfd26-f6f4-406f-9e98-d12f81024898,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-1f840467-55b2-4e24-8397-7775c3b08959,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-e0378496-860f-4aa8-a7b8-fad7e235a523,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-5ee5e3ee-d1ac-47ea-85e8-2c2ea0dff7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-c3955b89-e2ad-48b5-959c-8c003bdaf0de,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-a7141e4c-477a-47ff-8ee5-9468daacadaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980776771-172.17.0.4-1596952596399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-0c50d0e9-72c8-459e-aff2-d0c9ee5859b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-c83ef9c0-d4d7-499e-8d89-6c4b10876ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-e61bfd26-f6f4-406f-9e98-d12f81024898,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-1f840467-55b2-4e24-8397-7775c3b08959,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-e0378496-860f-4aa8-a7b8-fad7e235a523,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-5ee5e3ee-d1ac-47ea-85e8-2c2ea0dff7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-c3955b89-e2ad-48b5-959c-8c003bdaf0de,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-a7141e4c-477a-47ff-8ee5-9468daacadaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366140113-172.17.0.4-1596953168238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-74557720-bb46-4b9e-8ed8-f79c399f8dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-4ff4f46f-d67b-4663-8f91-788d796d9fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-3e68bb35-aa7c-4dce-9900-b7ee9020ee18,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-8c82dd32-c600-467d-8700-7e744b7d3fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-4de1eb50-0a27-48ed-b119-d84fde20db8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-f40ddd8a-ed1d-4fc8-8f53-ede5972c28c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-67680a90-a7a8-43ba-b7b4-60d574be3267,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-35eb6ac2-530f-4d0d-8737-ffa54a17b776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366140113-172.17.0.4-1596953168238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-74557720-bb46-4b9e-8ed8-f79c399f8dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-4ff4f46f-d67b-4663-8f91-788d796d9fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-3e68bb35-aa7c-4dce-9900-b7ee9020ee18,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-8c82dd32-c600-467d-8700-7e744b7d3fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-4de1eb50-0a27-48ed-b119-d84fde20db8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-f40ddd8a-ed1d-4fc8-8f53-ede5972c28c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-67680a90-a7a8-43ba-b7b4-60d574be3267,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-35eb6ac2-530f-4d0d-8737-ffa54a17b776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452435998-172.17.0.4-1596954019203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-02e120d6-8087-4256-9543-33e0247ec15b,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-1eeea43b-9591-4a6f-857c-97991752b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-700e31c1-86ea-4dcb-87d5-1685e8088f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-3da83e89-5085-42af-a040-185cbdf4a9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-1991f2e8-d391-4c98-b057-7776d686f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-f19a1ddf-02ff-4986-9fb5-3ee258381fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-4a08e49e-cf35-48ca-81d7-58e38d1bd9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-e413dbe3-2eb4-4c3e-9e03-a840d44a1719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452435998-172.17.0.4-1596954019203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-02e120d6-8087-4256-9543-33e0247ec15b,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-1eeea43b-9591-4a6f-857c-97991752b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-700e31c1-86ea-4dcb-87d5-1685e8088f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-3da83e89-5085-42af-a040-185cbdf4a9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-1991f2e8-d391-4c98-b057-7776d686f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-f19a1ddf-02ff-4986-9fb5-3ee258381fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-4a08e49e-cf35-48ca-81d7-58e38d1bd9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-e413dbe3-2eb4-4c3e-9e03-a840d44a1719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475831319-172.17.0.4-1596954608908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-154ca8e1-8d7c-42b1-a468-0406b5e78899,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-863536f9-43b5-457e-a035-53645cdb991d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-bd09169b-8977-41fc-b98c-0437486029b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-1a70073e-1fdd-4f1d-aaea-0dec9b1a5c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-b1c059c0-bb44-489e-b2f2-c769e6aea9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-b54e9fa1-ee03-424f-a8f3-211752545dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-ae3dc724-b4f8-48ed-9f1f-6110462d26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-ed8805e2-a469-4d4c-99a8-00537d841805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475831319-172.17.0.4-1596954608908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-154ca8e1-8d7c-42b1-a468-0406b5e78899,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-863536f9-43b5-457e-a035-53645cdb991d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-bd09169b-8977-41fc-b98c-0437486029b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-1a70073e-1fdd-4f1d-aaea-0dec9b1a5c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-b1c059c0-bb44-489e-b2f2-c769e6aea9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-b54e9fa1-ee03-424f-a8f3-211752545dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-ae3dc724-b4f8-48ed-9f1f-6110462d26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-ed8805e2-a469-4d4c-99a8-00537d841805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881325704-172.17.0.4-1596954975630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41255,DS-58abc635-8339-44ee-b9d6-f62c794e568f,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-cbfef3ab-f354-4b8b-aa80-d4e54d46e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-0ba7534b-8442-4d50-ad44-d965bb9d5038,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-748379f4-9c39-4d86-890f-35192fba80c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-13c027ef-7f1f-416e-8e3f-86a1733f5fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-dbe2b5ab-ab3f-49ed-a95c-8e45dfc82442,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-c89a9d06-7f7d-42b1-b510-8bdcc985cc49,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-dbed1d69-7960-44ac-b95a-5246d105115f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881325704-172.17.0.4-1596954975630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41255,DS-58abc635-8339-44ee-b9d6-f62c794e568f,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-cbfef3ab-f354-4b8b-aa80-d4e54d46e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-0ba7534b-8442-4d50-ad44-d965bb9d5038,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-748379f4-9c39-4d86-890f-35192fba80c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-13c027ef-7f1f-416e-8e3f-86a1733f5fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-dbe2b5ab-ab3f-49ed-a95c-8e45dfc82442,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-c89a9d06-7f7d-42b1-b510-8bdcc985cc49,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-dbed1d69-7960-44ac-b95a-5246d105115f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316317945-172.17.0.4-1596955073244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-48bb9272-ec47-4da1-8229-6ff0765860ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-48dab8a9-6ddb-4091-8d23-a628387cda4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-2bf0c63b-bdd3-4cdf-ae10-4f50d0895821,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-80f63258-fe77-4b37-bc43-271d9b949ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-bc3a6a61-530a-4492-9ce3-84e6291c31da,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-58b4d8b4-8f47-4f41-a909-128ab75590c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-bb1e127c-051d-45db-91a4-80c59267373b,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-2250cd06-a9d9-476c-9e3f-e7a214910cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316317945-172.17.0.4-1596955073244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-48bb9272-ec47-4da1-8229-6ff0765860ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-48dab8a9-6ddb-4091-8d23-a628387cda4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-2bf0c63b-bdd3-4cdf-ae10-4f50d0895821,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-80f63258-fe77-4b37-bc43-271d9b949ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-bc3a6a61-530a-4492-9ce3-84e6291c31da,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-58b4d8b4-8f47-4f41-a909-128ab75590c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-bb1e127c-051d-45db-91a4-80c59267373b,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-2250cd06-a9d9-476c-9e3f-e7a214910cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988376910-172.17.0.4-1596955205854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35311,DS-bcf6e429-6cf4-4d1b-914f-5a6aadc7ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-db196ad3-efb9-4cca-be26-a61049187dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-076cea87-8a5d-48be-b78c-2389887d8543,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-6a16f2a4-941f-4c2b-b191-b9a006cea79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-26babbb6-fd88-4ae8-83a9-4d81840230fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-ce9e069d-41d2-4a02-845f-f59dba3866fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-a8ec532d-c0f0-4088-9f5d-9b1d546f5b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-9fbd2d55-fbaa-412b-9b2d-9013165d516a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988376910-172.17.0.4-1596955205854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35311,DS-bcf6e429-6cf4-4d1b-914f-5a6aadc7ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-db196ad3-efb9-4cca-be26-a61049187dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-076cea87-8a5d-48be-b78c-2389887d8543,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-6a16f2a4-941f-4c2b-b191-b9a006cea79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-26babbb6-fd88-4ae8-83a9-4d81840230fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-ce9e069d-41d2-4a02-845f-f59dba3866fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-a8ec532d-c0f0-4088-9f5d-9b1d546f5b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-9fbd2d55-fbaa-412b-9b2d-9013165d516a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178025483-172.17.0.4-1596955298713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-bf4d55ae-bdb1-41f8-b5df-d2aff2786917,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-9834b339-1aae-4841-b925-d56444df8f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-fd1a8636-8db1-40fc-83ef-ee9a85bfd3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-0ffe73a5-5ab9-4672-890b-cb4faabd6e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-28deee58-1fac-43dc-b688-7473aaea9aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e33ba9f3-8d7a-49d3-beef-a7cc8c371f89,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-31d83578-086e-4f08-89d4-2ace1d528e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-0283a60f-78ae-4d82-8a77-15bf760ad31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178025483-172.17.0.4-1596955298713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-bf4d55ae-bdb1-41f8-b5df-d2aff2786917,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-9834b339-1aae-4841-b925-d56444df8f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-fd1a8636-8db1-40fc-83ef-ee9a85bfd3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-0ffe73a5-5ab9-4672-890b-cb4faabd6e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-28deee58-1fac-43dc-b688-7473aaea9aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e33ba9f3-8d7a-49d3-beef-a7cc8c371f89,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-31d83578-086e-4f08-89d4-2ace1d528e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-0283a60f-78ae-4d82-8a77-15bf760ad31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480004364-172.17.0.4-1596955331391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-1690e631-af25-45eb-873c-79ac7656aba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-1fd23d0d-d98a-4dab-9ebe-15264c8f739b,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-a4cc56cc-5cd4-4c2f-968a-467147a0a761,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-6f1445f7-f72a-4d18-a7d8-796d0801cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-f6a6f7f2-e0e8-4f25-9721-4bb94e37e245,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-c7405664-921e-4a7d-9119-ff664015e709,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-e512e68e-16ec-4402-9dd6-fa1a568b6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-48ad9afa-187c-488e-a8fb-27753090f27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480004364-172.17.0.4-1596955331391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-1690e631-af25-45eb-873c-79ac7656aba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-1fd23d0d-d98a-4dab-9ebe-15264c8f739b,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-a4cc56cc-5cd4-4c2f-968a-467147a0a761,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-6f1445f7-f72a-4d18-a7d8-796d0801cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-f6a6f7f2-e0e8-4f25-9721-4bb94e37e245,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-c7405664-921e-4a7d-9119-ff664015e709,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-e512e68e-16ec-4402-9dd6-fa1a568b6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-48ad9afa-187c-488e-a8fb-27753090f27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731793523-172.17.0.4-1596955665466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33003,DS-a4582a77-e8be-40f5-9e0e-726771a055d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-d80e7928-ea6e-43b4-bfb1-09ba824dbe87,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-1d9b026e-f614-428a-9c64-240e74d46a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-df86808e-5ae3-4354-95e3-5f1a9ec625d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-323126b2-1e73-4096-9fbf-362a8130a984,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-d8cc3e91-387d-4735-b9ff-30bfb4335f23,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-7e83804c-44e9-464a-b107-c329ad264fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-85888915-896a-428f-a4f6-d19078838fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731793523-172.17.0.4-1596955665466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33003,DS-a4582a77-e8be-40f5-9e0e-726771a055d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-d80e7928-ea6e-43b4-bfb1-09ba824dbe87,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-1d9b026e-f614-428a-9c64-240e74d46a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-df86808e-5ae3-4354-95e3-5f1a9ec625d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-323126b2-1e73-4096-9fbf-362a8130a984,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-d8cc3e91-387d-4735-b9ff-30bfb4335f23,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-7e83804c-44e9-464a-b107-c329ad264fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-85888915-896a-428f-a4f6-d19078838fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535696759-172.17.0.4-1596955730092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-f65e051f-0ca1-4d74-ae3a-33d0a5429ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-d9c0b1aa-4852-4a8d-8455-066db82dea92,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-9b9dd8a3-b9c0-45cd-992b-32e4d3ecaec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-c7190f6a-8391-4579-a9b6-b4db2d1492a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-d2503d4c-f634-4dcc-bebf-678423fb79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-0cb9df54-868d-4ad4-b03e-690a5bd47a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-1fd23653-cad5-4757-8c5a-b07d1e60f537,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-3bd124e2-2f9b-431e-8040-5845651d1722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535696759-172.17.0.4-1596955730092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-f65e051f-0ca1-4d74-ae3a-33d0a5429ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-d9c0b1aa-4852-4a8d-8455-066db82dea92,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-9b9dd8a3-b9c0-45cd-992b-32e4d3ecaec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-c7190f6a-8391-4579-a9b6-b4db2d1492a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-d2503d4c-f634-4dcc-bebf-678423fb79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-0cb9df54-868d-4ad4-b03e-690a5bd47a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-1fd23653-cad5-4757-8c5a-b07d1e60f537,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-3bd124e2-2f9b-431e-8040-5845651d1722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342166021-172.17.0.4-1596955762751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34669,DS-26dc8a30-c187-441c-ba1e-25b918e2e22f,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-2572cf9c-b0bb-438b-bc18-117a8bfa5de3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-92d82bf8-a3b6-4e9f-bf30-dbe82c649c03,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-0273efd0-44fa-41b4-8bcf-d9b781efa3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-c8e5912a-88a2-485e-a001-e6d98696dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-50cafcfb-c5cf-4e6f-bdf6-f15ca27bb452,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-c850e864-02b4-4966-a2b6-07c93afeef27,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-24ecbb57-49c5-453b-9b37-fecca40d22c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342166021-172.17.0.4-1596955762751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34669,DS-26dc8a30-c187-441c-ba1e-25b918e2e22f,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-2572cf9c-b0bb-438b-bc18-117a8bfa5de3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-92d82bf8-a3b6-4e9f-bf30-dbe82c649c03,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-0273efd0-44fa-41b4-8bcf-d9b781efa3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-c8e5912a-88a2-485e-a001-e6d98696dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-50cafcfb-c5cf-4e6f-bdf6-f15ca27bb452,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-c850e864-02b4-4966-a2b6-07c93afeef27,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-24ecbb57-49c5-453b-9b37-fecca40d22c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237154436-172.17.0.4-1596955923145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43856,DS-6676538b-5649-42bb-99a8-df3b3f001d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-94f2f7cd-843b-4874-93e9-963e270f6855,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-59f75741-8324-43cc-acf3-06ee8672146e,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-2d75ca3b-4757-47bb-a0ad-a5a21892dc23,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-7a3c4039-eff8-482d-9fa9-925734591c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-06298029-080c-4295-b142-5e750e098abd,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-24b66618-d652-4a56-b91a-9916f45ee304,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-0cb5173c-a98e-4fc1-a7bc-d2f2f8d166d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237154436-172.17.0.4-1596955923145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43856,DS-6676538b-5649-42bb-99a8-df3b3f001d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-94f2f7cd-843b-4874-93e9-963e270f6855,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-59f75741-8324-43cc-acf3-06ee8672146e,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-2d75ca3b-4757-47bb-a0ad-a5a21892dc23,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-7a3c4039-eff8-482d-9fa9-925734591c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-06298029-080c-4295-b142-5e750e098abd,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-24b66618-d652-4a56-b91a-9916f45ee304,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-0cb5173c-a98e-4fc1-a7bc-d2f2f8d166d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5187
