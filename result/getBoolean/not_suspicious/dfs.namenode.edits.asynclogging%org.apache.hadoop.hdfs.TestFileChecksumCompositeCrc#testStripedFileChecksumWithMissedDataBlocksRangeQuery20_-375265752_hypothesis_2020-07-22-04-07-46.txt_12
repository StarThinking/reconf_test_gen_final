reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488373635-172.17.0.7-1595390913333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-a737633a-9e7e-4b2b-9187-41646919a46a,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-82a06d36-ebec-4cec-bc50-9502a029fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-75bea658-191e-4924-af40-84d0a4617dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-de80c0ec-00f0-4aa1-8aa3-bb2fcf1b3d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-7ca0fb49-e0e0-40e1-adce-194e5748256e,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-c47471ea-59bb-4d80-a83e-2fdfa735bcba,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-4c1ff551-a0a6-49ed-8d1b-d298d4c375e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-76db155c-545d-4d3a-9b30-c3d71a50eb01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488373635-172.17.0.7-1595390913333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-a737633a-9e7e-4b2b-9187-41646919a46a,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-82a06d36-ebec-4cec-bc50-9502a029fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-75bea658-191e-4924-af40-84d0a4617dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-de80c0ec-00f0-4aa1-8aa3-bb2fcf1b3d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-7ca0fb49-e0e0-40e1-adce-194e5748256e,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-c47471ea-59bb-4d80-a83e-2fdfa735bcba,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-4c1ff551-a0a6-49ed-8d1b-d298d4c375e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-76db155c-545d-4d3a-9b30-c3d71a50eb01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675633302-172.17.0.7-1595391087065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-0014d355-0a20-4bb0-8723-8e1e81bd6a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-24e622eb-95e8-45d9-a138-7474c2a4ffb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-bedbf5d7-5861-412d-a9a8-7b703b1c00af,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-d6638b68-947c-41b0-9c54-08324381eb78,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-6a14719e-a9f3-45d3-946a-6d8590ed72a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-83aa777b-26a4-4abb-8a33-1f9592a5d446,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-c3aaedd0-4219-4f95-8d5f-18b3fe5ab118,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-4104ab9b-b6d1-421e-aa50-c099921707e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675633302-172.17.0.7-1595391087065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-0014d355-0a20-4bb0-8723-8e1e81bd6a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-24e622eb-95e8-45d9-a138-7474c2a4ffb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-bedbf5d7-5861-412d-a9a8-7b703b1c00af,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-d6638b68-947c-41b0-9c54-08324381eb78,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-6a14719e-a9f3-45d3-946a-6d8590ed72a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-83aa777b-26a4-4abb-8a33-1f9592a5d446,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-c3aaedd0-4219-4f95-8d5f-18b3fe5ab118,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-4104ab9b-b6d1-421e-aa50-c099921707e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838679851-172.17.0.7-1595392652823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-9dad33f1-b2d5-4b4d-bbbe-1730f30b66f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a6697bc1-c0e4-4269-b1ae-63810948521f,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-94c46d3f-2097-4ec2-9324-0f18ec166849,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-18c442fd-5ca7-46ee-9cf1-0469baf16d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-124c3c2e-4b67-4f95-82c5-14c3f5384a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-9a6d9e8d-2dba-4fe6-b966-9828ea46aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-cf892b36-789b-4365-b7e1-714bdaa3539e,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-9fe8e05b-c5e1-4811-95f1-498113591c19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838679851-172.17.0.7-1595392652823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-9dad33f1-b2d5-4b4d-bbbe-1730f30b66f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a6697bc1-c0e4-4269-b1ae-63810948521f,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-94c46d3f-2097-4ec2-9324-0f18ec166849,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-18c442fd-5ca7-46ee-9cf1-0469baf16d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-124c3c2e-4b67-4f95-82c5-14c3f5384a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-9a6d9e8d-2dba-4fe6-b966-9828ea46aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-cf892b36-789b-4365-b7e1-714bdaa3539e,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-9fe8e05b-c5e1-4811-95f1-498113591c19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765907288-172.17.0.7-1595393075751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41565,DS-38ee7e58-de11-488d-aa7a-21de470ae3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-d78fd11b-0978-4be1-96ba-276d19879d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-b4f9db23-ad31-48ec-bf42-495ea6193eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-e6968cd9-7610-460f-92ad-dc2303659c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-be888074-e3a6-4aec-87de-c4167dd4d1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-5da2a5ad-be33-48ce-b1f3-0c37ee27628e,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-d86d5c64-9819-47aa-90ec-d424ce38e3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-33447514-b2d0-4efb-b164-75cdb3710d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765907288-172.17.0.7-1595393075751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41565,DS-38ee7e58-de11-488d-aa7a-21de470ae3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-d78fd11b-0978-4be1-96ba-276d19879d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-b4f9db23-ad31-48ec-bf42-495ea6193eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-e6968cd9-7610-460f-92ad-dc2303659c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-be888074-e3a6-4aec-87de-c4167dd4d1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-5da2a5ad-be33-48ce-b1f3-0c37ee27628e,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-d86d5c64-9819-47aa-90ec-d424ce38e3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-33447514-b2d0-4efb-b164-75cdb3710d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473627080-172.17.0.7-1595393512737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-f983b8fd-6232-4cf4-9853-043a009e907e,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-460e2d08-9c48-4ecb-890c-3c789217a133,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-76165173-eff1-4586-9f3e-ba0e5f1cb0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-549df95c-d854-4e23-b35e-412ccee66ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-e8176eb0-2ab3-4143-9a56-ae8e655aab90,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-06521864-7948-400c-93d1-081eaa0f0ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-f30ac9ed-bc5d-4ca8-ad35-ed7f8c1c6169,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-95f22fce-9b7e-4b88-9c8d-ed9a6ddda7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473627080-172.17.0.7-1595393512737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-f983b8fd-6232-4cf4-9853-043a009e907e,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-460e2d08-9c48-4ecb-890c-3c789217a133,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-76165173-eff1-4586-9f3e-ba0e5f1cb0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-549df95c-d854-4e23-b35e-412ccee66ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-e8176eb0-2ab3-4143-9a56-ae8e655aab90,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-06521864-7948-400c-93d1-081eaa0f0ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-f30ac9ed-bc5d-4ca8-ad35-ed7f8c1c6169,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-95f22fce-9b7e-4b88-9c8d-ed9a6ddda7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306175425-172.17.0.7-1595393580735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-24229197-5125-49c3-9855-66823aeee7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-ae75ca65-895a-49c1-9cb3-7550fa530c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-12092e3c-c839-4c89-9602-2dd6afae10da,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-0979166d-7f8c-411b-94b7-408f735bd635,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-5887d8d4-7aec-48dd-b47e-d83a679e07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-2fa2abc7-3db4-4e28-a63b-e1974eafea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-e0655d82-cce7-475a-87c7-ec32d15f333a,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-c46d9124-eee0-49f1-b508-2e79148f8150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306175425-172.17.0.7-1595393580735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-24229197-5125-49c3-9855-66823aeee7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-ae75ca65-895a-49c1-9cb3-7550fa530c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-12092e3c-c839-4c89-9602-2dd6afae10da,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-0979166d-7f8c-411b-94b7-408f735bd635,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-5887d8d4-7aec-48dd-b47e-d83a679e07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-2fa2abc7-3db4-4e28-a63b-e1974eafea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-e0655d82-cce7-475a-87c7-ec32d15f333a,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-c46d9124-eee0-49f1-b508-2e79148f8150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602041673-172.17.0.7-1595393620797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-5858a3d1-a3d2-4528-a28d-0968b6bf37a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-3bf5d6e4-1725-4eae-b457-7441359344df,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-1ec78402-ddd9-4633-9939-f23409deb948,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9af30955-0693-4483-a9c3-3765cd0bc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-4890b87d-fdb1-4385-b4ca-c4f54da8da52,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-60dba0d1-833a-486a-acef-38d544a7c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-e26039be-936d-4d7e-b6c7-97750b96edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-7f0528a8-2728-47dc-9df1-fc082774b29d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602041673-172.17.0.7-1595393620797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-5858a3d1-a3d2-4528-a28d-0968b6bf37a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-3bf5d6e4-1725-4eae-b457-7441359344df,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-1ec78402-ddd9-4633-9939-f23409deb948,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9af30955-0693-4483-a9c3-3765cd0bc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-4890b87d-fdb1-4385-b4ca-c4f54da8da52,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-60dba0d1-833a-486a-acef-38d544a7c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-e26039be-936d-4d7e-b6c7-97750b96edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-7f0528a8-2728-47dc-9df1-fc082774b29d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178630641-172.17.0.7-1595393805706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45106,DS-451caf02-b146-4e8a-bfb4-1813479ad236,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-9f28bc4c-cf6a-4064-a67f-947f43c6e260,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-aea3159e-f663-459c-9860-6a9bb45c090c,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-27d7e07f-b338-4028-a4a9-2804e996176f,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-4c1c293e-225d-4380-af51-b4a98ac1f452,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-f3726270-138f-48ff-8a3f-4677d60a7b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-fdcd18eb-dcab-4e94-b8a4-49d108c15945,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-f60a4f97-4feb-40dd-baf5-16c2233c7230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178630641-172.17.0.7-1595393805706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45106,DS-451caf02-b146-4e8a-bfb4-1813479ad236,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-9f28bc4c-cf6a-4064-a67f-947f43c6e260,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-aea3159e-f663-459c-9860-6a9bb45c090c,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-27d7e07f-b338-4028-a4a9-2804e996176f,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-4c1c293e-225d-4380-af51-b4a98ac1f452,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-f3726270-138f-48ff-8a3f-4677d60a7b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-fdcd18eb-dcab-4e94-b8a4-49d108c15945,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-f60a4f97-4feb-40dd-baf5-16c2233c7230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582274952-172.17.0.7-1595394398060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39469,DS-ad9daa22-45e2-41be-ba2b-f9fe5a63674c,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-a9bc38a9-016b-4122-bef6-392aa36c3b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-c9725627-05c5-4069-9edb-3637bf5dcb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-eb5decba-5165-420e-b6a3-dbd8815d3047,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-c2b45a2c-7b4e-424e-9dc1-b1e4a6da04a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-c33c5327-ecb6-448c-b1d1-bdc457b5138c,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-6df326cc-dfe7-46ab-8188-19568940346b,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-7f158922-738a-4fc8-b29a-a99a35afb626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582274952-172.17.0.7-1595394398060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39469,DS-ad9daa22-45e2-41be-ba2b-f9fe5a63674c,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-a9bc38a9-016b-4122-bef6-392aa36c3b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-c9725627-05c5-4069-9edb-3637bf5dcb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-eb5decba-5165-420e-b6a3-dbd8815d3047,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-c2b45a2c-7b4e-424e-9dc1-b1e4a6da04a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-c33c5327-ecb6-448c-b1d1-bdc457b5138c,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-6df326cc-dfe7-46ab-8188-19568940346b,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-7f158922-738a-4fc8-b29a-a99a35afb626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864219494-172.17.0.7-1595394548816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-8f632aa7-04e0-4f4b-9157-ab86ddbcfd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-0a127bbd-efff-48f1-acab-6fcb88274061,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-1dad6db6-7d6d-4b54-b198-c1a5f5063455,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-ffd1119e-63dd-477e-b710-eea5414294cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-200a6fa0-e42d-48a7-9900-6f6799aa6de7,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-bbf9ce38-a9e7-4644-919d-0c4e7b342ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-30b4cd83-9a10-406d-9a35-f33ece7df686,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-037aa2b2-6b7c-4944-9b08-aba63e2e1e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864219494-172.17.0.7-1595394548816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-8f632aa7-04e0-4f4b-9157-ab86ddbcfd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-0a127bbd-efff-48f1-acab-6fcb88274061,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-1dad6db6-7d6d-4b54-b198-c1a5f5063455,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-ffd1119e-63dd-477e-b710-eea5414294cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-200a6fa0-e42d-48a7-9900-6f6799aa6de7,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-bbf9ce38-a9e7-4644-919d-0c4e7b342ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-30b4cd83-9a10-406d-9a35-f33ece7df686,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-037aa2b2-6b7c-4944-9b08-aba63e2e1e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073478110-172.17.0.7-1595395259529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-bf966101-1119-4a5b-9c22-024771efe7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-768af3a1-ffce-4278-81f2-cad53226c19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-3bff7ff6-2c7a-4d62-b62b-a6b9e41ecc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-864cb61c-4b83-475f-8cb1-99350c2ee2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-55cd8f4b-e1b1-4b7a-8263-9ef08791d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-7c42888a-7fb0-4df1-bce3-95f2f4dd976a,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-de7b208d-4147-443d-92cb-31e69e3a085a,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-7414bcba-3204-48d7-84a4-5cc1b037c986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073478110-172.17.0.7-1595395259529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-bf966101-1119-4a5b-9c22-024771efe7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-768af3a1-ffce-4278-81f2-cad53226c19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-3bff7ff6-2c7a-4d62-b62b-a6b9e41ecc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-864cb61c-4b83-475f-8cb1-99350c2ee2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-55cd8f4b-e1b1-4b7a-8263-9ef08791d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-7c42888a-7fb0-4df1-bce3-95f2f4dd976a,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-de7b208d-4147-443d-92cb-31e69e3a085a,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-7414bcba-3204-48d7-84a4-5cc1b037c986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407773310-172.17.0.7-1595395296124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40273,DS-d2cd6b81-184f-4aa9-8712-f1c90208d6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-b766e267-e2fe-4c97-88e1-c9630ba83f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-39ae6574-58e9-4758-bbdf-d1868af20629,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-f5f67a91-535c-4c63-8391-1eb3e424015d,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-9024b674-f702-4c0c-a3b8-036ccb48dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-24408f10-842d-4005-a0e0-aac9fea40a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-81a2274d-e2d2-4b40-989b-42143cee86ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a821fd1e-9685-43d5-8f48-f3146be1296f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407773310-172.17.0.7-1595395296124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40273,DS-d2cd6b81-184f-4aa9-8712-f1c90208d6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-b766e267-e2fe-4c97-88e1-c9630ba83f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-39ae6574-58e9-4758-bbdf-d1868af20629,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-f5f67a91-535c-4c63-8391-1eb3e424015d,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-9024b674-f702-4c0c-a3b8-036ccb48dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-24408f10-842d-4005-a0e0-aac9fea40a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-81a2274d-e2d2-4b40-989b-42143cee86ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a821fd1e-9685-43d5-8f48-f3146be1296f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151232387-172.17.0.7-1595395762586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33885,DS-feadd165-5cd6-4df3-91e2-c9793c12d718,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-015b9bbf-7cc9-463c-ac3a-756a86db090a,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-25a42114-252e-464f-afbb-d12c48fea1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-7815e5bf-3ccb-4629-9d80-8290a97d0491,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-5ef80210-ade6-41e1-98b7-a0166495c4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-76e463e4-81c6-4383-b6b2-88171f901165,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-308ce5f8-2b27-4232-8670-c592abff86d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-930496c6-d95c-402c-b838-10bc3fa31f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151232387-172.17.0.7-1595395762586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33885,DS-feadd165-5cd6-4df3-91e2-c9793c12d718,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-015b9bbf-7cc9-463c-ac3a-756a86db090a,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-25a42114-252e-464f-afbb-d12c48fea1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-7815e5bf-3ccb-4629-9d80-8290a97d0491,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-5ef80210-ade6-41e1-98b7-a0166495c4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-76e463e4-81c6-4383-b6b2-88171f901165,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-308ce5f8-2b27-4232-8670-c592abff86d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-930496c6-d95c-402c-b838-10bc3fa31f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876588114-172.17.0.7-1595396249215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-a39acecc-f8ba-4a33-b655-f5fa0fbc436c,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-5d7af23d-6804-49aa-9b90-2299bbde3f25,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-6b0eb149-b147-441b-9f7f-a03bf7af8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-22f32417-b9fe-4752-ac39-0eb93acb190d,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-c59039ff-334b-4a23-b757-05badaa129e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-4e34aee8-f57d-4a00-a5cb-acd7ff5cfecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-c1987db5-e12b-489f-9b94-a9ee987eb3be,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-06366f14-3ba1-49d2-99fb-13b3b14dad64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876588114-172.17.0.7-1595396249215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-a39acecc-f8ba-4a33-b655-f5fa0fbc436c,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-5d7af23d-6804-49aa-9b90-2299bbde3f25,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-6b0eb149-b147-441b-9f7f-a03bf7af8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-22f32417-b9fe-4752-ac39-0eb93acb190d,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-c59039ff-334b-4a23-b757-05badaa129e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-4e34aee8-f57d-4a00-a5cb-acd7ff5cfecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-c1987db5-e12b-489f-9b94-a9ee987eb3be,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-06366f14-3ba1-49d2-99fb-13b3b14dad64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5585
