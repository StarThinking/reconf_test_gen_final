reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070143634-172.17.0.6-1596867271155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-0f1584f3-0e6f-481f-89b1-f08d8f4ecaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-5c0d5d1c-946f-405a-8570-26778a06a60d,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-230dcba6-90e5-468a-aee7-58a819400566,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-cfff24b1-ff89-4d81-aefd-493da08df9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1a6565f2-08b9-4f95-8612-dfe151499141,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-d7816c81-011e-4428-bb92-0c739c90f654,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-1aa2145a-7981-4cad-83ac-b94512a85bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-ffc5f233-295b-405e-9345-c1fd885e7607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070143634-172.17.0.6-1596867271155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-0f1584f3-0e6f-481f-89b1-f08d8f4ecaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-5c0d5d1c-946f-405a-8570-26778a06a60d,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-230dcba6-90e5-468a-aee7-58a819400566,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-cfff24b1-ff89-4d81-aefd-493da08df9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1a6565f2-08b9-4f95-8612-dfe151499141,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-d7816c81-011e-4428-bb92-0c739c90f654,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-1aa2145a-7981-4cad-83ac-b94512a85bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-ffc5f233-295b-405e-9345-c1fd885e7607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37590448-172.17.0.6-1596868120192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-65e49550-350f-44cb-929a-96c7b7057891,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-c3175ace-9d31-463b-ab98-ab1bcc8c4438,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-9a222d57-24d5-456e-9733-3bb13fb413f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-7b232fbc-9ca7-4ad4-9e34-a88310e5e460,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-ec326997-d244-469b-b3b7-5f49d55ac139,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-09e3eaed-e8cd-42c1-bcbb-332d8137b234,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-b6d9f9b7-9f78-4d46-a7c9-512b0fe1a421,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-5ce6904b-4b2b-4cc6-86a3-094a65e95e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37590448-172.17.0.6-1596868120192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-65e49550-350f-44cb-929a-96c7b7057891,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-c3175ace-9d31-463b-ab98-ab1bcc8c4438,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-9a222d57-24d5-456e-9733-3bb13fb413f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-7b232fbc-9ca7-4ad4-9e34-a88310e5e460,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-ec326997-d244-469b-b3b7-5f49d55ac139,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-09e3eaed-e8cd-42c1-bcbb-332d8137b234,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-b6d9f9b7-9f78-4d46-a7c9-512b0fe1a421,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-5ce6904b-4b2b-4cc6-86a3-094a65e95e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258693958-172.17.0.6-1596868206608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-751b7a8c-e038-4afa-9ed9-7a81a7d38e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-70a9dc11-2858-4d13-a672-91010eac5497,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-21624b67-1386-4187-a587-18b3153c003f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-e20c40ae-7eee-443c-a888-ec1342d84855,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-4fea3c00-2387-454f-935e-1a94ded45a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-b075a7b2-0fc8-498a-be4e-f6ac73ee7c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-68134c65-2c29-49c7-8e0f-6f7367160b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-356951c3-51be-454d-9299-7faa14b393de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258693958-172.17.0.6-1596868206608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-751b7a8c-e038-4afa-9ed9-7a81a7d38e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-70a9dc11-2858-4d13-a672-91010eac5497,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-21624b67-1386-4187-a587-18b3153c003f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-e20c40ae-7eee-443c-a888-ec1342d84855,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-4fea3c00-2387-454f-935e-1a94ded45a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-b075a7b2-0fc8-498a-be4e-f6ac73ee7c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-68134c65-2c29-49c7-8e0f-6f7367160b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-356951c3-51be-454d-9299-7faa14b393de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258603933-172.17.0.6-1596868770608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-b316fdf2-7a09-48e3-bebe-61365b750c85,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-80627a98-c7a8-44c9-b040-b9e4051f3958,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-27369f3c-18bf-41aa-aefb-2c70a51a8052,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-067c5ff8-7f26-48e5-9285-c1f2ed25f3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-f1bfa985-d7c0-47f8-8cfa-656648f77c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-8ce94a2a-eed6-4a96-980d-fd2d91060954,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-93432aa6-7ebd-4697-92d8-840f85b8da49,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-c35649b5-027e-407b-ae86-09a28ea86657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258603933-172.17.0.6-1596868770608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-b316fdf2-7a09-48e3-bebe-61365b750c85,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-80627a98-c7a8-44c9-b040-b9e4051f3958,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-27369f3c-18bf-41aa-aefb-2c70a51a8052,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-067c5ff8-7f26-48e5-9285-c1f2ed25f3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-f1bfa985-d7c0-47f8-8cfa-656648f77c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-8ce94a2a-eed6-4a96-980d-fd2d91060954,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-93432aa6-7ebd-4697-92d8-840f85b8da49,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-c35649b5-027e-407b-ae86-09a28ea86657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309245454-172.17.0.6-1596868875629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-86c72759-f36f-4278-bd89-9e0ee712c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-87a298b0-8e35-49e6-85c8-0aea96fb73ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-c9ee2efb-c5ad-4d27-883d-5af57dae1072,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-81a4cac8-e6a9-474d-af86-b5bade59a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-5b9289a0-8bf1-47d1-bfce-dd6e8a3a423a,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-0349916b-4be7-4718-934f-f05a1d9a787d,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-b6408824-21e3-4b9d-840a-50b1ada3cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-19c5b464-3a39-465e-aa08-7c76bab58531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309245454-172.17.0.6-1596868875629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-86c72759-f36f-4278-bd89-9e0ee712c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-87a298b0-8e35-49e6-85c8-0aea96fb73ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-c9ee2efb-c5ad-4d27-883d-5af57dae1072,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-81a4cac8-e6a9-474d-af86-b5bade59a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-5b9289a0-8bf1-47d1-bfce-dd6e8a3a423a,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-0349916b-4be7-4718-934f-f05a1d9a787d,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-b6408824-21e3-4b9d-840a-50b1ada3cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-19c5b464-3a39-465e-aa08-7c76bab58531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117968858-172.17.0.6-1596869119631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-0657918d-1bad-4291-b2a0-17cf2510ab97,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-28075a38-45bf-4e66-87c7-551966151ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-a45255fa-92ce-4883-8dcd-9dd2b330fae8,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-765967ad-5ac3-432f-9abf-57a025f9f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-550eb5bf-231a-422d-8329-16f6674c0586,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-09a73f60-8922-40b2-bee2-e9fcf9e71d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-8660fa09-b590-4acf-bfd6-3f66f88a94d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-5ed401c4-8a85-4b46-afb7-ca0443f932a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117968858-172.17.0.6-1596869119631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-0657918d-1bad-4291-b2a0-17cf2510ab97,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-28075a38-45bf-4e66-87c7-551966151ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-a45255fa-92ce-4883-8dcd-9dd2b330fae8,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-765967ad-5ac3-432f-9abf-57a025f9f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-550eb5bf-231a-422d-8329-16f6674c0586,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-09a73f60-8922-40b2-bee2-e9fcf9e71d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-8660fa09-b590-4acf-bfd6-3f66f88a94d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-5ed401c4-8a85-4b46-afb7-ca0443f932a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996462412-172.17.0.6-1596869154678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-c09e4638-0cac-42ae-b550-25730cf7b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-03c79302-8acd-4749-b16c-be40932efb86,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-56c6e180-8d1f-4fd3-b0ab-a407459d3bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-b39fd752-3ee6-4f0c-9118-d76c01688d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-de7ae8cd-24c1-4c95-9e55-c72ab3465a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3c80560b-b0ec-4ca6-870a-5d797a5c0c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-83ecee4a-1390-4b20-8291-09082e19bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-9875c3de-e2d9-4f19-b453-fce39e04f430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996462412-172.17.0.6-1596869154678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-c09e4638-0cac-42ae-b550-25730cf7b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-03c79302-8acd-4749-b16c-be40932efb86,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-56c6e180-8d1f-4fd3-b0ab-a407459d3bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-b39fd752-3ee6-4f0c-9118-d76c01688d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-de7ae8cd-24c1-4c95-9e55-c72ab3465a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3c80560b-b0ec-4ca6-870a-5d797a5c0c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-83ecee4a-1390-4b20-8291-09082e19bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-9875c3de-e2d9-4f19-b453-fce39e04f430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13652446-172.17.0.6-1596869656051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-d8f7ded1-3a49-4c71-9f35-e2899f8a0760,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-588a6995-6f07-491a-9c57-b1316be90d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-ed22bf4b-554c-4116-a68f-18163dca0ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-6f88da1b-2fde-40ee-a867-707490481272,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-f41d406f-bab9-42a4-b676-c23b9f406f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-f962f0ac-a2eb-44b8-bdf5-fe5a7bbeebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-8e0efe18-caa3-45f1-9ce5-0de54a7c0dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-56dfe3c5-4f4f-412d-a8f0-876bce61ad5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13652446-172.17.0.6-1596869656051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-d8f7ded1-3a49-4c71-9f35-e2899f8a0760,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-588a6995-6f07-491a-9c57-b1316be90d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-ed22bf4b-554c-4116-a68f-18163dca0ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-6f88da1b-2fde-40ee-a867-707490481272,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-f41d406f-bab9-42a4-b676-c23b9f406f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-f962f0ac-a2eb-44b8-bdf5-fe5a7bbeebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-8e0efe18-caa3-45f1-9ce5-0de54a7c0dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-56dfe3c5-4f4f-412d-a8f0-876bce61ad5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250402526-172.17.0.6-1596870198858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-1f3ccdf1-d9a6-4fd6-a582-554ca9a29b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-d133e02c-aed8-407a-838a-2b5cb2726397,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-635237d4-e131-427c-9e74-0792bc2bb46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-ac93c035-8657-4f82-8ba8-1806ed129b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-9ad8302d-d5bc-4b25-bb96-adf8a5707025,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-c64a9035-ed8d-45dc-80b7-aafac12db9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-24b3fad0-0147-4ebd-b740-6af13b95e08a,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-8da92e66-3ae7-43cf-a8cd-820f30e4540c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250402526-172.17.0.6-1596870198858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-1f3ccdf1-d9a6-4fd6-a582-554ca9a29b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-d133e02c-aed8-407a-838a-2b5cb2726397,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-635237d4-e131-427c-9e74-0792bc2bb46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-ac93c035-8657-4f82-8ba8-1806ed129b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-9ad8302d-d5bc-4b25-bb96-adf8a5707025,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-c64a9035-ed8d-45dc-80b7-aafac12db9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-24b3fad0-0147-4ebd-b740-6af13b95e08a,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-8da92e66-3ae7-43cf-a8cd-820f30e4540c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993668907-172.17.0.6-1596870802378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-d1884ec7-7239-439b-8794-ac84effb203f,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-a6a71d01-b819-45cc-8ddc-2623263b753d,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-bc9e1da8-67c0-4386-b6a2-28217a21a01a,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-78ec2ec3-29a9-460a-b0f2-60a48112a4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b94daef6-598c-4b64-9657-1e186bec1acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-297fb598-18cc-4018-ba23-5900c44613d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-575a682f-2413-4d49-8609-b32994be8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-270f69a1-ede8-4636-b02e-7613154916bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993668907-172.17.0.6-1596870802378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-d1884ec7-7239-439b-8794-ac84effb203f,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-a6a71d01-b819-45cc-8ddc-2623263b753d,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-bc9e1da8-67c0-4386-b6a2-28217a21a01a,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-78ec2ec3-29a9-460a-b0f2-60a48112a4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b94daef6-598c-4b64-9657-1e186bec1acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-297fb598-18cc-4018-ba23-5900c44613d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-575a682f-2413-4d49-8609-b32994be8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-270f69a1-ede8-4636-b02e-7613154916bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817194004-172.17.0.6-1596870842912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-09353f05-8beb-4137-a42d-d1b602f785c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4a3b2a11-2c6c-43d9-96e8-8935bb73c767,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-79214138-8d64-416d-8330-f161e08ec3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-e250a73f-94a5-48df-973c-cce6b6a09541,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-d75f072a-8ede-4f85-9efc-b169e32260d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-27ad9497-f1f8-41cc-8f6a-df1cf5ecb9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-29179e18-56b5-4128-971b-a38ed9aec3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-9a7813f8-bc3c-4f31-9e91-c2e84d0416b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817194004-172.17.0.6-1596870842912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-09353f05-8beb-4137-a42d-d1b602f785c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4a3b2a11-2c6c-43d9-96e8-8935bb73c767,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-79214138-8d64-416d-8330-f161e08ec3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-e250a73f-94a5-48df-973c-cce6b6a09541,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-d75f072a-8ede-4f85-9efc-b169e32260d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-27ad9497-f1f8-41cc-8f6a-df1cf5ecb9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-29179e18-56b5-4128-971b-a38ed9aec3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-9a7813f8-bc3c-4f31-9e91-c2e84d0416b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581280379-172.17.0.6-1596871020593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38087,DS-06267ad0-1c60-45c4-be27-e2d90d07ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-d5f8e2c6-2f3c-4cf7-a214-d99408bbd426,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-2c53e7b3-b3e5-43af-93e2-e4afc30903c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-232d89d8-e44f-4190-8053-8fa942046953,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-12f6a44d-88eb-44a3-a366-1162d52ed227,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-28b5a6d0-7662-43cb-8dd4-9d1fdf72487a,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-583196fe-875a-4b27-b6c0-c5d5e21f93ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-61c47c28-97aa-41e4-9343-b6930c55d1e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581280379-172.17.0.6-1596871020593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38087,DS-06267ad0-1c60-45c4-be27-e2d90d07ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-d5f8e2c6-2f3c-4cf7-a214-d99408bbd426,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-2c53e7b3-b3e5-43af-93e2-e4afc30903c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-232d89d8-e44f-4190-8053-8fa942046953,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-12f6a44d-88eb-44a3-a366-1162d52ed227,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-28b5a6d0-7662-43cb-8dd4-9d1fdf72487a,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-583196fe-875a-4b27-b6c0-c5d5e21f93ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-61c47c28-97aa-41e4-9343-b6930c55d1e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848980665-172.17.0.6-1596871511089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-b8e23ec2-dae1-4f17-ba11-486872b5647a,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-fd5af8ae-d5b5-4952-a56b-3a254eff882b,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-b2fd5ce9-3e53-4c8d-b3ca-d03de431637c,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-26dc7799-baea-4cfc-a6e9-e102c3173830,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-20dd6e0d-6c54-4bd2-aa68-8030374ec2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-910fcf32-a20d-41be-97b4-9ac648b409ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-73a2cab6-d74d-4a06-8a70-939de1b4dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-7f56f883-2b55-4efd-93be-d9d42d18d4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848980665-172.17.0.6-1596871511089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-b8e23ec2-dae1-4f17-ba11-486872b5647a,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-fd5af8ae-d5b5-4952-a56b-3a254eff882b,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-b2fd5ce9-3e53-4c8d-b3ca-d03de431637c,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-26dc7799-baea-4cfc-a6e9-e102c3173830,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-20dd6e0d-6c54-4bd2-aa68-8030374ec2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-910fcf32-a20d-41be-97b4-9ac648b409ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-73a2cab6-d74d-4a06-8a70-939de1b4dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-7f56f883-2b55-4efd-93be-d9d42d18d4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5463
