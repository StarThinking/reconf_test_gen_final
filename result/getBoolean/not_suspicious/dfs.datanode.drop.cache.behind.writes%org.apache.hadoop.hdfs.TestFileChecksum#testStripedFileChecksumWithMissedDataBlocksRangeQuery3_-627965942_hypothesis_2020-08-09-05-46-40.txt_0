reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210353887-172.17.0.11-1596952085968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43740,DS-5e1fa08d-f6e6-4647-bd0a-0d159d40da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-0031e688-4d25-4179-a9eb-91bafb098d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0a8c8b73-60f4-43ee-99e0-59272c9df1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-a207a14b-7ff3-4224-8e30-1281d018d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-d555b46a-8788-4704-a22f-f4600938f30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-468f00a6-1733-4b34-b65d-367596d1aa71,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-0873534a-77aa-424d-8e63-6460041368b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-e409b525-2b06-43b4-91c2-fdfd30d3813f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210353887-172.17.0.11-1596952085968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43740,DS-5e1fa08d-f6e6-4647-bd0a-0d159d40da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-0031e688-4d25-4179-a9eb-91bafb098d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0a8c8b73-60f4-43ee-99e0-59272c9df1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-a207a14b-7ff3-4224-8e30-1281d018d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-d555b46a-8788-4704-a22f-f4600938f30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-468f00a6-1733-4b34-b65d-367596d1aa71,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-0873534a-77aa-424d-8e63-6460041368b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-e409b525-2b06-43b4-91c2-fdfd30d3813f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111392205-172.17.0.11-1596952122598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-56ebb7b5-decf-4aae-a7c5-60e38a18ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-ffbe3730-386e-43ed-871f-869218f7085c,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-208e7bdd-a978-464f-b8ca-a0138cd11e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-1ff5e36e-6ba4-4b16-ae54-1f8e7327fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-31518418-0171-4cea-9950-4c468862ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-a30424e8-c9a7-4725-8bb7-feb77d103eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-b5830b43-07f0-4058-9001-f21dfdb95959,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-f61f480e-c265-417f-aa9b-4b8636c247d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111392205-172.17.0.11-1596952122598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-56ebb7b5-decf-4aae-a7c5-60e38a18ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-ffbe3730-386e-43ed-871f-869218f7085c,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-208e7bdd-a978-464f-b8ca-a0138cd11e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-1ff5e36e-6ba4-4b16-ae54-1f8e7327fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-31518418-0171-4cea-9950-4c468862ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-a30424e8-c9a7-4725-8bb7-feb77d103eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-b5830b43-07f0-4058-9001-f21dfdb95959,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-f61f480e-c265-417f-aa9b-4b8636c247d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455652289-172.17.0.11-1596952669544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-a19ab7f1-10ad-41e5-98c6-0794a6b43fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-4e087c9d-0972-4650-9fb1-bb6dd49b4ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-63ae8698-9788-4fdf-a634-394843ffaa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-a16fe50b-1700-4640-a46b-87f948c116cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-c7967091-0c3c-44ef-a36f-1ad2ce9ab16c,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-429e1943-de29-42af-9f21-cdc4f8413bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-364a5c36-099c-49e0-a9f6-98345a62f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-21c42ca1-7326-4de1-8cc3-3dd7496d62c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455652289-172.17.0.11-1596952669544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-a19ab7f1-10ad-41e5-98c6-0794a6b43fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-4e087c9d-0972-4650-9fb1-bb6dd49b4ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-63ae8698-9788-4fdf-a634-394843ffaa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-a16fe50b-1700-4640-a46b-87f948c116cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-c7967091-0c3c-44ef-a36f-1ad2ce9ab16c,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-429e1943-de29-42af-9f21-cdc4f8413bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-364a5c36-099c-49e0-a9f6-98345a62f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-21c42ca1-7326-4de1-8cc3-3dd7496d62c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001002387-172.17.0.11-1596952707510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-493a2fff-0a2a-43fd-9260-ea5a3e9c23c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-2965d3e8-482a-45b5-b106-4cc1eb5f837e,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b90c6369-4542-4f4a-aee1-04a4576679ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-17152248-a114-4295-852f-a400145b0373,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-3ccc25ec-bf8f-41bb-935e-71b430b5fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-453b9375-4d22-44c7-8e65-88357513d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-ff340a04-e022-4d2b-9db8-ac79f6082868,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-119fab98-e0d3-46c4-bcbe-aa09af0dbd72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001002387-172.17.0.11-1596952707510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-493a2fff-0a2a-43fd-9260-ea5a3e9c23c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-2965d3e8-482a-45b5-b106-4cc1eb5f837e,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b90c6369-4542-4f4a-aee1-04a4576679ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-17152248-a114-4295-852f-a400145b0373,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-3ccc25ec-bf8f-41bb-935e-71b430b5fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-453b9375-4d22-44c7-8e65-88357513d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-ff340a04-e022-4d2b-9db8-ac79f6082868,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-119fab98-e0d3-46c4-bcbe-aa09af0dbd72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910852610-172.17.0.11-1596952749661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-f2a3d3eb-9261-4ee1-b1c7-613f9fc7f3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-6691c142-8907-402f-8e22-3137cfbd10fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-0bcb6f1b-7baf-4de2-a970-dbdc68b6d45b,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-c588680c-5e77-4211-b7ca-7c9f4d2a9999,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-1efbf15b-9a8c-4dc1-8577-f5b11761e938,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-b7ea4188-290c-4fd0-b9df-5eed79c815d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-1533a855-af44-4420-b52d-7643cf570f05,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-b2e29118-9d81-463f-9ad2-11f3a36ad28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910852610-172.17.0.11-1596952749661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-f2a3d3eb-9261-4ee1-b1c7-613f9fc7f3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-6691c142-8907-402f-8e22-3137cfbd10fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-0bcb6f1b-7baf-4de2-a970-dbdc68b6d45b,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-c588680c-5e77-4211-b7ca-7c9f4d2a9999,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-1efbf15b-9a8c-4dc1-8577-f5b11761e938,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-b7ea4188-290c-4fd0-b9df-5eed79c815d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-1533a855-af44-4420-b52d-7643cf570f05,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-b2e29118-9d81-463f-9ad2-11f3a36ad28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416956408-172.17.0.11-1596953226892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44382,DS-19f2061b-0c3d-4ddd-894d-b56349e42b24,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-0bfe017e-94fd-4e51-99db-b01611c98434,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-5957055f-703d-402b-9a03-68e096d2a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-67c2058f-c249-4651-8ba5-f11d1fbe7c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-7cd5d859-844b-4c18-b1be-6bf2f4bb14c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-5051a01b-9e86-4c9b-ae18-b3594301ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-c24f08f3-1b87-4373-be00-053036163502,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-8f6d51e7-83e9-4407-9227-3b2b8d9f4015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416956408-172.17.0.11-1596953226892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44382,DS-19f2061b-0c3d-4ddd-894d-b56349e42b24,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-0bfe017e-94fd-4e51-99db-b01611c98434,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-5957055f-703d-402b-9a03-68e096d2a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-67c2058f-c249-4651-8ba5-f11d1fbe7c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-7cd5d859-844b-4c18-b1be-6bf2f4bb14c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-5051a01b-9e86-4c9b-ae18-b3594301ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-c24f08f3-1b87-4373-be00-053036163502,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-8f6d51e7-83e9-4407-9227-3b2b8d9f4015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526201692-172.17.0.11-1596953334336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-78f8ae69-2ca5-4db3-9f46-5b5489c74d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-b48a7f6d-f3e6-4baa-a822-a6e6e7d76cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-3c59f4c4-10c7-4064-af54-a20ff22bc891,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-7b4e6758-15db-4893-9d65-899f96776128,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-cbd260b5-771e-4697-8314-a8ab7749db58,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-8ec50b19-6fb5-4062-bb2b-05cffeb59137,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-a131b054-8243-494d-9ecd-f371e4978aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-255b6ee2-822b-49c2-93c6-c8e32d1662f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526201692-172.17.0.11-1596953334336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-78f8ae69-2ca5-4db3-9f46-5b5489c74d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-b48a7f6d-f3e6-4baa-a822-a6e6e7d76cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-3c59f4c4-10c7-4064-af54-a20ff22bc891,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-7b4e6758-15db-4893-9d65-899f96776128,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-cbd260b5-771e-4697-8314-a8ab7749db58,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-8ec50b19-6fb5-4062-bb2b-05cffeb59137,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-a131b054-8243-494d-9ecd-f371e4978aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-255b6ee2-822b-49c2-93c6-c8e32d1662f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235087579-172.17.0.11-1596953453752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-18a27b29-c69d-44b9-9fac-4604137ffc36,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-38d12883-ee94-44d3-b268-fd50551291c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-a1feeff7-f589-4daa-b31c-d79b40ef2d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-89fc0840-9f22-483c-91c1-46a6a8df2405,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-c0e478aa-a161-4032-9361-0cc49a1011f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-768b9653-d4e9-4c31-834b-db1f8d2f58d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-4aed7c39-681e-4e23-83a8-87e02f1ae8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-433ecbb8-4d3f-4d70-ae1d-ad6fa7da1075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235087579-172.17.0.11-1596953453752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-18a27b29-c69d-44b9-9fac-4604137ffc36,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-38d12883-ee94-44d3-b268-fd50551291c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-a1feeff7-f589-4daa-b31c-d79b40ef2d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-89fc0840-9f22-483c-91c1-46a6a8df2405,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-c0e478aa-a161-4032-9361-0cc49a1011f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-768b9653-d4e9-4c31-834b-db1f8d2f58d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-4aed7c39-681e-4e23-83a8-87e02f1ae8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-433ecbb8-4d3f-4d70-ae1d-ad6fa7da1075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601141664-172.17.0.11-1596953860621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-96d03f3d-1256-443a-a7e8-d2cba153b526,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-403194b8-dee0-4d04-bf57-c2c650cf1f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-948d8358-d78d-4958-bb35-5db530c8964a,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-cc23ec85-b996-4928-ba4f-4dece21230be,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-31818ab0-6893-4d92-a106-da5617be7ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-77e12f55-6de9-421c-9cd3-a25f63c7e95d,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-b6f4f24c-9cba-4148-a922-cae89ab72c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-b1fa608c-bd30-4a17-bd60-738dc0694f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601141664-172.17.0.11-1596953860621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-96d03f3d-1256-443a-a7e8-d2cba153b526,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-403194b8-dee0-4d04-bf57-c2c650cf1f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-948d8358-d78d-4958-bb35-5db530c8964a,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-cc23ec85-b996-4928-ba4f-4dece21230be,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-31818ab0-6893-4d92-a106-da5617be7ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-77e12f55-6de9-421c-9cd3-a25f63c7e95d,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-b6f4f24c-9cba-4148-a922-cae89ab72c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-b1fa608c-bd30-4a17-bd60-738dc0694f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957555131-172.17.0.11-1596953934919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-8e775d21-c671-44cb-96b0-0f9f6b5ac283,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-aa582d73-7b76-4881-be7c-b31de7715407,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-752bdff5-d28b-4b92-a365-4e55b8694c99,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-08bf15e8-0b3e-4256-bd24-bc967f706f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-2fc3cc15-9d26-4d2c-af3d-f89a29912b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-3b314dd5-a997-40f0-aa8a-39c3dd7e057b,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-a68d4322-9798-4314-8ef1-2d3b0eaed3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-d09c6c55-ae56-4361-9251-4f7202bb92fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957555131-172.17.0.11-1596953934919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-8e775d21-c671-44cb-96b0-0f9f6b5ac283,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-aa582d73-7b76-4881-be7c-b31de7715407,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-752bdff5-d28b-4b92-a365-4e55b8694c99,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-08bf15e8-0b3e-4256-bd24-bc967f706f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-2fc3cc15-9d26-4d2c-af3d-f89a29912b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-3b314dd5-a997-40f0-aa8a-39c3dd7e057b,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-a68d4322-9798-4314-8ef1-2d3b0eaed3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-d09c6c55-ae56-4361-9251-4f7202bb92fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294572107-172.17.0.11-1596954340624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-18b31f5e-8cfa-45cf-ad36-c162340ae917,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-021d97c3-7e89-48f0-99ef-c9f594358d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-424ac8a5-361b-45f4-ba42-cd59fe883136,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-64a70a42-d2f9-429b-b486-6d45f9c16e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-7aca36d7-e608-4301-be96-5052ada3c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-334fed29-d49e-4227-9156-ef17a2581bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-512475bf-516d-4111-9a3b-6193a15e7267,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-5503d0fe-461e-48e2-a157-52285c2cc60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294572107-172.17.0.11-1596954340624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-18b31f5e-8cfa-45cf-ad36-c162340ae917,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-021d97c3-7e89-48f0-99ef-c9f594358d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-424ac8a5-361b-45f4-ba42-cd59fe883136,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-64a70a42-d2f9-429b-b486-6d45f9c16e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-7aca36d7-e608-4301-be96-5052ada3c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-334fed29-d49e-4227-9156-ef17a2581bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-512475bf-516d-4111-9a3b-6193a15e7267,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-5503d0fe-461e-48e2-a157-52285c2cc60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211375009-172.17.0.11-1596954419305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-2b545e1b-4a11-49e9-a584-6707df1b1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-596a9677-5e5b-443c-b81e-41841f12c52e,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-cc47d76f-2434-472f-923a-3b18632edca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-78655825-3457-4a94-be6e-f76adf3b3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-5e3a4710-aecf-4a29-b57e-023d2112fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-be0a31d0-d553-4934-a14a-6389531495df,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-79ef120a-541c-4996-ab53-b4f791bea105,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-34bf397f-388b-4f06-a1b1-1d72da2622f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211375009-172.17.0.11-1596954419305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-2b545e1b-4a11-49e9-a584-6707df1b1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-596a9677-5e5b-443c-b81e-41841f12c52e,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-cc47d76f-2434-472f-923a-3b18632edca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-78655825-3457-4a94-be6e-f76adf3b3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-5e3a4710-aecf-4a29-b57e-023d2112fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-be0a31d0-d553-4934-a14a-6389531495df,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-79ef120a-541c-4996-ab53-b4f791bea105,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-34bf397f-388b-4f06-a1b1-1d72da2622f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144218799-172.17.0.11-1596954936753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34923,DS-a505a77e-6e33-4234-8a87-f96f419e9220,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-525a751c-57a1-405c-a9a4-28a30c0d6db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-92d1e23c-c7c1-41d0-ad8d-464a34840da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-06424795-90c8-48c8-af43-2e258b38b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-c195b01e-0071-4cd5-ad24-1649952794d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-8bb19862-15af-4903-93ad-e2de7baaef9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-79fe5805-4edb-49a0-a7a9-6fdc60c29f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-c8edc394-54f8-4864-b07a-d315fd254b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144218799-172.17.0.11-1596954936753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34923,DS-a505a77e-6e33-4234-8a87-f96f419e9220,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-525a751c-57a1-405c-a9a4-28a30c0d6db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-92d1e23c-c7c1-41d0-ad8d-464a34840da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-06424795-90c8-48c8-af43-2e258b38b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-c195b01e-0071-4cd5-ad24-1649952794d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-8bb19862-15af-4903-93ad-e2de7baaef9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-79fe5805-4edb-49a0-a7a9-6fdc60c29f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-c8edc394-54f8-4864-b07a-d315fd254b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481254707-172.17.0.11-1596955423858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-cd492ee1-fef6-43db-a28e-bf01efefefa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-4408bdb2-3a85-4615-a1ca-85fb40da35be,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c747cbaa-946d-4ad3-a20e-832980045f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-2767a466-9e60-49fb-bcc5-323ba8248f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-be1e6894-0c59-46dc-b44c-af6178bc37ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-66605331-9d17-4155-a811-409b5b54a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-1f333713-56cd-44b5-9fe0-582fe9864fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-8271c023-b4fd-48cb-a33a-0e5eb477b8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481254707-172.17.0.11-1596955423858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-cd492ee1-fef6-43db-a28e-bf01efefefa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-4408bdb2-3a85-4615-a1ca-85fb40da35be,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c747cbaa-946d-4ad3-a20e-832980045f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-2767a466-9e60-49fb-bcc5-323ba8248f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-be1e6894-0c59-46dc-b44c-af6178bc37ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-66605331-9d17-4155-a811-409b5b54a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-1f333713-56cd-44b5-9fe0-582fe9864fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-8271c023-b4fd-48cb-a33a-0e5eb477b8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501023338-172.17.0.11-1596955600268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-764674b3-c132-43e0-a7ac-7f39fc1a76f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-c12a4759-8214-42e8-8d35-0a5a5c1836b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-f032c6ca-b282-41d6-ae1c-047c4fb32883,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-7e98b21c-4d27-4c80-9294-c3cdd03bc317,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-7b212cce-0a07-4675-9274-8221fa6090d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-e34b4acc-4151-4655-a1f6-142b0dc27310,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-642d6e3a-36b3-46d0-92b1-fdfacdbd7f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-71a731f7-bc90-4b13-a7e2-2684fe6298a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501023338-172.17.0.11-1596955600268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-764674b3-c132-43e0-a7ac-7f39fc1a76f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-c12a4759-8214-42e8-8d35-0a5a5c1836b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-f032c6ca-b282-41d6-ae1c-047c4fb32883,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-7e98b21c-4d27-4c80-9294-c3cdd03bc317,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-7b212cce-0a07-4675-9274-8221fa6090d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-e34b4acc-4151-4655-a1f6-142b0dc27310,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-642d6e3a-36b3-46d0-92b1-fdfacdbd7f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-71a731f7-bc90-4b13-a7e2-2684fe6298a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187233037-172.17.0.11-1596955745477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-cef4a923-d350-4086-a9cb-42c73296b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-710d56bd-514b-4552-af64-986a9532d105,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-2fcc26b5-84d4-4a7f-ad79-65e372e53a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-9bc2627d-c470-4d61-8d1a-467a76eedb25,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-c3b6e317-1c89-402d-b191-3990cfff4a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-8f4246b2-cbdf-4c36-9c16-017009b3b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-3df32d72-502f-4a41-b2e4-97337da4fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-a3d29914-a33e-4b53-82b0-33a85f9d1c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187233037-172.17.0.11-1596955745477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-cef4a923-d350-4086-a9cb-42c73296b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-710d56bd-514b-4552-af64-986a9532d105,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-2fcc26b5-84d4-4a7f-ad79-65e372e53a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-9bc2627d-c470-4d61-8d1a-467a76eedb25,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-c3b6e317-1c89-402d-b191-3990cfff4a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-8f4246b2-cbdf-4c36-9c16-017009b3b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-3df32d72-502f-4a41-b2e4-97337da4fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-a3d29914-a33e-4b53-82b0-33a85f9d1c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470993797-172.17.0.11-1596955792466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46648,DS-aad356ee-c4d7-4ffa-ba6c-4072ab7a8a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-840a8b74-7bbd-4225-90f9-128c3c785948,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-0df914e3-0338-4a58-87b3-a54c837739ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-7ac97156-b6e7-41ba-8a8c-62774d5723e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-7cfa2291-8038-4a04-a8ae-a3e0d5385a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-ec7ffb15-6680-4cd2-bbf4-6c80e5034a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-0f4770e8-dc60-46c0-9e26-bf6c3967a65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-48566040-5940-4bf6-9f6d-bbca385a05d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470993797-172.17.0.11-1596955792466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46648,DS-aad356ee-c4d7-4ffa-ba6c-4072ab7a8a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-840a8b74-7bbd-4225-90f9-128c3c785948,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-0df914e3-0338-4a58-87b3-a54c837739ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-7ac97156-b6e7-41ba-8a8c-62774d5723e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-7cfa2291-8038-4a04-a8ae-a3e0d5385a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-ec7ffb15-6680-4cd2-bbf4-6c80e5034a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-0f4770e8-dc60-46c0-9e26-bf6c3967a65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-48566040-5940-4bf6-9f6d-bbca385a05d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418622817-172.17.0.11-1596956195605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43451,DS-e3d4ae08-9248-43dc-8b62-dc9e99725821,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-3f7170c1-0497-4a7c-89c9-9dd7c1cebfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-8b55ce64-550d-495a-947f-75b8e46b9915,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-6fd1983b-fdd5-41cb-80c0-82cb1cdd8162,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-1bd12b7b-bafc-489e-94b6-2efda11a24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-833e2dba-cdac-4aa1-832d-7aa67e640f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-3443e9e7-6f4c-47ce-861a-bf867a2166a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-74cc4e35-83c4-4579-8b3c-4e6fd3d0b878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418622817-172.17.0.11-1596956195605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43451,DS-e3d4ae08-9248-43dc-8b62-dc9e99725821,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-3f7170c1-0497-4a7c-89c9-9dd7c1cebfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-8b55ce64-550d-495a-947f-75b8e46b9915,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-6fd1983b-fdd5-41cb-80c0-82cb1cdd8162,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-1bd12b7b-bafc-489e-94b6-2efda11a24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-833e2dba-cdac-4aa1-832d-7aa67e640f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-3443e9e7-6f4c-47ce-861a-bf867a2166a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-74cc4e35-83c4-4579-8b3c-4e6fd3d0b878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18308158-172.17.0.11-1596956452964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-feaa10bb-7fc1-41d3-b42a-3946e77f0771,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-17844c9a-e4ee-4baf-ba12-17ec3020ee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-2304f599-34e6-4b57-85df-63ca14d3b45a,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-72e4cac8-9993-4fa5-b344-a844bf60e026,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-9a7c7c2f-7be8-4179-9677-6a91fa15a92f,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-00805074-e46f-4e7b-80fd-dbb7f3f3a586,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b0443459-ad79-4d32-9924-7785f2485e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-d470a6e8-707d-4708-8b4c-f7e7ef8bd660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18308158-172.17.0.11-1596956452964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-feaa10bb-7fc1-41d3-b42a-3946e77f0771,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-17844c9a-e4ee-4baf-ba12-17ec3020ee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-2304f599-34e6-4b57-85df-63ca14d3b45a,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-72e4cac8-9993-4fa5-b344-a844bf60e026,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-9a7c7c2f-7be8-4179-9677-6a91fa15a92f,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-00805074-e46f-4e7b-80fd-dbb7f3f3a586,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b0443459-ad79-4d32-9924-7785f2485e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-d470a6e8-707d-4708-8b4c-f7e7ef8bd660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903438180-172.17.0.11-1596956490328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-0396c062-7152-45fd-bc80-c5da0a311407,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-ecaff0e0-9799-408e-8110-9fd2c10081b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-0e523432-4b5a-4781-b810-5bd5070ed87a,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-38f23528-ca82-4820-97bd-fec490021892,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-99c99df8-e776-4c02-bd82-80a288b3b986,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-6573161f-d8c7-4bd8-9444-ccb416c51ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-110ea1ec-97d9-453a-bca7-2ddb8ca8263f,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-ed63cf14-70e0-4beb-b985-c50e2e5973f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903438180-172.17.0.11-1596956490328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-0396c062-7152-45fd-bc80-c5da0a311407,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-ecaff0e0-9799-408e-8110-9fd2c10081b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-0e523432-4b5a-4781-b810-5bd5070ed87a,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-38f23528-ca82-4820-97bd-fec490021892,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-99c99df8-e776-4c02-bd82-80a288b3b986,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-6573161f-d8c7-4bd8-9444-ccb416c51ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-110ea1ec-97d9-453a-bca7-2ddb8ca8263f,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-ed63cf14-70e0-4beb-b985-c50e2e5973f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062030770-172.17.0.11-1596956706474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38365,DS-94a4dd72-1540-4972-b400-32d209cb03d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-2ec2ee38-d426-4bb8-9d88-dd8f8592725b,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-6135bf82-2f8d-4824-9c9a-71287d245189,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-57b1b516-49a3-4816-959b-37fe1c5fd3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-2fa9ba65-f5cb-4f73-8da3-034dad562f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-5f85600a-a96b-4693-8c59-e5fb5de0d358,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-243b7321-1537-4376-ba48-4aa9fea1d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-f99339d6-7fe8-48f3-9a7e-3cd0ec738011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062030770-172.17.0.11-1596956706474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38365,DS-94a4dd72-1540-4972-b400-32d209cb03d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-2ec2ee38-d426-4bb8-9d88-dd8f8592725b,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-6135bf82-2f8d-4824-9c9a-71287d245189,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-57b1b516-49a3-4816-959b-37fe1c5fd3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-2fa9ba65-f5cb-4f73-8da3-034dad562f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-5f85600a-a96b-4693-8c59-e5fb5de0d358,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-243b7321-1537-4376-ba48-4aa9fea1d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-f99339d6-7fe8-48f3-9a7e-3cd0ec738011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986283182-172.17.0.11-1596956935206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44179,DS-c11922da-8026-489e-b2fd-c392b3413349,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-fe4e104a-2e19-42b2-b19d-4f0fc318aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-fe890079-c2f2-4f0c-85ba-d5a7271a4f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-082c4e1a-2c23-4831-ac38-5e3b0d0c7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-ca3864cb-32f2-44eb-9da5-fe5502b92018,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-f8b10882-9b9f-44a3-9484-4cac7d5c6dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-02f0447c-5c50-45a0-a1f9-7401302fcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-4553dc2d-3d41-479d-8aab-60e6c0481b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986283182-172.17.0.11-1596956935206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44179,DS-c11922da-8026-489e-b2fd-c392b3413349,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-fe4e104a-2e19-42b2-b19d-4f0fc318aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-fe890079-c2f2-4f0c-85ba-d5a7271a4f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-082c4e1a-2c23-4831-ac38-5e3b0d0c7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-ca3864cb-32f2-44eb-9da5-fe5502b92018,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-f8b10882-9b9f-44a3-9484-4cac7d5c6dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-02f0447c-5c50-45a0-a1f9-7401302fcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-4553dc2d-3d41-479d-8aab-60e6c0481b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5473
