reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588464880-172.17.0.16-1595369043202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41341,DS-da0004d0-fb8b-425d-a85d-b5c955a8b610,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-5543b72c-c367-4bb7-9e72-083843a608ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-9df4b28b-87f6-4ca9-b1e9-5193c82ec2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-1858a699-d7d6-4469-b68f-9fae4656343b,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-e0ff79b6-049d-4cbd-b73e-d65013c16ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-699b1af6-2778-46bc-af11-500ccb167cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-50457ade-f2a9-464c-b70f-fc953e922f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-1b703421-daab-426d-b89b-0cccbe885fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588464880-172.17.0.16-1595369043202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41341,DS-da0004d0-fb8b-425d-a85d-b5c955a8b610,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-5543b72c-c367-4bb7-9e72-083843a608ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-9df4b28b-87f6-4ca9-b1e9-5193c82ec2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-1858a699-d7d6-4469-b68f-9fae4656343b,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-e0ff79b6-049d-4cbd-b73e-d65013c16ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-699b1af6-2778-46bc-af11-500ccb167cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-50457ade-f2a9-464c-b70f-fc953e922f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-1b703421-daab-426d-b89b-0cccbe885fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838396818-172.17.0.16-1595369306087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-c4341cec-4848-4945-93ca-07f3c3ad0d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-5c435fef-41e6-4fb6-95a4-98132ce87182,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-3135beea-cddb-4167-bb62-66172fca846f,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-3c1957b9-413c-4fbd-b321-4c43d1f061f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5fc50a36-7963-4204-8a47-b4cc088b3875,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-38d2b754-f6c3-47a1-bbb9-e9c939276e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-1806ad1c-1930-498f-ad55-109d9ef0f510,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-ec57c821-ce45-43f2-992c-afeadd896ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838396818-172.17.0.16-1595369306087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-c4341cec-4848-4945-93ca-07f3c3ad0d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-5c435fef-41e6-4fb6-95a4-98132ce87182,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-3135beea-cddb-4167-bb62-66172fca846f,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-3c1957b9-413c-4fbd-b321-4c43d1f061f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5fc50a36-7963-4204-8a47-b4cc088b3875,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-38d2b754-f6c3-47a1-bbb9-e9c939276e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-1806ad1c-1930-498f-ad55-109d9ef0f510,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-ec57c821-ce45-43f2-992c-afeadd896ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286823812-172.17.0.16-1595369733360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-3d03fb3f-0bc3-419a-8b0b-41fbc3c67fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-2bb9687e-789c-4022-9f39-accb7893f193,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-6bfaed8b-b8d5-414c-a78a-14f9c4263ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-be780942-69e9-4783-9216-35bd24d77cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-de85c9f9-bb32-4e7c-921c-687e08595525,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-14761e39-c301-4b6e-bdf0-54fa02989c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-afedab24-70ab-4273-8038-36140bcb99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-9b06e175-4a4b-401d-840a-a4273cf2f628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286823812-172.17.0.16-1595369733360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-3d03fb3f-0bc3-419a-8b0b-41fbc3c67fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-2bb9687e-789c-4022-9f39-accb7893f193,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-6bfaed8b-b8d5-414c-a78a-14f9c4263ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-be780942-69e9-4783-9216-35bd24d77cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-de85c9f9-bb32-4e7c-921c-687e08595525,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-14761e39-c301-4b6e-bdf0-54fa02989c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-afedab24-70ab-4273-8038-36140bcb99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-9b06e175-4a4b-401d-840a-a4273cf2f628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595538303-172.17.0.16-1595369907263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-706e7955-703d-4f96-a8a3-869fd1422f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9b30ed80-e9fa-40d7-b6a2-c8741b5f866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-ba314f34-5931-4edf-b217-f404faf1469c,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-d071ee1a-69b5-4784-8d79-3e9c75ab2e44,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-0f194d07-6ad1-433a-9aee-a5552acb3689,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-e62cc0ce-a876-44d6-9f32-5daca8bcce07,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-f1dfb0e6-24ec-4800-b061-87e33ba39f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-9283a769-4224-4593-a254-f2571d4370d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595538303-172.17.0.16-1595369907263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-706e7955-703d-4f96-a8a3-869fd1422f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9b30ed80-e9fa-40d7-b6a2-c8741b5f866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-ba314f34-5931-4edf-b217-f404faf1469c,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-d071ee1a-69b5-4784-8d79-3e9c75ab2e44,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-0f194d07-6ad1-433a-9aee-a5552acb3689,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-e62cc0ce-a876-44d6-9f32-5daca8bcce07,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-f1dfb0e6-24ec-4800-b061-87e33ba39f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-9283a769-4224-4593-a254-f2571d4370d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535879574-172.17.0.16-1595369936959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-af70cfbc-db9e-4a51-aa48-ea71851cb63a,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-d286aee9-dfdb-4ed2-b3b1-dd32fd705ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-c5bb3254-ef02-42a7-8533-394d13d5a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-3be8a106-70b8-448b-911f-8c580f35c98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-6f0d178b-0c46-4c3a-9600-809fec729834,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-67d040c1-6f98-4f0d-b51b-04b4814b4035,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-3efc7a39-ec72-4e30-8e6a-c17bdbf8f8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-e7aadfa7-41e5-4457-93ee-983597e4a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535879574-172.17.0.16-1595369936959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-af70cfbc-db9e-4a51-aa48-ea71851cb63a,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-d286aee9-dfdb-4ed2-b3b1-dd32fd705ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-c5bb3254-ef02-42a7-8533-394d13d5a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-3be8a106-70b8-448b-911f-8c580f35c98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-6f0d178b-0c46-4c3a-9600-809fec729834,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-67d040c1-6f98-4f0d-b51b-04b4814b4035,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-3efc7a39-ec72-4e30-8e6a-c17bdbf8f8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-e7aadfa7-41e5-4457-93ee-983597e4a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067566384-172.17.0.16-1595370731326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-50ace352-7f9d-442b-9fed-c0d610ab6920,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-25d18b28-963e-4ef8-9563-d7c240c8ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-40892230-faa1-44c8-a709-414b9d775d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-4d17a00d-bd40-4837-aad9-f840ee890e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-1b7fdc4a-f919-46d1-a131-722403cf6881,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-befdf3eb-fffa-4d36-a360-5fb9213e3210,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-80a69b21-7836-47c9-9fda-d6cd3d9e5b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-f6a03a73-4ca7-460b-a85d-095a7969c132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067566384-172.17.0.16-1595370731326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-50ace352-7f9d-442b-9fed-c0d610ab6920,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-25d18b28-963e-4ef8-9563-d7c240c8ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-40892230-faa1-44c8-a709-414b9d775d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-4d17a00d-bd40-4837-aad9-f840ee890e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-1b7fdc4a-f919-46d1-a131-722403cf6881,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-befdf3eb-fffa-4d36-a360-5fb9213e3210,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-80a69b21-7836-47c9-9fda-d6cd3d9e5b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-f6a03a73-4ca7-460b-a85d-095a7969c132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455582994-172.17.0.16-1595370915571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-914afd67-eae3-41d2-83ce-c5dfd1b628c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-fe43b420-642d-48e4-9c17-94cac7ee8967,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9d0a7ae5-f59a-4fbe-b734-481f1d8562f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-afb330f7-4392-4b1a-83c9-a562fc8372f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-fc00442e-8d7d-4576-a40b-c1d82b69a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-c4ec5bd2-5e82-46b2-aef6-ecd70564f416,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-c877b43a-e591-4621-8f67-66ea6c78d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a1c1b4e9-0b3f-4ffb-a33b-30dff2e5079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455582994-172.17.0.16-1595370915571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-914afd67-eae3-41d2-83ce-c5dfd1b628c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-fe43b420-642d-48e4-9c17-94cac7ee8967,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9d0a7ae5-f59a-4fbe-b734-481f1d8562f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-afb330f7-4392-4b1a-83c9-a562fc8372f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-fc00442e-8d7d-4576-a40b-c1d82b69a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-c4ec5bd2-5e82-46b2-aef6-ecd70564f416,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-c877b43a-e591-4621-8f67-66ea6c78d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a1c1b4e9-0b3f-4ffb-a33b-30dff2e5079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181501326-172.17.0.16-1595371113355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-2f8e3073-f7e8-4b49-82b2-c4c5e47132d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-115d8071-a062-4295-b4d8-d150e41aa815,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-3a91af6e-7d37-44b6-a34d-750020fbfc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-d9b9a84e-00d3-4222-90dc-642cc472416b,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-9ab327f6-9211-4242-90bc-fe4c286faaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-8a9706b0-abe6-4ffe-bf3f-ae04b2a03f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-144b41b7-7097-4732-ab6b-166bdbd2e519,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-72a312a7-cd60-4b19-8b22-781bd1c4f42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181501326-172.17.0.16-1595371113355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-2f8e3073-f7e8-4b49-82b2-c4c5e47132d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-115d8071-a062-4295-b4d8-d150e41aa815,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-3a91af6e-7d37-44b6-a34d-750020fbfc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-d9b9a84e-00d3-4222-90dc-642cc472416b,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-9ab327f6-9211-4242-90bc-fe4c286faaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-8a9706b0-abe6-4ffe-bf3f-ae04b2a03f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-144b41b7-7097-4732-ab6b-166bdbd2e519,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-72a312a7-cd60-4b19-8b22-781bd1c4f42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002147978-172.17.0.16-1595371512975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44673,DS-54d5d1b2-afa3-4eea-903b-9580c333645f,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-c15094d4-dd17-431e-8732-ac87211e3ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-8e85c32e-f73b-461e-8928-22cfd320be36,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-d2c6971c-e2be-410a-9e5d-b187e59dcfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-c53d99e6-c4c0-4f8a-872d-5ff222906697,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-a59ae701-ece3-4933-b76b-79b34e325787,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-1c80a3a5-00c1-4469-a93a-1a0f2d9bb917,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-f3955c52-8277-41a9-ab19-fe96d2391bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002147978-172.17.0.16-1595371512975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44673,DS-54d5d1b2-afa3-4eea-903b-9580c333645f,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-c15094d4-dd17-431e-8732-ac87211e3ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-8e85c32e-f73b-461e-8928-22cfd320be36,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-d2c6971c-e2be-410a-9e5d-b187e59dcfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-c53d99e6-c4c0-4f8a-872d-5ff222906697,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-a59ae701-ece3-4933-b76b-79b34e325787,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-1c80a3a5-00c1-4469-a93a-1a0f2d9bb917,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-f3955c52-8277-41a9-ab19-fe96d2391bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67997539-172.17.0.16-1595371701512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-77b0c37e-37f5-49ec-896c-598b115aa562,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-8bd02817-aa45-4689-9f7b-08fcdb5d66b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-9da6a1cc-043d-4e82-a25e-5d6d34ea14cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-26b13542-6c4f-40d1-a2f8-d45973096ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-4ed5ecc1-bbd9-4e97-a487-216300af84e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6e24b463-9116-49d3-b53e-179e42f83be7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-31140cc1-ae70-4cd0-aac7-50e09ae8f624,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-467ae789-9333-4c6f-a6cd-2df51f03bf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67997539-172.17.0.16-1595371701512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-77b0c37e-37f5-49ec-896c-598b115aa562,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-8bd02817-aa45-4689-9f7b-08fcdb5d66b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-9da6a1cc-043d-4e82-a25e-5d6d34ea14cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-26b13542-6c4f-40d1-a2f8-d45973096ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-4ed5ecc1-bbd9-4e97-a487-216300af84e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6e24b463-9116-49d3-b53e-179e42f83be7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-31140cc1-ae70-4cd0-aac7-50e09ae8f624,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-467ae789-9333-4c6f-a6cd-2df51f03bf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833043674-172.17.0.16-1595371804462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-daeda8a1-323e-417b-80bb-10725009ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-e44ca417-551f-4be7-a8f8-c5b188421393,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-7927f89d-881d-4e47-a409-d8169f995f56,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-28c9c3fc-e995-4701-b81f-9fbe73c5c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-1d1384ab-b339-443b-8790-69755d249371,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-31a2d3ff-2184-4600-81ae-2b060a13b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3860f5a2-8019-4c7a-bc91-a0ef945253d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-22cc2bb8-1e52-4cca-bb9d-f0554ae9fa60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833043674-172.17.0.16-1595371804462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-daeda8a1-323e-417b-80bb-10725009ce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-e44ca417-551f-4be7-a8f8-c5b188421393,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-7927f89d-881d-4e47-a409-d8169f995f56,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-28c9c3fc-e995-4701-b81f-9fbe73c5c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-1d1384ab-b339-443b-8790-69755d249371,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-31a2d3ff-2184-4600-81ae-2b060a13b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3860f5a2-8019-4c7a-bc91-a0ef945253d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-22cc2bb8-1e52-4cca-bb9d-f0554ae9fa60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800021005-172.17.0.16-1595372040165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-6eaa9ca6-b49e-4823-9c70-93297013e152,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-5af7bc46-8e87-4245-86e0-e7ecbf77268c,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-9971baff-9d40-49ce-886a-fecd1761b061,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-630e8efd-a35e-4837-9f91-f1163e3f8038,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-9af2ad44-02c5-4953-a1b0-7096784cebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-92cb3996-da71-4e03-93cb-c075202676cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-ec0b8029-0d0c-462d-b644-ffccf97ae4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-2aac18b4-7f01-4591-87c6-fd48e1872daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800021005-172.17.0.16-1595372040165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-6eaa9ca6-b49e-4823-9c70-93297013e152,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-5af7bc46-8e87-4245-86e0-e7ecbf77268c,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-9971baff-9d40-49ce-886a-fecd1761b061,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-630e8efd-a35e-4837-9f91-f1163e3f8038,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-9af2ad44-02c5-4953-a1b0-7096784cebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-92cb3996-da71-4e03-93cb-c075202676cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-ec0b8029-0d0c-462d-b644-ffccf97ae4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-2aac18b4-7f01-4591-87c6-fd48e1872daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581280274-172.17.0.16-1595372519185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37568,DS-3fa8b54d-ac0d-4097-bf40-2c6ffce76bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-2ed781df-8c53-4920-b83e-a8b355de2a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-76a3a936-f863-4b28-9679-ae5066c653b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-0fb6bc77-2d7a-4087-a0aa-d5d7773de0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-773afda0-5f02-4ea5-a801-854b751e8b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-11f3b155-b1e5-4566-adc7-54a827352383,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-92b7e4c4-30cf-49b7-a354-058cd5a9030c,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-2de21484-1231-4ffa-baba-1d89776451cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581280274-172.17.0.16-1595372519185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37568,DS-3fa8b54d-ac0d-4097-bf40-2c6ffce76bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-2ed781df-8c53-4920-b83e-a8b355de2a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-76a3a936-f863-4b28-9679-ae5066c653b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-0fb6bc77-2d7a-4087-a0aa-d5d7773de0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-773afda0-5f02-4ea5-a801-854b751e8b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-11f3b155-b1e5-4566-adc7-54a827352383,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-92b7e4c4-30cf-49b7-a354-058cd5a9030c,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-2de21484-1231-4ffa-baba-1d89776451cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629434143-172.17.0.16-1595372714495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33147,DS-b3dd0229-9966-49c2-bf65-9f31fa597ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-97af679b-ce1f-4080-83a1-727d924aed14,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-04220b3e-8e16-4828-b180-2f8f3e179766,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-590b0314-7cc2-491e-8f20-7435e247fb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-8e918af6-fe98-4d99-8e22-98133978b6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-c4d4b450-cf60-477e-bf72-dc3334d29ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-ce030dfe-c9c0-484a-a54a-64ab8c3b724d,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-e88c7c5f-e5d2-4c36-a266-6b85b6ec1713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629434143-172.17.0.16-1595372714495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33147,DS-b3dd0229-9966-49c2-bf65-9f31fa597ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-97af679b-ce1f-4080-83a1-727d924aed14,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-04220b3e-8e16-4828-b180-2f8f3e179766,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-590b0314-7cc2-491e-8f20-7435e247fb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-8e918af6-fe98-4d99-8e22-98133978b6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-c4d4b450-cf60-477e-bf72-dc3334d29ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-ce030dfe-c9c0-484a-a54a-64ab8c3b724d,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-e88c7c5f-e5d2-4c36-a266-6b85b6ec1713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086912674-172.17.0.16-1595372987309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39860,DS-2332bfbf-e8a8-475b-910d-03cd6b00739c,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-aa4f4d40-11d9-471a-9d2d-6d638dc58f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-6a574df6-288e-4d06-9aaf-2f9f6f5f2c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-c2f5eebd-9faa-4781-a98e-ddaad428f02d,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-4ad8be4c-3549-4141-b26b-3ed89e222189,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-8bf12b49-081b-4ac2-878b-a7065f5fb27f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-3f36e6dc-c965-4802-977a-c74fd789302b,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-75225bc5-1fcd-4a8a-91a0-e79119c774b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086912674-172.17.0.16-1595372987309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39860,DS-2332bfbf-e8a8-475b-910d-03cd6b00739c,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-aa4f4d40-11d9-471a-9d2d-6d638dc58f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-6a574df6-288e-4d06-9aaf-2f9f6f5f2c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-c2f5eebd-9faa-4781-a98e-ddaad428f02d,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-4ad8be4c-3549-4141-b26b-3ed89e222189,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-8bf12b49-081b-4ac2-878b-a7065f5fb27f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-3f36e6dc-c965-4802-977a-c74fd789302b,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-75225bc5-1fcd-4a8a-91a0-e79119c774b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507395774-172.17.0.16-1595373057262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-88ad14eb-52ef-4d22-a4a4-aef646da65da,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-2aa89a5d-0b33-4077-97c7-6197248bee32,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-752702ea-f39e-451e-841a-6c8276649296,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-c12ede26-4185-47ad-954d-6dcf770ab620,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-bad7b664-18c1-4ceb-85e2-662ecdcfb3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-47f97e64-53aa-4713-a24d-ec77625318a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-d6027af1-07fe-43e0-82e8-7c875a764fce,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-36779aae-05aa-4fd4-aabf-01cb02ff85b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507395774-172.17.0.16-1595373057262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-88ad14eb-52ef-4d22-a4a4-aef646da65da,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-2aa89a5d-0b33-4077-97c7-6197248bee32,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-752702ea-f39e-451e-841a-6c8276649296,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-c12ede26-4185-47ad-954d-6dcf770ab620,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-bad7b664-18c1-4ceb-85e2-662ecdcfb3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-47f97e64-53aa-4713-a24d-ec77625318a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-d6027af1-07fe-43e0-82e8-7c875a764fce,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-36779aae-05aa-4fd4-aabf-01cb02ff85b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329265391-172.17.0.16-1595373649525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42760,DS-3b511928-3b3f-46a3-b9d9-450e1ee56621,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-c7ba2b00-ec34-419b-835b-be1308454405,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-93ec7cf7-7086-4ac8-ad12-e458241a4848,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-28b74afd-49bd-40bc-9fce-a6b78275ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-1aa621f5-e4b6-4710-b78b-9204688fe460,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4deacf95-4f0c-43b5-b222-44d3dbd90d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-7d70ef7a-2950-470b-905f-699b61c5aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-3b57c9a7-05e0-400b-9326-9b160eea96e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329265391-172.17.0.16-1595373649525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42760,DS-3b511928-3b3f-46a3-b9d9-450e1ee56621,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-c7ba2b00-ec34-419b-835b-be1308454405,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-93ec7cf7-7086-4ac8-ad12-e458241a4848,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-28b74afd-49bd-40bc-9fce-a6b78275ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-1aa621f5-e4b6-4710-b78b-9204688fe460,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4deacf95-4f0c-43b5-b222-44d3dbd90d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-7d70ef7a-2950-470b-905f-699b61c5aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-3b57c9a7-05e0-400b-9326-9b160eea96e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787283598-172.17.0.16-1595373758563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39526,DS-4f7e6212-ea7a-48e6-87c4-6d60c2465ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-e795de82-b80a-4bdd-8eb8-52e29a045a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-22164897-9c6e-49b6-8619-9852fa3625f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-023d127b-a237-4bf9-ba87-9bdcf0274a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-117cdd00-1c51-4021-9550-a1569e07cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-7f04731b-72fa-4d5f-8057-1ed6740a9f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c0f499c3-5982-4f47-b1af-cb922c158792,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-b629e324-850e-424b-8a9a-0a4d863c25b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787283598-172.17.0.16-1595373758563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39526,DS-4f7e6212-ea7a-48e6-87c4-6d60c2465ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-e795de82-b80a-4bdd-8eb8-52e29a045a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-22164897-9c6e-49b6-8619-9852fa3625f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-023d127b-a237-4bf9-ba87-9bdcf0274a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-117cdd00-1c51-4021-9550-a1569e07cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-7f04731b-72fa-4d5f-8057-1ed6740a9f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c0f499c3-5982-4f47-b1af-cb922c158792,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-b629e324-850e-424b-8a9a-0a4d863c25b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82947554-172.17.0.16-1595373854265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-ea9036fc-2ad9-46d8-91d4-948c39bb90f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-897f6a07-7575-41eb-b8d5-a8b723985500,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-4782a456-5479-458f-b190-db4570514cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-e9a21b8d-51bc-4206-a8be-7c209a08fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-c7bd0bbb-fb62-4db8-b616-84f3b219e925,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-994cb2a0-ead4-4dc6-8ba6-3ca726995cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-631d006b-d114-47d1-83e3-270081cc6d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-656b84f2-81eb-40ae-b29f-4ae0fb6f21b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82947554-172.17.0.16-1595373854265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-ea9036fc-2ad9-46d8-91d4-948c39bb90f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-897f6a07-7575-41eb-b8d5-a8b723985500,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-4782a456-5479-458f-b190-db4570514cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-e9a21b8d-51bc-4206-a8be-7c209a08fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-c7bd0bbb-fb62-4db8-b616-84f3b219e925,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-994cb2a0-ead4-4dc6-8ba6-3ca726995cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-631d006b-d114-47d1-83e3-270081cc6d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-656b84f2-81eb-40ae-b29f-4ae0fb6f21b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5231
