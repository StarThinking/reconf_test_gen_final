reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330292080-172.17.0.2-1596984199806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-4dd16f56-a913-4708-8145-5d4ce0b79666,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-40e93aed-7995-4a9c-bfe9-6f47e8b0e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-d060fdb3-b4f7-4d71-8b47-d8a823c53c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-14bbd445-afe3-42b6-934d-9ef3f7d9bacc,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-7fda2b98-fb14-4569-b742-539d6b24a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-90f32eb0-c902-4ca0-9f8c-5f276ad7fbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-aa323fc3-5b3c-4301-b0dc-af9726ed4090,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-4a921f95-742c-4b56-9e1c-49ca7d2c9ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330292080-172.17.0.2-1596984199806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-4dd16f56-a913-4708-8145-5d4ce0b79666,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-40e93aed-7995-4a9c-bfe9-6f47e8b0e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-d060fdb3-b4f7-4d71-8b47-d8a823c53c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-14bbd445-afe3-42b6-934d-9ef3f7d9bacc,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-7fda2b98-fb14-4569-b742-539d6b24a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-90f32eb0-c902-4ca0-9f8c-5f276ad7fbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-aa323fc3-5b3c-4301-b0dc-af9726ed4090,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-4a921f95-742c-4b56-9e1c-49ca7d2c9ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960546615-172.17.0.2-1596984342805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33680,DS-41a8ce31-189f-4c5b-bb2f-295339f6ae60,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-02959f61-15a9-4c14-9b00-6b3d277734ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-0c4835e2-ae8a-4937-b84e-69fb1f27ab5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-9d1a800e-9f57-4a51-9f34-5a140a44f328,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-75c7e901-9d77-4d5a-86f1-698bb6e3afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-cb4d708c-36e5-44d2-97d6-650be602f655,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-b2c62d9b-bf36-4b8c-98ff-f57496a71a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-b1326229-f7ec-45fd-8687-bfd38ebf6d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960546615-172.17.0.2-1596984342805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33680,DS-41a8ce31-189f-4c5b-bb2f-295339f6ae60,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-02959f61-15a9-4c14-9b00-6b3d277734ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-0c4835e2-ae8a-4937-b84e-69fb1f27ab5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-9d1a800e-9f57-4a51-9f34-5a140a44f328,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-75c7e901-9d77-4d5a-86f1-698bb6e3afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-cb4d708c-36e5-44d2-97d6-650be602f655,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-b2c62d9b-bf36-4b8c-98ff-f57496a71a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-b1326229-f7ec-45fd-8687-bfd38ebf6d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950077752-172.17.0.2-1596984678579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35283,DS-81ac706e-1b59-4d08-916d-f02d612d4f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-ccfe136e-6003-4b46-a5e3-a0afc6958b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-44dfc340-65c1-46a2-88cc-18ce394af044,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-f320993a-702d-4357-8343-8cd38a1bb93f,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-4f5c0311-234c-4125-8460-b1b0e26264a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-3a2269d3-9c21-4426-8396-ecedbfe83107,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-b239d7bb-8e61-4cf4-9073-8de75e8373f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-b1e10ea6-7473-43b7-ab16-5afe3c26177a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950077752-172.17.0.2-1596984678579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35283,DS-81ac706e-1b59-4d08-916d-f02d612d4f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-ccfe136e-6003-4b46-a5e3-a0afc6958b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-44dfc340-65c1-46a2-88cc-18ce394af044,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-f320993a-702d-4357-8343-8cd38a1bb93f,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-4f5c0311-234c-4125-8460-b1b0e26264a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-3a2269d3-9c21-4426-8396-ecedbfe83107,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-b239d7bb-8e61-4cf4-9073-8de75e8373f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-b1e10ea6-7473-43b7-ab16-5afe3c26177a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006490502-172.17.0.2-1596984882129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-bbc73b49-28cd-408b-bc01-7e186536387f,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-270f2251-7677-4442-bcdc-599f1ee82964,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-94997c96-e80d-4228-a863-85171e1d0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-477c962d-7004-42a0-bb90-2122755378ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-8907e4cb-45de-4a0c-9c45-afa530573f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c6fbdc77-4ed7-4364-a2a1-4e3ace082ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-d29d7fc9-fe6e-41b2-a4b0-2d967ba4aa09,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-855ff7d9-e43b-4533-9612-8da1d457ef60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006490502-172.17.0.2-1596984882129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-bbc73b49-28cd-408b-bc01-7e186536387f,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-270f2251-7677-4442-bcdc-599f1ee82964,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-94997c96-e80d-4228-a863-85171e1d0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-477c962d-7004-42a0-bb90-2122755378ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-8907e4cb-45de-4a0c-9c45-afa530573f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c6fbdc77-4ed7-4364-a2a1-4e3ace082ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-d29d7fc9-fe6e-41b2-a4b0-2d967ba4aa09,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-855ff7d9-e43b-4533-9612-8da1d457ef60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745419203-172.17.0.2-1596985019309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-b0a350f6-305b-4903-b43a-88648ff26bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-fa071641-10da-4563-8fe3-5a4bb50663f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-515772df-efb6-423c-8bdc-af049bdac303,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-f1558c3f-4e46-4f65-9000-21383a24669a,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-cc22e378-7927-4ab9-85ea-2c2af5ae87ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-face765d-408f-4613-8552-07e7ea3d6046,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-c652963e-a50f-4331-866d-1592788eb0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-4d6c9879-3c3f-495c-89bd-c67e7dc2c943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745419203-172.17.0.2-1596985019309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-b0a350f6-305b-4903-b43a-88648ff26bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-fa071641-10da-4563-8fe3-5a4bb50663f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-515772df-efb6-423c-8bdc-af049bdac303,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-f1558c3f-4e46-4f65-9000-21383a24669a,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-cc22e378-7927-4ab9-85ea-2c2af5ae87ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-face765d-408f-4613-8552-07e7ea3d6046,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-c652963e-a50f-4331-866d-1592788eb0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-4d6c9879-3c3f-495c-89bd-c67e7dc2c943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000674721-172.17.0.2-1596985163892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46652,DS-01db520f-7aae-479d-836b-d778367e69ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-41671138-0b03-4c26-8c1b-8df4e69f781e,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-af5f5aa8-42a8-411c-9924-9b429bad3d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-7b26378c-673f-418f-99f5-11385ab9d2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-3517e40f-2534-458c-bdcb-b576f5942573,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-1e5f23a1-30f1-491e-8bc3-9bbacc69ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-e267487f-0985-4584-a793-9dc4d4d7b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-c3dbedd5-e0b5-4493-a236-a3fbab1560c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000674721-172.17.0.2-1596985163892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46652,DS-01db520f-7aae-479d-836b-d778367e69ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-41671138-0b03-4c26-8c1b-8df4e69f781e,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-af5f5aa8-42a8-411c-9924-9b429bad3d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-7b26378c-673f-418f-99f5-11385ab9d2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-3517e40f-2534-458c-bdcb-b576f5942573,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-1e5f23a1-30f1-491e-8bc3-9bbacc69ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-e267487f-0985-4584-a793-9dc4d4d7b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-c3dbedd5-e0b5-4493-a236-a3fbab1560c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556707271-172.17.0.2-1596985482067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-154e1eea-ef2a-4bb5-bb87-08619f3de3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-c0a21b8e-b571-44f3-abaf-1ca18b86668c,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-166d81c9-b451-4aee-b77c-d750047a3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-6584e9f3-6e8f-4a22-83c5-f5cc162b860c,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-8bd21096-8380-4531-b092-307f2ea6085f,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-061913d5-8c6e-45d2-83d1-f51928d65f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-2c4634d1-e882-4eb4-9e84-d139a85e93b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-22846b1c-c7fe-4f4a-ba03-22e9cb2c0cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556707271-172.17.0.2-1596985482067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-154e1eea-ef2a-4bb5-bb87-08619f3de3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-c0a21b8e-b571-44f3-abaf-1ca18b86668c,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-166d81c9-b451-4aee-b77c-d750047a3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-6584e9f3-6e8f-4a22-83c5-f5cc162b860c,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-8bd21096-8380-4531-b092-307f2ea6085f,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-061913d5-8c6e-45d2-83d1-f51928d65f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-2c4634d1-e882-4eb4-9e84-d139a85e93b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-22846b1c-c7fe-4f4a-ba03-22e9cb2c0cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027918943-172.17.0.2-1596986211657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-cc3590b0-f302-4643-976d-ce3dfc15dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-cd69facd-83bd-4cd2-ac5f-3e6d7a2b196b,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-06deccf5-cf3d-4ebb-8830-df82368deb25,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-5a3f3e1f-f84b-4205-879f-f0e975e837a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-1e05a1e5-7aa4-4746-b141-1fb23c6c4e41,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-bb5576f5-4f7f-4257-882c-33dd020aee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-5eb7f153-2f16-486c-9799-5cce789213f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-d2613826-eaa5-4bdc-8ed6-6b7db73af436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027918943-172.17.0.2-1596986211657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-cc3590b0-f302-4643-976d-ce3dfc15dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-cd69facd-83bd-4cd2-ac5f-3e6d7a2b196b,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-06deccf5-cf3d-4ebb-8830-df82368deb25,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-5a3f3e1f-f84b-4205-879f-f0e975e837a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-1e05a1e5-7aa4-4746-b141-1fb23c6c4e41,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-bb5576f5-4f7f-4257-882c-33dd020aee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-5eb7f153-2f16-486c-9799-5cce789213f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-d2613826-eaa5-4bdc-8ed6-6b7db73af436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462421844-172.17.0.2-1596986449128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-eee8c1a8-d44b-4ca6-8e15-acd8b3a41a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-67550ffa-aafd-4fea-95e6-e79e3ce1a908,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-adbbf610-c3d4-424b-9f76-aa09dafff566,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-a1fd7ee6-4df5-4c1b-a6dc-b219ebaffb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-1efd515b-b591-41e7-b0ae-3cdcb3fb16ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-ab176ad9-08aa-41b7-8c9d-e945bcda6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-d6aea219-97a4-4dc2-bfa6-e5f28d8fdfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-2c756412-98d9-4238-b5da-7beb8cf26b56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462421844-172.17.0.2-1596986449128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-eee8c1a8-d44b-4ca6-8e15-acd8b3a41a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-67550ffa-aafd-4fea-95e6-e79e3ce1a908,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-adbbf610-c3d4-424b-9f76-aa09dafff566,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-a1fd7ee6-4df5-4c1b-a6dc-b219ebaffb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-1efd515b-b591-41e7-b0ae-3cdcb3fb16ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-ab176ad9-08aa-41b7-8c9d-e945bcda6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-d6aea219-97a4-4dc2-bfa6-e5f28d8fdfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-2c756412-98d9-4238-b5da-7beb8cf26b56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156930683-172.17.0.2-1596987171498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35748,DS-18a4b2c1-5e3d-4391-94a5-d8771f65fe53,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-738d8e05-877c-41bb-af7a-190731bfcf37,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-24c6907c-2634-4de4-89ef-a3073f4e2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-1ddfa198-cf18-4038-9fc4-366b71b9f7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-bee9b203-ece3-4ef0-a462-8d397e55ff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-a4f82b3d-9eff-4423-9a8e-59ceeb16a5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-3e58a1eb-2ebd-41a4-b94c-a3c22c80253e,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-76aa38b4-135c-4ff4-805f-11c1ac96172e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156930683-172.17.0.2-1596987171498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35748,DS-18a4b2c1-5e3d-4391-94a5-d8771f65fe53,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-738d8e05-877c-41bb-af7a-190731bfcf37,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-24c6907c-2634-4de4-89ef-a3073f4e2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-1ddfa198-cf18-4038-9fc4-366b71b9f7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-bee9b203-ece3-4ef0-a462-8d397e55ff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-a4f82b3d-9eff-4423-9a8e-59ceeb16a5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-3e58a1eb-2ebd-41a4-b94c-a3c22c80253e,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-76aa38b4-135c-4ff4-805f-11c1ac96172e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590664111-172.17.0.2-1596987528655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42425,DS-7245f724-ef94-4101-8f17-b4dcf06e032f,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-2cee0c2b-e50d-45d8-9307-6d2a59ca27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-f944bc05-1672-4e8a-be68-a1d0a20bbd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-88cfec80-0875-4e32-935c-874515f48e42,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-59c41894-687d-4368-a3ad-0d6ac3a794af,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-a66749d4-a838-4918-ad06-2e82511121f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-6894379a-fae9-416a-93f9-299a2ef74431,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-d5d7932f-ceb3-4457-a64a-e9ca86c004db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590664111-172.17.0.2-1596987528655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42425,DS-7245f724-ef94-4101-8f17-b4dcf06e032f,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-2cee0c2b-e50d-45d8-9307-6d2a59ca27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-f944bc05-1672-4e8a-be68-a1d0a20bbd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-88cfec80-0875-4e32-935c-874515f48e42,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-59c41894-687d-4368-a3ad-0d6ac3a794af,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-a66749d4-a838-4918-ad06-2e82511121f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-6894379a-fae9-416a-93f9-299a2ef74431,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-d5d7932f-ceb3-4457-a64a-e9ca86c004db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980922717-172.17.0.2-1596987644150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43571,DS-e8caecbb-147c-4fbb-a4c3-595411844c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-d9566991-89c8-4710-81b8-f2cf5ed6d16b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-9750bd7f-35ec-4827-9afb-b194690c6f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-ad512b64-aa2f-4159-84db-9bda17a39d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-c34f78ae-ffb9-4e09-8cc0-de3deea246a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-a2ec8aec-c349-4e02-9d2a-412017bf1b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-a432b922-75f9-43e6-b1b1-a1e68b5b8b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-1d931d95-82d9-43ba-95b7-7b4ed4f5bcf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980922717-172.17.0.2-1596987644150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43571,DS-e8caecbb-147c-4fbb-a4c3-595411844c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-d9566991-89c8-4710-81b8-f2cf5ed6d16b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-9750bd7f-35ec-4827-9afb-b194690c6f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-ad512b64-aa2f-4159-84db-9bda17a39d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-c34f78ae-ffb9-4e09-8cc0-de3deea246a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-a2ec8aec-c349-4e02-9d2a-412017bf1b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-a432b922-75f9-43e6-b1b1-a1e68b5b8b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-1d931d95-82d9-43ba-95b7-7b4ed4f5bcf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717546798-172.17.0.2-1596988155359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43758,DS-58d23017-fc73-49cd-a24f-ed93828e5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-5c064d37-d3c7-4661-9597-986ae1667e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-74580626-d5f3-4024-98ac-9a5710ef57a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-3eb5f1a5-ad26-4fc1-b297-48b4e5dd72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-d34d426e-af32-4940-9868-7f4a03bcf064,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-1afce40a-f3b1-4b2e-be38-cf73987a62af,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-6436d13d-45e5-4f69-98e8-ec401e3fff68,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-e143b9da-0cc6-45b8-91f1-90796800ce5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717546798-172.17.0.2-1596988155359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43758,DS-58d23017-fc73-49cd-a24f-ed93828e5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-5c064d37-d3c7-4661-9597-986ae1667e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-74580626-d5f3-4024-98ac-9a5710ef57a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-3eb5f1a5-ad26-4fc1-b297-48b4e5dd72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-d34d426e-af32-4940-9868-7f4a03bcf064,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-1afce40a-f3b1-4b2e-be38-cf73987a62af,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-6436d13d-45e5-4f69-98e8-ec401e3fff68,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-e143b9da-0cc6-45b8-91f1-90796800ce5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861588509-172.17.0.2-1596988567190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-dde94a7b-0078-43fd-88a8-3e0199e15d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-0b895cd4-7be0-4f91-ab88-fa8bb14ce644,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-62cb5b12-1cd3-4b75-afa2-ea08e6745e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-ffb47ecf-15ec-459e-b5f0-ff93f8b6d834,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-5d61e94e-0863-4a35-8d59-336f7f9ffe83,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-5a2f1fbd-4cea-4f33-8cea-135f8c850020,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-aea4c3b2-7ed9-4108-bb92-90d3440c8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-9aecf3b9-cb8e-444e-8084-03002dd233ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861588509-172.17.0.2-1596988567190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-dde94a7b-0078-43fd-88a8-3e0199e15d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-0b895cd4-7be0-4f91-ab88-fa8bb14ce644,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-62cb5b12-1cd3-4b75-afa2-ea08e6745e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-ffb47ecf-15ec-459e-b5f0-ff93f8b6d834,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-5d61e94e-0863-4a35-8d59-336f7f9ffe83,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-5a2f1fbd-4cea-4f33-8cea-135f8c850020,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-aea4c3b2-7ed9-4108-bb92-90d3440c8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-9aecf3b9-cb8e-444e-8084-03002dd233ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640520451-172.17.0.2-1596988585808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41591,DS-66581aef-5303-4da3-a0c4-49394242387a,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-d03ee8b8-3b13-4f6a-850a-a7a7b6f488a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-fb17613f-5ef1-4c16-b097-c0fdc566591b,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-dee8ef17-d539-4910-aa3f-3fa74b2d6700,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-b5aa2917-7d6d-45cc-ac54-8a8cb623e378,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-126359a1-b789-4262-997b-4dd26ec3a453,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-f46cf6cc-3907-41a7-95cc-3c0609df1d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-4157c4dd-95a0-4228-842f-94a32f6020e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640520451-172.17.0.2-1596988585808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41591,DS-66581aef-5303-4da3-a0c4-49394242387a,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-d03ee8b8-3b13-4f6a-850a-a7a7b6f488a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-fb17613f-5ef1-4c16-b097-c0fdc566591b,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-dee8ef17-d539-4910-aa3f-3fa74b2d6700,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-b5aa2917-7d6d-45cc-ac54-8a8cb623e378,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-126359a1-b789-4262-997b-4dd26ec3a453,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-f46cf6cc-3907-41a7-95cc-3c0609df1d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-4157c4dd-95a0-4228-842f-94a32f6020e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4632
