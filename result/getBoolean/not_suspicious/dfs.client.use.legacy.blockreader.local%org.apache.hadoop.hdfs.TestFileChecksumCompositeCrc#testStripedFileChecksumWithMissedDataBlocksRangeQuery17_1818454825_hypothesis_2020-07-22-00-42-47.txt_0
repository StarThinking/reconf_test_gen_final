reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256383953-172.17.0.18-1595378616383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-8564d3e4-93ad-4719-a481-ab3374858ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-f5bd49b2-6c1f-4f01-be16-98530dbcb803,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-0a49aea7-05ee-4b88-bea8-5fd487024554,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-6a8d06d2-55ec-49ca-8b05-d5c8d11752c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-2e9cbfea-ebed-4092-9a7d-0bd0dbd9cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-51fd53c0-e4e8-48b0-b2f9-b0fb9d7f1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-b935bb09-12c5-4e78-a299-97fff21b29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-83679193-d26f-4cdc-8cb5-8a82b881b062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256383953-172.17.0.18-1595378616383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-8564d3e4-93ad-4719-a481-ab3374858ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-f5bd49b2-6c1f-4f01-be16-98530dbcb803,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-0a49aea7-05ee-4b88-bea8-5fd487024554,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-6a8d06d2-55ec-49ca-8b05-d5c8d11752c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-2e9cbfea-ebed-4092-9a7d-0bd0dbd9cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-51fd53c0-e4e8-48b0-b2f9-b0fb9d7f1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-b935bb09-12c5-4e78-a299-97fff21b29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-83679193-d26f-4cdc-8cb5-8a82b881b062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495585372-172.17.0.18-1595378888066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-698e454f-d4a7-40d4-b3bf-d5806b98faf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-55415192-4baf-406a-9930-39cc9c35b9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-d2f1e584-520f-48c7-9be3-4a08a5d9cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-0e42641e-d46b-4cb3-82a7-2ac670eab307,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-5d5103c9-2642-47c7-9aa3-2c010a56de4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-e5487680-3489-494f-bb63-aca87807c08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-3d3f8f1a-1fe6-4545-8a91-ff5e383d3dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-80685f11-d699-4d7a-987c-35105c5ef165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495585372-172.17.0.18-1595378888066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-698e454f-d4a7-40d4-b3bf-d5806b98faf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-55415192-4baf-406a-9930-39cc9c35b9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-d2f1e584-520f-48c7-9be3-4a08a5d9cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-0e42641e-d46b-4cb3-82a7-2ac670eab307,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-5d5103c9-2642-47c7-9aa3-2c010a56de4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-e5487680-3489-494f-bb63-aca87807c08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-3d3f8f1a-1fe6-4545-8a91-ff5e383d3dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-80685f11-d699-4d7a-987c-35105c5ef165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597534204-172.17.0.18-1595379130367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-bda76b57-3816-4ca2-837e-9111bace5447,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-43e87c85-6dcb-47b5-a87a-6a360ac92bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-8ab28912-4a1d-448f-a428-e9ffe9b02d57,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-d72897fb-3d8e-472b-84d0-96430301eebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-61a2ecff-a7df-4a0a-ad44-3dd787bde177,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-08b98c5c-40c0-4a60-81a4-66df4dcf23e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-67935491-20db-41b8-950a-919ec888f596,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-3f450b85-7c97-4a64-a111-88b10c2dfbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597534204-172.17.0.18-1595379130367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-bda76b57-3816-4ca2-837e-9111bace5447,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-43e87c85-6dcb-47b5-a87a-6a360ac92bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-8ab28912-4a1d-448f-a428-e9ffe9b02d57,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-d72897fb-3d8e-472b-84d0-96430301eebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-61a2ecff-a7df-4a0a-ad44-3dd787bde177,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-08b98c5c-40c0-4a60-81a4-66df4dcf23e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-67935491-20db-41b8-950a-919ec888f596,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-3f450b85-7c97-4a64-a111-88b10c2dfbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685204634-172.17.0.18-1595379195778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-f903736f-8f5a-4f41-ae1d-adca7a27f385,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-07a3e66c-053c-4436-af00-e4f1107fd553,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-e2e3e60d-de0d-4d77-98f4-ae58f50da841,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-1c0993ad-0fc4-4a4f-b612-b49ffd5a9147,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-17e891df-d45d-4887-8571-ac76eabcc041,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-570cb1c5-d612-4383-866f-dc3e490735f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-420a3e97-6c54-4df2-a3b8-5fb94109d29e,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-ee103b59-ccfd-48c2-bd58-930210dadeb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685204634-172.17.0.18-1595379195778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-f903736f-8f5a-4f41-ae1d-adca7a27f385,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-07a3e66c-053c-4436-af00-e4f1107fd553,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-e2e3e60d-de0d-4d77-98f4-ae58f50da841,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-1c0993ad-0fc4-4a4f-b612-b49ffd5a9147,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-17e891df-d45d-4887-8571-ac76eabcc041,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-570cb1c5-d612-4383-866f-dc3e490735f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-420a3e97-6c54-4df2-a3b8-5fb94109d29e,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-ee103b59-ccfd-48c2-bd58-930210dadeb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086199786-172.17.0.18-1595379257229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41643,DS-a86f378c-6998-4695-843a-2261d0da032e,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-3d6282dd-c045-4d9c-9bc3-8f58bafa6425,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-f02b3843-32b7-456f-99d7-45a433b5d803,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-bb6c0150-7e2f-4b12-b126-610043b5756b,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-08155227-7389-4593-adcb-1b9c3c02da80,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-5e5e47e5-0490-4086-9571-3919a6e566b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-86466a1d-35e0-490d-b479-854011e303d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-e13809c0-ec1a-4ccd-ae7f-bca471514646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086199786-172.17.0.18-1595379257229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41643,DS-a86f378c-6998-4695-843a-2261d0da032e,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-3d6282dd-c045-4d9c-9bc3-8f58bafa6425,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-f02b3843-32b7-456f-99d7-45a433b5d803,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-bb6c0150-7e2f-4b12-b126-610043b5756b,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-08155227-7389-4593-adcb-1b9c3c02da80,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-5e5e47e5-0490-4086-9571-3919a6e566b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-86466a1d-35e0-490d-b479-854011e303d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-e13809c0-ec1a-4ccd-ae7f-bca471514646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252420314-172.17.0.18-1595379393045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-eb4fd64a-aac7-40df-a236-8c6bb4897933,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-73748490-ce60-4e36-afd2-0d44282c9fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-2ce69706-9578-4ba7-84f8-236dd82c1167,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-34733baf-144a-471f-a4ac-0002226b96f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-f5d5270d-b79e-4a73-8a74-5054261f41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-a120d79e-fc55-4d44-befd-e833c90d2933,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-764bbb62-356d-4d3d-894c-2a1f26783dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-1261b42b-d2b5-47a1-aaa8-1e5e9fbbde78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252420314-172.17.0.18-1595379393045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-eb4fd64a-aac7-40df-a236-8c6bb4897933,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-73748490-ce60-4e36-afd2-0d44282c9fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-2ce69706-9578-4ba7-84f8-236dd82c1167,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-34733baf-144a-471f-a4ac-0002226b96f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-f5d5270d-b79e-4a73-8a74-5054261f41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-a120d79e-fc55-4d44-befd-e833c90d2933,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-764bbb62-356d-4d3d-894c-2a1f26783dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-1261b42b-d2b5-47a1-aaa8-1e5e9fbbde78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096967573-172.17.0.18-1595379783006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46708,DS-8560780e-341b-40f6-9faf-f00b927144f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-e99b89fc-1353-4217-bb4b-e499ec33f966,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-334e1fd1-b726-4906-9ce1-0e566f756a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-c1c0e581-d8ed-48f4-b5e5-70c4c820a824,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-a7e46c5c-9d26-4a97-ba6a-049c5988ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-fe298ac9-3060-411d-8550-3612851a55b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-1b6560b8-c774-41d9-8299-076b4021e743,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-264d487d-bff3-4fc6-9536-3664aff7b0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096967573-172.17.0.18-1595379783006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46708,DS-8560780e-341b-40f6-9faf-f00b927144f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-e99b89fc-1353-4217-bb4b-e499ec33f966,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-334e1fd1-b726-4906-9ce1-0e566f756a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-c1c0e581-d8ed-48f4-b5e5-70c4c820a824,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-a7e46c5c-9d26-4a97-ba6a-049c5988ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-fe298ac9-3060-411d-8550-3612851a55b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-1b6560b8-c774-41d9-8299-076b4021e743,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-264d487d-bff3-4fc6-9536-3664aff7b0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155681409-172.17.0.18-1595379921591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-13bb5662-fb8f-406b-be34-491cf42c4ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-56632d3b-00ec-41a6-8c7c-03d2bc7258a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-dd752d12-15e2-4d66-acac-dd7e5a801238,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-91ccae6f-d1ed-44d6-b483-ad7fd97cb8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-40a892f2-1bdb-406e-95b6-8072b6973b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-761e5268-91e6-46de-baa8-160bff9ba635,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-f49349bf-17d3-44e1-95d1-b1cecc2a2fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-8e13d3b2-eaba-433d-b54f-24524a498edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155681409-172.17.0.18-1595379921591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-13bb5662-fb8f-406b-be34-491cf42c4ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-56632d3b-00ec-41a6-8c7c-03d2bc7258a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-dd752d12-15e2-4d66-acac-dd7e5a801238,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-91ccae6f-d1ed-44d6-b483-ad7fd97cb8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-40a892f2-1bdb-406e-95b6-8072b6973b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-761e5268-91e6-46de-baa8-160bff9ba635,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-f49349bf-17d3-44e1-95d1-b1cecc2a2fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-8e13d3b2-eaba-433d-b54f-24524a498edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822559566-172.17.0.18-1595380944642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-3bd918a2-e69d-4fc6-8f95-017e1811c56d,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-01bc48cc-b7b7-485c-8779-a58439b06fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-0a7eb3fa-8184-4ed6-a91e-fbceaabe6000,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-820ae3f0-f931-4aeb-957b-6d038b832bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-8e56bb26-8ef4-46f8-a9fe-836376a42650,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-dcb6202b-56d0-4db2-b158-1fd2d949b695,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-1a7839e3-cbd4-4495-acbb-b7b7eeee2153,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d0b1c696-f142-4a7e-b6ea-0864e1dbc353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822559566-172.17.0.18-1595380944642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-3bd918a2-e69d-4fc6-8f95-017e1811c56d,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-01bc48cc-b7b7-485c-8779-a58439b06fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-0a7eb3fa-8184-4ed6-a91e-fbceaabe6000,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-820ae3f0-f931-4aeb-957b-6d038b832bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-8e56bb26-8ef4-46f8-a9fe-836376a42650,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-dcb6202b-56d0-4db2-b158-1fd2d949b695,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-1a7839e3-cbd4-4495-acbb-b7b7eeee2153,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d0b1c696-f142-4a7e-b6ea-0864e1dbc353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971192101-172.17.0.18-1595381110833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-1d8f6147-1543-4eea-855c-67823115da65,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-f95d0f52-3077-4b30-afec-4732b70dca33,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-9b43d28c-ee78-4c93-81fb-22195da73ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-7fb29941-4558-4a98-bb07-d005759fe590,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-54cdc8cb-1a6b-40c9-88b8-acae972783b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-a6846153-d7e9-4cf6-98fa-1cac9c30cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-84c5ad9c-5eb1-408a-9336-c40491552704,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-02fc7d53-cb82-4402-b1b0-da8c0f440c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971192101-172.17.0.18-1595381110833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-1d8f6147-1543-4eea-855c-67823115da65,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-f95d0f52-3077-4b30-afec-4732b70dca33,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-9b43d28c-ee78-4c93-81fb-22195da73ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-7fb29941-4558-4a98-bb07-d005759fe590,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-54cdc8cb-1a6b-40c9-88b8-acae972783b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-a6846153-d7e9-4cf6-98fa-1cac9c30cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-84c5ad9c-5eb1-408a-9336-c40491552704,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-02fc7d53-cb82-4402-b1b0-da8c0f440c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939402325-172.17.0.18-1595381299371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35167,DS-98bab228-9591-4001-bd7e-23f0a3d8013a,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-70a6fea8-718b-4db9-849d-1e22ed3d2954,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-32c1f4c7-6b3d-4d7e-b6ba-f5ff92c2ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-9e53896b-6a15-48b2-8a64-52a41fc5d7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-a446a743-2241-42a5-8bb7-6476c29ae954,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-40a378e5-ff18-494c-8f8d-a7bd60c1d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-f5bd7177-5ece-45ef-91fa-12d9f03c4f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-d481456d-a7b7-4195-a843-6c2a591bb67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939402325-172.17.0.18-1595381299371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35167,DS-98bab228-9591-4001-bd7e-23f0a3d8013a,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-70a6fea8-718b-4db9-849d-1e22ed3d2954,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-32c1f4c7-6b3d-4d7e-b6ba-f5ff92c2ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-9e53896b-6a15-48b2-8a64-52a41fc5d7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-a446a743-2241-42a5-8bb7-6476c29ae954,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-40a378e5-ff18-494c-8f8d-a7bd60c1d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-f5bd7177-5ece-45ef-91fa-12d9f03c4f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-d481456d-a7b7-4195-a843-6c2a591bb67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704074664-172.17.0.18-1595382248469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-769da191-3baa-47ff-af5e-854fa7adacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-cf223290-7a45-447f-b5df-a041cac8dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-99bf49a3-6e58-4520-9aa3-1d3a6b6f29d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-1ca1f0c9-4730-4e88-bcb3-e655e372d8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-690bf764-0338-43f1-a362-5d00003ae55d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-f43bf45e-4a04-49e1-b20c-d41afd92ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-9f1c21e9-aaf6-4a12-8246-61af2dcb7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-1fe97e04-b4b9-4b41-89b0-c2e319d5f1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704074664-172.17.0.18-1595382248469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-769da191-3baa-47ff-af5e-854fa7adacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-cf223290-7a45-447f-b5df-a041cac8dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-99bf49a3-6e58-4520-9aa3-1d3a6b6f29d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-1ca1f0c9-4730-4e88-bcb3-e655e372d8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-690bf764-0338-43f1-a362-5d00003ae55d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-f43bf45e-4a04-49e1-b20c-d41afd92ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-9f1c21e9-aaf6-4a12-8246-61af2dcb7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-1fe97e04-b4b9-4b41-89b0-c2e319d5f1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810497728-172.17.0.18-1595382343161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44987,DS-fcd084f8-11fc-4880-af0f-089c90f37473,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-2be6faa3-57d5-41ba-814e-8f2a8ef01fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-c19a2fde-2eb5-4ca4-9426-507db631e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-e9705369-788a-471b-9100-49b83103cb76,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-0c8a3a90-9437-47d7-820b-40c4bac25ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-7b742b68-1d42-4623-b4ed-e47fe8b76e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-e5714354-b2f2-4e71-ade9-5dd6fc3f4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-5df1fa0e-a3c2-4eb9-851d-a8cfbf859ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810497728-172.17.0.18-1595382343161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44987,DS-fcd084f8-11fc-4880-af0f-089c90f37473,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-2be6faa3-57d5-41ba-814e-8f2a8ef01fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-c19a2fde-2eb5-4ca4-9426-507db631e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-e9705369-788a-471b-9100-49b83103cb76,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-0c8a3a90-9437-47d7-820b-40c4bac25ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-7b742b68-1d42-4623-b4ed-e47fe8b76e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-e5714354-b2f2-4e71-ade9-5dd6fc3f4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-5df1fa0e-a3c2-4eb9-851d-a8cfbf859ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993288598-172.17.0.18-1595383142907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44691,DS-0803f5f2-1dfb-4574-b4b2-06b4955743f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-07f3ae16-7d0d-438b-9cf5-a1355a16cd67,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-fd267f7f-a438-465d-8695-d0089370d322,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-dcc3e3ba-e8a0-4243-8bb5-44a9bfc9100b,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-737e5dd9-9cbb-4db3-8269-be2c7d05c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-abaf79b3-64e1-4c79-a2ec-98fe934b082b,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-c3d9feb6-4451-4e22-895e-0b7d15628d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-f5b35bd4-12a4-4d5f-998d-4e3bfbfa1124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993288598-172.17.0.18-1595383142907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44691,DS-0803f5f2-1dfb-4574-b4b2-06b4955743f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-07f3ae16-7d0d-438b-9cf5-a1355a16cd67,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-fd267f7f-a438-465d-8695-d0089370d322,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-dcc3e3ba-e8a0-4243-8bb5-44a9bfc9100b,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-737e5dd9-9cbb-4db3-8269-be2c7d05c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-abaf79b3-64e1-4c79-a2ec-98fe934b082b,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-c3d9feb6-4451-4e22-895e-0b7d15628d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-f5b35bd4-12a4-4d5f-998d-4e3bfbfa1124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198694070-172.17.0.18-1595383332588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42549,DS-a63162a5-810b-4b84-ae3f-8cf89317dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-ee5548d8-c97f-47ce-9c2f-33dc6aff9a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-d0992f4b-503c-4d71-97ef-cd76790b48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-65a57f0f-dcd0-4a4d-9c51-a651fc206b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-203a12a7-5fc7-45d7-a719-05516cfc9aba,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-4d2d27ef-a701-452b-b933-dabbebd9eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-35a09a17-87f1-4332-8732-ba35813a70c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-464116be-23c7-4151-b28f-920319314d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198694070-172.17.0.18-1595383332588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42549,DS-a63162a5-810b-4b84-ae3f-8cf89317dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-ee5548d8-c97f-47ce-9c2f-33dc6aff9a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-d0992f4b-503c-4d71-97ef-cd76790b48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-65a57f0f-dcd0-4a4d-9c51-a651fc206b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-203a12a7-5fc7-45d7-a719-05516cfc9aba,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-4d2d27ef-a701-452b-b933-dabbebd9eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-35a09a17-87f1-4332-8732-ba35813a70c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-464116be-23c7-4151-b28f-920319314d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5220
