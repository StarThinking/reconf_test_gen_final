reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368889887-172.17.0.2-1595314874037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36199,DS-6b2af895-51b5-4de5-8fc7-6b91a9d5dab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-125d1a14-842d-4cef-b612-a0fb29b52be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-893eeb83-1a26-4ae9-92f6-11e2ab5666ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-1f2091b8-a34b-43d1-a55c-cb960eb9a2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-76ebec33-08cf-4c9f-a008-de99341dacd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-5899ad09-bf90-42fe-af86-7094b9c94264,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-769dcc60-2fc6-46e6-94f1-a07bf513d250,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-60875524-884a-437b-bbb9-8f53c4c02cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368889887-172.17.0.2-1595314874037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36199,DS-6b2af895-51b5-4de5-8fc7-6b91a9d5dab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-125d1a14-842d-4cef-b612-a0fb29b52be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-893eeb83-1a26-4ae9-92f6-11e2ab5666ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-1f2091b8-a34b-43d1-a55c-cb960eb9a2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-76ebec33-08cf-4c9f-a008-de99341dacd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-5899ad09-bf90-42fe-af86-7094b9c94264,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-769dcc60-2fc6-46e6-94f1-a07bf513d250,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-60875524-884a-437b-bbb9-8f53c4c02cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696808165-172.17.0.2-1595316122583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-e91a7ee5-93d6-4903-9e66-910cb810ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-2d4255b1-a7fc-4271-8d6d-34bc9489018d,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-d5caaec0-2b62-430d-b446-a31023765419,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-3a2a4a8e-5ff1-4b61-9b03-a343e2b02201,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-22baa95b-eeca-4055-8e63-a8fd59b39e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-b8c71fa2-f05b-4650-8168-22b95b352adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-10e01e4e-b184-4b74-8013-c00516f316e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-562af571-05ed-4899-814a-ca46e7be4e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696808165-172.17.0.2-1595316122583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-e91a7ee5-93d6-4903-9e66-910cb810ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-2d4255b1-a7fc-4271-8d6d-34bc9489018d,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-d5caaec0-2b62-430d-b446-a31023765419,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-3a2a4a8e-5ff1-4b61-9b03-a343e2b02201,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-22baa95b-eeca-4055-8e63-a8fd59b39e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-b8c71fa2-f05b-4650-8168-22b95b352adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-10e01e4e-b184-4b74-8013-c00516f316e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-562af571-05ed-4899-814a-ca46e7be4e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398266722-172.17.0.2-1595317004738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-f981d723-e526-487b-9460-c0c80b4b3f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-73179071-fa38-4878-b5c9-66a5962840c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-3319205e-7dff-420d-829c-1dbdb12b66cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-1e2668ba-b9cc-4c4c-b99e-1bb1f46a49c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-e90c0284-14c2-45e4-96e6-443119fcf671,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-53c14a8c-b80e-4643-ada7-68cdffc3cb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-befe10ed-5cd9-41e0-bd08-bb66769413ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-18f51a69-5141-4f45-b899-82407b9f939d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398266722-172.17.0.2-1595317004738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-f981d723-e526-487b-9460-c0c80b4b3f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-73179071-fa38-4878-b5c9-66a5962840c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-3319205e-7dff-420d-829c-1dbdb12b66cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-1e2668ba-b9cc-4c4c-b99e-1bb1f46a49c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-e90c0284-14c2-45e4-96e6-443119fcf671,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-53c14a8c-b80e-4643-ada7-68cdffc3cb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-befe10ed-5cd9-41e0-bd08-bb66769413ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-18f51a69-5141-4f45-b899-82407b9f939d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618327597-172.17.0.2-1595317222238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-64901859-03ae-4061-ab5e-169d43fde00c,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-827f7496-ce7c-4203-abb9-9ee2cd76cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-9b85362b-2161-4c8c-a747-2b14085ac638,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-3f08b605-8783-4a4a-8850-6724bac04b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-4ebc01f0-7d16-4c75-ae23-5e965f67eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-c19cc13a-0c75-4713-9919-203009915cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-a15fda3c-c3b6-4c8c-aa3b-e1a952537924,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-55aef59d-cbbd-4340-915e-8ff1423a955b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618327597-172.17.0.2-1595317222238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-64901859-03ae-4061-ab5e-169d43fde00c,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-827f7496-ce7c-4203-abb9-9ee2cd76cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-9b85362b-2161-4c8c-a747-2b14085ac638,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-3f08b605-8783-4a4a-8850-6724bac04b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-4ebc01f0-7d16-4c75-ae23-5e965f67eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-c19cc13a-0c75-4713-9919-203009915cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-a15fda3c-c3b6-4c8c-aa3b-e1a952537924,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-55aef59d-cbbd-4340-915e-8ff1423a955b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473621118-172.17.0.2-1595317524000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-92357576-912d-4a33-8558-95927f014d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-e900d1bb-6df5-43e8-8a35-88eecabf7094,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-5069b0ac-819a-43b0-955f-f2c12845eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-f9c0bdab-908a-4285-b002-a693daf0389a,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-9043c527-2826-45a2-9057-075ce97dd638,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-02779abf-79e5-46f7-b8ab-a56f13ca9551,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-78637869-4df0-4a3b-a950-e0729d7a3ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-8063fdeb-1cac-46a8-b07c-fa8f6dcbc404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473621118-172.17.0.2-1595317524000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-92357576-912d-4a33-8558-95927f014d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-e900d1bb-6df5-43e8-8a35-88eecabf7094,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-5069b0ac-819a-43b0-955f-f2c12845eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-f9c0bdab-908a-4285-b002-a693daf0389a,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-9043c527-2826-45a2-9057-075ce97dd638,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-02779abf-79e5-46f7-b8ab-a56f13ca9551,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-78637869-4df0-4a3b-a950-e0729d7a3ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-8063fdeb-1cac-46a8-b07c-fa8f6dcbc404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119290292-172.17.0.2-1595317584273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-455705c5-d779-42fe-abd0-756dbbd3c915,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-425ed74b-af6e-4398-8698-bd63d2ff8eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-eb169db0-8759-48d0-9a19-19853662e00b,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-9c30371e-dab9-49f6-91d2-7488ecd82aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-db12bbf2-8518-4659-a645-d7e5b09c8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-e79d5cd1-bc4f-4009-b50e-889c170db6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-66411cf2-b070-4b15-90a2-350d7ebf3db3,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-f8990bcd-a35a-4099-b7b0-7ce466673aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119290292-172.17.0.2-1595317584273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-455705c5-d779-42fe-abd0-756dbbd3c915,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-425ed74b-af6e-4398-8698-bd63d2ff8eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-eb169db0-8759-48d0-9a19-19853662e00b,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-9c30371e-dab9-49f6-91d2-7488ecd82aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-db12bbf2-8518-4659-a645-d7e5b09c8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-e79d5cd1-bc4f-4009-b50e-889c170db6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-66411cf2-b070-4b15-90a2-350d7ebf3db3,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-f8990bcd-a35a-4099-b7b0-7ce466673aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546405861-172.17.0.2-1595318111519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-e96c2d44-06ca-4577-9d98-3275c60249eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-fb1199f3-9b80-40c4-857e-e0f8cca75992,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-ee36f1ee-465b-4595-90aa-99c6a3ef83b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-0bc56c7e-8f2f-4668-b0f4-2a26d809558b,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-dd03b745-298f-4d40-a068-e0341a296c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-ee3ec05b-2289-407e-89c1-26cf09d5585e,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-179c0723-92fc-4d99-9ddb-96ec9f4ed0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-338b6ca7-7827-4305-bd0d-df7cae0a30d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546405861-172.17.0.2-1595318111519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-e96c2d44-06ca-4577-9d98-3275c60249eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-fb1199f3-9b80-40c4-857e-e0f8cca75992,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-ee36f1ee-465b-4595-90aa-99c6a3ef83b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-0bc56c7e-8f2f-4668-b0f4-2a26d809558b,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-dd03b745-298f-4d40-a068-e0341a296c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-ee3ec05b-2289-407e-89c1-26cf09d5585e,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-179c0723-92fc-4d99-9ddb-96ec9f4ed0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-338b6ca7-7827-4305-bd0d-df7cae0a30d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461094413-172.17.0.2-1595318444039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-74db0a84-c7ac-485d-a86e-3c6a4070c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-3766363f-8e68-4d7e-aca8-feb8d9f9b865,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-2f0c34ad-c56c-48b1-8ae1-2ed6a41a13a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-4c32c31a-63cc-4a96-be0e-f2ee02dbed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-10998fb5-3e13-4632-a929-9ac2ef9fd3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-c8b164bd-ddae-4a61-9c98-3f7feabeb1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-e7366f36-1e87-4e6a-92c3-2f7c986331dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-aa06c7fa-bd6a-4a56-8189-cc57eb9243c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461094413-172.17.0.2-1595318444039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-74db0a84-c7ac-485d-a86e-3c6a4070c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-3766363f-8e68-4d7e-aca8-feb8d9f9b865,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-2f0c34ad-c56c-48b1-8ae1-2ed6a41a13a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-4c32c31a-63cc-4a96-be0e-f2ee02dbed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-10998fb5-3e13-4632-a929-9ac2ef9fd3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-c8b164bd-ddae-4a61-9c98-3f7feabeb1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-e7366f36-1e87-4e6a-92c3-2f7c986331dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-aa06c7fa-bd6a-4a56-8189-cc57eb9243c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100820972-172.17.0.2-1595318788019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-993335fc-8656-4684-913c-91f1d9d6e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-5c5659e9-7b63-4c6e-974b-33bbc232a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-a20c0766-0d6d-463a-9281-e203a1c313e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-bbe68e75-d805-4cfc-8a92-a7949d4a5339,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-2cd383ae-e4e2-49e4-a8d9-1a69c309d338,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-c6ae02be-e174-4395-a159-c66efe47994b,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-b2255a84-3649-44a1-a767-16c7a9883e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-b893c13a-cfb4-485a-be9d-6dfaae2a736a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100820972-172.17.0.2-1595318788019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-993335fc-8656-4684-913c-91f1d9d6e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-5c5659e9-7b63-4c6e-974b-33bbc232a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-a20c0766-0d6d-463a-9281-e203a1c313e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-bbe68e75-d805-4cfc-8a92-a7949d4a5339,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-2cd383ae-e4e2-49e4-a8d9-1a69c309d338,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-c6ae02be-e174-4395-a159-c66efe47994b,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-b2255a84-3649-44a1-a767-16c7a9883e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-b893c13a-cfb4-485a-be9d-6dfaae2a736a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354220803-172.17.0.2-1595319063660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42819,DS-8d6c3fc8-05ab-4574-8172-106bc90bca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-5491db30-1676-48da-b415-bf08b67ce67c,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-c82ebef3-c2d5-4213-a9e3-a19eeb7cf4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-77a94870-b44e-46c7-8317-d7a9418d9b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-51928893-3ba4-46b3-8c07-490f82215ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-869aad52-7bc7-4421-b54f-962f430027a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-a0ba030b-908f-4371-a8f2-16ec9e32482c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-dd6dd1d2-921f-4e4c-865d-28ca74ed14f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354220803-172.17.0.2-1595319063660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42819,DS-8d6c3fc8-05ab-4574-8172-106bc90bca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-5491db30-1676-48da-b415-bf08b67ce67c,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-c82ebef3-c2d5-4213-a9e3-a19eeb7cf4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-77a94870-b44e-46c7-8317-d7a9418d9b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-51928893-3ba4-46b3-8c07-490f82215ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-869aad52-7bc7-4421-b54f-962f430027a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-a0ba030b-908f-4371-a8f2-16ec9e32482c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-dd6dd1d2-921f-4e4c-865d-28ca74ed14f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394425336-172.17.0.2-1595319464531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-c9232867-394f-4249-a5c3-4c9531d9dc89,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-7eb937b6-178b-455e-8c53-875d93b74ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-a4aeea68-8121-43e9-a0d4-940e320d695d,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-2dfcf9eb-2cfd-414d-b643-c5905a0dcec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-53325dd0-4d2e-4bd2-be2c-9e0a7e69810a,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-5b7cd2da-1e67-4d49-aa98-67a152ef418e,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-8c81d343-4735-43a8-9b10-618e19bbe80a,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-475d1919-f7d2-454e-825c-268fe2fa4a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394425336-172.17.0.2-1595319464531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-c9232867-394f-4249-a5c3-4c9531d9dc89,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-7eb937b6-178b-455e-8c53-875d93b74ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-a4aeea68-8121-43e9-a0d4-940e320d695d,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-2dfcf9eb-2cfd-414d-b643-c5905a0dcec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-53325dd0-4d2e-4bd2-be2c-9e0a7e69810a,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-5b7cd2da-1e67-4d49-aa98-67a152ef418e,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-8c81d343-4735-43a8-9b10-618e19bbe80a,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-475d1919-f7d2-454e-825c-268fe2fa4a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339107206-172.17.0.2-1595319662135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-dd0fa0ba-cb9e-453b-b086-3a90b703b612,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-cca05968-aab8-4dd5-adee-a05783ba8e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-6c8afb1e-7df7-4f4f-9cfd-479d56b61be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-5c7a4974-e2e5-4be7-91ef-78bffcd0cde1,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-f6464606-a1e3-4306-a87d-91dd8dbcf971,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-79c87833-3b11-487b-b570-5488b0dd1157,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-5af4c48e-0dc6-4a8d-b7b8-e28ec863f45c,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-135e0dc2-aa85-41f1-b764-43edc712e64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339107206-172.17.0.2-1595319662135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-dd0fa0ba-cb9e-453b-b086-3a90b703b612,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-cca05968-aab8-4dd5-adee-a05783ba8e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-6c8afb1e-7df7-4f4f-9cfd-479d56b61be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-5c7a4974-e2e5-4be7-91ef-78bffcd0cde1,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-f6464606-a1e3-4306-a87d-91dd8dbcf971,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-79c87833-3b11-487b-b570-5488b0dd1157,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-5af4c48e-0dc6-4a8d-b7b8-e28ec863f45c,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-135e0dc2-aa85-41f1-b764-43edc712e64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31197953-172.17.0.2-1595319725422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32835,DS-8598a4b3-ca5b-4b64-abc6-e22f26b4ba53,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-c5daea40-9318-4cef-9f96-8c4a1f3f4f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-5537f6b0-4599-4cea-a5cd-03a63b688ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-3d7ad2cf-e647-42c3-8e08-e41b17677dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-74fc84db-9e68-4ab7-a919-3485a4a37313,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-106ca18a-98e6-4f18-aa0a-526cd49fb1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-2a419a74-d9b4-42ae-a554-e070dbe2c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-77200e0a-88d3-4d11-8457-c0a11c8f0e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31197953-172.17.0.2-1595319725422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32835,DS-8598a4b3-ca5b-4b64-abc6-e22f26b4ba53,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-c5daea40-9318-4cef-9f96-8c4a1f3f4f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-5537f6b0-4599-4cea-a5cd-03a63b688ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-3d7ad2cf-e647-42c3-8e08-e41b17677dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-74fc84db-9e68-4ab7-a919-3485a4a37313,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-106ca18a-98e6-4f18-aa0a-526cd49fb1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-2a419a74-d9b4-42ae-a554-e070dbe2c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-77200e0a-88d3-4d11-8457-c0a11c8f0e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5265
