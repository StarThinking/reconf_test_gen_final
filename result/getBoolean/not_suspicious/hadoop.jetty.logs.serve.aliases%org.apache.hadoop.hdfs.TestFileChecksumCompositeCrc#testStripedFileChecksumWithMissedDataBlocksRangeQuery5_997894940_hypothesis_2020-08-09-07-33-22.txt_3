reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382031864-172.17.0.6-1596958481674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-75ffdcca-da79-423d-8b6a-dd7b53c723ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-af95ee8f-8bb5-4d81-b61b-df79f41978e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-b2b634bc-e408-4885-a228-66061aac4bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-14bceda6-2553-4a8d-acd6-ae3b80aabb47,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-a4d121d2-b44a-4118-84da-85d1871461a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-66543055-df94-410f-a972-9efcf456f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-a4aa67f2-c853-4b1b-9f83-ad319260e97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-ffacf925-4d89-4a50-aaa9-602df8649b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382031864-172.17.0.6-1596958481674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-75ffdcca-da79-423d-8b6a-dd7b53c723ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-af95ee8f-8bb5-4d81-b61b-df79f41978e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-b2b634bc-e408-4885-a228-66061aac4bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-14bceda6-2553-4a8d-acd6-ae3b80aabb47,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-a4d121d2-b44a-4118-84da-85d1871461a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-66543055-df94-410f-a972-9efcf456f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-a4aa67f2-c853-4b1b-9f83-ad319260e97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-ffacf925-4d89-4a50-aaa9-602df8649b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528946116-172.17.0.6-1596958544496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37794,DS-8a0890b8-a2ad-4fae-9050-04b953cc9eac,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-e40e137f-5b11-4ecf-b4ac-3230175f6130,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-f0d8721a-8e7c-4e66-9cb2-aaee31c13550,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-e5ce9e10-fb3b-4f67-9348-95c3ade9b47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-170ae8bf-5cd6-4dd6-af29-b2d071eba5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-8198d9a6-d593-4e3b-a318-ff7ff535bfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-1d4a5c9f-41c1-4446-8a60-8e822d790b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-31cf4f19-da62-41b4-b32e-11b73814ed1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528946116-172.17.0.6-1596958544496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37794,DS-8a0890b8-a2ad-4fae-9050-04b953cc9eac,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-e40e137f-5b11-4ecf-b4ac-3230175f6130,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-f0d8721a-8e7c-4e66-9cb2-aaee31c13550,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-e5ce9e10-fb3b-4f67-9348-95c3ade9b47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-170ae8bf-5cd6-4dd6-af29-b2d071eba5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-8198d9a6-d593-4e3b-a318-ff7ff535bfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-1d4a5c9f-41c1-4446-8a60-8e822d790b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-31cf4f19-da62-41b4-b32e-11b73814ed1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591860536-172.17.0.6-1596958851649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-bc869512-daa0-4ed7-8d14-2ba55365b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-7fa5c85d-5d96-461f-aed1-85f8b869a1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-91f36bd8-1c0e-4102-9279-2ba9495f0977,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-5c15216d-9c2c-4f3a-b6ef-decf80ff8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-d861c7b0-c59c-4739-80da-be07bcc0f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-54c7d61a-2478-4568-a499-65dcc2cbdfec,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-85091b29-434f-4aa1-852b-c09e4e8b1901,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-64b5df3c-f0e9-47bd-8079-244a7f2cac41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591860536-172.17.0.6-1596958851649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-bc869512-daa0-4ed7-8d14-2ba55365b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-7fa5c85d-5d96-461f-aed1-85f8b869a1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-91f36bd8-1c0e-4102-9279-2ba9495f0977,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-5c15216d-9c2c-4f3a-b6ef-decf80ff8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-d861c7b0-c59c-4739-80da-be07bcc0f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-54c7d61a-2478-4568-a499-65dcc2cbdfec,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-85091b29-434f-4aa1-852b-c09e4e8b1901,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-64b5df3c-f0e9-47bd-8079-244a7f2cac41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796696958-172.17.0.6-1596959090490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-770b9ed1-9ed8-43f0-925a-d5b975430206,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-221c2a57-f391-4c1d-b253-906f38152e92,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-5acec01d-4918-4889-9503-92bdb1a3576e,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-b14eb9de-0086-4118-a9ca-86aeda52b337,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-83f2bae6-a121-4cde-b0c2-da9dd95cebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-0fdcdb21-8c85-40d8-ae5f-63576fedb09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-46c58978-bae4-4f11-b4fa-437e03db3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-53657df1-cbc0-47bf-9c74-18fddd8443fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796696958-172.17.0.6-1596959090490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-770b9ed1-9ed8-43f0-925a-d5b975430206,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-221c2a57-f391-4c1d-b253-906f38152e92,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-5acec01d-4918-4889-9503-92bdb1a3576e,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-b14eb9de-0086-4118-a9ca-86aeda52b337,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-83f2bae6-a121-4cde-b0c2-da9dd95cebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-0fdcdb21-8c85-40d8-ae5f-63576fedb09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-46c58978-bae4-4f11-b4fa-437e03db3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-53657df1-cbc0-47bf-9c74-18fddd8443fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711100856-172.17.0.6-1596959551204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-b464f004-cda8-45bd-afe7-7cc314afc4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-0de98169-dbf3-4a83-9dc2-f99b031fd919,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-59b9bf9d-a84c-486c-83a9-83e48d65aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-6b7ac3f9-5232-4fb2-9615-ac286a201823,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-71bec6a3-e8ae-4e6a-819b-452407409b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-9e0668f7-8ef7-41ae-8004-b49935335d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-ed7cc105-4cee-4cc1-aa96-6c43f4405b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-a7890471-242d-4e7d-8e12-ddf7b2178c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711100856-172.17.0.6-1596959551204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-b464f004-cda8-45bd-afe7-7cc314afc4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-0de98169-dbf3-4a83-9dc2-f99b031fd919,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-59b9bf9d-a84c-486c-83a9-83e48d65aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-6b7ac3f9-5232-4fb2-9615-ac286a201823,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-71bec6a3-e8ae-4e6a-819b-452407409b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-9e0668f7-8ef7-41ae-8004-b49935335d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-ed7cc105-4cee-4cc1-aa96-6c43f4405b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-a7890471-242d-4e7d-8e12-ddf7b2178c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343277732-172.17.0.6-1596960165720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-bd12fab5-1a8c-447d-a829-03746098b791,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-d04e0d08-552e-49e7-9f9a-4d64c3020461,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-7ad28402-7a97-4da6-a9bd-111782d7683b,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-96e26307-d8dc-47ed-80b5-558f7bb2055e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-37af5405-36a3-4875-9ee3-0976c013a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-7fe66163-4de3-4ee4-9fd1-f3db2d480017,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-cab4d629-be44-4a28-90e1-016d355b4c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-170cd37b-4bb7-44e2-957a-1d27f70d5725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343277732-172.17.0.6-1596960165720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-bd12fab5-1a8c-447d-a829-03746098b791,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-d04e0d08-552e-49e7-9f9a-4d64c3020461,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-7ad28402-7a97-4da6-a9bd-111782d7683b,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-96e26307-d8dc-47ed-80b5-558f7bb2055e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-37af5405-36a3-4875-9ee3-0976c013a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-7fe66163-4de3-4ee4-9fd1-f3db2d480017,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-cab4d629-be44-4a28-90e1-016d355b4c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-170cd37b-4bb7-44e2-957a-1d27f70d5725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789093547-172.17.0.6-1596960592131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35829,DS-6cd6aa7a-8b32-488d-ab5a-29b264bb2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-db1d01c7-a6b4-4f9b-80f1-025e5e04f280,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-e448210a-3763-4383-9fd5-553769351a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-86e9df1b-eb1a-4f0f-8187-8ff15179ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-f350e8ed-16fa-4015-98c2-2ed3c66b83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6ea5f893-d31a-404e-bc7a-2e536874d3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a0034326-6fd6-434d-85ef-b6b313b02878,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-ff27b141-e283-417a-9af2-795722c643f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789093547-172.17.0.6-1596960592131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35829,DS-6cd6aa7a-8b32-488d-ab5a-29b264bb2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-db1d01c7-a6b4-4f9b-80f1-025e5e04f280,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-e448210a-3763-4383-9fd5-553769351a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-86e9df1b-eb1a-4f0f-8187-8ff15179ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-f350e8ed-16fa-4015-98c2-2ed3c66b83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6ea5f893-d31a-404e-bc7a-2e536874d3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a0034326-6fd6-434d-85ef-b6b313b02878,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-ff27b141-e283-417a-9af2-795722c643f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646964657-172.17.0.6-1596960824168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-b49e8aa8-d2fc-45b1-bc5c-03dafb477810,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-13839108-9f0f-45ea-abb0-972918f2867d,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-e6b1d667-89dd-47e8-98ff-c492ab4ede53,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-29d9b472-d299-44c4-b6d2-024908d55e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-4e8c4384-5b6d-4305-92db-1f97c38257d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-0f5df108-9132-48ea-a1bd-fe2353adecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-f961bfd8-27df-44be-b695-74306b3e731e,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-3efc8857-cb81-475b-a14f-3812c9c6fc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646964657-172.17.0.6-1596960824168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-b49e8aa8-d2fc-45b1-bc5c-03dafb477810,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-13839108-9f0f-45ea-abb0-972918f2867d,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-e6b1d667-89dd-47e8-98ff-c492ab4ede53,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-29d9b472-d299-44c4-b6d2-024908d55e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-4e8c4384-5b6d-4305-92db-1f97c38257d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-0f5df108-9132-48ea-a1bd-fe2353adecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-f961bfd8-27df-44be-b695-74306b3e731e,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-3efc8857-cb81-475b-a14f-3812c9c6fc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713681923-172.17.0.6-1596960857459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-ee83a485-add3-43a3-b02f-7b3391ada5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-2b38f7e1-8384-4d5d-b0ba-d5266b81a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-ab0c30a9-33e6-4a4e-ba83-d6d042315b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-dce5a229-d89d-48bc-b2cc-ebfd2158083c,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-77dd809e-f942-49c5-aff1-dc47744f8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-6d556c74-0797-4c95-8068-ccf60ff51918,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-208d1d58-c6dc-46b3-94bc-7ad6c67d9f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-483db499-97a0-4628-8049-6c56404e6eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713681923-172.17.0.6-1596960857459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-ee83a485-add3-43a3-b02f-7b3391ada5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-2b38f7e1-8384-4d5d-b0ba-d5266b81a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-ab0c30a9-33e6-4a4e-ba83-d6d042315b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-dce5a229-d89d-48bc-b2cc-ebfd2158083c,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-77dd809e-f942-49c5-aff1-dc47744f8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-6d556c74-0797-4c95-8068-ccf60ff51918,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-208d1d58-c6dc-46b3-94bc-7ad6c67d9f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-483db499-97a0-4628-8049-6c56404e6eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033871245-172.17.0.6-1596961025708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-e58836c5-ab9a-4fb2-b2fb-8f5362b0959d,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-46485902-19bf-43e6-959e-21c7c1a41156,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-16a1e7a5-1068-44e7-a59b-3bd5436e87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-a0cad830-cd4d-45c4-bdf4-4f7e4d4775eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-ef17f9de-e4f4-480a-997f-50da92092905,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-8c849ebe-e995-43fd-bcb9-0f1dd120f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-e68c332d-0be5-4282-9102-4e8413bff330,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-aa3b8987-7896-4c1c-8bd8-91e8c301df66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033871245-172.17.0.6-1596961025708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-e58836c5-ab9a-4fb2-b2fb-8f5362b0959d,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-46485902-19bf-43e6-959e-21c7c1a41156,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-16a1e7a5-1068-44e7-a59b-3bd5436e87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-a0cad830-cd4d-45c4-bdf4-4f7e4d4775eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-ef17f9de-e4f4-480a-997f-50da92092905,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-8c849ebe-e995-43fd-bcb9-0f1dd120f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-e68c332d-0be5-4282-9102-4e8413bff330,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-aa3b8987-7896-4c1c-8bd8-91e8c301df66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123214261-172.17.0.6-1596962184258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40000,DS-0e1e543c-0ae0-47b4-8ba6-528ef1ab4ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-215887b5-a02c-443e-b078-3ef32d927581,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-2154ec25-f8fd-459d-9ac2-407e261919bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-56abf13d-72cc-4880-9f69-b552ce2224b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-fe10bd4d-5e24-4511-9a17-e8c9134e6294,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c27fd2d8-eb14-4e92-a54e-faf9a30a27d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-d7b14a8c-1ef0-4d33-9cb9-96049d412527,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-67665ddf-2e77-4788-8360-985685f20fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123214261-172.17.0.6-1596962184258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40000,DS-0e1e543c-0ae0-47b4-8ba6-528ef1ab4ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-215887b5-a02c-443e-b078-3ef32d927581,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-2154ec25-f8fd-459d-9ac2-407e261919bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-56abf13d-72cc-4880-9f69-b552ce2224b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-fe10bd4d-5e24-4511-9a17-e8c9134e6294,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c27fd2d8-eb14-4e92-a54e-faf9a30a27d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-d7b14a8c-1ef0-4d33-9cb9-96049d412527,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-67665ddf-2e77-4788-8360-985685f20fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555957645-172.17.0.6-1596962370359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-6bf3e384-9000-4822-9699-548108b36790,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-e6332fa7-4bf8-4108-93e0-424ff974fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-84a9c430-5a27-43f5-ab5e-dbe27ba95bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-24697ce4-ba38-4636-ba96-dcab111a2f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-e2047daa-dbb7-4905-a523-e4bc1ba87a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-7b063acb-87b1-489f-bacb-3efc4617bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-90ac8e69-64a1-4978-8157-6bada7245262,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ef6e263f-920d-43cb-a388-3ef802a1f72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555957645-172.17.0.6-1596962370359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-6bf3e384-9000-4822-9699-548108b36790,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-e6332fa7-4bf8-4108-93e0-424ff974fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-84a9c430-5a27-43f5-ab5e-dbe27ba95bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-24697ce4-ba38-4636-ba96-dcab111a2f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-e2047daa-dbb7-4905-a523-e4bc1ba87a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-7b063acb-87b1-489f-bacb-3efc4617bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-90ac8e69-64a1-4978-8157-6bada7245262,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ef6e263f-920d-43cb-a388-3ef802a1f72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468816089-172.17.0.6-1596962665004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-3e3fd88b-cfab-43b8-9cc6-b79a26fc04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-8e75a063-bd0b-4a35-ad7b-349dfe79dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-8a573757-149b-4aee-9283-71da99a7e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-04324fa0-f66b-442d-992a-2c548d8f648b,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-940c1984-5304-4538-bab3-ea2059e5373b,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-e392222f-3771-4956-85c9-0816746f0c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-92df3374-1d0f-499d-adb1-cb82a030bfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-0f16293f-7a2f-4f07-8d9b-f3f6c9d8ce5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468816089-172.17.0.6-1596962665004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-3e3fd88b-cfab-43b8-9cc6-b79a26fc04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-8e75a063-bd0b-4a35-ad7b-349dfe79dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-8a573757-149b-4aee-9283-71da99a7e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-04324fa0-f66b-442d-992a-2c548d8f648b,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-940c1984-5304-4538-bab3-ea2059e5373b,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-e392222f-3771-4956-85c9-0816746f0c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-92df3374-1d0f-499d-adb1-cb82a030bfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-0f16293f-7a2f-4f07-8d9b-f3f6c9d8ce5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164404161-172.17.0.6-1596962784286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-5f7b40d6-d600-4255-9b5b-c3ee10891f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-7fe76128-1610-4673-affe-ebead451be32,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-8de9f0a5-8ba1-499a-8f58-f8b61ee845d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-649e70e8-bfe9-44b5-8207-e1733f7bb206,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-97a13610-aaeb-4cd6-83f4-b9b3f9732955,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-62abdf2a-eafa-4ebc-b8b7-f128cdc9b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-c87eb8b7-272c-4312-bf71-9876a4c0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-c816e68c-d09f-41f3-aeac-575cb47ebae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164404161-172.17.0.6-1596962784286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-5f7b40d6-d600-4255-9b5b-c3ee10891f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-7fe76128-1610-4673-affe-ebead451be32,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-8de9f0a5-8ba1-499a-8f58-f8b61ee845d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-649e70e8-bfe9-44b5-8207-e1733f7bb206,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-97a13610-aaeb-4cd6-83f4-b9b3f9732955,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-62abdf2a-eafa-4ebc-b8b7-f128cdc9b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-c87eb8b7-272c-4312-bf71-9876a4c0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-c816e68c-d09f-41f3-aeac-575cb47ebae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037571481-172.17.0.6-1596963043754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37267,DS-27efb085-0358-443f-ae64-ede86984c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-822a83d1-7cfb-49ee-8066-6be6960fe8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-ab0c3fbd-0edc-4823-9bff-2a563bf37bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-66017f8b-91ac-42e7-ae85-a51567fe447a,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-185738f2-3831-4690-b285-d57dd4b137b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-c97d2054-784c-4b4b-9060-6bf2b63ef1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-3e486086-5122-4f47-9d00-462feac8a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-a3a78dcc-e913-460c-ad3c-cedc40d049de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037571481-172.17.0.6-1596963043754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37267,DS-27efb085-0358-443f-ae64-ede86984c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-822a83d1-7cfb-49ee-8066-6be6960fe8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-ab0c3fbd-0edc-4823-9bff-2a563bf37bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-66017f8b-91ac-42e7-ae85-a51567fe447a,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-185738f2-3831-4690-b285-d57dd4b137b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-c97d2054-784c-4b4b-9060-6bf2b63ef1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-3e486086-5122-4f47-9d00-462feac8a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-a3a78dcc-e913-460c-ad3c-cedc40d049de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211796912-172.17.0.6-1596963376741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-9ed03b8c-7f70-4c74-8e52-9bd9d28cbd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-bcf69b41-7152-4189-8d51-c6b9e187ae03,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-85605cc6-4c4b-49be-bd67-924c4c0cc934,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-c6b2cbc3-7688-4492-8ff3-51112a7a2dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-b1e376ea-dde0-4199-9c6d-652c2f62e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-330ac84b-12f6-4124-95d9-7c98b00389c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-601b7f2f-d5cc-4f9a-89a5-442667ca1238,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-19e741ac-67e5-47b3-89f7-b8c3baeaea1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211796912-172.17.0.6-1596963376741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-9ed03b8c-7f70-4c74-8e52-9bd9d28cbd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-bcf69b41-7152-4189-8d51-c6b9e187ae03,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-85605cc6-4c4b-49be-bd67-924c4c0cc934,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-c6b2cbc3-7688-4492-8ff3-51112a7a2dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-b1e376ea-dde0-4199-9c6d-652c2f62e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-330ac84b-12f6-4124-95d9-7c98b00389c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-601b7f2f-d5cc-4f9a-89a5-442667ca1238,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-19e741ac-67e5-47b3-89f7-b8c3baeaea1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901278331-172.17.0.6-1596963412901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46334,DS-f0dfead1-b14e-4caa-ab69-f82bc1ba3108,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-ba85707a-dae7-43fa-8209-297cbad62e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-540f0e64-661b-47f4-b9f7-8f19dfdd592b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-53e09bf7-bcc2-4495-bf9b-e38c6e7f7001,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-8d637852-88be-4d4a-a310-55cdeda675f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-de3dd215-b6ae-428b-b573-510fa003b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-cfb42bc6-7bf2-406a-8c4c-24c3d04c7b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-9eadc083-3fd0-484f-9880-a540dd24b18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901278331-172.17.0.6-1596963412901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46334,DS-f0dfead1-b14e-4caa-ab69-f82bc1ba3108,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-ba85707a-dae7-43fa-8209-297cbad62e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-540f0e64-661b-47f4-b9f7-8f19dfdd592b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-53e09bf7-bcc2-4495-bf9b-e38c6e7f7001,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-8d637852-88be-4d4a-a310-55cdeda675f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-de3dd215-b6ae-428b-b573-510fa003b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-cfb42bc6-7bf2-406a-8c4c-24c3d04c7b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-9eadc083-3fd0-484f-9880-a540dd24b18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5032
