reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516614259-172.17.0.7-1595293577590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41934,DS-909e82ba-a1bd-49ae-a1ef-e6196fd76d02,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-b1442d02-b5c2-497f-90df-d86d7ed604e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-58d835a3-4395-4926-9bc3-be2c66532e72,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-89c495bf-9eb6-41d1-b111-57d161c49cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-339b88ea-7bcf-49f9-bf87-6bc81e3ba59c,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-80870b32-4e25-4492-97b4-c29bbbc0cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-d46a9d8c-cea8-444e-bd6d-59095fd2efe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-b164031a-0e2b-4aca-a39f-1323c2e2580d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516614259-172.17.0.7-1595293577590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41934,DS-909e82ba-a1bd-49ae-a1ef-e6196fd76d02,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-b1442d02-b5c2-497f-90df-d86d7ed604e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-58d835a3-4395-4926-9bc3-be2c66532e72,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-89c495bf-9eb6-41d1-b111-57d161c49cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-339b88ea-7bcf-49f9-bf87-6bc81e3ba59c,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-80870b32-4e25-4492-97b4-c29bbbc0cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-d46a9d8c-cea8-444e-bd6d-59095fd2efe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-b164031a-0e2b-4aca-a39f-1323c2e2580d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216673834-172.17.0.7-1595293765287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-e64218bd-52f7-44cd-81f9-23467d64d3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-19215fe6-2a8c-4d59-890d-8439682ea969,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-471a469f-adae-4101-9ef3-e8c641d8a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-100e85d8-4304-4235-adae-82d97c4d5a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-2948b757-6813-4361-9b1e-728bd4a95ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-05a9bb66-ea04-42ab-94be-5e49dbe21f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-983b0758-2544-411e-9e6f-5b1f634070e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-7de9c522-b406-46b4-a8ab-4ad295049517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216673834-172.17.0.7-1595293765287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-e64218bd-52f7-44cd-81f9-23467d64d3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-19215fe6-2a8c-4d59-890d-8439682ea969,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-471a469f-adae-4101-9ef3-e8c641d8a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-100e85d8-4304-4235-adae-82d97c4d5a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-2948b757-6813-4361-9b1e-728bd4a95ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-05a9bb66-ea04-42ab-94be-5e49dbe21f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-983b0758-2544-411e-9e6f-5b1f634070e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-7de9c522-b406-46b4-a8ab-4ad295049517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056397175-172.17.0.7-1595293900856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-0c07df72-3747-4f7f-bdc3-267003f4c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-87021f6c-553c-4ffa-8079-8b009be897a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-733ebcb1-dd5b-46d1-bba2-bb7cdb9e0311,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-8764c83a-a06d-4242-95b3-f7cf501ec4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-7bed4082-57b5-4b5c-966f-81ffd1ec42b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-c5a52b46-0d5c-4901-abe7-925c6eff77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-0c3af199-9dea-4e52-8349-3f63d96cfffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-a334b0b1-c84d-427b-927d-9d2197ec53b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056397175-172.17.0.7-1595293900856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-0c07df72-3747-4f7f-bdc3-267003f4c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-87021f6c-553c-4ffa-8079-8b009be897a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-733ebcb1-dd5b-46d1-bba2-bb7cdb9e0311,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-8764c83a-a06d-4242-95b3-f7cf501ec4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-7bed4082-57b5-4b5c-966f-81ffd1ec42b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-c5a52b46-0d5c-4901-abe7-925c6eff77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-0c3af199-9dea-4e52-8349-3f63d96cfffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-a334b0b1-c84d-427b-927d-9d2197ec53b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964931981-172.17.0.7-1595294010211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-9f9f59e8-2d7e-4b0e-8de7-61a9f365a8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-3e4cc421-f01a-4ef8-a1e5-4a84cd45b176,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-26c21eba-dac7-4b30-9b30-3c086676e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-2e6487d2-479c-4f15-843f-7ec1f19ea05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-8198973f-9f8a-464a-809c-65bf9fb271eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-35cc292d-9278-42bd-97a7-1604845026eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-873061ba-3a93-4901-9f5d-b0dacf980ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-0981fecd-8ece-471a-b1f3-7a205cc1eca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964931981-172.17.0.7-1595294010211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-9f9f59e8-2d7e-4b0e-8de7-61a9f365a8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-3e4cc421-f01a-4ef8-a1e5-4a84cd45b176,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-26c21eba-dac7-4b30-9b30-3c086676e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-2e6487d2-479c-4f15-843f-7ec1f19ea05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-8198973f-9f8a-464a-809c-65bf9fb271eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-35cc292d-9278-42bd-97a7-1604845026eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-873061ba-3a93-4901-9f5d-b0dacf980ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-0981fecd-8ece-471a-b1f3-7a205cc1eca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886275596-172.17.0.7-1595294044644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39092,DS-22ab0de7-cc54-426f-bf54-a483ef74ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-50cb0647-bdd5-4e81-924f-281faed8a3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-bab7b883-1397-43c9-9fba-880353af39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-2514251d-503d-4887-91e2-5af8c9555295,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-a8e2810b-17eb-42d2-a716-cdeb80285344,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-558260a1-fa1a-4fe5-93b5-ae1b5ad1d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-96725596-2ee3-4a30-ad1f-b498211596fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-6cbae429-ff7c-435f-81e2-fca04403d131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886275596-172.17.0.7-1595294044644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39092,DS-22ab0de7-cc54-426f-bf54-a483ef74ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-50cb0647-bdd5-4e81-924f-281faed8a3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-bab7b883-1397-43c9-9fba-880353af39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-2514251d-503d-4887-91e2-5af8c9555295,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-a8e2810b-17eb-42d2-a716-cdeb80285344,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-558260a1-fa1a-4fe5-93b5-ae1b5ad1d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-96725596-2ee3-4a30-ad1f-b498211596fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-6cbae429-ff7c-435f-81e2-fca04403d131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492642117-172.17.0.7-1595294454887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-bccd7e0c-f389-4a87-bcb7-16388f64b550,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-f9ff686e-6928-4a6e-8f9b-545ab5f9ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-7547fe4d-88b0-442a-b9c9-8509648f962b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-20734e3d-d581-410e-807a-355661fdc564,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-38d592b0-10a1-4992-b26d-da907644447a,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-f6343a5b-1a6b-417c-9ec4-e84c1f00723c,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-c10cc369-0913-44a5-8c09-b446a60e5a15,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-32a88756-a2d8-4292-83a9-52474bccd8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492642117-172.17.0.7-1595294454887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-bccd7e0c-f389-4a87-bcb7-16388f64b550,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-f9ff686e-6928-4a6e-8f9b-545ab5f9ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-7547fe4d-88b0-442a-b9c9-8509648f962b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-20734e3d-d581-410e-807a-355661fdc564,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-38d592b0-10a1-4992-b26d-da907644447a,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-f6343a5b-1a6b-417c-9ec4-e84c1f00723c,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-c10cc369-0913-44a5-8c09-b446a60e5a15,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-32a88756-a2d8-4292-83a9-52474bccd8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746224684-172.17.0.7-1595294770556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-d29cae87-8487-4d0c-91b7-7dd153a87698,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-eded5f60-3365-4baa-84ea-1b35f0749201,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-4a93ccbe-6914-47a9-819c-5005376f4cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-bdf4a552-7477-4c5f-a282-84384de20d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-892ac1b8-4058-4691-af25-75d71b823734,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-624084db-19a3-4399-851f-cf1f9f9cdce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-1f6714b0-a247-4799-bc8a-45c3554a82f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-bf51d0be-46f9-4c52-8bef-4e2bb7065367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746224684-172.17.0.7-1595294770556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-d29cae87-8487-4d0c-91b7-7dd153a87698,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-eded5f60-3365-4baa-84ea-1b35f0749201,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-4a93ccbe-6914-47a9-819c-5005376f4cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-bdf4a552-7477-4c5f-a282-84384de20d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-892ac1b8-4058-4691-af25-75d71b823734,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-624084db-19a3-4399-851f-cf1f9f9cdce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-1f6714b0-a247-4799-bc8a-45c3554a82f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-bf51d0be-46f9-4c52-8bef-4e2bb7065367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779613202-172.17.0.7-1595294956413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-1353fff0-2670-4cb7-b09a-bfa3c23678e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-ca786aac-ab24-4a8a-9b1e-06270ef96118,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-09c9cef9-7a69-4119-ab6e-d00c5b011a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-b39a328b-5bc5-44bf-b56d-e8e8726b87ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-c6fb60f6-3375-409e-92a2-d97b7fccb672,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-efe1cfd6-3dee-464d-ae03-c7c9cd4ee843,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-3a24cc74-2c91-4c8f-a1ba-b6fabc3875f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-e11ae2dd-cefb-42ca-8f12-689754dc6aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779613202-172.17.0.7-1595294956413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-1353fff0-2670-4cb7-b09a-bfa3c23678e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-ca786aac-ab24-4a8a-9b1e-06270ef96118,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-09c9cef9-7a69-4119-ab6e-d00c5b011a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-b39a328b-5bc5-44bf-b56d-e8e8726b87ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-c6fb60f6-3375-409e-92a2-d97b7fccb672,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-efe1cfd6-3dee-464d-ae03-c7c9cd4ee843,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-3a24cc74-2c91-4c8f-a1ba-b6fabc3875f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-e11ae2dd-cefb-42ca-8f12-689754dc6aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899591496-172.17.0.7-1595295150753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-9f1975c8-886d-43cf-a09a-5e3a92979afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-ed4c2bd0-6007-4a64-8946-7e5e5866ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-6109022b-342d-4887-8eb1-1f410b8cff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-5c4f0c40-bc1f-4e22-9369-5248b498775c,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-68f85b83-1027-4fda-b7ee-3454a3471179,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-a4867113-a6db-44a4-b14f-da2628c3af84,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-bec1867a-781e-46c3-834e-7a0ac13b99fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-108eba65-2f78-4ed1-bc6f-409b1df662b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899591496-172.17.0.7-1595295150753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-9f1975c8-886d-43cf-a09a-5e3a92979afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-ed4c2bd0-6007-4a64-8946-7e5e5866ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-6109022b-342d-4887-8eb1-1f410b8cff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-5c4f0c40-bc1f-4e22-9369-5248b498775c,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-68f85b83-1027-4fda-b7ee-3454a3471179,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-a4867113-a6db-44a4-b14f-da2628c3af84,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-bec1867a-781e-46c3-834e-7a0ac13b99fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-108eba65-2f78-4ed1-bc6f-409b1df662b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548320581-172.17.0.7-1595295527346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-de0e4717-9e2e-44c2-b54a-6e05494485d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-2b41a461-e616-4b2d-a674-728e3ac5ef79,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-e259b482-dac8-4c6c-8771-538f4d5a8a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-7e428dea-6e88-4fce-9879-1051f5386f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-ed965a8d-ecb7-4184-ac42-9d24440ba79a,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-6260efa1-9f47-4d6a-ba16-793c825a23ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-ffb4431b-c4b2-4bd0-9579-f664c68397e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-d4a798de-3f85-4e0b-aa1b-a364c4a14a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548320581-172.17.0.7-1595295527346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-de0e4717-9e2e-44c2-b54a-6e05494485d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-2b41a461-e616-4b2d-a674-728e3ac5ef79,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-e259b482-dac8-4c6c-8771-538f4d5a8a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-7e428dea-6e88-4fce-9879-1051f5386f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-ed965a8d-ecb7-4184-ac42-9d24440ba79a,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-6260efa1-9f47-4d6a-ba16-793c825a23ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-ffb4431b-c4b2-4bd0-9579-f664c68397e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-d4a798de-3f85-4e0b-aa1b-a364c4a14a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712631250-172.17.0.7-1595295879103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-d0056900-c188-4ef4-adcd-dae8567ccbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-5d911fb5-78e9-4417-9699-b49900aae532,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-6c13b56d-db0f-4760-bab5-ce6103e3fc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-970cb6b4-f312-4948-9909-28fd774b46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-538acd8c-7963-4e6a-bb3b-66ab87e1f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-e77c17ff-17eb-4ff2-a9f5-52f2cd482fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-dd03362f-2830-4b0e-aab2-3805fe870bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-e1359649-2159-4d66-8033-9697c6582995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712631250-172.17.0.7-1595295879103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-d0056900-c188-4ef4-adcd-dae8567ccbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-5d911fb5-78e9-4417-9699-b49900aae532,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-6c13b56d-db0f-4760-bab5-ce6103e3fc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-970cb6b4-f312-4948-9909-28fd774b46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-538acd8c-7963-4e6a-bb3b-66ab87e1f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-e77c17ff-17eb-4ff2-a9f5-52f2cd482fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-dd03362f-2830-4b0e-aab2-3805fe870bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-e1359649-2159-4d66-8033-9697c6582995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595978170-172.17.0.7-1595296372968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-d2bd560e-9cee-401a-9e99-2dcd3f8cd666,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-c69bc136-2b58-473b-9147-8e7c26f2d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-13f9510b-3acc-4618-9ecc-e2b5e06c0ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-b59a8a86-3f74-45f6-9bf8-332dc1fab0db,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-f8fcd4d5-7e90-4389-b1aa-1008e97239fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-8d77dae5-ba0a-4cc7-adc3-acd4a894e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-4c938c22-1340-4c73-b20a-3fbfb669f724,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-15d7e863-8d35-4995-af24-7bf272e61c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595978170-172.17.0.7-1595296372968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-d2bd560e-9cee-401a-9e99-2dcd3f8cd666,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-c69bc136-2b58-473b-9147-8e7c26f2d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-13f9510b-3acc-4618-9ecc-e2b5e06c0ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-b59a8a86-3f74-45f6-9bf8-332dc1fab0db,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-f8fcd4d5-7e90-4389-b1aa-1008e97239fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-8d77dae5-ba0a-4cc7-adc3-acd4a894e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-4c938c22-1340-4c73-b20a-3fbfb669f724,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-15d7e863-8d35-4995-af24-7bf272e61c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645932884-172.17.0.7-1595296407814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-e36980e5-ac19-4c50-81c0-a0ffe376cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-a6f07d26-b58c-4e5e-92f7-f3756d625002,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-3876463f-38f1-4dea-9f26-e8acb996bbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-bd6638d5-9f9b-4fb1-a06f-b5cbf340fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-e88a8bb0-d00a-4b2c-a5d5-754a8802b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-0aa09372-e7a7-4f42-8d5d-a40e029f66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-b5afee05-53e6-41c9-9103-d27aad3871af,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-2818aa52-be25-4ae1-9545-219b690f646a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645932884-172.17.0.7-1595296407814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-e36980e5-ac19-4c50-81c0-a0ffe376cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-a6f07d26-b58c-4e5e-92f7-f3756d625002,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-3876463f-38f1-4dea-9f26-e8acb996bbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-bd6638d5-9f9b-4fb1-a06f-b5cbf340fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-e88a8bb0-d00a-4b2c-a5d5-754a8802b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-0aa09372-e7a7-4f42-8d5d-a40e029f66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-b5afee05-53e6-41c9-9103-d27aad3871af,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-2818aa52-be25-4ae1-9545-219b690f646a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672239533-172.17.0.7-1595296553868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38587,DS-7dc2a5f2-9118-4502-b3b6-52974eec7c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-822d7692-43b6-422b-a0e3-6a723663a79c,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-aa8a07cb-9038-4890-87fc-632eee1a359b,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-fd38d60d-0a85-4698-8724-6d0058626f46,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-4030b05d-f259-49ec-943f-8119e04ffc40,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-b8949e11-7a2a-45dd-8704-3aca7d7910b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-de8ac92d-34a5-42a6-8b57-478c6d38d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-e94ed393-9d41-4f9a-8e72-f45a1148e386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672239533-172.17.0.7-1595296553868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38587,DS-7dc2a5f2-9118-4502-b3b6-52974eec7c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-822d7692-43b6-422b-a0e3-6a723663a79c,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-aa8a07cb-9038-4890-87fc-632eee1a359b,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-fd38d60d-0a85-4698-8724-6d0058626f46,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-4030b05d-f259-49ec-943f-8119e04ffc40,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-b8949e11-7a2a-45dd-8704-3aca7d7910b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-de8ac92d-34a5-42a6-8b57-478c6d38d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-e94ed393-9d41-4f9a-8e72-f45a1148e386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417633025-172.17.0.7-1595297014724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-34cf7c89-f9c2-4b6d-9162-24ac05d69c50,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-c3eb3fbf-63a8-40c1-96ab-5f68c47b9ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-a2d90275-f79e-4419-9f0d-562c0e578dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-513187f8-a694-454b-a64e-a3f093e0e20c,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-d8b5e4fd-3f8c-433b-a283-150c27e26c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-5c121937-df85-4f40-bb03-22512953e526,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-26856cda-877e-4efe-860a-c9c61043173e,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-2454b187-08c8-4abb-b556-e6c3c04ef1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417633025-172.17.0.7-1595297014724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-34cf7c89-f9c2-4b6d-9162-24ac05d69c50,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-c3eb3fbf-63a8-40c1-96ab-5f68c47b9ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-a2d90275-f79e-4419-9f0d-562c0e578dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-513187f8-a694-454b-a64e-a3f093e0e20c,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-d8b5e4fd-3f8c-433b-a283-150c27e26c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-5c121937-df85-4f40-bb03-22512953e526,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-26856cda-877e-4efe-860a-c9c61043173e,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-2454b187-08c8-4abb-b556-e6c3c04ef1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569064664-172.17.0.7-1595297166198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-5912426f-4aef-4145-ae8d-cdc47e60fdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-b397172c-4b36-4f28-a1eb-9a85330717dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-8bd390a8-527b-4247-b827-8ac75f1794d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-1cf23f16-a116-4b48-9e90-a60b401d15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-4097a8e0-eb0e-4e32-b9f0-128a3617d679,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-75751a99-6c34-453e-837b-ab7e55043872,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-3e915ee6-0b65-440e-8d4a-0f653eece502,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-f03d7280-5180-41ea-a09c-ff063921aa78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569064664-172.17.0.7-1595297166198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-5912426f-4aef-4145-ae8d-cdc47e60fdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-b397172c-4b36-4f28-a1eb-9a85330717dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-8bd390a8-527b-4247-b827-8ac75f1794d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-1cf23f16-a116-4b48-9e90-a60b401d15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-4097a8e0-eb0e-4e32-b9f0-128a3617d679,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-75751a99-6c34-453e-837b-ab7e55043872,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-3e915ee6-0b65-440e-8d4a-0f653eece502,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-f03d7280-5180-41ea-a09c-ff063921aa78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134076055-172.17.0.7-1595297215924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-f5cde385-1907-4f7a-a724-738d7da43884,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-024d796b-49ba-4e8d-ae6c-d72da27a3e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-6b928525-5c05-43b8-8179-55f758b5f6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-3b22ad05-9a4f-4e98-b343-04efc5a98532,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-220fd9d4-b15a-4aa1-95af-3157cf31ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-e1f65de1-93cb-421c-a53b-fa26a89ecf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-68f9cc65-6d5b-4f24-9125-b39b51e87212,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-a8c8fccf-73a6-4207-ab44-1ca00a6c1246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134076055-172.17.0.7-1595297215924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-f5cde385-1907-4f7a-a724-738d7da43884,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-024d796b-49ba-4e8d-ae6c-d72da27a3e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-6b928525-5c05-43b8-8179-55f758b5f6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-3b22ad05-9a4f-4e98-b343-04efc5a98532,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-220fd9d4-b15a-4aa1-95af-3157cf31ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-e1f65de1-93cb-421c-a53b-fa26a89ecf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-68f9cc65-6d5b-4f24-9125-b39b51e87212,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-a8c8fccf-73a6-4207-ab44-1ca00a6c1246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954109258-172.17.0.7-1595297368845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-53748cc3-a031-4689-b1f5-c699d3703bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-708ecf23-8a1f-4eec-a15a-d7c13cdb98bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-83b5cae6-ad71-4b35-952c-d59f1e4527fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-f6b22b78-0205-44b9-8f9f-c570cb962364,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-420241ea-4919-43cc-8f24-b9b3cfc1fb95,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-564f0134-d190-47fc-a349-a01d3e380afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-722a09e8-da3b-4287-8d0a-bf2e7de8197e,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-f261e5fb-19df-43d7-8eea-858a143c86e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954109258-172.17.0.7-1595297368845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-53748cc3-a031-4689-b1f5-c699d3703bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-708ecf23-8a1f-4eec-a15a-d7c13cdb98bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-83b5cae6-ad71-4b35-952c-d59f1e4527fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-f6b22b78-0205-44b9-8f9f-c570cb962364,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-420241ea-4919-43cc-8f24-b9b3cfc1fb95,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-564f0134-d190-47fc-a349-a01d3e380afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-722a09e8-da3b-4287-8d0a-bf2e7de8197e,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-f261e5fb-19df-43d7-8eea-858a143c86e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800533638-172.17.0.7-1595297408431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38845,DS-2bb64e41-dd1b-4b00-9459-61062eb8662a,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-47a1ae23-ab63-4292-bab1-c12bfffc6552,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-faa3a655-4a21-445b-b4c3-a6fabc36bbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-1f0b4bfd-4e88-4c97-8cad-1bae8bb30004,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-49f785bb-dacf-494a-a6ad-931598ef220e,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-006feed1-fcf6-4690-b03b-580498dd4c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-0f78c87f-dab5-482a-a689-8620ab8124c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2ca8a95c-2d31-4518-af64-38a90651fc27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800533638-172.17.0.7-1595297408431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38845,DS-2bb64e41-dd1b-4b00-9459-61062eb8662a,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-47a1ae23-ab63-4292-bab1-c12bfffc6552,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-faa3a655-4a21-445b-b4c3-a6fabc36bbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-1f0b4bfd-4e88-4c97-8cad-1bae8bb30004,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-49f785bb-dacf-494a-a6ad-931598ef220e,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-006feed1-fcf6-4690-b03b-580498dd4c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-0f78c87f-dab5-482a-a689-8620ab8124c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2ca8a95c-2d31-4518-af64-38a90651fc27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013778874-172.17.0.7-1595297950428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-65651288-1e88-4662-89d6-48a5a04e73ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-b87fcc8d-7688-4201-af87-535e46817c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-2bb15164-25b3-40d1-9887-688ba36b5ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-216294fa-c4ef-476c-b662-c5e71fe23771,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-5937117e-a90a-4d3c-9916-2feefe963e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-69e87f50-9da7-46ec-8c14-b344fcf5b880,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-9e7c8897-c4e3-4f11-8250-75446d69ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-bf739632-bb57-4916-bb4b-f1578a20cfe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013778874-172.17.0.7-1595297950428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-65651288-1e88-4662-89d6-48a5a04e73ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-b87fcc8d-7688-4201-af87-535e46817c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-2bb15164-25b3-40d1-9887-688ba36b5ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-216294fa-c4ef-476c-b662-c5e71fe23771,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-5937117e-a90a-4d3c-9916-2feefe963e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-69e87f50-9da7-46ec-8c14-b344fcf5b880,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-9e7c8897-c4e3-4f11-8250-75446d69ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-bf739632-bb57-4916-bb4b-f1578a20cfe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 4970
