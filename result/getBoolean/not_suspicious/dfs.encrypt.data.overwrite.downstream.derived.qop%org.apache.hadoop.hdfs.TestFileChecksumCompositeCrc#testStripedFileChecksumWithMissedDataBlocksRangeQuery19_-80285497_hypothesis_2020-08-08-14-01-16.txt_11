reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030445298-172.17.0.15-1596895547633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-5be8ed23-ea2c-4fa0-9f1c-738e4d7d10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-43004260-5f7e-4567-a080-449c87cadbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-93234531-2bb9-4953-a58c-fa68b89c5818,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-cf966389-f3bb-4dc8-83e4-9e018fae9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-275e99b7-cc6d-4895-833a-444e2daf776f,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-f934062f-1303-4b87-b632-b8a3efb6b53c,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-28d7f281-2c0f-4b4f-afa5-c8113944827f,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-3a8ee37a-8543-4736-b115-8c9e5b89e545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030445298-172.17.0.15-1596895547633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-5be8ed23-ea2c-4fa0-9f1c-738e4d7d10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-43004260-5f7e-4567-a080-449c87cadbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-93234531-2bb9-4953-a58c-fa68b89c5818,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-cf966389-f3bb-4dc8-83e4-9e018fae9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-275e99b7-cc6d-4895-833a-444e2daf776f,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-f934062f-1303-4b87-b632-b8a3efb6b53c,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-28d7f281-2c0f-4b4f-afa5-c8113944827f,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-3a8ee37a-8543-4736-b115-8c9e5b89e545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52216517-172.17.0.15-1596895621383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-3c7332de-ef3f-4e2a-8b62-499a2835b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-5aad4931-5b6d-415c-b9f5-b4bfe3d149b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-4ceeec44-ed68-4882-95c3-0dc20129c223,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-1eea3cae-45a3-41e7-b40e-af8d700b5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-cefea598-3cd2-4752-b337-74011b6d94f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-f915ade9-9913-4197-8503-220f2513644e,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-750f14d9-7dce-4da4-a26d-4e27a26078b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-dda0106f-2b51-4509-a65c-a882753ca9b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52216517-172.17.0.15-1596895621383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-3c7332de-ef3f-4e2a-8b62-499a2835b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-5aad4931-5b6d-415c-b9f5-b4bfe3d149b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-4ceeec44-ed68-4882-95c3-0dc20129c223,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-1eea3cae-45a3-41e7-b40e-af8d700b5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-cefea598-3cd2-4752-b337-74011b6d94f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-f915ade9-9913-4197-8503-220f2513644e,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-750f14d9-7dce-4da4-a26d-4e27a26078b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-dda0106f-2b51-4509-a65c-a882753ca9b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728199171-172.17.0.15-1596895659729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-508b03fd-b17c-4325-a255-d2da0571fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-7dcea2d5-8e8e-42af-a1dd-991dd49cd5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-dd4ca5ab-ab31-4375-aa65-59953bbebc21,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-cbad711c-e837-4357-b54a-5eb1a52e1f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-5fd98e7d-b5de-4b9c-9d9e-1824d23a543b,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-60cbe6eb-d724-4145-b84e-b3b179b1ec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-a4062331-c950-4848-9e2a-5c9fd365e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-ff8055bb-586b-4b61-9e09-03c1ed6b1294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728199171-172.17.0.15-1596895659729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-508b03fd-b17c-4325-a255-d2da0571fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-7dcea2d5-8e8e-42af-a1dd-991dd49cd5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-dd4ca5ab-ab31-4375-aa65-59953bbebc21,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-cbad711c-e837-4357-b54a-5eb1a52e1f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-5fd98e7d-b5de-4b9c-9d9e-1824d23a543b,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-60cbe6eb-d724-4145-b84e-b3b179b1ec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-a4062331-c950-4848-9e2a-5c9fd365e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-ff8055bb-586b-4b61-9e09-03c1ed6b1294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419241924-172.17.0.15-1596895755333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-a9f2e4d8-42ec-461f-93cd-7940359aae26,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-b7b1259b-4fbf-4b9e-877a-3e8b3521c126,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-466618e1-40ad-4856-9700-261c51512a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-32d423cf-2751-40c1-8cdb-16d2b2660a88,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-2e29664a-2b9d-4d21-93c5-1f795ea8fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-644263f9-e639-4e88-8646-7d13e964fb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-4ea77cc3-0b86-47e5-a916-bc9a375d3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-25b4ead6-6a38-498b-91da-aecbbb04d9da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419241924-172.17.0.15-1596895755333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-a9f2e4d8-42ec-461f-93cd-7940359aae26,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-b7b1259b-4fbf-4b9e-877a-3e8b3521c126,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-466618e1-40ad-4856-9700-261c51512a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-32d423cf-2751-40c1-8cdb-16d2b2660a88,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-2e29664a-2b9d-4d21-93c5-1f795ea8fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-644263f9-e639-4e88-8646-7d13e964fb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-4ea77cc3-0b86-47e5-a916-bc9a375d3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-25b4ead6-6a38-498b-91da-aecbbb04d9da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207562960-172.17.0.15-1596896504912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-6eea85ab-f7b1-4be8-8e1d-6673cc31a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-edfba01b-b4bf-4e6d-bdda-62ccdf0236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-1182cce1-3b4f-498c-9f92-6779c0e6e0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-90c5516a-4c37-4b71-b5bf-6b628b8dd933,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-acfff625-5987-44d2-87a0-5f4aab2541b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-68417bac-c09a-45be-a551-93c2c49fbb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-b1f60752-1e65-4a55-bced-2fa17d76b925,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-332668d7-55fc-4535-be31-7ffa669c4c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207562960-172.17.0.15-1596896504912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-6eea85ab-f7b1-4be8-8e1d-6673cc31a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-edfba01b-b4bf-4e6d-bdda-62ccdf0236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-1182cce1-3b4f-498c-9f92-6779c0e6e0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-90c5516a-4c37-4b71-b5bf-6b628b8dd933,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-acfff625-5987-44d2-87a0-5f4aab2541b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-68417bac-c09a-45be-a551-93c2c49fbb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-b1f60752-1e65-4a55-bced-2fa17d76b925,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-332668d7-55fc-4535-be31-7ffa669c4c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735864179-172.17.0.15-1596896540028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-1a1ead1c-ecb6-4ec3-a2f8-7cd4bc2ad3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0ff8dbe7-b291-4e8f-9a38-97c1374528f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-7b880ab1-6fbf-4418-a98b-b7d528bd3d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ecfe5ebd-f6ee-4a40-90bb-2ca2df7c9b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-521e4ce4-0b6c-46be-b830-7e8b5a7a6b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-635e690a-80e0-4b60-91a4-d9b593a3c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-c90efcb8-83de-41bf-ab7c-c1dc308d77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-7ddf47af-8d30-4f7e-ab4c-733f07351b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735864179-172.17.0.15-1596896540028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-1a1ead1c-ecb6-4ec3-a2f8-7cd4bc2ad3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0ff8dbe7-b291-4e8f-9a38-97c1374528f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-7b880ab1-6fbf-4418-a98b-b7d528bd3d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ecfe5ebd-f6ee-4a40-90bb-2ca2df7c9b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-521e4ce4-0b6c-46be-b830-7e8b5a7a6b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-635e690a-80e0-4b60-91a4-d9b593a3c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-c90efcb8-83de-41bf-ab7c-c1dc308d77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-7ddf47af-8d30-4f7e-ab4c-733f07351b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950723315-172.17.0.15-1596896575006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35828,DS-d8974a23-28bd-4c95-89bb-88a4abddf447,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-443b1c0b-7456-427d-b683-3c39559600d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-c34aeef6-0d4d-4f4b-a833-8f16bc890b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-981dce8d-dad0-4190-88a9-e41ebaa695a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-c212b150-d01d-4d6c-acb2-4066cbd12565,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-1b90cc51-76cd-4b20-89dd-959ca7851b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-62756edb-e6dd-48e5-95a4-f97a7c24cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-c93e8b89-5cd2-4817-8438-153b4c64b0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950723315-172.17.0.15-1596896575006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35828,DS-d8974a23-28bd-4c95-89bb-88a4abddf447,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-443b1c0b-7456-427d-b683-3c39559600d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-c34aeef6-0d4d-4f4b-a833-8f16bc890b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-981dce8d-dad0-4190-88a9-e41ebaa695a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-c212b150-d01d-4d6c-acb2-4066cbd12565,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-1b90cc51-76cd-4b20-89dd-959ca7851b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-62756edb-e6dd-48e5-95a4-f97a7c24cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-c93e8b89-5cd2-4817-8438-153b4c64b0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799090900-172.17.0.15-1596896637860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-6b4c4fd8-5d15-4271-9e7a-aa809e2e3ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-51b619cc-1dc7-4b47-aed8-ca31904bd837,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-c941b6c6-39a8-4967-8354-3439b16343f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-16991a86-fae9-43b2-ae87-80646d559d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-412c1cb9-1e26-4f3a-aaba-c7708f69812f,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-a55eaf34-e3e5-4105-b498-ffce630a5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-3602b418-d626-4423-91ef-01ed69d95935,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-adbf2970-7698-41d8-bc6d-7c24106bc99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799090900-172.17.0.15-1596896637860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-6b4c4fd8-5d15-4271-9e7a-aa809e2e3ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-51b619cc-1dc7-4b47-aed8-ca31904bd837,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-c941b6c6-39a8-4967-8354-3439b16343f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-16991a86-fae9-43b2-ae87-80646d559d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-412c1cb9-1e26-4f3a-aaba-c7708f69812f,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-a55eaf34-e3e5-4105-b498-ffce630a5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-3602b418-d626-4423-91ef-01ed69d95935,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-adbf2970-7698-41d8-bc6d-7c24106bc99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447207752-172.17.0.15-1596896875693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-4521c434-9dd3-46fd-b875-e3bc4f899922,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-61520da8-e89e-404a-8d20-6e76b940caae,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-c9ac598f-96b7-4a8b-b934-3254d92d57f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-a22cfbdc-3ac1-4d95-b041-20b0f79ea668,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-fc3dd0f2-4504-4ba4-8bfb-7f9be099bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-ac6fd49d-4f9e-4f20-acbf-fd3fad7f86fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-69c24783-c4de-47f2-bed8-5f15c67f2a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-298a3fb2-fb34-437d-844c-993af2561226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447207752-172.17.0.15-1596896875693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-4521c434-9dd3-46fd-b875-e3bc4f899922,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-61520da8-e89e-404a-8d20-6e76b940caae,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-c9ac598f-96b7-4a8b-b934-3254d92d57f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-a22cfbdc-3ac1-4d95-b041-20b0f79ea668,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-fc3dd0f2-4504-4ba4-8bfb-7f9be099bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-ac6fd49d-4f9e-4f20-acbf-fd3fad7f86fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-69c24783-c4de-47f2-bed8-5f15c67f2a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-298a3fb2-fb34-437d-844c-993af2561226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951338299-172.17.0.15-1596897041013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-b296546e-129f-4697-9774-fe640a6b6d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-5c5a6ff1-83ac-4895-b9fe-fda011520345,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-5e4d62dd-c097-4357-ab13-7edd5fbed7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-6a80ad5b-8301-4dc8-b979-32679bf0e150,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-219f26ef-4a27-43a7-bd33-675ac96e65be,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-74c8955b-30f5-4fb6-9972-1a6f2856f650,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-c8064e21-2525-49f3-ba1d-53db24a18db3,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-8d5f952e-7d27-494d-a403-82dc6f79ad8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951338299-172.17.0.15-1596897041013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-b296546e-129f-4697-9774-fe640a6b6d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-5c5a6ff1-83ac-4895-b9fe-fda011520345,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-5e4d62dd-c097-4357-ab13-7edd5fbed7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-6a80ad5b-8301-4dc8-b979-32679bf0e150,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-219f26ef-4a27-43a7-bd33-675ac96e65be,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-74c8955b-30f5-4fb6-9972-1a6f2856f650,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-c8064e21-2525-49f3-ba1d-53db24a18db3,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-8d5f952e-7d27-494d-a403-82dc6f79ad8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762913241-172.17.0.15-1596897143612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-91728b67-2307-4998-aaf9-77ca38e54b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-9a8de14f-b2f1-4b13-8f52-c032d3cb634d,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-27983e50-4635-47dd-9c55-7c6b386664d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-7b6d3c7d-edb4-43bb-b819-32e898be4a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-a2934558-0a48-4220-a235-ba27bf645db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-36b61541-c277-4fac-98c7-3d5fa7511123,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-ccd009f6-857f-44cd-bb98-9823ea606903,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-7b84dff8-b10c-4389-adb3-46c30263514e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762913241-172.17.0.15-1596897143612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-91728b67-2307-4998-aaf9-77ca38e54b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-9a8de14f-b2f1-4b13-8f52-c032d3cb634d,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-27983e50-4635-47dd-9c55-7c6b386664d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-7b6d3c7d-edb4-43bb-b819-32e898be4a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-a2934558-0a48-4220-a235-ba27bf645db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-36b61541-c277-4fac-98c7-3d5fa7511123,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-ccd009f6-857f-44cd-bb98-9823ea606903,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-7b84dff8-b10c-4389-adb3-46c30263514e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141724559-172.17.0.15-1596897371296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-e602160a-8d40-48aa-b617-659606b7dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-fd6835c2-0b37-45e0-8879-c466ba969bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-a093952a-1ceb-458c-9f73-d4d724d91226,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-ccbb2c6b-5891-407c-9d59-9a42de4c9fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6f00c807-22f9-4ae8-8d8c-905730d998ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-16d84e98-ffe4-454c-967e-1bdecf6e5c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-0b166015-37f5-4c39-9424-5ca8218fd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b99a0a06-4bf4-4ed2-886f-cbb46f4cd2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141724559-172.17.0.15-1596897371296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-e602160a-8d40-48aa-b617-659606b7dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-fd6835c2-0b37-45e0-8879-c466ba969bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-a093952a-1ceb-458c-9f73-d4d724d91226,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-ccbb2c6b-5891-407c-9d59-9a42de4c9fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6f00c807-22f9-4ae8-8d8c-905730d998ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-16d84e98-ffe4-454c-967e-1bdecf6e5c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-0b166015-37f5-4c39-9424-5ca8218fd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b99a0a06-4bf4-4ed2-886f-cbb46f4cd2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106707559-172.17.0.15-1596897407032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-44a7c78a-f680-4768-bc13-9ad7a1b8edc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-f6bfff89-3988-48c7-a0a4-dd28ef7ea197,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-59b1259d-cad7-4846-abd0-d7430d1ebb20,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-4da2fe29-0457-48a7-ad95-3215bd99f7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-09f5d6df-823e-405d-9f27-193bdf670486,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-5bfdc3e9-855a-4de7-a314-9e3266435504,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-7456a1ae-9b75-4133-8d7d-5a8f68ea767d,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-152a7544-6d3b-483e-a070-2f375197cbdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106707559-172.17.0.15-1596897407032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-44a7c78a-f680-4768-bc13-9ad7a1b8edc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-f6bfff89-3988-48c7-a0a4-dd28ef7ea197,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-59b1259d-cad7-4846-abd0-d7430d1ebb20,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-4da2fe29-0457-48a7-ad95-3215bd99f7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-09f5d6df-823e-405d-9f27-193bdf670486,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-5bfdc3e9-855a-4de7-a314-9e3266435504,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-7456a1ae-9b75-4133-8d7d-5a8f68ea767d,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-152a7544-6d3b-483e-a070-2f375197cbdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985295816-172.17.0.15-1596897607617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40266,DS-59fabc90-7fd9-4f74-b429-0b719bf65a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-9ceec9c8-9bc9-4061-9cec-8d110737a123,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-c8f0b851-66db-4522-bad1-bd56997b3874,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-a1799a60-901b-427b-9dad-0ee1f3d642c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-5b84cdb7-3bb5-4440-a0c9-192dc60484c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-c0c61a34-a027-4e7c-87f1-8459ee6871a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-c682d904-ca9a-4ff4-a222-76b377c7a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-dc992276-3c78-46cf-8247-23e28bca8f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985295816-172.17.0.15-1596897607617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40266,DS-59fabc90-7fd9-4f74-b429-0b719bf65a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-9ceec9c8-9bc9-4061-9cec-8d110737a123,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-c8f0b851-66db-4522-bad1-bd56997b3874,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-a1799a60-901b-427b-9dad-0ee1f3d642c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-5b84cdb7-3bb5-4440-a0c9-192dc60484c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-c0c61a34-a027-4e7c-87f1-8459ee6871a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-c682d904-ca9a-4ff4-a222-76b377c7a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-dc992276-3c78-46cf-8247-23e28bca8f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548184177-172.17.0.15-1596898258844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38248,DS-2594da5f-a9f9-4048-9ce6-5b7008a16056,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-d469a6ec-ff63-4c4f-978a-625ca0dc9d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-e33d2720-ba86-441c-a551-c120d6b167a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-90c0746a-fd71-4e40-8930-6d2d69dd5869,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-689a05d6-deb8-4f5a-a4e8-27f89a2f0b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-3eb11415-2941-457b-b30f-10b9b92ad398,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-17e69388-7712-4e37-88b1-659a400f3195,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-69ea6258-54db-4ab5-accd-25750ea71bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548184177-172.17.0.15-1596898258844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38248,DS-2594da5f-a9f9-4048-9ce6-5b7008a16056,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-d469a6ec-ff63-4c4f-978a-625ca0dc9d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-e33d2720-ba86-441c-a551-c120d6b167a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-90c0746a-fd71-4e40-8930-6d2d69dd5869,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-689a05d6-deb8-4f5a-a4e8-27f89a2f0b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-3eb11415-2941-457b-b30f-10b9b92ad398,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-17e69388-7712-4e37-88b1-659a400f3195,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-69ea6258-54db-4ab5-accd-25750ea71bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306223475-172.17.0.15-1596898298517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-622cdc73-9429-4ccf-b662-3660059ce788,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-456c1dc7-617b-4fb7-86e8-83f8d96d6f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-bba62e85-a1e7-4f03-8a0c-22baec5cbf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-d4b75fce-3a73-4279-b5c6-e48e4f7da27c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-843f90e3-a025-42d9-a3d4-03bf9ab24138,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-e73593dc-390b-44df-b2a0-bee9691a739c,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-f30020dc-e369-4370-b246-8d59c333b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a63fb166-cafc-4886-9927-f92e8cda0b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306223475-172.17.0.15-1596898298517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-622cdc73-9429-4ccf-b662-3660059ce788,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-456c1dc7-617b-4fb7-86e8-83f8d96d6f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-bba62e85-a1e7-4f03-8a0c-22baec5cbf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-d4b75fce-3a73-4279-b5c6-e48e4f7da27c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-843f90e3-a025-42d9-a3d4-03bf9ab24138,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-e73593dc-390b-44df-b2a0-bee9691a739c,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-f30020dc-e369-4370-b246-8d59c333b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a63fb166-cafc-4886-9927-f92e8cda0b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799259085-172.17.0.15-1596898490588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-126f437c-a00c-45c7-ac4b-d493856c2043,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-cf3cf321-4925-401f-bf62-96e8ecd9f467,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-6baeb5f4-45f9-4b12-8b6b-24237804d17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-b26f94ce-dada-44ee-835a-e6d39db300fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-08952ed9-8d64-4f0b-9113-e0ac7048279d,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-f58f4632-4238-43ec-bc1f-6fcdcdbae09f,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-96d91c8d-672a-4642-b1fd-d5a1e15594d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-39b8a327-12cc-49eb-b292-82dfc234e4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799259085-172.17.0.15-1596898490588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-126f437c-a00c-45c7-ac4b-d493856c2043,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-cf3cf321-4925-401f-bf62-96e8ecd9f467,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-6baeb5f4-45f9-4b12-8b6b-24237804d17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-b26f94ce-dada-44ee-835a-e6d39db300fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-08952ed9-8d64-4f0b-9113-e0ac7048279d,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-f58f4632-4238-43ec-bc1f-6fcdcdbae09f,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-96d91c8d-672a-4642-b1fd-d5a1e15594d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-39b8a327-12cc-49eb-b292-82dfc234e4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899425002-172.17.0.15-1596898922912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-c790f8e0-c533-468a-b1f4-2acbf2610a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-674197cf-221b-445e-8998-50a8d07c03cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-e9c38c7f-4cf8-4f8a-8a3a-0037dd97c745,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-2fd5ed2e-9503-4639-8056-6f5b05c2d28b,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-04319fdc-6a8e-4c82-87f4-7a115d111f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-676cec3a-6802-4f75-837a-4da4e2154fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-f8994b1c-6a7d-400b-aed6-085e37bdbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-814c3d7f-d4bf-45dc-bc58-ab7789e0eea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899425002-172.17.0.15-1596898922912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-c790f8e0-c533-468a-b1f4-2acbf2610a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-674197cf-221b-445e-8998-50a8d07c03cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-e9c38c7f-4cf8-4f8a-8a3a-0037dd97c745,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-2fd5ed2e-9503-4639-8056-6f5b05c2d28b,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-04319fdc-6a8e-4c82-87f4-7a115d111f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-676cec3a-6802-4f75-837a-4da4e2154fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-f8994b1c-6a7d-400b-aed6-085e37bdbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-814c3d7f-d4bf-45dc-bc58-ab7789e0eea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285747998-172.17.0.15-1596899599619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-786cc17f-4830-4aa8-a9bb-3a4d20bee9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-77d5b69d-d44f-41ac-9591-14b0f8c613db,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-028f2ec2-e534-44fc-b212-cbae98b00e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-8fd90071-4668-43b6-ae48-b92296a2413b,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-430b34fa-dce6-426c-a9ae-27a3d6b3b4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-c9f0775b-2be4-4cee-b6e7-7425d5134be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-1deffcff-8d15-45c4-a4cc-8997a5748782,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-e17edddf-48cd-4f43-b848-1d03f8a4a5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285747998-172.17.0.15-1596899599619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-786cc17f-4830-4aa8-a9bb-3a4d20bee9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-77d5b69d-d44f-41ac-9591-14b0f8c613db,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-028f2ec2-e534-44fc-b212-cbae98b00e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-8fd90071-4668-43b6-ae48-b92296a2413b,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-430b34fa-dce6-426c-a9ae-27a3d6b3b4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-c9f0775b-2be4-4cee-b6e7-7425d5134be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-1deffcff-8d15-45c4-a4cc-8997a5748782,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-e17edddf-48cd-4f43-b848-1d03f8a4a5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482752998-172.17.0.15-1596899857336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-32c6fd6a-c88c-4c3a-a7fd-b440b706efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-6e8a4131-0050-4f93-b331-3c35f8ef4d25,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-b45858c8-5ee3-424e-aa9c-9831422a8ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1c24fb5e-8904-4d47-958f-f8e9664fbb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-588d41b5-aeb4-44af-b4c1-d0b93ff84aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-b97719aa-cde7-4862-99a4-aae3ec9a390d,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-80811663-29d9-4655-acf9-58d34099e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-c6efad00-6212-4f35-b37a-f9f8fa4026fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482752998-172.17.0.15-1596899857336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-32c6fd6a-c88c-4c3a-a7fd-b440b706efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-6e8a4131-0050-4f93-b331-3c35f8ef4d25,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-b45858c8-5ee3-424e-aa9c-9831422a8ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1c24fb5e-8904-4d47-958f-f8e9664fbb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-588d41b5-aeb4-44af-b4c1-d0b93ff84aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-b97719aa-cde7-4862-99a4-aae3ec9a390d,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-80811663-29d9-4655-acf9-58d34099e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-c6efad00-6212-4f35-b37a-f9f8fa4026fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1045924690-172.17.0.15-1596900187177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32768,DS-da6d6b64-215f-4dd9-88ac-ebf2f6ea8406,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-ddef35e0-cf1c-42fc-ba89-c47c0615debb,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-824d070f-6703-4a0e-a088-ecd32cf9c987,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-b721b939-80c4-477a-abc3-a4ced2d84bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-e35b98df-850d-4572-84bd-9ae88e4b695b,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-4ac4e4e4-f4c4-4938-92d6-3a275f719460,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8539348c-079c-4332-9160-92de2720a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-93e6e592-24d0-4128-848c-585b28294864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1045924690-172.17.0.15-1596900187177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32768,DS-da6d6b64-215f-4dd9-88ac-ebf2f6ea8406,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-ddef35e0-cf1c-42fc-ba89-c47c0615debb,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-824d070f-6703-4a0e-a088-ecd32cf9c987,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-b721b939-80c4-477a-abc3-a4ced2d84bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-e35b98df-850d-4572-84bd-9ae88e4b695b,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-4ac4e4e4-f4c4-4938-92d6-3a275f719460,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8539348c-079c-4332-9160-92de2720a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-93e6e592-24d0-4128-848c-585b28294864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334474887-172.17.0.15-1596900431779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-5b51c479-a103-4b04-ae55-66d05c105093,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-1f57feda-b004-4c23-93eb-ba4a661529f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-74d98c80-86ff-4da3-838b-00d6c2e3cfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-1ef90ae6-9c7f-46f4-8f89-32773a66098c,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c7408403-506d-447a-a7e0-4d4c916d21fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-725c4902-1d9f-47e7-9def-e2219dbd1bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-5c08d2eb-6f4f-4f2b-b457-c395de1a68a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-d0044481-b6fc-4ce5-a1dc-d9f2c6ba2883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334474887-172.17.0.15-1596900431779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-5b51c479-a103-4b04-ae55-66d05c105093,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-1f57feda-b004-4c23-93eb-ba4a661529f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-74d98c80-86ff-4da3-838b-00d6c2e3cfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-1ef90ae6-9c7f-46f4-8f89-32773a66098c,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c7408403-506d-447a-a7e0-4d4c916d21fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-725c4902-1d9f-47e7-9def-e2219dbd1bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-5c08d2eb-6f4f-4f2b-b457-c395de1a68a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-d0044481-b6fc-4ce5-a1dc-d9f2c6ba2883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5270
