reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704693025-172.17.0.18-1595342042346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35238,DS-3b503582-9e8c-4504-8663-b81341292656,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-540fca8d-44e5-4a31-bbd0-2db039161585,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-e22428c0-e9e1-4296-82a0-e4ad19c42e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-6a5b9dc4-57af-4bec-a3c2-eda2ec54e639,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-3a1d2617-c728-4f5d-ac5d-e228d8156092,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-6f0927d6-735c-4a56-b182-ce489a78c103,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-21080bc8-950a-4341-ade8-6863bb4a9952,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-8e627357-9a69-48e1-b99d-ce70879cfb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704693025-172.17.0.18-1595342042346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35238,DS-3b503582-9e8c-4504-8663-b81341292656,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-540fca8d-44e5-4a31-bbd0-2db039161585,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-e22428c0-e9e1-4296-82a0-e4ad19c42e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-6a5b9dc4-57af-4bec-a3c2-eda2ec54e639,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-3a1d2617-c728-4f5d-ac5d-e228d8156092,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-6f0927d6-735c-4a56-b182-ce489a78c103,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-21080bc8-950a-4341-ade8-6863bb4a9952,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-8e627357-9a69-48e1-b99d-ce70879cfb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288483957-172.17.0.18-1595342916732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-1efe1b03-4420-494c-9c43-38babcf836f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-da59548e-e727-4e06-a375-4b8efe05076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-76dc53ee-4967-422f-8631-88dc883930c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-9c5f6257-094d-42c2-974e-f391dd5713e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-181ff577-b1d8-4a3a-b7a7-ee7df3f25cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-bd6a3ade-6270-447d-99ae-9b20bb23c66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-e100ef15-e241-4457-b702-1d5671bdd57e,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-507f829f-05db-4e26-b3a7-3fc5309b84ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288483957-172.17.0.18-1595342916732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-1efe1b03-4420-494c-9c43-38babcf836f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-da59548e-e727-4e06-a375-4b8efe05076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-76dc53ee-4967-422f-8631-88dc883930c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-9c5f6257-094d-42c2-974e-f391dd5713e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-181ff577-b1d8-4a3a-b7a7-ee7df3f25cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-bd6a3ade-6270-447d-99ae-9b20bb23c66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-e100ef15-e241-4457-b702-1d5671bdd57e,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-507f829f-05db-4e26-b3a7-3fc5309b84ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037099870-172.17.0.18-1595342950831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-2b6bfe4f-ab05-4dda-94ff-517de80a18b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-2b45c1b8-cece-47e1-87bd-812416e65117,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-9ab7fdc8-ab48-4ad3-a2a2-cbbb5719a969,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-3fb218a3-a44e-4317-8688-6dcd68d324e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-bf841b26-471e-412b-8bb2-adf08ec23169,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-3ad8a6f9-a30f-485e-88a5-c55c2f4ca4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-9a3e63f7-3f03-4188-81ed-5211d40828f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-a411a45b-76db-4ef6-91cc-0af4ff87010e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037099870-172.17.0.18-1595342950831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-2b6bfe4f-ab05-4dda-94ff-517de80a18b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-2b45c1b8-cece-47e1-87bd-812416e65117,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-9ab7fdc8-ab48-4ad3-a2a2-cbbb5719a969,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-3fb218a3-a44e-4317-8688-6dcd68d324e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-bf841b26-471e-412b-8bb2-adf08ec23169,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-3ad8a6f9-a30f-485e-88a5-c55c2f4ca4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-9a3e63f7-3f03-4188-81ed-5211d40828f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-a411a45b-76db-4ef6-91cc-0af4ff87010e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771750767-172.17.0.18-1595343058402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36730,DS-0331a3cd-8146-43d8-8f9d-f31e91599040,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-9015e79f-6dd1-480d-8c8c-744a872f8b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-e7e85a58-5c04-4c44-909b-00772dfb067b,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-219394ab-a387-4d9d-991e-0314499df8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-f5bb3fe0-49b7-4064-ac8e-1fdf9b4cb812,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-d0577bc3-827f-48c7-b1cb-6651d5b49a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-49d8caff-6ed7-4dba-a042-64fe2c058aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-6a4d855b-a281-4997-a47c-8893b8b3a1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771750767-172.17.0.18-1595343058402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36730,DS-0331a3cd-8146-43d8-8f9d-f31e91599040,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-9015e79f-6dd1-480d-8c8c-744a872f8b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-e7e85a58-5c04-4c44-909b-00772dfb067b,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-219394ab-a387-4d9d-991e-0314499df8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-f5bb3fe0-49b7-4064-ac8e-1fdf9b4cb812,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-d0577bc3-827f-48c7-b1cb-6651d5b49a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-49d8caff-6ed7-4dba-a042-64fe2c058aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-6a4d855b-a281-4997-a47c-8893b8b3a1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039623514-172.17.0.18-1595343166922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-2a8ec2df-c202-4c30-9a56-ebc6ee21bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-a1cff2ab-300c-4284-bc86-5485f3d2c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-52fe1b8b-a796-46f7-84ba-0e1d01e2c469,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-ce531ab8-3992-4e54-b7c5-ede79ff06f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-3d25e9fa-5dd5-442b-b2cc-21cb002b68ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-158a239f-f130-425c-876c-33638f5f2dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-abc53fb2-e839-42d4-938e-68da375d1726,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-19b9c725-0145-40d9-9ce5-e7e7dbd464bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039623514-172.17.0.18-1595343166922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-2a8ec2df-c202-4c30-9a56-ebc6ee21bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-a1cff2ab-300c-4284-bc86-5485f3d2c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-52fe1b8b-a796-46f7-84ba-0e1d01e2c469,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-ce531ab8-3992-4e54-b7c5-ede79ff06f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-3d25e9fa-5dd5-442b-b2cc-21cb002b68ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-158a239f-f130-425c-876c-33638f5f2dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-abc53fb2-e839-42d4-938e-68da375d1726,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-19b9c725-0145-40d9-9ce5-e7e7dbd464bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516367528-172.17.0.18-1595343621269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-e18860f7-0c08-490a-88a9-e6a2b865f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-b350fb19-d9c5-483b-a746-dd5721f659bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-3258480a-875e-4af9-8274-dabec8a6a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-9fa9a3f7-0e9b-4d95-be31-0ce191d50fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-db8ca2d9-d97d-46d3-8027-23ba2dbb874e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-13962446-3a9e-4c9c-9e2c-60a324ec595d,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-01648c78-6a9a-400b-b7b3-298d086951d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-97209793-f3f5-4b29-8d61-e72776d10d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516367528-172.17.0.18-1595343621269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-e18860f7-0c08-490a-88a9-e6a2b865f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-b350fb19-d9c5-483b-a746-dd5721f659bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-3258480a-875e-4af9-8274-dabec8a6a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-9fa9a3f7-0e9b-4d95-be31-0ce191d50fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-db8ca2d9-d97d-46d3-8027-23ba2dbb874e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-13962446-3a9e-4c9c-9e2c-60a324ec595d,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-01648c78-6a9a-400b-b7b3-298d086951d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-97209793-f3f5-4b29-8d61-e72776d10d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097079601-172.17.0.18-1595343725732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-3094aaf8-9358-4ab6-9ffc-a9e9c50b9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-3f1868f5-a9ca-4966-8e93-b2c4ef4bbdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-d9e0761c-28c4-4634-a4db-45738b74add2,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-ff40d943-53c1-4caa-93f6-d1c5b9dca953,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-d1deed6e-444e-4bec-bc0e-277909c6ed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-eae6496f-747b-4188-919e-3a6b92b83b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-b062bff4-0525-40e6-8396-6a8720f73bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-50f790c7-0b67-45ac-afce-488d44d80a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097079601-172.17.0.18-1595343725732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-3094aaf8-9358-4ab6-9ffc-a9e9c50b9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-3f1868f5-a9ca-4966-8e93-b2c4ef4bbdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-d9e0761c-28c4-4634-a4db-45738b74add2,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-ff40d943-53c1-4caa-93f6-d1c5b9dca953,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-d1deed6e-444e-4bec-bc0e-277909c6ed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-eae6496f-747b-4188-919e-3a6b92b83b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-b062bff4-0525-40e6-8396-6a8720f73bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-50f790c7-0b67-45ac-afce-488d44d80a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284701510-172.17.0.18-1595343881005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-c2cdfeb3-1ff7-4a23-be81-b6c6f396f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-592a813a-a79a-4271-87b5-4797a7eba384,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-e1dc715c-fbb1-450b-b12a-d893b0f14ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-43553389-6e84-4dd4-86a7-7307b74c50dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-a53ffb74-89b7-4974-90c9-951aca042d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-1a659388-1c91-42e9-9515-b892bca9f802,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-d1945ddb-753d-4b4a-b2a3-23917811700b,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-b9c70374-6614-4d7f-bbf6-7f81dfa99822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284701510-172.17.0.18-1595343881005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-c2cdfeb3-1ff7-4a23-be81-b6c6f396f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-592a813a-a79a-4271-87b5-4797a7eba384,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-e1dc715c-fbb1-450b-b12a-d893b0f14ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-43553389-6e84-4dd4-86a7-7307b74c50dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-a53ffb74-89b7-4974-90c9-951aca042d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-1a659388-1c91-42e9-9515-b892bca9f802,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-d1945ddb-753d-4b4a-b2a3-23917811700b,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-b9c70374-6614-4d7f-bbf6-7f81dfa99822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830169389-172.17.0.18-1595344392529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34981,DS-26216730-afa9-4ffd-89ec-c21537612caf,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-7f7d58f1-679c-401c-a381-00f0978da558,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4226d520-df04-489a-b04c-93bda0c2f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-cce68826-33d1-4869-bc60-c475fb674ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-c445276b-2ae8-4c75-bdd1-60954088aca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-58e5ff07-10cc-494a-8e8b-9d231459e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-c7ea4f7e-9db1-45f5-8243-b56b14c44d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-192b33c4-a7d1-4743-a8c7-64e26cc07c53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830169389-172.17.0.18-1595344392529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34981,DS-26216730-afa9-4ffd-89ec-c21537612caf,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-7f7d58f1-679c-401c-a381-00f0978da558,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4226d520-df04-489a-b04c-93bda0c2f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-cce68826-33d1-4869-bc60-c475fb674ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-c445276b-2ae8-4c75-bdd1-60954088aca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-58e5ff07-10cc-494a-8e8b-9d231459e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-c7ea4f7e-9db1-45f5-8243-b56b14c44d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-192b33c4-a7d1-4743-a8c7-64e26cc07c53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689974247-172.17.0.18-1595344634373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33286,DS-da230d48-3d4f-498a-9018-da2074a7e444,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-29072f0e-e3d7-441c-8f9c-31a5d40ba1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-9dff5913-6bfd-4ac2-ba56-905f6b5051fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-3a49d999-c2e4-4533-98d6-87a238c0b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-b78789cc-e5c0-4851-b11d-ef5d6f609878,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-aa01a032-ed85-4b89-b88e-7919cc2b395d,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-10daef00-2f86-436b-b637-1bd3dd55acbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-cedd4277-2c24-4149-8aa8-6323d21ed198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689974247-172.17.0.18-1595344634373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33286,DS-da230d48-3d4f-498a-9018-da2074a7e444,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-29072f0e-e3d7-441c-8f9c-31a5d40ba1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-9dff5913-6bfd-4ac2-ba56-905f6b5051fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-3a49d999-c2e4-4533-98d6-87a238c0b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-b78789cc-e5c0-4851-b11d-ef5d6f609878,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-aa01a032-ed85-4b89-b88e-7919cc2b395d,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-10daef00-2f86-436b-b637-1bd3dd55acbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-cedd4277-2c24-4149-8aa8-6323d21ed198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881884038-172.17.0.18-1595344741638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-08055e3b-9fbb-4948-8277-158a4941c3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-b53903c2-5e48-4366-9a2e-a494e5cfcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-b95febc6-636a-4b3f-92df-628607b98f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-3a8d965b-e1d2-41ee-959b-f5cf52b65447,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-5278eb39-27a8-4de4-aad2-a010e0d2a9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-022d0873-6c50-44db-aaf3-c3d95ceaf68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-e8185f8c-29a9-4795-adbc-7be7a9c2a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-51fd76be-3cd0-43de-abc6-c5c058c9b257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881884038-172.17.0.18-1595344741638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-08055e3b-9fbb-4948-8277-158a4941c3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-b53903c2-5e48-4366-9a2e-a494e5cfcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-b95febc6-636a-4b3f-92df-628607b98f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-3a8d965b-e1d2-41ee-959b-f5cf52b65447,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-5278eb39-27a8-4de4-aad2-a010e0d2a9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-022d0873-6c50-44db-aaf3-c3d95ceaf68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-e8185f8c-29a9-4795-adbc-7be7a9c2a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-51fd76be-3cd0-43de-abc6-c5c058c9b257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994680353-172.17.0.18-1595344833280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-f84035c1-559e-43c3-b001-c6c88f0359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-84d540a5-ac86-4270-bf90-0dfdd6acab16,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-3290848d-44fe-45e1-8f24-8f73eb4fe1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-e89f06ee-63ce-4bc1-a87f-6be0a290a9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-000973fe-080f-4342-b6c1-b66072cef01b,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-e9c50bf2-47f8-4ed4-be22-639bc20d1e30,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-fa47ee17-6b8c-4b43-82b9-fc034a68da3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7aec8beb-f061-4986-9a5d-27e69f2be8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994680353-172.17.0.18-1595344833280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-f84035c1-559e-43c3-b001-c6c88f0359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-84d540a5-ac86-4270-bf90-0dfdd6acab16,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-3290848d-44fe-45e1-8f24-8f73eb4fe1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-e89f06ee-63ce-4bc1-a87f-6be0a290a9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-000973fe-080f-4342-b6c1-b66072cef01b,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-e9c50bf2-47f8-4ed4-be22-639bc20d1e30,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-fa47ee17-6b8c-4b43-82b9-fc034a68da3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7aec8beb-f061-4986-9a5d-27e69f2be8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480437916-172.17.0.18-1595345262722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37440,DS-6e68a559-871b-486d-b863-1f8cc7fc491b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-a87e1dee-e4b1-4de9-8c33-471a7e058e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-8cc76b4c-affb-43e4-ab58-dcbb50936a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-2f1ce6ef-f8d5-4268-9fd6-7e9485de8013,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-8c90bc15-2a02-4ff3-9c81-9bbaf951b12a,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-d4f6d2e4-e79c-4b78-9ccb-669987d0e577,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-6870a3e6-b33f-4336-b2cd-2e9b36eb0790,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-93c35fe2-0f57-4761-83c3-bea83d42f973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480437916-172.17.0.18-1595345262722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37440,DS-6e68a559-871b-486d-b863-1f8cc7fc491b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-a87e1dee-e4b1-4de9-8c33-471a7e058e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-8cc76b4c-affb-43e4-ab58-dcbb50936a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-2f1ce6ef-f8d5-4268-9fd6-7e9485de8013,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-8c90bc15-2a02-4ff3-9c81-9bbaf951b12a,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-d4f6d2e4-e79c-4b78-9ccb-669987d0e577,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-6870a3e6-b33f-4336-b2cd-2e9b36eb0790,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-93c35fe2-0f57-4761-83c3-bea83d42f973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903656070-172.17.0.18-1595345408258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-f52027c4-5eb5-4ada-b597-69be648ed524,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-e6e92885-045d-454a-8a25-ec28c0daf438,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-5d6a0ec8-ba23-4028-b21e-16c86ac278e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-994a2e2e-a70d-461b-bf15-2725fc24c091,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-69a880b9-aec2-496f-be5c-7259a6a77cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-b81b11b1-fad9-4fed-912d-bbbccb3dc103,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-d27b3b5e-fb18-441a-b60e-be18aedbb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-e8c98b73-0f83-43c0-9be7-7fbfd7630b3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903656070-172.17.0.18-1595345408258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-f52027c4-5eb5-4ada-b597-69be648ed524,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-e6e92885-045d-454a-8a25-ec28c0daf438,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-5d6a0ec8-ba23-4028-b21e-16c86ac278e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-994a2e2e-a70d-461b-bf15-2725fc24c091,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-69a880b9-aec2-496f-be5c-7259a6a77cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-b81b11b1-fad9-4fed-912d-bbbccb3dc103,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-d27b3b5e-fb18-441a-b60e-be18aedbb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-e8c98b73-0f83-43c0-9be7-7fbfd7630b3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433511733-172.17.0.18-1595346029229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-356936ee-a40d-4990-9c92-94a44164b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-649f3709-fd7a-4369-9ca1-63c101ff36fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-9553a68e-2f81-4d43-a4a8-28785403a30b,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-cdb36639-cfeb-4fea-b7f8-042ab57dc89d,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-9e795287-d232-421d-8ce1-02641adfbfab,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-d9c1a51e-73bb-41b8-bd12-06f76791643d,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-a8aa4664-5be5-4032-a4d9-ff73eee85f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-9f2ae6e1-14d1-47cb-9d71-5a866b6e0305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433511733-172.17.0.18-1595346029229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-356936ee-a40d-4990-9c92-94a44164b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-649f3709-fd7a-4369-9ca1-63c101ff36fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-9553a68e-2f81-4d43-a4a8-28785403a30b,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-cdb36639-cfeb-4fea-b7f8-042ab57dc89d,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-9e795287-d232-421d-8ce1-02641adfbfab,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-d9c1a51e-73bb-41b8-bd12-06f76791643d,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-a8aa4664-5be5-4032-a4d9-ff73eee85f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-9f2ae6e1-14d1-47cb-9d71-5a866b6e0305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257149816-172.17.0.18-1595346176558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-ef9e06be-57d2-408a-bb24-c459452f596a,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-2849b854-ebeb-49c3-aa97-b467af589f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-4608163a-958f-4d4d-9e69-6811f1bd18e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-be587a68-6c4c-4929-87f6-bb2d1dac8235,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-bd1e9b6e-21ff-4859-8462-5104c9050b21,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-b905ba0a-4a58-40cd-a19a-98461027056a,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-14acfc54-5329-408f-b559-1dc0d33fd5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-1e2d037f-59ef-4c7f-bd90-8a80417425f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257149816-172.17.0.18-1595346176558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-ef9e06be-57d2-408a-bb24-c459452f596a,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-2849b854-ebeb-49c3-aa97-b467af589f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-4608163a-958f-4d4d-9e69-6811f1bd18e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-be587a68-6c4c-4929-87f6-bb2d1dac8235,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-bd1e9b6e-21ff-4859-8462-5104c9050b21,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-b905ba0a-4a58-40cd-a19a-98461027056a,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-14acfc54-5329-408f-b559-1dc0d33fd5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-1e2d037f-59ef-4c7f-bd90-8a80417425f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934328547-172.17.0.18-1595346212470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-1586409e-28b6-44b0-bbdb-f32ac796f46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-54ec6f1e-9109-4485-8d52-73bed702ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-61baf7c0-fc4b-42f9-bfff-240030107f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-3a90e1d4-c8e3-4274-92b9-0a02330dfeab,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-bec23380-9d50-4a0e-aafb-e641073068c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-5dc52be2-2bf6-4ce6-b0c5-53e9c56530f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-6cdce850-41aa-4eb0-9c70-623fbf08d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-125a5429-8567-4e0b-a087-e14866331851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934328547-172.17.0.18-1595346212470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-1586409e-28b6-44b0-bbdb-f32ac796f46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-54ec6f1e-9109-4485-8d52-73bed702ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-61baf7c0-fc4b-42f9-bfff-240030107f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-3a90e1d4-c8e3-4274-92b9-0a02330dfeab,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-bec23380-9d50-4a0e-aafb-e641073068c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-5dc52be2-2bf6-4ce6-b0c5-53e9c56530f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-6cdce850-41aa-4eb0-9c70-623fbf08d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-125a5429-8567-4e0b-a087-e14866331851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006402453-172.17.0.18-1595346248809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-1c78edde-0209-41c7-9f4b-0822b6d623a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-7bba86b5-65b3-43fe-b920-d718f92d07a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-2a482676-d97a-4844-b800-43608727658e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-bfd2dc87-763d-438c-bef6-9c91f799f302,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-54b0678a-9ad7-491f-933c-50725c069193,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-5ef228fa-a08a-4ee3-a5cd-97d207fd1784,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-f917729c-5866-494e-8ec0-947a3a2d0719,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-0bab9b4b-996d-460b-90d1-e484a33fa0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006402453-172.17.0.18-1595346248809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-1c78edde-0209-41c7-9f4b-0822b6d623a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-7bba86b5-65b3-43fe-b920-d718f92d07a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-2a482676-d97a-4844-b800-43608727658e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-bfd2dc87-763d-438c-bef6-9c91f799f302,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-54b0678a-9ad7-491f-933c-50725c069193,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-5ef228fa-a08a-4ee3-a5cd-97d207fd1784,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-f917729c-5866-494e-8ec0-947a3a2d0719,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-0bab9b4b-996d-460b-90d1-e484a33fa0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247752165-172.17.0.18-1595346292490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37735,DS-8a5a8514-5ad5-4c1e-abab-193f9d027210,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-2118eade-d9a5-41f6-aecb-d3e02ed60d14,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-ab5286b6-1a2f-4343-a9d9-0828b02ce1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-ad969850-e4bf-4361-a71d-5250879d4930,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-a414c78d-161e-4fc0-bfdd-f1175127ba18,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-88f9c5da-34c8-485e-8ef0-c65c90fbdd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-c26a8065-787b-4fd7-84e8-a024dfa9623c,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-723f7ca2-24f6-43b8-91c1-86de2d6154a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247752165-172.17.0.18-1595346292490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37735,DS-8a5a8514-5ad5-4c1e-abab-193f9d027210,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-2118eade-d9a5-41f6-aecb-d3e02ed60d14,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-ab5286b6-1a2f-4343-a9d9-0828b02ce1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-ad969850-e4bf-4361-a71d-5250879d4930,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-a414c78d-161e-4fc0-bfdd-f1175127ba18,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-88f9c5da-34c8-485e-8ef0-c65c90fbdd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-c26a8065-787b-4fd7-84e8-a024dfa9623c,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-723f7ca2-24f6-43b8-91c1-86de2d6154a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072546268-172.17.0.18-1595346323428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-358764af-6205-43bb-8fff-e1d7d70e2c42,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-144b6fa4-3d8b-48e4-a06b-fa06dd812f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-ba436e93-d89b-46ff-8eff-ccafe29ba415,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-ce4207b3-f0fc-4c0f-bdaf-fe4122c9fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-f3902b39-8428-4ba2-b98f-0a77ccbc3f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-3d16e329-72de-4813-a46d-2e50e375ba59,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-d50e53a7-95fb-4481-81fc-a4666c211e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-c923d0b5-2ba6-485b-8ff0-bbf09e16b675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072546268-172.17.0.18-1595346323428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-358764af-6205-43bb-8fff-e1d7d70e2c42,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-144b6fa4-3d8b-48e4-a06b-fa06dd812f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-ba436e93-d89b-46ff-8eff-ccafe29ba415,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-ce4207b3-f0fc-4c0f-bdaf-fe4122c9fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-f3902b39-8428-4ba2-b98f-0a77ccbc3f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-3d16e329-72de-4813-a46d-2e50e375ba59,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-d50e53a7-95fb-4481-81fc-a4666c211e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-c923d0b5-2ba6-485b-8ff0-bbf09e16b675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181416254-172.17.0.18-1595346558120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33513,DS-a542c875-838d-4299-a93e-b9092c5b697a,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-69fb857b-e235-4966-b1ba-499bf1ef69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-801dfc2c-03cc-4009-9169-1e98f55e388b,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-7995c9e3-facd-4f6b-bb75-397548be6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-8b26df4d-9591-4ffc-ace2-fd94f93c7928,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-82253235-3afd-4fe2-bb4a-0c023d31db86,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-51c9b1a7-2e5b-45ab-b242-95b1c032e591,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-3f93aadf-3e2c-47a1-94e0-0413f9aa8b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181416254-172.17.0.18-1595346558120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33513,DS-a542c875-838d-4299-a93e-b9092c5b697a,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-69fb857b-e235-4966-b1ba-499bf1ef69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-801dfc2c-03cc-4009-9169-1e98f55e388b,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-7995c9e3-facd-4f6b-bb75-397548be6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-8b26df4d-9591-4ffc-ace2-fd94f93c7928,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-82253235-3afd-4fe2-bb4a-0c023d31db86,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-51c9b1a7-2e5b-45ab-b242-95b1c032e591,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-3f93aadf-3e2c-47a1-94e0-0413f9aa8b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696833943-172.17.0.18-1595346747076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-a8b227a1-bddd-47a2-a9ef-cf112f012ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-34e000c5-3c2b-4f6b-8b9f-e40266891373,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-18e3c6fd-9456-4bd7-8f37-188cc26b5359,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-28fb601f-0337-45a3-8fbf-caa30a2741da,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-e17ac095-4541-42de-878b-c3ae46288802,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-b2345c05-8154-4cbb-832d-a3fe67b055bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-5daeda08-a197-4a12-83b0-0ed9eefe4465,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-f58c1321-0629-4e53-a78e-161c2f6e24d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696833943-172.17.0.18-1595346747076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-a8b227a1-bddd-47a2-a9ef-cf112f012ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-34e000c5-3c2b-4f6b-8b9f-e40266891373,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-18e3c6fd-9456-4bd7-8f37-188cc26b5359,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-28fb601f-0337-45a3-8fbf-caa30a2741da,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-e17ac095-4541-42de-878b-c3ae46288802,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-b2345c05-8154-4cbb-832d-a3fe67b055bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-5daeda08-a197-4a12-83b0-0ed9eefe4465,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-f58c1321-0629-4e53-a78e-161c2f6e24d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625717851-172.17.0.18-1595346817098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-a76eeeb1-900b-47b9-8d9c-d9b56b3798cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-109e7fa4-f500-4d57-a856-e653c77c2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-38688d60-28a6-4479-a08e-051dfe42287f,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-b9dd81da-0d1d-42ea-9d3e-4062bb0df97b,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-6a70af7d-ae1e-46eb-81e4-8463164092b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-ee9dc139-33e4-4ad6-b0c4-bc39a932d28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-890a5645-ca87-46de-8422-e14c848e2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-c526fc52-a33c-4d51-b4ad-a77a34e912b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625717851-172.17.0.18-1595346817098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-a76eeeb1-900b-47b9-8d9c-d9b56b3798cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-109e7fa4-f500-4d57-a856-e653c77c2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-38688d60-28a6-4479-a08e-051dfe42287f,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-b9dd81da-0d1d-42ea-9d3e-4062bb0df97b,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-6a70af7d-ae1e-46eb-81e4-8463164092b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-ee9dc139-33e4-4ad6-b0c4-bc39a932d28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-890a5645-ca87-46de-8422-e14c848e2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-c526fc52-a33c-4d51-b4ad-a77a34e912b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5280
