reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703233236-172.17.0.4-1595363224161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-7bb1f6c2-6301-4998-959f-c01005aa6710,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-9d5c90db-daf4-4d0f-befb-2d3706981f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-39198a85-b2a8-4f6c-9a85-2aa69b6c5fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-793e9c90-050d-4302-9cdd-79e252da03a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-85875666-dc62-4070-9acb-54ed455c493d,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-5de428e8-ff66-4a49-ad6d-51dbe6d45003,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-8eb8b280-110f-4a90-b03f-29c321f0023f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-9dcb5098-c17a-4f88-b0e4-9a61e4b719c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703233236-172.17.0.4-1595363224161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-7bb1f6c2-6301-4998-959f-c01005aa6710,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-9d5c90db-daf4-4d0f-befb-2d3706981f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-39198a85-b2a8-4f6c-9a85-2aa69b6c5fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-793e9c90-050d-4302-9cdd-79e252da03a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-85875666-dc62-4070-9acb-54ed455c493d,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-5de428e8-ff66-4a49-ad6d-51dbe6d45003,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-8eb8b280-110f-4a90-b03f-29c321f0023f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-9dcb5098-c17a-4f88-b0e4-9a61e4b719c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763772894-172.17.0.4-1595363510871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40923,DS-12d03e8e-9805-4eb9-80f7-511e3147495e,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-fdd26db2-6ea0-495c-9fcc-bb302c6902ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-27ad872f-2efa-4e05-9b4a-0e9c855c286e,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-12c6a131-22e5-4f72-9417-3ccfd34e1865,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-538cc733-fef1-49ce-86d4-f942861226fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-607482af-d4d2-4577-9852-34869dabd1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-5be17eb1-7e6c-4987-8749-e112b732a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-50044ac6-7f8b-4eea-ac03-187c6602d430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763772894-172.17.0.4-1595363510871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40923,DS-12d03e8e-9805-4eb9-80f7-511e3147495e,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-fdd26db2-6ea0-495c-9fcc-bb302c6902ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-27ad872f-2efa-4e05-9b4a-0e9c855c286e,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-12c6a131-22e5-4f72-9417-3ccfd34e1865,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-538cc733-fef1-49ce-86d4-f942861226fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-607482af-d4d2-4577-9852-34869dabd1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-5be17eb1-7e6c-4987-8749-e112b732a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-50044ac6-7f8b-4eea-ac03-187c6602d430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595153953-172.17.0.4-1595363871259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-3ae68f5b-b06f-4fc6-8062-e349aeaf44b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-55ca4501-42d7-4ac8-973f-629c3dabac23,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-3b1da53a-8f46-4e6b-9a8f-fa21f579f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-d97291fb-f631-48a2-8d8d-245a75e4aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-765832a2-6c79-4abc-a2b3-84cbfff2991f,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-4b9b3d98-087b-4fe7-a125-ebf9dcec0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-9f095041-e2dd-49f1-bfbe-1c61fff217d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-5ea4e7b2-9865-47da-937b-0bd7bd73684a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595153953-172.17.0.4-1595363871259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-3ae68f5b-b06f-4fc6-8062-e349aeaf44b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-55ca4501-42d7-4ac8-973f-629c3dabac23,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-3b1da53a-8f46-4e6b-9a8f-fa21f579f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-d97291fb-f631-48a2-8d8d-245a75e4aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-765832a2-6c79-4abc-a2b3-84cbfff2991f,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-4b9b3d98-087b-4fe7-a125-ebf9dcec0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-9f095041-e2dd-49f1-bfbe-1c61fff217d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-5ea4e7b2-9865-47da-937b-0bd7bd73684a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783167769-172.17.0.4-1595364694331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40329,DS-335cadee-e061-41ce-a05b-ab48c8bfd377,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-092f36b3-8844-4860-a329-4833f3f9c883,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-f41659ab-86f5-496a-8dc1-4e03e4f33120,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-006d1a1c-1dd0-4905-b50b-7c1564887219,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-a3627e7a-eb8a-4fc3-92d8-e7985ac6b220,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-2e64db7a-0c6e-4d92-8f60-0dc37b5911f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-fd9c6751-055d-4467-abf8-196449b6d8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-0760782f-8ea1-4b0d-a82c-80ccef2b8f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783167769-172.17.0.4-1595364694331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40329,DS-335cadee-e061-41ce-a05b-ab48c8bfd377,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-092f36b3-8844-4860-a329-4833f3f9c883,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-f41659ab-86f5-496a-8dc1-4e03e4f33120,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-006d1a1c-1dd0-4905-b50b-7c1564887219,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-a3627e7a-eb8a-4fc3-92d8-e7985ac6b220,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-2e64db7a-0c6e-4d92-8f60-0dc37b5911f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-fd9c6751-055d-4467-abf8-196449b6d8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-0760782f-8ea1-4b0d-a82c-80ccef2b8f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681216857-172.17.0.4-1595365195813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-07943189-626e-4f64-880f-a9bda1c34a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-0d72f0df-3f0b-4801-ba28-c53f5b0623e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-28eaab54-13d7-4de2-863b-5ee1cc9f41ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-9636c78c-73ba-47bc-ad09-ca9cc061578f,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-0629d9d7-6585-48fc-b349-a3d2a7fb3fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-3d34425d-3ac6-44a9-b415-c2715517a4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-079e2863-d513-484b-8a35-12e828e5724b,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-b2afc7e1-7d68-4080-a16e-8d890f38c1f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681216857-172.17.0.4-1595365195813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-07943189-626e-4f64-880f-a9bda1c34a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-0d72f0df-3f0b-4801-ba28-c53f5b0623e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-28eaab54-13d7-4de2-863b-5ee1cc9f41ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-9636c78c-73ba-47bc-ad09-ca9cc061578f,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-0629d9d7-6585-48fc-b349-a3d2a7fb3fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-3d34425d-3ac6-44a9-b415-c2715517a4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-079e2863-d513-484b-8a35-12e828e5724b,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-b2afc7e1-7d68-4080-a16e-8d890f38c1f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103736359-172.17.0.4-1595366354248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-eddc7b42-0926-4acd-919e-59469ebdda1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-db966c3e-3505-4620-9ca9-21e06f6d5437,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-a927987d-86cb-40f7-b62a-2baa544c21d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-afa796d2-2533-4aba-b7ec-7ae434928eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-2e6fae73-e2e5-4747-85e1-05a74dbcd207,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-16bf91ad-b591-4cd5-b867-4a61e7e907ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-0f536061-50b5-41c9-818f-f72db6fb81c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-064806b1-e436-4e84-a95d-f8ff77863423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103736359-172.17.0.4-1595366354248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-eddc7b42-0926-4acd-919e-59469ebdda1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-db966c3e-3505-4620-9ca9-21e06f6d5437,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-a927987d-86cb-40f7-b62a-2baa544c21d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-afa796d2-2533-4aba-b7ec-7ae434928eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-2e6fae73-e2e5-4747-85e1-05a74dbcd207,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-16bf91ad-b591-4cd5-b867-4a61e7e907ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-0f536061-50b5-41c9-818f-f72db6fb81c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-064806b1-e436-4e84-a95d-f8ff77863423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008963428-172.17.0.4-1595366736798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-3edf3873-0819-4284-ae50-4c5a0228ba1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-1c8c4a54-8f36-48d1-9d8f-c799aa75deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-86acbac0-9dd3-4798-a7ac-4449efd1ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-7c55a358-ff51-4a1d-a431-09101ef2b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-d37b2620-fd15-4191-9d21-9ad24a205d66,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-2832abc2-f777-4195-9eba-c346696d44f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-35cfbd4a-e465-42b5-b0e6-be4e3f2df689,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a9d4a6e6-5bc4-429c-9c08-6711d962dea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008963428-172.17.0.4-1595366736798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-3edf3873-0819-4284-ae50-4c5a0228ba1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-1c8c4a54-8f36-48d1-9d8f-c799aa75deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-86acbac0-9dd3-4798-a7ac-4449efd1ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-7c55a358-ff51-4a1d-a431-09101ef2b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-d37b2620-fd15-4191-9d21-9ad24a205d66,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-2832abc2-f777-4195-9eba-c346696d44f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-35cfbd4a-e465-42b5-b0e6-be4e3f2df689,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a9d4a6e6-5bc4-429c-9c08-6711d962dea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: false positive !!!
Total execution time in seconds : 5857
