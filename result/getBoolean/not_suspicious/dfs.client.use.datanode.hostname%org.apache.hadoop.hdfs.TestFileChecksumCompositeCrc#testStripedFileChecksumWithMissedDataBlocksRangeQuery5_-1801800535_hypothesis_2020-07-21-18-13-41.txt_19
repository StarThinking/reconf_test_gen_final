reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729179546-172.17.0.15-1595356627356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-c2afaf68-b15a-4b25-9a4a-96d65a41a3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-7d899bce-6a0d-441f-9a22-916d80ca6698,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b7a6b27b-954a-4566-8e0d-28cda69b7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-260418c3-9dff-4d39-a132-58aca3c45be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-76c52b3b-0ffe-4d38-b26a-8faad31e2c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-dbc07bfb-1998-430b-ba96-ea0255c2eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-753a0697-b681-4e07-9950-a2b6629acb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-3c380f4f-2cab-4bd2-9b9e-5dc368400750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729179546-172.17.0.15-1595356627356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-c2afaf68-b15a-4b25-9a4a-96d65a41a3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-7d899bce-6a0d-441f-9a22-916d80ca6698,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b7a6b27b-954a-4566-8e0d-28cda69b7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-260418c3-9dff-4d39-a132-58aca3c45be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-76c52b3b-0ffe-4d38-b26a-8faad31e2c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-dbc07bfb-1998-430b-ba96-ea0255c2eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-753a0697-b681-4e07-9950-a2b6629acb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-3c380f4f-2cab-4bd2-9b9e-5dc368400750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76686363-172.17.0.15-1595357426518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-b6b499f1-50f1-4ab0-97bc-4999503eca29,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-8c08b209-dd2f-4d8e-94c9-91cb90a1958d,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-3ac520ed-8e5d-404e-b4ff-e31f8763e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-b44ceaf8-e195-4219-8e36-7c46a87e7899,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-3e765a48-a221-48ac-af28-97c999a116fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-2da92f61-2551-4138-ab04-9b5d50c735c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-4486ea71-5e45-4406-a5af-a4d2d2fbb73c,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-4b5fa62a-4d21-468b-a179-e60020705e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76686363-172.17.0.15-1595357426518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-b6b499f1-50f1-4ab0-97bc-4999503eca29,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-8c08b209-dd2f-4d8e-94c9-91cb90a1958d,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-3ac520ed-8e5d-404e-b4ff-e31f8763e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-b44ceaf8-e195-4219-8e36-7c46a87e7899,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-3e765a48-a221-48ac-af28-97c999a116fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-2da92f61-2551-4138-ab04-9b5d50c735c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-4486ea71-5e45-4406-a5af-a4d2d2fbb73c,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-4b5fa62a-4d21-468b-a179-e60020705e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950324118-172.17.0.15-1595357548676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-2a2b6c61-656f-4a1d-b801-3299c8eafdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-3347e7d8-b800-4a68-a097-d1ca20e89ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-3d968cb1-93c6-4dd3-8f2c-7d7647852223,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-1aeca272-bd77-4c28-b126-274364ec917f,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-3c9c4d73-6e16-4d41-9bd2-af3baf34567b,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-40b4d448-7795-4edb-a104-8985b30a451f,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-461e9de8-c119-4114-8574-f0b9122fcc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-a71e1dbe-2818-4881-8184-e8021840962e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950324118-172.17.0.15-1595357548676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-2a2b6c61-656f-4a1d-b801-3299c8eafdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-3347e7d8-b800-4a68-a097-d1ca20e89ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-3d968cb1-93c6-4dd3-8f2c-7d7647852223,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-1aeca272-bd77-4c28-b126-274364ec917f,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-3c9c4d73-6e16-4d41-9bd2-af3baf34567b,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-40b4d448-7795-4edb-a104-8985b30a451f,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-461e9de8-c119-4114-8574-f0b9122fcc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-a71e1dbe-2818-4881-8184-e8021840962e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469280367-172.17.0.15-1595358080247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-781cb5a5-5609-43e2-a762-7ff5667b5343,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-dc6e0ecf-86f9-4822-9291-59db1bdbbe93,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-ecb861df-c1f6-4dd5-9be8-9a2c2e5af82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-dd312e10-cbe7-44b5-8e6a-f91c9df7849d,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-c579038d-d9a2-4f81-85aa-0093d7912275,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-6738f62f-d759-4f5e-b34d-a8d63386fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-48d59568-97c3-4a90-96ce-29417fe9c835,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-08cf6c70-c630-4ee1-a8da-8c1d31b7aa4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469280367-172.17.0.15-1595358080247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-781cb5a5-5609-43e2-a762-7ff5667b5343,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-dc6e0ecf-86f9-4822-9291-59db1bdbbe93,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-ecb861df-c1f6-4dd5-9be8-9a2c2e5af82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-dd312e10-cbe7-44b5-8e6a-f91c9df7849d,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-c579038d-d9a2-4f81-85aa-0093d7912275,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-6738f62f-d759-4f5e-b34d-a8d63386fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-48d59568-97c3-4a90-96ce-29417fe9c835,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-08cf6c70-c630-4ee1-a8da-8c1d31b7aa4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213991622-172.17.0.15-1595358538257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-1617b358-58e2-47fe-b675-84070528feae,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-45e1687e-e82b-45b7-b97b-15ec26bd43ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-7c5e2aa5-99c3-4bd0-8591-353a09a378b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-4d654ca6-f494-4831-8134-94bfff92703e,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-e8f31e6d-013e-497d-90b6-5fe2e5c8e529,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-0ecbd964-2fc7-493c-873b-bc15ff16fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-e2353cca-b3d0-44ca-8715-e4dcaa6b83d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-92f98320-9844-4947-8d6d-cc0d838db1a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213991622-172.17.0.15-1595358538257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-1617b358-58e2-47fe-b675-84070528feae,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-45e1687e-e82b-45b7-b97b-15ec26bd43ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-7c5e2aa5-99c3-4bd0-8591-353a09a378b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-4d654ca6-f494-4831-8134-94bfff92703e,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-e8f31e6d-013e-497d-90b6-5fe2e5c8e529,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-0ecbd964-2fc7-493c-873b-bc15ff16fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-e2353cca-b3d0-44ca-8715-e4dcaa6b83d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-92f98320-9844-4947-8d6d-cc0d838db1a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598372973-172.17.0.15-1595359068580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-6dddfdee-e9bb-4ecf-982b-780bd06fee0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-85c9c970-cacf-45a2-9ce9-752d2984ec18,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-6d775cf2-1e79-4867-97b9-017225827a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-e3dca75d-8fb3-4281-925d-a04f881433a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-7c639700-c74a-4222-a9c0-326dce2da4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-64b73852-2109-4cdc-bf2a-3711d8c9f631,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-5f20991d-5603-45c6-a71b-dc2b36912901,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-478a5fd9-5180-491d-80c9-c2e291edf018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598372973-172.17.0.15-1595359068580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-6dddfdee-e9bb-4ecf-982b-780bd06fee0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-85c9c970-cacf-45a2-9ce9-752d2984ec18,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-6d775cf2-1e79-4867-97b9-017225827a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-e3dca75d-8fb3-4281-925d-a04f881433a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-7c639700-c74a-4222-a9c0-326dce2da4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-64b73852-2109-4cdc-bf2a-3711d8c9f631,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-5f20991d-5603-45c6-a71b-dc2b36912901,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-478a5fd9-5180-491d-80c9-c2e291edf018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516337674-172.17.0.15-1595359111992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-65905957-8073-42b6-b098-cb0d858ca3af,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-d9b29c85-31e6-4ec7-b567-8e73349dc9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-11b4b4e5-9c59-4723-bbf4-0ccf0be8422a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-de7c9849-89f5-4f01-876e-895d39180799,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-ed81d5d8-ec73-4b68-8986-06c17ab98721,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-28fb3a4b-e0bb-4108-b22d-7a6dcec0129e,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-53e48ed6-19e3-4f7e-9eaf-c4570af865b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-86d90871-7972-4b97-bafe-c13a24faa3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516337674-172.17.0.15-1595359111992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-65905957-8073-42b6-b098-cb0d858ca3af,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-d9b29c85-31e6-4ec7-b567-8e73349dc9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-11b4b4e5-9c59-4723-bbf4-0ccf0be8422a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-de7c9849-89f5-4f01-876e-895d39180799,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-ed81d5d8-ec73-4b68-8986-06c17ab98721,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-28fb3a4b-e0bb-4108-b22d-7a6dcec0129e,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-53e48ed6-19e3-4f7e-9eaf-c4570af865b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-86d90871-7972-4b97-bafe-c13a24faa3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091327280-172.17.0.15-1595359836802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-f2af92e4-162a-4f9d-bb80-299e36a1b1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-917cea87-86aa-4e74-a10c-812e77f66382,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-d9244735-c5e7-45fb-a276-9540583b750c,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d7d364ee-2f72-46b7-885a-08f812e4f70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-123ef991-a2c6-4fad-b848-c3ba894eecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-1c5065f2-9f54-4c6c-8bae-5d04320625ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-8605752f-8c85-44d5-833a-a82990c8a05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-745d4726-1878-40f1-8d4b-259c27474ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091327280-172.17.0.15-1595359836802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-f2af92e4-162a-4f9d-bb80-299e36a1b1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-917cea87-86aa-4e74-a10c-812e77f66382,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-d9244735-c5e7-45fb-a276-9540583b750c,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d7d364ee-2f72-46b7-885a-08f812e4f70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-123ef991-a2c6-4fad-b848-c3ba894eecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-1c5065f2-9f54-4c6c-8bae-5d04320625ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-8605752f-8c85-44d5-833a-a82990c8a05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-745d4726-1878-40f1-8d4b-259c27474ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355745262-172.17.0.15-1595360085579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-79d4a4ef-e089-4371-8046-f2c69fe6b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-20459034-f340-4ad8-af29-f7287595a347,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-f730d439-ffb7-4b21-85e4-45534c6c7906,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-306d10e5-13ba-457b-ae1f-1083d94534ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-10bdfc0e-0bfa-40a9-8b5f-07e66e9f0c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-fe5bcb5b-b2f0-497c-981c-0599bdbfc81f,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-ede92b47-f5a2-455c-9f31-53fe56e01a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-a956eaec-8878-43a4-8455-5a0390a942f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355745262-172.17.0.15-1595360085579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-79d4a4ef-e089-4371-8046-f2c69fe6b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-20459034-f340-4ad8-af29-f7287595a347,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-f730d439-ffb7-4b21-85e4-45534c6c7906,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-306d10e5-13ba-457b-ae1f-1083d94534ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-10bdfc0e-0bfa-40a9-8b5f-07e66e9f0c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-fe5bcb5b-b2f0-497c-981c-0599bdbfc81f,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-ede92b47-f5a2-455c-9f31-53fe56e01a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-a956eaec-8878-43a4-8455-5a0390a942f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869705998-172.17.0.15-1595361265492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-fc7cd996-a220-4d8b-8b79-7a0191b9add9,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-38467600-d42f-402d-ba1e-4a67dfdddf65,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-db3f0b3f-2afd-4539-bfc6-9a9891817e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-7ca61400-4d29-4d6c-8ecb-d7c724d211f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-ca617322-a21d-4468-bf88-fdb16429fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-dc1e092e-2126-4c4d-8bb2-c8033a1540ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-911fd7e0-43c4-4ad8-a77c-4adacd29bcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-7e3296f8-e879-4807-88ce-f0dae1f11b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869705998-172.17.0.15-1595361265492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-fc7cd996-a220-4d8b-8b79-7a0191b9add9,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-38467600-d42f-402d-ba1e-4a67dfdddf65,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-db3f0b3f-2afd-4539-bfc6-9a9891817e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-7ca61400-4d29-4d6c-8ecb-d7c724d211f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-ca617322-a21d-4468-bf88-fdb16429fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-dc1e092e-2126-4c4d-8bb2-c8033a1540ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-911fd7e0-43c4-4ad8-a77c-4adacd29bcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-7e3296f8-e879-4807-88ce-f0dae1f11b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099297436-172.17.0.15-1595361521236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-5761e7e5-b52e-45f3-a9db-000c7d8254b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-bf74b1e5-7a16-4212-86a4-a0f2981789ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-e37ce06c-4ca5-4362-8451-269ce5003f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-8b9268f6-4fec-4115-aea1-ca393d7a3127,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-2728b355-7bfe-4a78-8941-8f889af20cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-701e4a4f-e9b5-40a2-9ac9-585e2f79cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-ce2869ab-4a1f-4ff1-915f-fe6cbb1ae261,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-399aaf8e-f19a-404b-878a-7243157f0467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099297436-172.17.0.15-1595361521236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-5761e7e5-b52e-45f3-a9db-000c7d8254b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-bf74b1e5-7a16-4212-86a4-a0f2981789ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-e37ce06c-4ca5-4362-8451-269ce5003f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-8b9268f6-4fec-4115-aea1-ca393d7a3127,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-2728b355-7bfe-4a78-8941-8f889af20cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-701e4a4f-e9b5-40a2-9ac9-585e2f79cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-ce2869ab-4a1f-4ff1-915f-fe6cbb1ae261,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-399aaf8e-f19a-404b-878a-7243157f0467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549088413-172.17.0.15-1595361573412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-edcc8d45-48a5-4a50-9e9b-21773f78d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-66d32337-6d3f-4799-b2c0-fc0a34ea6993,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-a28efba0-0597-47ac-9657-019d4017779c,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-c6dfb151-08e9-44f6-a843-a59cc780598d,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-d5de6d4f-9743-4cdb-be2f-c4d95a8edf55,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-9ab92c41-e470-4eb0-9868-044befcb00fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-ba5507cf-afc0-4b59-858d-016c249d9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-28857c0d-622d-4105-beaf-912031140ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549088413-172.17.0.15-1595361573412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-edcc8d45-48a5-4a50-9e9b-21773f78d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-66d32337-6d3f-4799-b2c0-fc0a34ea6993,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-a28efba0-0597-47ac-9657-019d4017779c,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-c6dfb151-08e9-44f6-a843-a59cc780598d,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-d5de6d4f-9743-4cdb-be2f-c4d95a8edf55,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-9ab92c41-e470-4eb0-9868-044befcb00fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-ba5507cf-afc0-4b59-858d-016c249d9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-28857c0d-622d-4105-beaf-912031140ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396939505-172.17.0.15-1595361712010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35379,DS-9e470507-ca46-4201-9c38-13778b8065db,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-3f8ab869-71f3-4fd9-aa68-20251e85d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-ac96370d-00d8-4fe4-9b62-9f266fd9f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-7c28f753-82b6-44de-b838-c11914f9088d,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-3641e5c1-19fc-42ae-86f8-8c7e780bd523,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-2903230a-5d41-47b9-81f0-110de50dd017,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-fffcc338-d203-469a-bd0f-32ebcb831bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-7114cc17-a26c-41f7-b529-45fb2c35d29b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396939505-172.17.0.15-1595361712010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35379,DS-9e470507-ca46-4201-9c38-13778b8065db,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-3f8ab869-71f3-4fd9-aa68-20251e85d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-ac96370d-00d8-4fe4-9b62-9f266fd9f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-7c28f753-82b6-44de-b838-c11914f9088d,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-3641e5c1-19fc-42ae-86f8-8c7e780bd523,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-2903230a-5d41-47b9-81f0-110de50dd017,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-fffcc338-d203-469a-bd0f-32ebcb831bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-7114cc17-a26c-41f7-b529-45fb2c35d29b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6659
