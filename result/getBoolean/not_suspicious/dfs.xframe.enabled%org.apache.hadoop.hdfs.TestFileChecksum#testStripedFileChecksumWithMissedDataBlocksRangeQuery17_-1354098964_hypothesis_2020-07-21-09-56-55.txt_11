reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942459782-172.17.0.21-1595325773698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-8828f4ee-c03d-4d9b-86e3-7822012d2bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-aa156dce-dda8-47d9-b79e-c3772d3fe2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-c69db5b3-bba0-4902-9689-457549fbcf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-14f6610e-6ca0-4e69-b749-217167de4efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-c97e8963-9b5b-41d1-b74a-ae77ef780664,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-33565757-2493-4a42-8b4a-c8505a69297d,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-01205d3f-5075-42cc-8792-e259ea27cf72,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-9c81e426-3f11-4f30-82ae-10a15274bb65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942459782-172.17.0.21-1595325773698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-8828f4ee-c03d-4d9b-86e3-7822012d2bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-aa156dce-dda8-47d9-b79e-c3772d3fe2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-c69db5b3-bba0-4902-9689-457549fbcf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-14f6610e-6ca0-4e69-b749-217167de4efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-c97e8963-9b5b-41d1-b74a-ae77ef780664,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-33565757-2493-4a42-8b4a-c8505a69297d,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-01205d3f-5075-42cc-8792-e259ea27cf72,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-9c81e426-3f11-4f30-82ae-10a15274bb65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964415953-172.17.0.21-1595326022347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44366,DS-e9ab7323-918c-4d77-9dac-9c6c86766644,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-84a1433f-32da-4458-a54e-29bf1759209b,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-cfcfb6ac-1a5b-4d42-a983-a953566187e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-c10ba0c3-ac74-4f6c-94cd-2250ba91182f,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-22a08fcf-298c-4f9d-9c81-774e9a80bc53,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-ee106e55-d243-454d-8053-5712b599a128,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-1ecb18c4-beed-49d9-ba9d-92dc4207e3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-3a747b98-668f-4db9-bf51-2036eb54c9eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964415953-172.17.0.21-1595326022347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44366,DS-e9ab7323-918c-4d77-9dac-9c6c86766644,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-84a1433f-32da-4458-a54e-29bf1759209b,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-cfcfb6ac-1a5b-4d42-a983-a953566187e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-c10ba0c3-ac74-4f6c-94cd-2250ba91182f,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-22a08fcf-298c-4f9d-9c81-774e9a80bc53,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-ee106e55-d243-454d-8053-5712b599a128,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-1ecb18c4-beed-49d9-ba9d-92dc4207e3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-3a747b98-668f-4db9-bf51-2036eb54c9eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108495433-172.17.0.21-1595326055944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37391,DS-7d0c2677-fd04-46e8-a602-0072e02f434a,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-9c1748b4-a351-489c-9081-f48dbd525b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-79ac4dc9-f8b9-4c55-8753-53684dc1e06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-6f68eeab-002c-4505-a7d2-821b9a7daa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-9b457248-9e2b-44dc-b1bc-d804fb4d95eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-8182e834-b2da-46de-b3b0-29f6a34deb90,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-298979ee-0048-4aae-a922-4ad98558bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-77d131a6-89ad-4b9e-a78a-2aef5bfb1972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108495433-172.17.0.21-1595326055944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37391,DS-7d0c2677-fd04-46e8-a602-0072e02f434a,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-9c1748b4-a351-489c-9081-f48dbd525b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-79ac4dc9-f8b9-4c55-8753-53684dc1e06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-6f68eeab-002c-4505-a7d2-821b9a7daa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-9b457248-9e2b-44dc-b1bc-d804fb4d95eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-8182e834-b2da-46de-b3b0-29f6a34deb90,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-298979ee-0048-4aae-a922-4ad98558bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-77d131a6-89ad-4b9e-a78a-2aef5bfb1972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624506725-172.17.0.21-1595327223296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40720,DS-a924a109-3563-42f0-ad30-9bbac06ab337,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-6a9228c9-068c-4f1e-ac2d-cc84e1dab2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-a2ce1ca1-ace3-4aa4-b36c-63b2aba57ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-f6606f74-665b-49ca-94c2-e960aa61f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-638490eb-ac7a-4f70-a6a3-db8e54b4f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-b99279e4-4ffa-4363-a519-6a64c283f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-c4291f9c-12ba-4bda-a0d0-42bc38d3afb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-daba38b3-432f-477c-8edb-df961449ef4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624506725-172.17.0.21-1595327223296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40720,DS-a924a109-3563-42f0-ad30-9bbac06ab337,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-6a9228c9-068c-4f1e-ac2d-cc84e1dab2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-a2ce1ca1-ace3-4aa4-b36c-63b2aba57ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-f6606f74-665b-49ca-94c2-e960aa61f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-638490eb-ac7a-4f70-a6a3-db8e54b4f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-b99279e4-4ffa-4363-a519-6a64c283f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-c4291f9c-12ba-4bda-a0d0-42bc38d3afb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-daba38b3-432f-477c-8edb-df961449ef4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605682945-172.17.0.21-1595327394601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-6c0c883b-61a7-49db-84df-f0a43e8ae9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-ab29c397-f8e9-410d-b735-7e666e6bc37c,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-1444e829-456d-4130-85f9-e795206e73c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-6c509a11-d833-472e-8232-685791209ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-1a21eee9-5c3d-44c9-9482-aaf0996f560b,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-0bb7a87d-e881-4531-9497-1b80a2dd17e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-32bb9f05-a041-4f4d-a615-a590a578227e,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-d7240281-1d61-4fc5-8ac3-7e0aa5b345e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605682945-172.17.0.21-1595327394601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-6c0c883b-61a7-49db-84df-f0a43e8ae9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-ab29c397-f8e9-410d-b735-7e666e6bc37c,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-1444e829-456d-4130-85f9-e795206e73c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-6c509a11-d833-472e-8232-685791209ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-1a21eee9-5c3d-44c9-9482-aaf0996f560b,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-0bb7a87d-e881-4531-9497-1b80a2dd17e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-32bb9f05-a041-4f4d-a615-a590a578227e,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-d7240281-1d61-4fc5-8ac3-7e0aa5b345e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208773374-172.17.0.21-1595327564792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36819,DS-346ac02f-55c8-4483-b80b-b6899c140a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-f023f5ef-5e8a-4254-81ca-29dac52a62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-17479819-1886-4cee-a050-7b16ac42a921,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-4a67b8d5-154a-42e7-9aea-1c2a11ae8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-52e56eb3-9165-407c-9ba2-041022f20006,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-59a9ffc0-5968-43da-82de-6c9fdb2a6a79,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-e5c05d2e-d016-478e-90e2-dcf017b62e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-aa7cdcf6-7853-4cce-a1fb-4814742dc4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208773374-172.17.0.21-1595327564792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36819,DS-346ac02f-55c8-4483-b80b-b6899c140a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-f023f5ef-5e8a-4254-81ca-29dac52a62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-17479819-1886-4cee-a050-7b16ac42a921,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-4a67b8d5-154a-42e7-9aea-1c2a11ae8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-52e56eb3-9165-407c-9ba2-041022f20006,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-59a9ffc0-5968-43da-82de-6c9fdb2a6a79,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-e5c05d2e-d016-478e-90e2-dcf017b62e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-aa7cdcf6-7853-4cce-a1fb-4814742dc4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776427453-172.17.0.21-1595327877979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42895,DS-2715acbc-c86d-4331-96c5-61693e7e131a,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-d4f1dfb5-97d6-460a-838f-d8c42d7f8fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-01e61199-86a5-4b9b-9774-94412f4f1ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-fcd8582d-1f81-403b-a8ce-db49b6d1f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-611c7d35-a142-433d-ac5f-1d0d7c30d53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-c1fb61de-da98-4a4f-8454-710c44bf288c,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-37c05127-a773-4062-9c3e-c2d92c270182,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-2322c5d7-8e5f-4338-aa37-86b458a8ecaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776427453-172.17.0.21-1595327877979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42895,DS-2715acbc-c86d-4331-96c5-61693e7e131a,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-d4f1dfb5-97d6-460a-838f-d8c42d7f8fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-01e61199-86a5-4b9b-9774-94412f4f1ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-fcd8582d-1f81-403b-a8ce-db49b6d1f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-611c7d35-a142-433d-ac5f-1d0d7c30d53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-c1fb61de-da98-4a4f-8454-710c44bf288c,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-37c05127-a773-4062-9c3e-c2d92c270182,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-2322c5d7-8e5f-4338-aa37-86b458a8ecaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457899075-172.17.0.21-1595328645521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-13b5d345-28c1-4975-9be0-11c57a39e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-96ffb7b6-0ce2-4235-bd9a-559965cdc237,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-95effa6b-eb91-49fa-b8c6-ebd0c9daa1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-5b0db181-5f76-4437-8dd8-59592055ba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-6cb4b761-9bd5-401f-aab2-1a58ac3fb987,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-5549e5a7-eb78-462f-bec5-8ac6f2d7f804,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-ec21a098-b39d-4c2c-a66d-7fcfa4ba3839,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-14e1d1cf-71b1-41cb-8792-c8bbe55020f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457899075-172.17.0.21-1595328645521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-13b5d345-28c1-4975-9be0-11c57a39e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-96ffb7b6-0ce2-4235-bd9a-559965cdc237,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-95effa6b-eb91-49fa-b8c6-ebd0c9daa1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-5b0db181-5f76-4437-8dd8-59592055ba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-6cb4b761-9bd5-401f-aab2-1a58ac3fb987,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-5549e5a7-eb78-462f-bec5-8ac6f2d7f804,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-ec21a098-b39d-4c2c-a66d-7fcfa4ba3839,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-14e1d1cf-71b1-41cb-8792-c8bbe55020f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475980601-172.17.0.21-1595328680817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-392284ea-0b0f-42c0-a2dc-9781259a2509,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-4d005de8-7f7e-4cd4-a40f-deee44f3d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-d3604435-ae87-4fab-81e7-fd41bb5c7950,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-08b6178d-79ff-4f91-8323-a65df2e60b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-656af81d-04ee-4fb3-b0a5-97087271d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-1f6098f0-9109-4358-93f4-ec8328ef3cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-c77e38a7-64b2-4aaa-ad4b-b227e63dd857,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-02da0dd0-07d8-406f-a020-37088ca5b1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475980601-172.17.0.21-1595328680817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-392284ea-0b0f-42c0-a2dc-9781259a2509,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-4d005de8-7f7e-4cd4-a40f-deee44f3d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-d3604435-ae87-4fab-81e7-fd41bb5c7950,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-08b6178d-79ff-4f91-8323-a65df2e60b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-656af81d-04ee-4fb3-b0a5-97087271d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-1f6098f0-9109-4358-93f4-ec8328ef3cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-c77e38a7-64b2-4aaa-ad4b-b227e63dd857,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-02da0dd0-07d8-406f-a020-37088ca5b1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685655394-172.17.0.21-1595329102924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41088,DS-e5fb429f-1623-44e2-9e24-e70296aba8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5ac7338d-9478-40b7-9a0f-ce5e51f78cea,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-fbe538b6-8fab-411a-90ae-4c98b5a88215,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-f3b6f217-3225-4417-a0e3-ab23552f0c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-3698c6d1-2acd-4848-9f07-28420e30b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-627ec7a5-5f90-4919-974b-a06b2ac6feaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-2a322a63-53eb-4819-a198-99d3a5d03a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-8c8017a6-eef7-4869-834d-dcc602e3fa6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685655394-172.17.0.21-1595329102924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41088,DS-e5fb429f-1623-44e2-9e24-e70296aba8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5ac7338d-9478-40b7-9a0f-ce5e51f78cea,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-fbe538b6-8fab-411a-90ae-4c98b5a88215,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-f3b6f217-3225-4417-a0e3-ab23552f0c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-3698c6d1-2acd-4848-9f07-28420e30b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-627ec7a5-5f90-4919-974b-a06b2ac6feaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-2a322a63-53eb-4819-a198-99d3a5d03a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-8c8017a6-eef7-4869-834d-dcc602e3fa6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624456027-172.17.0.21-1595329140929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-6a83c62b-e8b0-4746-99cf-f2f3acc85e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-7ac2fca5-c3be-4028-b65a-f5e0b8931601,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-8b112312-56cf-4f05-824e-e608004f5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-2e3a0a66-6db4-4636-897b-5b6e3a216a51,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-9a08a5fc-3a3d-46c3-bb19-3e8cd4dda7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-4aad2229-4a58-4c04-a496-9d65ef52a208,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-ff33a518-8ac8-4d20-a5d0-cca1ea05edc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-668ad64f-a26f-445f-83c4-f8538390574d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624456027-172.17.0.21-1595329140929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-6a83c62b-e8b0-4746-99cf-f2f3acc85e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-7ac2fca5-c3be-4028-b65a-f5e0b8931601,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-8b112312-56cf-4f05-824e-e608004f5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-2e3a0a66-6db4-4636-897b-5b6e3a216a51,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-9a08a5fc-3a3d-46c3-bb19-3e8cd4dda7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-4aad2229-4a58-4c04-a496-9d65ef52a208,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-ff33a518-8ac8-4d20-a5d0-cca1ea05edc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-668ad64f-a26f-445f-83c4-f8538390574d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799600038-172.17.0.21-1595329290617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40175,DS-1ffec289-9b9e-4d69-9fbd-37425adea499,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-4cd3e69c-b316-4a99-ad4d-c18466a4195f,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-e9ada2f8-b7de-4ea1-a71f-1cc31d2d527c,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-7bd77d0f-a646-4452-a481-753ec51f4ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-908b4bbb-2e01-4650-ba64-b83f4febb5af,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-e5414cf4-21b8-4288-bd04-251ca9a48ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-bac8ee64-0fc7-423e-8841-b584c467fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-336a1f43-7562-48a2-99aa-60d104224a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799600038-172.17.0.21-1595329290617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40175,DS-1ffec289-9b9e-4d69-9fbd-37425adea499,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-4cd3e69c-b316-4a99-ad4d-c18466a4195f,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-e9ada2f8-b7de-4ea1-a71f-1cc31d2d527c,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-7bd77d0f-a646-4452-a481-753ec51f4ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-908b4bbb-2e01-4650-ba64-b83f4febb5af,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-e5414cf4-21b8-4288-bd04-251ca9a48ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-bac8ee64-0fc7-423e-8841-b584c467fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-336a1f43-7562-48a2-99aa-60d104224a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699980431-172.17.0.21-1595329569413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-36287a6c-b10e-4606-8ead-d5321265c8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-84099b33-a329-42fa-8eb5-635b1691f5db,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-fe763375-e9f8-46f0-a071-4b0cdfbd1522,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-00b63d4c-f5e9-4f62-b6bc-29cf6d7fb49f,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-4db2984d-f618-4580-9c34-cf360c0bba47,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-e1f8188b-3eeb-45bd-8930-48dbc13e3483,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-7695493f-649a-403b-8944-572e10f35fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-a56c8abd-3a14-4688-9e4a-653312238a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699980431-172.17.0.21-1595329569413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-36287a6c-b10e-4606-8ead-d5321265c8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-84099b33-a329-42fa-8eb5-635b1691f5db,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-fe763375-e9f8-46f0-a071-4b0cdfbd1522,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-00b63d4c-f5e9-4f62-b6bc-29cf6d7fb49f,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-4db2984d-f618-4580-9c34-cf360c0bba47,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-e1f8188b-3eeb-45bd-8930-48dbc13e3483,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-7695493f-649a-403b-8944-572e10f35fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-a56c8abd-3a14-4688-9e4a-653312238a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888232881-172.17.0.21-1595329671731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35885,DS-ae1e3370-e036-4a7b-a0cb-12e7ad4b7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-411e229c-5bc9-4a81-95fb-c7149ab0d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-89e5a50b-b31d-4edd-be5e-0cb787b8c1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-0222cb62-d5e7-4a2c-ab5c-3d5510b5ea42,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-4cf4a1e7-596e-49da-b1ed-9480d839fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-216971b8-8565-48ba-a679-550a3af0823d,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-1f71a261-4941-48dd-8954-0fde41199da9,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-6bab0221-8096-41eb-bc7f-8c068afdd991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888232881-172.17.0.21-1595329671731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35885,DS-ae1e3370-e036-4a7b-a0cb-12e7ad4b7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-411e229c-5bc9-4a81-95fb-c7149ab0d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-89e5a50b-b31d-4edd-be5e-0cb787b8c1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-0222cb62-d5e7-4a2c-ab5c-3d5510b5ea42,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-4cf4a1e7-596e-49da-b1ed-9480d839fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-216971b8-8565-48ba-a679-550a3af0823d,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-1f71a261-4941-48dd-8954-0fde41199da9,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-6bab0221-8096-41eb-bc7f-8c068afdd991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007247277-172.17.0.21-1595330012067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-ae9805f2-13b2-4c6e-9736-c4a806aaf29f,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-2a4e4682-c4ad-4d61-99bd-e38fa22fcce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-89a1afe7-a616-46a0-a337-4223a9a3c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-1e1b67d7-4ec1-4ee9-8cf0-a11d78709953,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-b20e70f0-ce91-4529-9d24-60218d4577aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-8ee9f3f5-6f9f-449d-8ea4-a8d09ac12b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-d0c2318c-abe8-4306-84ee-fbf80d5c832d,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-0a69c685-396a-468d-a6cf-e25bde21fbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007247277-172.17.0.21-1595330012067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-ae9805f2-13b2-4c6e-9736-c4a806aaf29f,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-2a4e4682-c4ad-4d61-99bd-e38fa22fcce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-89a1afe7-a616-46a0-a337-4223a9a3c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-1e1b67d7-4ec1-4ee9-8cf0-a11d78709953,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-b20e70f0-ce91-4529-9d24-60218d4577aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-8ee9f3f5-6f9f-449d-8ea4-a8d09ac12b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-d0c2318c-abe8-4306-84ee-fbf80d5c832d,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-0a69c685-396a-468d-a6cf-e25bde21fbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378355280-172.17.0.21-1595330237966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-bec3ced9-f276-4e24-8a88-15aaf7537d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-0a5831f5-10a2-4b70-b741-02951618b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-03aac840-c972-4853-a0c2-4f6f83e0bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-7d7fe551-43cf-412f-8da9-b41bb3ef14b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-d7f0d27f-6e03-47f3-a8fa-518289bb4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-14968add-9f7a-42ba-850f-f6fd085b3b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-2df6304e-baf7-4702-9a38-b1586969ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-19d785a0-a49e-43de-8dc6-fed6a8bf3217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378355280-172.17.0.21-1595330237966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-bec3ced9-f276-4e24-8a88-15aaf7537d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-0a5831f5-10a2-4b70-b741-02951618b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-03aac840-c972-4853-a0c2-4f6f83e0bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-7d7fe551-43cf-412f-8da9-b41bb3ef14b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-d7f0d27f-6e03-47f3-a8fa-518289bb4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-14968add-9f7a-42ba-850f-f6fd085b3b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-2df6304e-baf7-4702-9a38-b1586969ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-19d785a0-a49e-43de-8dc6-fed6a8bf3217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276705215-172.17.0.21-1595330465388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-d92c05b7-d0c7-4059-9374-182892ada489,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-534b421a-f1d2-4ca7-8547-644b174dce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-b74ec780-1af6-43dc-89cc-8a47fcfb45f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-4c746622-6496-4b5a-9485-8777eac35c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-53987f07-becd-4bb0-9a86-5480707d6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-c45822d6-25b6-4473-9183-f26db8220098,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-c3009c32-0a47-4624-80b5-e291cd6de583,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-439a9edf-097d-4952-8304-b2cc3050c3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276705215-172.17.0.21-1595330465388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-d92c05b7-d0c7-4059-9374-182892ada489,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-534b421a-f1d2-4ca7-8547-644b174dce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-b74ec780-1af6-43dc-89cc-8a47fcfb45f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-4c746622-6496-4b5a-9485-8777eac35c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-53987f07-becd-4bb0-9a86-5480707d6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-c45822d6-25b6-4473-9183-f26db8220098,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-c3009c32-0a47-4624-80b5-e291cd6de583,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-439a9edf-097d-4952-8304-b2cc3050c3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990741425-172.17.0.21-1595330497070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38142,DS-929a1de2-9599-45bb-b575-5c1796013815,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-0b19677f-a475-4634-92ed-7060d2dbaa22,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c6e4ba64-92c7-4420-ab69-650d39260ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-c745b288-d2d1-41cc-a0ff-ed78a7bce340,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-b64859f5-44c3-4228-a243-b2aec8958bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-7162e284-74e8-4603-a672-8ce1f48b8f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-ab9f5292-f1c8-4123-a8c4-fec0c3ad6f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-55d79f52-46b5-478c-835f-6249120d34db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990741425-172.17.0.21-1595330497070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38142,DS-929a1de2-9599-45bb-b575-5c1796013815,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-0b19677f-a475-4634-92ed-7060d2dbaa22,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c6e4ba64-92c7-4420-ab69-650d39260ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-c745b288-d2d1-41cc-a0ff-ed78a7bce340,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-b64859f5-44c3-4228-a243-b2aec8958bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-7162e284-74e8-4603-a672-8ce1f48b8f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-ab9f5292-f1c8-4123-a8c4-fec0c3ad6f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-55d79f52-46b5-478c-835f-6249120d34db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5240
